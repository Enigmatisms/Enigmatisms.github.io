<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>&lt;i class=&quot;fas fa-quote-left&quot;&gt;&lt;/i&gt;   To strive, to seek, to find, and not to yield.   &lt;i class=&quot;fas fa-quote-right&quot;&gt;&lt;/i&gt;</title>
    <url>/2021/02/11/To-strive-to-seek-to-find-and-not-to-yield/</url>
    <content><![CDATA[<center>
<i class="fas fa-quote-left"></i> To follow knowledge like a sinking
star<br> Beyond the utmost bound of human thought.
<i class="fas fa-quote-right"></i>
</center>
<p><br> <span id="more"></span></p>
<p>Read, and fell in love. Wondering whether I will lose restless heart
like this when I'm old. Yet here I am, and I possess.</p>
<hr>
<p><br></p>
<center>
<font size="5"><b>Ulysses </b></font><font size="2">by Tennyson</font>
</center>
<p><br></p>
<p>It little profits that an idle king,</p>
<p>By this still hearth, among these barren crags,</p>
<p>Match’d with an aged wife, I mete and dole</p>
<p>Unequal laws unto a savage race,</p>
<p>That hoard, and sleep, and feed, and know not me.</p>
<p><br></p>
<p>I cannot rest from travel: I will drink</p>
<p>Life to the lees: all times I have enjoyed</p>
<p>Greatly, have suffered greatly, both with those</p>
<p>That loved me, and alone; on shore, and when</p>
<p>Through scudding drifts the rainy Hyades</p>
<p>Vexed the dim sea: I am become a name</p>
<p><br></p>
<p>For always roaming with a hungry heart</p>
<p>Much have I seen and known – cities of men</p>
<p>And manners, climates, councils, governments,</p>
<p>Myself not least, but honored of them all –</p>
<p>And drunk delight of battle with my peers,</p>
<p>Far on the ringing plains of windy Troy,</p>
<p>I am a part of all that I have met;</p>
<p>Yet all experience is an arch wherethrough</p>
<p>Gleams that untravelled world, whose margin fades</p>
<p>For ever and for ever when I move</p>
<p><br></p>
<p>How dull it is to pause, to make an end,</p>
<p>To rust unburnished, not to shine in use!</p>
<p>As though to breathe were life. Life piled on life</p>
<p>Were all too little, and of one to me</p>
<p>Little remains: but every hour is saved</p>
<p>From that eternal silence, something more,</p>
<p>A bringer of new things; and vile it were</p>
<p>For some three suns to store and hoard myself,</p>
<p>And this grey spirit yearning in desire</p>
<p>To follow knowledge like a sinking star,</p>
<p>Beyond the utmost bound of human thought.</p>
<p><br></p>
<p>This is my son, mine own Telemachus,</p>
<p>To whom I leave the sceptre and the isle –</p>
<p>Well-loved of me, discerning to fulfil</p>
<p>This labour, by slow prudence to make mild</p>
<p>A rugged people, and through soft degrees</p>
<p>Subdue them to the useful and the good.</p>
<p>Most blameless is he, centred in the sphere</p>
<p>Of common duties, decent not to fail</p>
<p>In offices of tenderness, and pay</p>
<p>Meet adoration to my household gods,</p>
<p>When I am gone. He works his work, I mine.</p>
<p><br></p>
<p>There lies the port; the vessel puffs her sail:</p>
<p>There gloom the dark broad seas. My mariners,</p>
<p>Souls that have toil’d, and wrought, and thought with me –</p>
<p>That ever with a frolic welcome took</p>
<p>The thunder and the sunshine, and opposed</p>
<p>Free hearts, free foreheads – you and I are old;</p>
<p>Old age hath yet his honour and his toil;</p>
<p>Death closes all: but something ere the end,</p>
<p>Some work of noble note, may yet be done,</p>
<p>Not unbecoming men that strove with Gods.</p>
<p><br></p>
<p>The lights begin to twinkle from the rocks:</p>
<p>The long day wanes: the slow moon climbs: the deep</p>
<p>Moans round with many voices. Come, my friends,</p>
<p>‘Tis not too late to seek a newer world.</p>
<p>Push off, and sitting well in order smite</p>
<p>The sounding furrows; for my purpose holds</p>
<p>To sail beyond the sunset, and the baths</p>
<p>Of all the western stars, until I die.</p>
<p>It may be that the gulfs will wash us down:</p>
<p>It may be we shall touch the Happy Isles,</p>
<p>And see the great Achilles, whom we knew.</p>
<p>Tho’ much is taken, much abides; and though</p>
<p><br></p>
<p>We are not now that strength which in old days</p>
<p>Moved earth and heaven; that which we are, we are;</p>
<p>One equal temper of heroic hearts,</p>
<p>Made weak by time and fate, but strong in will</p>
<p>To strive, to seek, to find, and not to yield.</p>
<p><br></p>
<hr>
<p>Poem written by <a href="https://en.wikipedia.org/wiki/Alfred%2C_Lord_Tennyson">Alfred,
Lord Tennyson <i class="fab fa-wikipedia-w"></i></a>.</p>
<p>可惜wiki被墙了，看百度吧-&gt;<a href="https://baike.baidu.com/item/%E9%98%BF%E5%B0%94%E5%BC%97%E9%9B%B7%E5%BE%B7%C2%B7%E4%B8%81%E5%B0%BC%E7%94%9F/3303915?fr=aladdin">Alfred,
Lord Tennyson</a></p>
<p><br></p>
<hr>
]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>poetry</tag>
      </tags>
  </entry>
  <entry>
    <title>What is &#39;snippet&#39; section?</title>
    <url>/1970/01/01/What-is-snippet-section/</url>
    <content><![CDATA[<p>Snippet板块是专门为“小型博客”设置的，意在保存：</p>
<ul>
<li>字数不多但有感觉非常有记录的必要性</li>
<li>简单有趣，撰写和阅读都不费力</li>
<li>一些原markdown文档遗失、或是更适合使用pdf共享的文档</li>
</ul>
<p>Enjoy and Rejoice! ------------ 2022.2.11</p>
]]></content>
      <categories>
        <category>snippet</category>
      </categories>
      <tags>
        <tag>notification</tag>
      </tags>
  </entry>
  <entry>
    <title>Write a software CUDA path tracer from scratch: the road to better parallelism</title>
    <url>/2024/12/16/Write-a-software-CUDA-path-tracer-from-scratch-the-road-to-better-parallelism/</url>
    <content><![CDATA[<h1 id="cuda-pt">CUDA-PT</h1>
<h2 id="i.-intro">I. Intro</h2>
<p>I decide to write this blog post in English, which might potentially
help more people, I guess. It's been a while since I've finished the
backbone of the CUDA-PT, and I think it's time to honor the original
purpose of developing this repo: write your own wheel, profile and
benchmark it, feel the challenges and understand things better. I can't
say I have done a pretty good job at benchmarking, since the commits
make it difficult to rewind back to the previous sub-optimal
implementation. Nevertheless, I'll try making my point, offering my two
cents, even if they are insignificant for those CUDA geeks.</p>
<span id="more"></span>
<hr>
<h2 id="ii.-preliminaries">II. Preliminaries</h2>
<p>I've already written a path tracing renderer <a href>AdaPT</a>, so
why there is yet another path tracer? The answer is simple: I didn't
dive deep into the IR layer of Taichi lang, therefore, it's difficult to
max out the performance of GPU with the JIT of Taichi lang. The
experiments show that my handcrafted CUDA kernels can be 2~3x as fast as
the code based on Taichi lang. The more access we have to the basic
elements, the more we, as humans, can do to manually improve the
implementation. I am not saying that I am smarter than the compilers. I
am just saying that if I don't know how these stuffs in the bottom layer
work, it's highly unlikely that I wrote anything that's better than a
good compiler</p>
<blockquote>
<p>Write your own wheel, profile and benchmark it, feel the challenges
and understand things better along the way.</p>
</blockquote>
<p>So much for the self hypnosis, let's cut to the chase. The tide of AI
is surging more fiercely lately, creating a huge demand for computation
power. However, the AI related computation like deep learning is way too
<em>regular</em>, that is, the parallelism seems to be a natural thing
to do. Take General Matrix Multiply (GEMM) as an example. This is the
most important building block of deep learning: linear layer and
attention both need it. Yet for GEMM, the threads in a GPU can pretty
much do the same thing, at any given time point: there can be no
branching (flow divergence), and the memory access pattern are regular
enough (coalesced, can be vectorized, even). We even have specialized
cores for this op (Tensor Core, well, I do know we have RT Core for ray
tracing). Balanced workloads and regular memory access make it possible
for us to compute the theoretical upper bound of efficiency, and through
optimization techniques, we can progressively approach this upper
bound.</p>
<p>But... it's somewhat hard for a soft path tracing program: for a
classic path tracing pipeline, each thread processes the tracing of a
ray (from a pixel). The ray bounces stochastically in the scene, meaning
that:</p>
<details class="note warning"><summary><p>problems</p>
</summary>
<ul>
<li>The neighboring threads might access memory locations distant to
each other (Random and un-coalesced accesses).</li>
<li>The neighboring threads might have different behaviors, like one
gets reflected, the other gets refracted (Breaks SIMT).</li>
<li>Tailing effect: some threads are dead, while others survive (the
warp is neither full nor empty).</li>
</ul>

</details>
<p>All these problems can be fatal for the speed of the renderer.</p>
<p>Ok, there are two main kinds of kernels (renderers):</p>
<div class="tabs" id="algos"><ul class="nav-tabs"><li class="tab active"><a href="#algos-1">Megakernel</a></li><li class="tab"><a href="#algos-2">Wavefront</a></li></ul><div class="tab-content"><div class="tab-pane active" id="algos-1"><p>All the logics are in the same, big, kernel. We can use registers to
hold some intermediate results.</p></div><div class="tab-pane" id="algos-2"></div></div></div>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>CG</tag>
        <tag>renderer</tag>
        <tag>GPU</tag>
        <tag>CUDA</tag>
      </tags>
  </entry>
  <entry>
    <title>NeRF-GS Interview Preparation</title>
    <url>/2024/04/25/NeRF-GS-Interview-Preparation/</url>
    <content><![CDATA[<h1 id="nerf-3dgs">NeRF-3DGS</h1>
<hr>
<p>​
找实习的时候也投了一些相关的岗位（三维重建、NeRF/GS等等），考虑到我本科是搞SLAM的，大四到研二上学期也断断续续做了一年半的NeRF，面相关的岗位时感觉还是比较轻松的，基本上比赛、开源项目吹吹水，回答一些简单的基础问题，做一些简单的题目就结束了，目前面试相关岗位还没碰上答不上来的问题。本部分
review NeRF 的基本工作，此前的 NeRF 项目、比赛以及 3D Gaussian
基本概念。</p>
<span id="more"></span>
<hr>
<h2 id="i.-基本原理部分">I. 基本原理部分</h2>
<h3 id="积分离散化渲染方程">1.1 积分离散化渲染方程</h3>
<p>​ NeRF
中只有一个基本原理需要说，也就是渲染方程。渲染方程的连续形式，搞渲染的人可以说是信手拈来，对于
camera 需要积分的方向 <span class="math inline">\(\omega\)</span>，我们有： <span class="math display">\[
\int _{0}^{T_{\max}} L_o(o+\omega t, -\omega)\sigma(t)T_r(t)dt
\]</span> ​ 其中，<span class="math inline">\(L_o\)</span> 是某一点的
output radiance，<span class="math inline">\(T_r(t)\)</span>
是透射率。那么离散化以后将是这样的：假设我们使用 ray marching，也即每个
step 内部的 density 是不变的，那么实际上会有：</p>
<ul>
<li><ol type="1">
<li>当前点在没有经过衰减的情况下，将贡献 <span class="math inline">\((1
- \exp(\sigma_i t))L_{o, i}\)</span> radiance。为什么是这样？由于 <span class="math inline">\(\sigma(t)\)</span> 的物理含义是，在 t
位置，光子传播直接终止于此处（消光）的 differential
概率（终止于此处的概念是，被吸收，或者不再向 <span class="math inline">\(\omega\)</span> 方向传播）。为什么最后成为了与
<span class="math inline">\(\exp\)</span> 有关的形式？这是通过
RTE（辐射传输方程） 推出来的：我们假设光的能量变化为 <span class="math inline">\(dL\)</span>，根据 RTE，实际上可以得到：</li>
</ol></li>
</ul>
<p><span class="math display">\[
dL = -\sigma_t L dt
\]</span></p>
<p>​ 可以解出被消光的部分相当于是 <span class="math inline">\(\exp(-\sigma_t
t)L(0)\)</span>。则显然，本段内，可以成功出射（产生贡献的，也就是没有被消光的）部分为：<span class="math inline">\((1 - \exp(\sigma_i t))L_{o,
i}\)</span>。则此后，这部分 radiance 需要经过前面所有段的 transmittance
的消光： <span class="math display">\[
\prod_{i = 1}^k\exp(-\sigma_i \delta_i) =\exp\biggl(-\sum_{i = 1}^k
\sigma_i \delta_i \biggr)
\]</span> ​ 那么实际上，可以得到 radiance 的最终表示： <span class="math display">\[
\sum_{i = 1}^Nc_i\times (1 - \exp(-\sigma_i
\delta_i))\exp\biggl(-\sum_{k = 1}^{i-1} \sigma_k \delta_k \biggr)
\]</span> ​ 后面的 <span class="math inline">\(\exp(-\sum)\)</span>
项通常被称为
transmittance，这你都十分熟悉了。注意，在图形渲染里，这种针对
heterogeneous medium 的操作 ray marching，是有偏的。可能可以替换为
unbiased MC integration？这涉及到 delta-tracking (也就是 null scattering
操作)，导致采样不能是并行的。当然也可以用 MC importance sampling
但采样效率不会高：不是在被积函数大的地方采样。此部分其实没有什么好多说的，不要忘记
<span class="math inline">\(\sigma(t)\)</span> 就行，此部分为
differential 概率，离散化的时候由于不再使用微分表示，所以需要积（1 -
指数部分）。其中的 delta 也没有什么好说的。</p>
<h3 id="相机模型">1.2 相机模型</h3>
<p>​ 正常来说，相机模型会是由内参矩阵定义的： <span class="math display">\[
K = \begin{pmatrix}
f_x &amp; 0 &amp; c_x \\
0 &amp; f_y &amp; c_y \\
0 &amp; 0 &amp; 1
\end{pmatrix}
\]</span> ​ 一个 point on normalized plane 上的点 (X/Z, Y/Z, 1)
通过左乘上式就会到像素坐标。注意，上式是线性的，而在左乘之前，一般需要进行畸变操作：径向畸变和切向畸变。畸变后的点再左乘对应的
K 得到像素坐标。所以，如果要从外参来求光线方向一般则是：乘以 <span class="math inline">\(K^{-1}\)</span>（不考虑畸变的话，考虑则比较麻烦，因为畸变是非线性的，从
u, v 反推 x/z, y/z
相对麻烦一些）。但这样还没完，由于我们得到的结果是相机系下的，所以要到世界系，需要相机本身的位姿（旋转施加在方向上即可）。</p>
<p>​ 如果用焦距定义的，只需要：除以对应焦距即可。所以，焦距越小，FOV
越大。</p>
<p>​ 这里整个都还比较简单。那么接下来可以看看 nerfstudio
中我的改动。nerfstudio 原生支持对 camera
的位姿进行优化，三个模式：SO3，SE3（对 4 * 4 矩阵）。此后我在 nerfstudio
里改动了：</p>
<ol type="1">
<li><p>内参优化：给了三个模式，所有相机使用不同的内参 / 共用内参 /
不优化。</p></li>
<li><p>畸变优化：也是三个模式。这里比较简单，主要涉及到改 API 以及查
gradient flow 有没有断掉的地方以及在最后的 output 中显示这两个参数每个
iter 的相对变化。</p></li>
</ol>
<p>​ 这里没有多少好说的，就是一个端到端的模块，复用了一下
optimizer。这是有效的。看比赛答辩 ppt 就行了。</p>
<h3 id="positional-encoding-与基础网络结构">1.3 positional encoding
与基础网络结构</h3>
<p>​
网络适合学习高频的信息（因为内部本身就是一个复杂参数的网络），所以需要将
position 以及 direction 经过 positional encoding 将结果送入网络中。原始
NeRF 的 positional encoding 与 NLP 中的很像： <span class="math display">\[
[\sin(x), \cos(x), \sin(2x), \cos(2x), ..., \sin(2^{L - 1}x), \cos(2^{L
- 1}x)]
\]</span> ​ 注意，这样进行 positional encoding 之后，需要与原始 x, y, z
concat 到一起。实际的结果是这样的： <span class="math display">\[
[x, y, z, \sin(x), \sin(y), \sin(z), \cos(x), \cos(y), \cos(z),
\sin(2x), ..., \cos(2^{L - 1}x)]
\]</span> ​ 所以，按照原始 NeRF 的 L，positional encoding 之后有 63
维。而 direction 的 positional encoding level 低一些，我没记错的话应该是
27。基础网络架构：</p>
<p>（1）encoding 之后 positional 先过，几层之后与未过的原始输入 concat
(可以认为这叫 residual concat，哈哈)。过第二个线性层。后用一个 opacity
head 单独输出 density。encode 的 positional feature 与 directional
encoding 一同输入浅的 RGB 网络。</p>
<ul>
<li>内部不用 norm，使用的激活函数除了 opacity head (可以直接输出
softplus，ReLU，或者输出时不做处理，render时算) 以及 RGB（输出结果用
sigmoid），其他几乎都是 ReLU。</li>
</ul>
<p>​ 注意，在 mip NeRF 中，positional encoding 进行了积分（Gaussian
weight 的一个积分），相当于如下形式： <span class="math display">\[
\int \text{Gaussian}(x, \mu, \Sigma)[\sin(x), \cos(x)]dx
\]</span> ​ 此积分貌似是有解析解的？这个操作实际上在求 positional
encoding 在 Gaussian
分布下的期望。确实是有解析形式的，不过要高效计算，就需要一些数学上的操作（比如，由于各个
dimension 之间是独立的，可以只算协方差的对角，从 <span class="math inline">\(O(n^2)\)</span> 变 <span class="math inline">\(O(n)\)</span>
）。这样的一个操作，相当于将高频部分积分掉了（sin, cos
高频时是周期的，积分也会特别接近 0），则有了这个，positional encoding
在两采样点间距离大的情况下，频率就会带限。</p>
<h3 id="无界场景压缩mip-nerf-360">1.4 无界场景压缩（mip NeRF 360）</h3>
<p>​ space-warping 技术（contract operator，压缩算子）。</p>
<ol type="1">
<li><p>无界场景映射需要新的 sampling 方式，uniform
是不好的（远近一致不行，远应该少一些）。不需要说得非常具体，可以举一个例子（比如
exponential sampling，虽然比较激进），注意是 truncated exponential
sampling，然后可以举双 log 的例子。</p></li>
<li><p>contract operator: <span class="math display">\[
\text{contract}(\mathbf{x}) = \begin{cases}
\mathbf{x}, &amp; \Vert \mathbf{x}\Vert \leq 1\\
(2 - \frac{1}{\Vert \mathbf{x}\Vert})(\frac{\mathbf{x}}{\Vert
\mathbf{x}\Vert}), &amp; \Vert \mathbf{x}\Vert \gt 1\\
\end{cases}
\]</span> ​ 注意，在 mip NeRF 360 中，我们处理的不再是 point，而是 cone
(Gaussian 近似)。上式的第二个 case 的第二个乘积项用来表示
方向，第一项表示其在圆（外圈环）上的位置。也即：内圈是距离上
uniform，外圈是 disparity 上 uniform。</p></li>
</ol>
<p>​ mip NeRF 360 并不是使用两个 MLP 表示的（而是一个），相当于送进
positional encoding 之前，需要先进行 contract
mapping，但我不是很明白，mip NeRF 是怎么保证所需的 foreground 场景处于
<span class="math inline">\(\Vert \mathbf{x} \Vert &lt; 1\)</span>
的范围内的（难道需要先进行一步 scaling? 这并不是什么大问题，因为只需要
scale camera 的 position 参数即可），如果我们认为相机围绕 (0, 0, 0)
点拍摄，那确实只需要 scale 相机的 translation。</p>
<p>​ 这里没有什么好说的，不过要注意 contract 之后的 sampling 操作。</p>
<h3 id="高斯-cone-近似mip-nerf">1.5 高斯 cone 近似（mip NeRF）</h3>
<p>​ 这里我只说一下思想，因为整个过程数学性比较强。而其实整个过程都是围绕
positional encoding
的积分来的。首先，我们知道一个像素发出的光线可以看成一级一级的 cones，但
cone 本身数学描述很难，作者则用一个 Gauss 近似这整个
cone。那么这个近似公式怎么来的呢，我现在肯定忘了，当时推过一遍。得到了一个
Gauss 之后，就用 Gauss 对整个段上的 positional encoding 进行积分。</p>
<p>​ 积分的结果相当于囊括了这一段上的所有 position
信息，如果比较宽（scale 问题）则相当于进行了模糊（降低频率）。用积分后的
<span class="math inline">\(\mu\)</span> 过 positional
encoding，再乘以一个与 <span class="math inline">\(\Sigma\)</span>
有关的值就是新的 positional encoding。</p>
<h3 id="一些比较重要的-nerf-工作">1.6 一些比较重要的 NeRF 工作</h3>
<p>​
这里我只能举一些我看过的例子，这部分工作可能很老了，我研一下之后基本只看光线追踪（纯CG）相关的文章了。只能简单说说：</p>
<h4 id="nerf-在稀疏视角下怎么办">NeRF 在稀疏视角下怎么办？</h4>
<p>​ 稀疏视角造成的严重问题是几何不准或者不对。比如学 floaters
出来，以及一些 degenerate 的 几何结果。几何对了其实 RGB
只要不是十分高频（如金属反射、镜面反射、折射），RGB 就很好学。</p>
<ul>
<li>pixel NeRF，pixel NeRF
是通过在图像域上提取特征，基于先验的方法（跨场景的先验，用一个 CNN
提取的）：首先，pretrained encoder 将所有输入图片转成 feature
image。此后新视角合成时，ray marching 的 query 点去其他 feature image
上通过 projection 以及 BILERP 去 query 对应 feature，用 feature 做
rendering。有一篇升级版（浙大周晓巍老师组的，好像叫
NeuRay？）考虑了遮挡，使得结果更加 robust。</li>
<li>free NeRF：两个 intuition（1）few shot 情况下不应该用高频 positional
encoding，在训练过程中逐步限制 position encoding
的维度（具体怎么操作，忘了，太久没看了）（2）另外一个，为了限制
floaters（一般是过拟合导致的），作者对临近相机的 density
进行了惩罚，这个操作很有效。我在 giga 比赛中就用了这个操作。</li>
<li>info NeRF：两个 contribution（1）熵 regularization 项，可以称为是
density 的非0即1惩罚。惩罚所有半透明物体。（2）perturbed ray，对于
clustered views，可以从单个 ray 通过噪声 perturbation 生成一些其他
ray，我记得是限制这些 ray 上的 ray marching 点 density 值与原始生成的
ray 一致。</li>
</ul>
<h4 id="nerf-在大场景下怎么做如何节省内存">NeRF
在大场景下怎么做？如何节省内存？</h4>
<p>​ 大场景一般都是空间划分：</p>
<ul>
<li>Mega-NeRF：三个主要贡献吧（1）空间划分，空间划分后，每一块投影到不同图像上，对应图像的
pixel 取出来就成了对应 NeRF 的训练集。（2）NeRF++ 的 outer volume
(NeRF++ 不是基于 spatial contraction 的，而是相当于两个
NeRF)，在上面做了一些改进（毕竟要建模背景）以及 NeRF-W 的 appearance
embedding（我们在 Giga 比赛中也用了，涨点）（3）渲染加速：用了一个
OccTree cache（有点像 plenoctree）并且做了时域的复用（前后帧了，有点像
TAA）</li>
<li>Kilo-NeRF：看过（大四），真忘了。我记得是加速大场景 NeRF
渲染的（好像有什么空间与方向解耦的MLP）</li>
<li>Grid-guided Neural Radiance Fields：略读过。two stage，将 Grid 和
MLP NeRF 结合了。说实在的，可能是我比较菜，我觉得 idea
并不是第一眼就觉得比较 intuitive 的。为什么 grid branch 的
multi-resolution pyramid 有助于 rendering？
<ul>
<li>话说，起个好点的名字，大家容易记住这个工作。都是
XXXNeRF的，一下就能记住。你可以叫 GG-NeRF 嘛，GG（good game)</li>
</ul></li>
</ul>
<h4 id="nerf-如何进行压缩">NeRF 如何进行压缩？</h4>
<ul>
<li>MERF：当时看到感觉效果很惊艳了（虽然貌似马上被 GS 干了，GS
魔鬼）。MERF 包含一个 low res 的 空域 grid 一个三个 high res 的
（axis-aligned？）三平面（2D）feature grids，所以相当于每次取四个
feature vectors。加在一起，split 后 non-linear mapping 就可以得到 pixel
RGB。也能 real time rendering。</li>
<li>MobileNeRF：很有名的工作。MobileNeRF 其实在某种程度上与 GS 是很像的:
MobileNeRF 将场景先描述成一个可优化的 mesh，（虽然我不知道对应 UV
coordinates
是怎么算的，可能因为一开始是规则的，很好直接分配？），以及一个 feature
texture (8
channel)，此后，渲染是单次光追？（一个像素计算光线与mesh的交，但我不清楚的是这怎么用加速方法，triangle
culling 怎么做？因为 mesh 表征是不断变化的），又有一说是 mesh 首先会
rasterize 到一个 deferred renderer 里，我觉得这才像话嘛...
我只需要知道每个 fragment 来自哪个面片（以便处理其顶点位置梯度以及 query
UV 坐标）就可以了（但很可惜的是，面片是有 opacity
的，一般来说不能用延迟渲染管线？管不了这么多了），后 8 channel 的
feature 通过一个小网络，配合 view direction 转成 view dependent
color。</li>
</ul>
<h4 id="nerf-如何在动态场景下使用">NeRF 如何在动态场景下使用？</h4>
<ul>
<li>Deformation network（D-NeRF）这样的，学一个
deformation，好像挺多工作这样做的。</li>
<li>去动态物体：NeRF-W 用的 transient
encoding。其他的就不太清楚了，感觉做人体的文章与这个相关的多一些。</li>
</ul>
<h4 id="nerf-与-camera-trajectory">NeRF 与 camera trajectory</h4>
<p>​ 如果 trajectory 来自视频怎么办？如果 camera pose
不准甚至没有了怎么办（Nope-NeRF，这名字很憨）。BARF
面试的时候还问到了。</p>
<ul>
<li>BARF（有点老的工作）：还真叫这个名字，想想漫威蜘蛛侠第二部（神秘客在的那一部）里面一哥们因为自己的东西被钢铁侠展示的时候叫BARF，心生怨念成了
Mysterio ...
wow，他们一个组都是神秘客么？BA，老朋友了（虽然我感觉我好像没有实际写过，大学期间太菜了）。反正当时
BARF 给我的最深印象就是这个工作的实验非常漂亮，建议去学习一下人家的
project page 怎么做的，太优雅了。positional encoding 对图像配准不好！当
poses 不准确的时候，positional encoding
的高频部分会产生非常不准确的梯度。所以 BARF
的核心思想就是，优化位姿的过程中，逐渐提高 positional encoding
的可用维度（Free NeRF，你好像它啊）。coarse
情况下，配准更容易（梯度噪声小，更正确，简单嘛，相当于一个好的
initialization），而 fine 的情况下才能真正的进行 high-precision pose
adjustment。</li>
<li><span class="math inline">\(F^2\)</span>-NeRF（Fast Free
NeRF！FreeNeRF的 fast 版本是吧（狗头））。记不太清了，好像是提出了第三种
warping 方式（forward facing 是 warp 到 NDC，360 是 warp 到 内外
spheres，这种是 perspective warping），反正就是一种可以对 free
trajectory 进行 warping 的方式。本文另外还提出了一种基于单 hash
table，多 hash functions 的 grid-based 表征。作者说：反正 instant-NGP
都说hash冲突也没关系，MLP 能自动 resolve... 所以即使进行 spatial
partition，也可以只用一个 hash feature grid... 恩，但是为什么可以
resolve，这是玄学。</li>
</ul>
<h4 id="相关面经问题">1.7 相关面经问题</h4>
<ul class="task-list">
<li><label><input type="checkbox" checked>高斯分布有什么重要的性质？挺多的：</label></li>
</ul>
<p>​ 首先，多维高斯分布： <span class="math display">\[
\frac{1}{\sqrt{(2\pi)^n
|\Sigma|}}\exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))
\]</span> ​ exp 里面是 Mahalanobis
距离，归一化常数可能不是那么好记。多看几遍就知道了。</p>
<p>（1）高斯随机变量的仿射变换仍然是高斯分布：<span class="math inline">\(X\sim N(\mu, \Sigma)\)</span>，则 <span class="math inline">\(AX + v \sim N(A\mu + v, A\Sigma
A^T)\)</span>。此结论可以用于 1D
的情况吗？两个1D正态分布随机变量直接相加，结果会是？这当然属于仿射变换的范畴：
<span class="math display">\[
A = [1, 1], X = \begin{pmatrix} X_1 \\ X_2 \end{pmatrix}
\]</span> ​
这和混合高斯模型不一样。混合高斯模型是形成一个新的采样分布（多个 PDF
的混合，而不是变量的混合）。</p>
<p>​ 上述性质直接用在了 3D GS 以及 mip NeRF 里：</p>
<p>（2）3D GS: 投影变换取 Jacobian（3D <span class="math inline">\(\mu\)</span> 变 2D <span class="math inline">\(\mu&#39;\)</span>
的过程）。可以根据相机模型回顾一下： <span class="math display">\[
K\begin{pmatrix}
X/Z\\
Y/Z\\
1
\end{pmatrix} = \begin{pmatrix}
u\\
v\\
1
\end{pmatrix}
\]</span></p>
<p>​ 所以 Jacobian 到底取的是什么？已知，<span class="math inline">\(f(X)\rightarrow  Y\)</span>，则我们需要取： <span class="math display">\[
J = \frac{d(u, v, 1)}{d(X, Y, Z)}
=\begin{pmatrix}
3\times 3
\end{pmatrix}
\]</span> ​ 之后形成：<span class="math inline">\(J\Sigma
J^T\)</span>，注意这里的 <span class="math inline">\(\Sigma\)</span>
已经是 view tranform (global to local) 转过的。</p>
<ul>
<li>mip NeRF：里面也有一步，是 positional encoding 的 cascade <span class="math inline">\(P \in \R^{3\times
3L}\)</span>，用这个去变换。</li>
<li>剩下的其实都没有那么重要，剩余的有些在基于正态分布的推理里面。比如条件分布：</li>
</ul>
<p><span class="math display">\[
p(X_1 | X_2=a) \sim N(\mu_1 + \Sigma_{12}\Sigma_{22}^{-1}(a - \mu_2),
\Sigma_{11} - \Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21})
\]</span></p>
<h4 id="neus-与-neuralangelo">NeuS 与 Neuralangelo</h4>
<ul>
<li><p>NeuS 的核心思想就是找到一个无偏的渲染权重（由于原始的 <span class="math inline">\(Tr(t)\sigma(t)\)</span> 在 <span class="math inline">\(\sigma(t)\)</span> 最大的时候不是取最大值，而
<span class="math inline">\(\sigma(t)\)</span>
取最大值时意味着此处应该是面概率最高的位置）。此渲染权重需要有另一个特点：occlusion
aware，也即一条光线上的两处，前一处要把后一处遮住。最后用的时一个 <span class="math inline">\(|cos|\)</span> 函数（作为 f），在某一点算 SDF
的梯度（数值梯度，或者是差分）（一阶近似）。</p></li>
<li><p>Neuralangelo 论文使用了这样的思想：如果我们学习了一个 SDF
方程（隐式表征），我们可以在所求得的表面处通过求 SDF
的梯度来获得法向量（事实上，ref NeRF 就这么做了，Ref NeRF
有一个梯度预测模块，用 positional 网络的梯度作为监督）。而 Hash table
中，由于有不同grid（相当于不连续的多个函数），grid内的 position
梯度是连续的，而grid间是不连续的（显然，跨越了不同的三线性插值的值）。这时作者就用了数值梯度（可能噪声比较大）。</p>
<ul>
<li>coarse-to-fine，很多这样的工作啊，比如原始 NeRF，BARF 都是很经典的
coarse to fine。这里 coarse to fine
的主要是数值梯度步长，步长大则不准，但有助于优化。所以步长不断减小，而另一方面，大步长对应大的
grid size (分辨率低)，所以 grid 的精细度也是随步长变化逐级提高的。</li>
</ul></li>
</ul>
<h4 id="其他八股基本3d视觉问题本科的时候比较熟搞渲染之后就不熟啦">其他八股（基本3D视觉问题，本科的时候比较熟，搞渲染之后就不熟啦）</h4>
<ul>
<li>SfM 与 MVS 的基本含义是什么？
<ul>
<li>SfM，这个含义不多说。可以举一个例子：COLMAP。COLMAP
就是一个非常常用的 SfM 库，一般来说，流程都是：correspondence
search（先匹配，后match，然后会有一个验证环节，可能涉及到多帧验证），根据搜到的不同帧的多对
correspondences 通过三角化计算是 3D 点位置、本质矩阵与图像位姿。此后
BA：好像要用 ceres，比赛的时候在 docker 上装 pyceres
之类的环境工程可折磨了。BA 联合优化 3D
点位置与相机位姿，最小化重投影误差剔除 outliers
。是否稠密重建就看管线里有没有必要做这个事情了。</li>
<li>MVS：多视角立体视觉。有本书就叫MVS（展开为英文全称）这个名字...
很厚，本科期间看过前几章。</li>
</ul></li>
</ul>
<p>​ 以下这些本科搞 RM 以及 SLAM
的时候就接触过。没有展开写在这里，自行回顾就好了。</p>
<ul>
<li>相机标定与极线矫正</li>
<li>基本矩阵，本质矩阵，单应矩阵。</li>
<li>ICP 算法的基本步骤</li>
<li>PnP 算法的基本步骤</li>
</ul>
<hr>
<h2 id="ii.-gs">II. GS</h2>
<h3 id="gs-基本实现流程">2.1 GS 基本实现流程</h3>
<p>​ 整个工作的实现难度比 NeRF
大得多（端到端的好处就体现出来了）。如果能找到简单的 reference code
进行逐一拆解是比较好的。个人建议是去阅读基于 Taichi lang 的 Gaussian
Splatting 实现：<a href="https://github.com/wanmeihuali/taichi_3d_gaussian_splatting">github:
taichi_3d_gaussian_splatting</a>。本文光读论文是很容易觉得自己也没学到什么的（因为非本领域研究者挺难直接从论文的描述想到这是怎么实现的），而基于
Taichi lang 的实现由于语法都是 python，代码本身没有那么晦涩。此实现的
forward 部分我已经完全搞懂了，backward
部分由于有些涉及到需要自己上手算算，这里由于时间关系，只看了个大概。下面我结合图形渲染管线讲一下具体的实现。</p>
<figure>
<img src="/2024/04/25/NeRF-GS-Interview-Preparation/image-20240426000448455.png" alt="image-20240426000448455">
<figcaption aria-hidden="true">image-20240426000448455</figcaption>
</figure>
<center>
<font size="2"> Figure 1. （哥们的 mermaid 炸了，只能截图了）从 vertex
shader 以及 pixel shader 角度来理解 GS </font>
</center>
<p>​ 上图概括了整个基于图形渲染管线理解的 Gaussian Splatting forward pass
过程。注意，由于没一个 tile 内部的 Gaussian
个数都可能非常不一样，这导致基于 tensor 进行并行十分难做（tensor ---
规则的形状）。所以在整个 forward 管线中，本实现是 torch，Taichi
混合编程（用 torch 当底层数据容器，用 Taichi 自定义细粒度的 GPU 并行
kernel）。所以 <strong><u>backward</u></strong> 需要自己写。考虑到
backward 的链式求导的过程： <span class="math display">\[
\frac{d L}{d \mathbf{\Theta}} = \frac{d L}{d I} \times \frac{d I}{d
\mathbf{\Theta}}
\]</span> ​ 其中，<span class="math inline">\(I\)</span> 是 Gaussian
渲染得到的图像。<span class="math inline">\(d L/dI\)</span> 可以通过
Pytorch AD 模块直接算出来，不需要自定义。如果我们选择在此处加基于输出
<span class="math inline">\(I\)</span> 的正则化项，应该是不涉及 pytorch
或者 CUDA 端的自定义 backward 实现的。</p>
<p>​ 但此处是否可以加入对 <span class="math inline">\(\alpha\)</span>
的惩罚？是否涉及到自定义 backward 函数？如果加入对 <span class="math inline">\(\alpha\)</span>
的惩罚，则一般来说不涉及到渲染某一张图与某 GT 进行比较（因为没有
GT），估计也就是在 tile 内部对 transmittance
增加一个单一峰值惩罚或者非0即1惩罚（有点像
log-barrier）。估计会涉及到自定义 backward
函数的实现。举个例子：假设我对 <span class="math inline">\(\alpha\)</span> 进行惩罚，有一个惩罚函数 <span class="math inline">\(L_\alpha(I_{\alpha})\)</span>, <span class="math inline">\(I_{\alpha}\)</span>
是被惩罚的内容（比如单点的log惩罚或者 transmittance 的 L1
值），那么将有如下的梯度： <span class="math display">\[
\frac{d L_\alpha(I_{\alpha})}{d \mathbf{\Theta}} = \underbrace{\frac{d
L_\alpha(I_{\alpha})}{d I_{\alpha}}}_{\text{trivial}} \times
\underbrace{\frac{d I_{\alpha}}{d \mathbf{\Theta}}}_{\text{difficult
part}}
\]</span> ​ 其中 <span class="math inline">\({d I_{\alpha}} / {d
\mathbf{\Theta}}\)</span> 还是需要自定义的（相当于 forward 中，在
fragment shader 端，需要自定义 $ L_(I_{})$ 的计算方式，backward</p>
<p>中需要定义其梯度）。一些简单的想法中，梯度的形式还是相对较为简单的，由于每个点的实际
<span class="math inline">\(\alpha\)</span> 为： <span class="math display">\[
\alpha(i)=\alpha_i \times \text{2DGaussian}((u, v), \pmb{\mu}, \Sigma)_i
\]</span> ​ 如果对其进行非 0即1 惩罚就是： <span class="math display">\[
L(\alpha(i)) = \alpha(i)(1 - \alpha(i))
\]</span> ​ 上式对 <span class="math inline">\(\alpha\)</span>
求导，其实相对容易，是有很容易实现的解析形式的。所以 backward
从原理上来不会难实现，<strong><u>但是需要知道 torch
怎么写</u></strong>，forward backward
都需要去改还是有一定工作量的，并且需要对 torch 比较熟练。</p>
<p>​ 同样地，与 transmittance 有关的实现，实际上是与： <span class="math display">\[
\text{T}_r \times \text{RGB}_{\text{Gaussian}}
\]</span> ​ 有关，目前看来求导相对比较容易（RGB
项是个乘性的因子），如果要自定义 backward 的话，应该比较简单。</p>
<h3 id="一些问题">2.2 一些问题</h3>
<h4 id="gs-参数一般是什么样的covariance-matrix-要怎么训练可以用-gd-吗">GS
参数一般是什么样的？Covariance Matrix 要怎么训练，可以用 GD 吗？</h4>
<p>​ GS 参数挺多的：<span class="math inline">\(\mu\)</span>（三维），<span class="math inline">\(\Sigma\)</span>（协方差矩阵，不可直接学习，一般来说拆成一个四元数
<span class="math inline">\(q\)</span> 和一个scale
vector（某对角矩阵的对角部分）），primitive 本身的 <span class="math inline">\(\alpha\)</span> 值，以及 SH：各向异性的 RGB
evaluator。</p>
<p>​ 其中 CovMat 是不能直接 GD 的，GD
满足不了协方差矩阵的约束。拆成四元数和 scale vector
之后可以进行学习，但其中的梯度怎么求就是一个比较难的问题了，其中从 <span class="math inline">\(4\times 1\)</span> 的 Quaternion 到 <span class="math inline">\(3\times 3\)</span> rotation matrix，实际上会有一个
<span class="math inline">\(4\times 9\)</span> 的
Jacobian（具体形式会比较复杂，希望别来问我）。剩下的就是 GD 的事情。</p>
<h4 id="gs-与一般-nerf-的优缺点比较可以着重说一下-gs-的缺点nerf-mlp-引入的-inductive-bias-有什么好处">GS
与一般 NeRF 的优缺点比较，可以着重说一下 GS 的缺点？NeRF MLP 引入的
inductive bias 有什么好处？</h4>
<p>​ GS 如果要表示一个高精度的场景，通常意味着非常大的模型存储压力：每个
primitive 都需要存：3 + 4 + 3 + 1 + (16 * 3, SH) ? 个 float，
而一般来说普通的 NeRF 甚至可以用我的笔记本电脑训练（7GB）。</p>
<p>​ 显式表征对于场景的描述能力与 primitive
数量是成正相关关系的（当然隐式表征也是，只不过显式明显一些）。</p>
<p>​ 另外，GS 的定制化一般来说比 NeRF 要复杂：NeRF
端到端隐式表征，意味着内部绝大多数操作都可以用 AD 直接做。但 GS
由于存在不均衡的 workload，用 tensor 方法并行较难（可能用到很多
mask），有时需要自定义 backward 或者梯度计算。</p>
<p>​ NeRF 引入的最重要的 inductive bias 是，radiance
是可以通过稀疏视角训练的结果通过隐式表征的平滑性在新视角下插值得到的。而
Gaussian Splatting 由于是显式表征，所以没有这个 inductive bias，所以
Gaussian Splatting 必须要保证 Gaussian primitives
在场景中的覆盖率，以及正确地使用正则化项，避免出现 broken
的场景表示。</p>
<p>​ 这里面比较重要的一部分是 Gaussian primitives 的 adaptive splitting
操作。覆盖率不够的：clone，过大的，split。</p>
<h4 id="有关复现的胡思乱想">有关复现的胡思乱想</h4>
<p>​ GS
这种东西应该自己写一个<strong><u>简单版本</u></strong>的，可以加深理解。整个流程其实相对来说比较麻烦：</p>
<ol type="1">
<li><p>输入首先需要有 COLMAP 的 sparse point cloud (with
RGB)，这一步需要首先跑 COLMAP，对应的输出文件需要 parse
出来（除非有对应的数据集）。</p></li>
<li><p>如何选择正确的表征？我不是特别清楚，如果使用 Pytorch
去实现的话，是否应该使用 ModuleList。或者说，我实际应该有一个
tensor，比如 <span class="math inline">\(\mu, \Sigma\)</span> 这样的
tensor，所有 Gaussian 都在一起。这样才能利用好 tensor
并行操作，否则需要自己写
CUDA（要花很长时间，而且是正向反向一起写）。能否先避免使用 CUDA 写自定义
kernel function？</p></li>
</ol>
<ul>
<li>可以看看 Taichi-based Gaussian</li>
</ul>
<p>​ 假设我没有对 Gaussian
的合并、复制、拆分操作，能达到什么效果？只优化现有高斯，是否还能得到好的结果？</p>
<ul>
<li>如果没有合并、复制、拆分、删除操作，tensor
大小可以固定不变。如果有的话，可能需要设计一个 binary mask。
<ul>
<li>合并：两个高斯中，其中一个的参数重新计算，另一个的 binary mask
设置为 false</li>
<li>复制：原始情况下我们会给 tensor 留裕量，比如开始时有 N 个 sparse
point，那 tensor 设置为 N + 1024 * k 个（比如接近 1.5 N）。整个 tensor
是 <code>requires_grad = True</code>
的。这种情况下，我们维护的指针向后移动（表示当前 valid
的点最多到什么地方），复制对应的参数即可（但可能要加一个小的扰动），对应
binary mask 设置为 1</li>
<li>拆分：大拆小，大的改参数，拆分出的放在末尾（与复制类似），对应
binary mask 设置为 1</li>
<li>删除：binary mask 先设置为 0</li>
</ul></li>
<li>以上所有操作完成之后，压缩：把所有 binary mask 为 1
的数据移动到一起（但是对应梯度怎么变就不知道了）</li>
</ul>
<p>​ 在 tensor 固定大小不变时，删除也是可以做的：使用 binary mask，alpha
太小的不参数渲染（梯度自然就不会算）。</p>
<ol start="3" type="1">
<li><p>view independent RGB 这部分怎么算？涉及到 SH 到 RGB
的转换</p></li>
<li><p>sorting：肯定对整个 GS tensor 进行 sort
操作。最好是分块的。我们如果首先可以知道不同的 GS 落在什么 tile 内，每个
tile 拿到对应的 GS index，就可以进行 sorting
了。但这样涉及一个问题，每个 tile 拿到的 index 是不一样多的，首先
workload 就会很不均衡。另外，如果要进行并行化也会很麻烦。</p></li>
<li><p>color splatting: 最后是要用一个 2D Gaussian 在某个 tile
上计算颜色值。怎么去 cut-off color 也会是个问题：我不太可能一个 Gaussian
就直接需要对所有的像素有贡献，那么遍历的代价将会是 <span class="math inline">\(O(HWP)\)</span> 的，<span class="math inline">\(P\)</span> 是 高斯个数。由于 Gaussian
实际上是一个全空间的函数，我必须限定范围。这样又要反过来确定高斯（的主要贡献区域）在哪个
tile 上。相当麻烦。</p></li>
</ol>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://towardsdatascience.com/a-comprehensive-overview-of-gaussian-splatting-e7d570081362">A
Comprehensive Overview of Gaussian Splatting</a></p>
<p>[2] <a href="https://radiancefields.com/understanding-3d-gaussian-splatting-via-render-engines/">Understanding
3D Gaussian Splatting via Render Engines! ✨</a></p>
<p>[3] <a href="https://wandb.ai/geekyrakshit/mip-nerf-360/reports/Mip-NeRF-360-Unbounded-Anti-Aliased-Neural-Radiance-Fields--VmlldzoxOTc4Mjk4">Mip-NeRF
360: Unbounded Anti-Aliased Neural Radiance Fields</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>NeRF</tag>
        <tag>MVS</tag>
        <tag>3DGS</tag>
      </tags>
  </entry>
  <entry>
    <title>高性能异构计算相关知识</title>
    <url>/2024/04/03/%E9%AB%98%E6%80%A7%E8%83%BD%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<h1 id="hpc-i">HPC I</h1>
<hr>
<p>​ 投了几个 HPC 岗... 虽然不是科班出身，但个人觉得 HPC
还是挺有意思的（尤其是自己写 CUDA kernel
加速几百几千倍，那种成就感简直...）。HPC
的魅力之一在于，反馈非常及时：某种优化策略可能可以瞬间带来 profiling
时某一项的提高（比如 throughput, speed 等等）。我自己搞 rendering
的过程中也在不断尝试一些小的 tricks
（比如SSE啥的，毕竟多线程这种东西根本不用我写...
随便拉出一个线程池来都是自带 scheduler
的...），感觉过程中还是能学到很多东西的，对 CPU/GPU
的各种设计也能有更深的理解。</p>
<p>​
本博客是我认为比较重要的相关知识（第一部分）以及我觉得我可以回答的一些问题。
<span id="more"></span></p>
<hr>
<h2 id="底层计算加速知识">1.1 底层计算加速知识</h2>
<ul>
<li><p><label><input type="checkbox" checked>为什么经典 CPU
有五级流水线，里面有什么类型的hazard，怎么解决的：</label></p></li>
<li><p>解答这个问题，主要知道 CPU 的流水线模型。CPU
执行代码一般都是按如下的方式：（1）取指令（2）取数据（3）执行指令（4）写回。假设我们有大量计算需要进行，实际上可以：</p></li>
<li><table>
<colgroup>
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead>
<tr>
<th>取指令（1）</th>
<th>取数据（1）</th>
<th>执行指令（1）</th>
<th>写回（1）</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>取指令（2）</td>
<td>取数据（2）</td>
<td>执行指令（2）</td>
<td>写回（2）</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>取指令（3）</td>
<td>取数据（3）</td>
<td>执行指令（3）</td>
<td>写回（3）</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>取指令（4）</td>
<td>取数据（4）</td>
<td>执行指令（4）</td>
<td>写回（4）</td>
</tr>
</tbody>
</table></li>
<li><p>我的理解：每个这样的简单阶段都需要花费一个时钟周期，所以如果我们把这四个阶段标注为
A, B, C, D，实际的执行顺序会是：A1, (B1, A2), (C1, B2, A3), (D1, C2, B3,
A4), (D2, C3, B4), (D3, C4),
D4。看起来好像还是串行的，那么为什么流水线化就有好处？<strong><u>因为被骗了</u></strong>，可以这么理解：<strong><u>调用（call）一个指令</u></strong>，一般只要一个周期，<strong><u>但是指令完成（complete）</u></strong>，时间是不定的。比如
B1（第一次取数据），cache miss，则可能花费几十到几百周期。在此期间，CPU
可以选择直接开始执行 A2。A2 完成了如果 B1 还没有完成，则 B2 会停下来等
B1，整个流水线停住（流水线停滞）。</p></li>
<li><p>如果要更清晰地理解，请看下面将 GPU stream multiprocessing 的图
(Figure 1.1)</p></li>
</ul>
<p>​ 所以为什么要五级？越多看起来虽然越好...
但是：（1）硬件复杂度与设计、实现成本。流水线多了硬件自然就复杂了，而且功耗可能还会变大。（2）会提高流水线停滞的风险：越多指令进入，就越有可能产生数据依赖与竞争。这是一方面：不能太多，多了也不好。自然，也不能太少，少了则无法做到
latency
hiding，吞吐量也上不去，指令级并行（<strong><u>I</u></strong>nstruction
<strong><u>L</u></strong>evel
<strong><u>P</u></strong>arallel）效率也就不高。</p>
<p>​ 五级是骗人的... intel i3/i5/i7 很多是 14 级。</p>
<p>​
里面的另一个概念：超标量处理器（super-scalar）。超标量处理器表示此处理器可以同时（<strong><u>真正的并行，而不是并发</u></strong>）执行多条指令，比如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ADD R1, R2, R3     ; 整数加法指令</span><br><span class="line">SUB R4, R5, R6     ; 整数减法指令</span><br><span class="line">MUL F1, F2, F3     ; 浮点乘法指令</span><br><span class="line">DIV F4, F5, F6     ; 浮点除法指令</span><br></pre></td></tr></table></figure>
<p>​ 以上四条指令可以一起处理。可以认为是一种“硬件层面的多线程”：</p>
<ul>
<li>并发：同一时间段内处理多个任务。不要求某一个时刻多个任务在进行。单核也可以并发（时间片轮转），非超标量处理器的指令执行模式一般就是并发。强调任务之间的协调与调度。</li>
<li>并行：同一时刻处理多个任务。超标量处理器可以同时处理多条指令，所以是并行模式。强调任务之间的同时执行。</li>
</ul>
<p>​ 关于 CPU 流水线中可能出现的 hazard，本文罗列一下三种：</p>
<ul>
<li><p><strong><u>data
hazard</u></strong>：数据依赖性：一个指令依赖于另一个指令的数据，但对应指令尚未完成，使用的错误的值进行计算。</p>
<ul>
<li><p>RAW（read after
write）：指正常情况，第二条指令执行需要在第一条指令执行完成之后，写入了某个区域再读取（最常见的，比如说连续计算）。当出现乱序执行或者超标量执行时，顺序可能会变，导致
read before write（相当于使用旧值）。这种情况在compile
time一般无法处理，需要在run-time 处理。因为对应的数据依赖是 compile
不可知的。</p></li>
<li><p>WAR（write after
read）：这种情况正常时，是读取完对应区域的值后，再用新值覆盖之。结果出现
hazard
时，还没有读某个区域，就已经覆盖了对应区域。导致读到的值过新。这种情况一般可以通过
register renaming 在 compile time 就解决了。</p>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. ADD R1, R2, R3   ; 将R2和R3相加，并将结果存入R1</span><br><span class="line">2. LOAD R2, [MEM]   ; 从内存中加载数据到R2寄存器</span><br></pre></td></tr></table></figure></p></li>
<li><p>比如上面这个例子。R2 是会发生 WAR hazard 的寄存器。实际 register
renaming 时，renaming 会将 R2（load
指令）替换为一个实际的物理寄存器地址（本来是逻辑寄存器）。是的 ADD 的 R2
与 LOAD rename 之后的寄存器对应不同的物理寄存器，避免了 hazard</p></li>
<li><p>WAW: write after write。指对同一处内存的两次
write，顺序错了。比如应该是指令1先 write，指令2
覆盖。结果由于乱序导致指令1
的结果覆盖了指令2（正常人写不出这样的指令，因为这样的指令必然导致一个指令的结果被覆盖，一般都是乱序发射和超标量引起的顺序改变导致的）。所以也可以在
compile-time 进行 register renaming。</p></li>
</ul></li>
<li><p><strong><u>control
hazard</u></strong>：主要是逻辑跳转不加处理时，流水线不知道之后应该往哪一条路走。一般来说，control
hazard
引入的是控制逻辑的依赖，会导致流水线停滞。处理方法一般有两种：</p>
<ul>
<li>分支预测：预测对了就不会有问题，相当于没有分支，流水线不会停。而如果预测错了，只能清空流水线了。所以...
if else 能不用的地方就别用。GPU 不喜欢，CPU 其实也没有多喜欢。branchless
的 二分查找都比有 branch 的快很多。</li>
<li>branch delay slot:
之前计组课说到了。主要意思是：分支指令执行一般需要比较长的时间，我们可以利用这段时间来处理分支指令附近无依赖关系的指令（比如先做个预取）。实际实现时，就是在分支指令后插入（调整位置）对应的指令，使得分支指令执行时，流水线可以继续处理。</li>
</ul></li>
<li><p><strong><u>structural hazard</u></strong>: 指资源竞争。比如 IO
设备，DMA总线，ALU 等等。比如：两个计算指令，只有一个
ALU，那么两个指令只能排队。这种情况就只能去设计一个好的调度算法，并且注意资源复用性。</p></li>
<li><p><label><input type="checkbox" checked>CPU 内存管理模式：RAII
(C++, Rust), GC (Java, Python) 简介</label></p></li>
</ul>
<p>​ C++ 与 Rust 是编译型语言，内存的使用与释放都需要显式定义。虽然引入
RAII（资源获取即初始化）之后，“显式”并不那么突出了：</p>
<ul>
<li>std::vector
你知道其底层怎么分配数据的吗？代码全部将这一块藏起来了。实际是其对应的
allocator
进行的，其析构实际上是对应变量超出生命周期后，自动进行的（析构函数的调用是由编译器插入的，比如插在
delete 后，或者超出生命周期位置）。</li>
<li>但对于编译器而言，什么时候申请与释放，大多数时候都是确定的。</li>
</ul>
<p>​ Java 与 Python 是解释型语言（Java 是 JIT，其实还挺快的，Python
属实... 那什么）。这两种语言使用的内存管理模式是 GC (garbage
collection)。因为执行是动态的，变量的生存周期难以确定，只能找个捡垃圾的人，不断地问：你这水瓶还要吗？不要我捡走了。但
Python 和 Java 的操作不一样：</p>
<ul>
<li>Python 的 GC 感觉挺像
std::shared_pointer，是有一个引用计数的。但是引用计数坏就坏在存在循环引用，循环引用还会比较恶心：假设
A 要 B，B 要 C，C 要 D..., Z 要 A，就成了一个大环。Python
会有一个查环的机制，如果查到一个环，并且没有外界引用，相当于瓶子开会，瓶子们希望保留别的瓶子，那捡垃圾的哥们可不管这么多，发现都是瓶子互相依赖就捡走了。</li>
<li>Java：从某个根对象开始，标记所有变量是否可达。如果不可达（没有引用关系），就回收掉。</li>
</ul>
<p>​ 所以 GC 本身会占用一定的算力：一般是以一个后台线程或者进程实现的。GC
会定期检查不需要的内存（或者在用户指定时，比如 del 可以触发
GC。慎用，小变量就没必要了，大内存回收可以手动）。</p>
<p>​ 下面我们来讲讲 C++ 的 operator new 与 delete 与系统调用 malloc/free
的区别，以及 operator new / delete 是怎么实现的。</p>
<p>​ 可以这么认为：new 是个更强力的 malloc。底层也有 malloc，但 new
会多做这么两个事情：</p>
<ul>
<li>operator::new 会调用对应对象的构造函数。malloc
就只有一块内存（没有经过
initialized的）。相当于：<code>std::vector::reserve</code>
就在申请一块未初始化的内存，<code>emplace_back</code>
则会原地初始化。</li>
<li>operator::new 会抛出异常：如果申请失败，会抛
<code>std::bad_alloc</code>，相当于一个带 try / catch 的 malloc，malloc
失败就返回一个 NULL。我们可以指定 <code>new(std::nothrow)</code>
来模拟普通 malloc 的模式（失败返回 nullptr）。</li>
</ul>
<p>​
同样地，free只清除内存分配空间，不调用析构函数（所以，如果有特殊析构就GG）。但
operator delete
一般不会抛异常，除非析构函数抛异常（说是，我们应该避免在析构函数里抛异常）。注意，我们一般不会说
delete 有什么异常（exception）特性，但除调用析构函数之外，与 free
还是有一些其他区别：</p>
<ul>
<li><code>delete []</code> 会逐数组元素调用析构函数。</li>
<li>delete nullptr 什么事都不会发生。nullptr 是 delete-safe
的。但我们不能 free(NULL)。</li>
</ul>
<p>​
最后提一句，为什么要避免在析构处抛出异常：析构函数首先需要保证一件事情：任何时候都可以成功完成，不会被打断，应该是
<code>noexcept</code> 的（C++ 的一个隐式声明，析构一般都是
<code>noexcept(true)</code>
的）。一旦被打断，可能会导致未定义行为以及调试困难：</p>
<ul>
<li>部分析构：某些动态内存没有完成 free，直接泄漏了。某些文件句柄没有
release，直接泄漏了。</li>
<li>调试出现很大的问题：抛出异常时，调用栈一般会开解（回想一下：调试的时候，出现了异常，异常会按照调用栈不断向上抛，抛到一个合适的
entry
point，可以被异常处理机制捕获到，此时，与异常相关的一些变量全部会存在内存中），但如果是析构函数，调用栈开解前可能释放了部分内存，导致调用栈的上下文信息不完整。</li>
</ul>
<p>​ delete 行为与析构关系很大，一般delete抛的错误是析构函数抛的。delete
失败（比如 double
delete）一般是出未定义行为，可能会抛异常，也可以直接段错误了。</p>
<ul class="task-list">
<li><label><input type="checkbox" checked>光线追踪哪些部分是 memory
bound, 哪些是 compute bound，如何设计以及优化：</label></li>
</ul>
<p>​ <strong><u>Memory bound:</u></strong></p>
<ul>
<li>光线与场景求交。求交操作本身很简单：AABB
与光线求交就没有特别难处理的计算，而光线与面片相交本质是求一个线性方程组（重心坐标u,
v 以及光线方向距离 t，三个值我们都需要），计算也不难。但不同的
BVH，AABB，面片以及 object
信息，在内存中的位置可能非常分散（即便使用了一定的访存优化）。此部分很容易引起
cache miss。
<ul>
<li>化分树线性化。BVH 树，或者 KD
树通常的构建方法是基于指针（指向左右孩子），这种方法会导致内存非常分散。当光线求交时，我们总是顺树去查：从根到对应的叶子，而跨度大可能造成
cache
miss。如果将树展成线性的，比如中序遍历输出或者是先序遍历输出，所有节点保存在连续的内存中，可以提高访存效率。相应地，对应的面片数据也可以按同样方式划分。同样，存成
AOS（这里 SOA 效率不够），AOSOA 感觉也不用考虑。</li>
</ul></li>
<li>texture fetching 也是 memory
bound：光线每次击中的位置都可能非常不一样，不同核（对应不同cache）可能每次拿到的光线也不一样（基于thread
pool，可能没什么规律，tiled-based 会好一点）。而一般每次 texture
都只取一个 texture map 上三个孤立点：texture 经常变，texture mapping
的点也经常变。
<ul>
<li>怎么优化呢？AOS 和 SOA 需要权衡。比如 texture 一般是 SOA 的（R G B
分别存），但光追 texture mapping 每次就取几个 离散的 RGB，所以 RGB
连续会比较好。否则不同通道之间还可能需要多次传输，可能还会存在 cache
miss。</li>
<li>tiled-based：分块渲染。块内的光线方向差别不大，在光追时，击中的位置相对集中（相对，相对于本次取
(0, 0)，下一线程取 (H - 1, W - 1)）。可能可以带来更好的 cache
coherency。</li>
</ul></li>
<li>Path guiding: 在线学习的 EM 过程是 compute
bound（用于迭代的数据比较集中，取一次迭代多次），但采样 /
空间划分的时候是 memory bound。这个怎么提升不多说了，方法差不多。</li>
</ul>
<p>​ <strong><u>Compute bound</u></strong>:</p>
<ul>
<li><p>采样算法：比如 microfacet 模型吧：<span class="math inline">\(FGD
/ (4\cos\theta_o\cos\theta_i)\)</span>，F
是菲涅尔（不是特别好算，但已经算不错的了），<span class="math inline">\(D\)</span>
NDF（一般来说是一个复杂的函数），G（也是一个复杂的函数）。分母还有两个
cos（不是 cos 就是点积）。而且有的时候需要
MIS（多种采样策略，每一种都试试，最后加权），我论文里的 distance
sampling 就是典型的 compute bound。</p></li>
<li><p>其他时候，光线追踪中的 compute bound 并不多。BDPT 中的 MIS
算另一个，但那个就很复杂了，而且很难说清楚是 compute bound 还是 memory
bound (vertex 内存分散，但计算本身又需要循环)。</p></li>
<li><p><strong><u>怎么提升？</u></strong> compute bound 一般都很难通过
trick
提升。计算复杂是没办法的，特别是与数学公式有关的。只能找一个更好的理论，或者找更好的算法。否则只有近似这一条路。我们一般不讨论
compute bound 问题的提升方法，因为非常 domain/task specific。</p></li>
<li><p><label><input type="checkbox" checked>GPU
光追，需要考虑哪些问题。这里需要知道 texture memory 和 constant memory
的具体用法了，以及去看一些别人的设计。</label></p></li>
<li><p>负载不均衡问题：可以使用 tiled-based rendering 解决（local tile
的负载一般比较均衡，除非场景的几何在图像域的变化非常大）。在实现代码的过程中，需要尽可能避免分支。比如
DrJIT 以及 taichi lang 其实都有对应的条件选择函数，实现 branchless 值
selection。现代 GPU 有 ptx 指令集的 SEL 指令，我们也可以实现
masking，也可以通过条件表达式来做到这件事。</p></li>
<li><p>texture 与 常量内存使用的问题。constant memory 不用多说，constant
memory
适合存小块的且经常访问的内存（比如，光源信息，相机信息，全局场景介质信息等等），关于
constant memory 为什么快，看 3.2 节的内存访问模型。texture memory
我们说得很少（我自己没用过），texture memory 需要经过 CUDA 绑定为
texture 对象：</p></li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">cudaArray* cudaTexArray;</span><br><span class="line"><span class="built_in">cudaMallocArray</span>(&amp;cudaTexArray, &amp;cudaTexDesc, width, height);</span><br><span class="line"><span class="built_in">cudaBindTextureToArray</span>(texRef, cudaTexArray, &amp;cudaTexDesc);</span><br></pre></td></tr></table></figure>
<p>​ 先分配一个 Array（多维数组），后将 texture 绑定在对应的
Array，将会生成一个 texRef (纹理的引用)，可以用
<code>float value = tex2D(texRef, x, y);</code> 来 query。注意，此 query
自带硬件 lerp（可以设置方法），而且还可以通过 <code>cudaTexDesc</code>
设置 mip-mapping（牛）。texture memory 可以使得 text fetching
这件事简单一些（效率更高）。光线与场景求交就用 RT-core 吧！剩下的采样...
写在kernel里。</p>
<h2 id="底层计算加速知识-1">1.2 底层计算加速知识</h2>
<ul class="task-list">
<li><label><input type="checkbox" checked>SM
以及之后的计算组织层级</label></li>
</ul>
<p>​ GPU 的内存模型还稍微好写一点，执行模型就有点不行了...
感觉自己老是分不清楚 SM, SP 这些概念。</p>
<center>
<img src="/2024/04/03/%E9%AB%98%E6%80%A7%E8%83%BD%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/B485B3DF2120F72A2A2D27F7974CC907.jpg" style="zoom:50%;">
</center>
<center>
<font size="2"> Figure 1.1 GPU execution model </font>
</center>
<p>​ SM 是一个执行器，一个 SM 只能同时处理一个 block（所以说，为什么要
block
内部线程足够多）。如果线程不够多，相当于我们给一个庞大的工厂提供了一个简单的任务，而工厂维持设备运转是有成本的（高负荷生产一小时也是X成本，低负荷也是X成本，那理所当然应该高负荷），需要工作尽可能填充对应的机器。SM
是最顶层的计算单元，一个 SM 将会有很多 SP（stream processer)。而由于一个
SM 处理一个 block，那么可知，一个 SP 处理的是 block
的一部分，<strong><u>那么是哪一部分？</u></strong>
很容易想到：warp。我们可以这么认为：</p>
<ul>
<li>一个 SP 通常只有一个 IP（instruction pointer），所以一个 SP
只能在同一时间处理同样的指令，有同样的行为。如果遇到 branch (warp
divergence)，就必须有一部分线程被 mask 掉，处于暂时 idle
状态，直到待会儿需要的时候继续执行（串形化）。</li>
<li>顶级 SIMD 思想：只有数据不一样，指令是一样的。</li>
</ul>
<p>​ 注意，<strong><u>SP 和 warp 一样，都是硬件概念。</u></strong> warp
是 nvidia GPU 中任务执行的基本<strong><u>硬件单元</u></strong>（不是
thread 哦），thread 是基本的<strong><u>软件单元</u></strong>：thread
（软件端）定义了一个 warp（硬件端） 的行为 --- 写 CUDA
的时候都是定义单个 thread 的行为，而不是定义单个 warp 的行为，因为 warp
内部确实是允许有不同行为的（分支）：</p>
<ul>
<li>thread：编程模型，软件端的最基本单元</li>
<li>warp: 硬件模型，执行指令的最基本单元</li>
</ul>
<p>​ SP 一般包含三个大组成部分：</p>
<ul>
<li>warp：被执行的“指令容器”（相当于一块可编程的电路）---
被执行的硬件单元</li>
<li>执行单元：ALU 等 --- 配备给 warp 中的每个
thread（软件行为层面的概念） 的：相当于 warp 有 32 个
lanes，每个lane可以容纳一个线程（<strong><u>包括指令流，上下文，寄存器与内存状态</u></strong>），对应
lane 会提供 ALU，寄存器等。</li>
<li>存储器：包括寄存器、cache以及对应的内存。</li>
</ul>
<p>​ 对应地，block 也是一个软件概念：由于 block
相当于任务（包括其逻辑与指令），其执行器是 SM，也即：硬件端 SM
的资源限定了 block 的任务能用多少资源。则 block 在进行设计时，需要考虑
SM 能给多少寄存器、thread lane：</p>
<ul>
<li>thread 的软件概念就是 a stream of tasks, 硬件实现就是一个工人。warp
就是这32个工人的小车间，SP
会提示这32个工人要做什么（通常，都只需要广播，因为大家做的事情都一致）。block
就是某个对应订单（block 打包的所有 thread
对应的人物）的大车间，大车间内只有有限个工人（thread
限制），有限的袋子（寄存器）以及有限大小的大箱子（共享内存），以及一个超大，但是超慢（当然，工人们要走过去）的工厂库房（global
memory）</li>
<li>当一个任务过大时（一个大车间干不完），那么就划分成多个
block（多个大车间一起）：同时要保证划分合理：
<ul>
<li>一个车间工人过多，会导致袋子不够用（寄存器，比如出现寄存器 spilling
问题，工人 A
的袋子不够用了，就只能先往工厂库房里存，之后再取出来），且也有可能根本站不下那么多工人（超过
thread 数量上限）</li>
<li>一个车间工人过少：不能极致压榨！工人 8
小时工作里面摸了四小时鱼。我开灯要钱吧？开空调要钱吧？放这么多袋子，你也用不了多少。</li>
</ul></li>
</ul>
<p>​ 那么 stream 是做什么的？stream 是个软件概念，CUDA
中描述的是执行任务的机制。还是太抽象了，stream 描述的内容本身就不是一个
kernel call 了，<strong><u>而是多个存在依赖关系的 kernel
call</u></strong>。如果两个 kernel call
本身不存在依赖关系，则可以直接并行，由 GPU 调度：直接调用完 A 调用
B，因为 A B 不存在依赖关系，且 kernel call 在不 synchronize
的情况下，是异步的，A 和 B 会被送到不同的 SM
同时执行（几乎，可能A稍微快一点，毕竟A先被call）。而存在数据依赖就不能这样，我们必须老老实实：A结束，GPU
层级的 synchronize，之后调用 B，synchronize，...
直到所有顺序化的工作完成。而这样实际上是不太好的：会出现短板效应。</p>
<ul>
<li>A kernel call 完成并且 synchronize 取决于 A
最慢的执行单元花了多长时间执行。直到所有执行完毕，才能继续。</li>
</ul>
<p>​ stream
所提供的好处就在于：我可以把大的任务划分为小份，小份任务内部是自动串行自动同步的，而小份任务之间可以并行，任务之间又不存在依赖关系。实际上可以用这样的图表示：</p>
<p><img src="/2024/04/03/%E9%AB%98%E6%80%A7%E8%83%BD%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/19026745C2E6B41D9DE3BB731ABC5F45.jpg" style="zoom:50%;"></p>
<center>
<font size="2"> Figure 1.1 stream multiprocessing </font>
</center>
<p>​ 可以看到，这种情况还是节省了很多时间的，因为不同 kernel
对应的短板不一定是一起出现的。</p>
<p>​ 感觉今天算是完全理解了 stream 这个简单的概念：</p>
<ul>
<li><p>stream
适合用在具有依赖关系的任务上。不具有依赖关系的可并行任务，当 kernel
被调用时，我们可以手动将其映射到不同的 stream 上，以实现多个 kernel call
的同时执行。<strong>千万注意，不是同时调用</strong>：</p>
<ul>
<li><p>A 与 B 之间，不管有没有 synchronize，只要 A 和 B 在同一个
stream（包括默认的 default stream），A 和 B
<strong><u>执行就会顺序化</u></strong>。synchronize <strong><u>只会让 B
在 A 执行完成之后调用</u></strong>。看下图：</p>
<p><img src="/2024/04/03/%E9%AB%98%E6%80%A7%E8%83%BD%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/1B35BD16A467A1DDB787D8BC05FF9BB2.jpg" style="zoom: 50%;"></p>
<center>
<p><font size="2"> Figure 1.2 synchronization </font></p>
</center></li>
<li><p>所以，要让两个函数并行调用很简单：别同步就行。但要并行执行，需要至少在不同
stream 上（相当于不同的 task queue 上），为什么说至少？软件可以开很多
queue，硬件够不够是另一回事。</p></li>
<li><p>此部分和 Hyper-Q 有一定关系，可以联系起来说。</p></li>
</ul></li>
<li><p>单个 kernel 就别划分为 streams 了，没必要，控制好 block
数量就行。别瞎 jb 加花，我研一上学期写的 CUDA
就有这种傻逼操作：</p></li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">8</span>; i++) &#123;</span><br><span class="line">    rayTraceKernel&lt;&lt;&lt;lidar_ray_blocks, DEPTH_DIV_NUM, shared_mem_size, streams[i]&gt;&gt;&gt;(</span><br><span class="line">        sid_ptr, eid_ptr, angles_ptr, dists_ptr, flag_ptr, i, segment_per_block, </span><br><span class="line">        ((i &lt; <span class="number">7</span>) ? segment_per_block : last_block_seg_num), &amp;oct_ranges[i * ray_num], lidar_param.x, lidar_param.z, pose.z</span><br><span class="line">    );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 你说你一个 kernel 分啥 stream 啊，还多次调用。而我大三写的 CUDA
却没有（虽然不是多个 kernel，是 GPU + CPU
代码，也算拆分成不同块，并行执行了）。所以我感觉我写 CUDA
这么久，到现在就没有真正是用过 stream。所以回到打比方上，stream
是什么呢？</p>
<ul>
<li><p>单
stream：大家都做完同一个工作，再进入下一个工作。理所当然地，有些小车间快一些，就会停下来不做事。</p></li>
<li><p>多 stream:
给车间分组，只要整个组做完了，就可以整组进行下一个工作。</p></li>
<li><p><label><input type="checkbox" checked>Hyper-Q ？
这是啥，有人的面筋上有这个。Hyper-Q 的基本思想是：当 kernel 明显无法对
GPU 有很好的利用时（occupancy），CPU 可以选择同时并行地执行多个不同的
kernel（kernel call 的 并行化）来使得 GPU 利用率提高。由于 CUDA 的
kernel call 都是 async 的，可能执行起来比较简单。注意 Hyper-Q 的
pipeline behavior:</label></p>
<ul>
<li><p>没有 hyper-Q 时，同一个 kernel，即便 stream
不同也是不能并行的。因为没有 hyper-Q 时只会有一个 hardware queue。同一个
kernel 的不同 calls，放在不同的 stream 内，也会压到同一个 FIFO
结构中。</p>
<p><img src="/2024/04/03/%E9%AB%98%E6%80%A7%E8%83%BD%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/Screenshot 2024-03-31 002206-1711815804493-1.png" style="zoom:75%;"></p>
<center>
<p><font size="2"> Figure 1.3 false dependency
(来自CUDA官方一个讲Hyper-Q的文档) </font></p>
</center></li>
<li><p>执行顺序是从右往左。注意 kernel
的启动顺序刚好与执行顺序一致（FIFO）：</p>
<p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span> ; i &lt; <span class="number">3</span> ; i++) &#123;</span><br><span class="line">     A&lt;&lt;&lt;gdim,bdim,smem,streams[i]&gt;&gt;&gt;();</span><br><span class="line">     B&lt;&lt;&lt;gdim,bdim,smem,streams[i]&gt;&gt;&gt;();</span><br><span class="line">     C&lt;&lt;&lt;gdim,bdim,smem,streams[i]&gt;&gt;&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>由于 B 依赖 A，C 依赖
B，所以AB不能并行，BC不能并行，C和另一个stream的A可以并行。最后会形成这一效果：</p></li>
<li><p>无 Hyper-Q：长流水线。这是因为 A 与 B 不能并行，只有 B 被 call
时，才会查看队列中是否有可以同时 launch 的 kernel。</p>
<p><img src="/2024/04/03/%E9%AB%98%E6%80%A7%E8%83%BD%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/Screenshot%202024-03-31%20002343.png"></p>
<center>
<p><font size="2"> Figure 1.4 false dependency
(来自CUDA官方一个讲Hyper-Q的文档) </font></p>
</center></li>
<li><p>有Hyper-Q：</p>
<p><img src="/2024/04/03/%E9%AB%98%E6%80%A7%E8%83%BD%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20240331002412345.png" alt="image-20240331002412345" style="zoom: 80%;"></p>
<center>
<p><font size="2"> Figure 1.5 no false dependency
(来自CUDA官方一个讲Hyper-Q的文档) </font></p>
</center></li>
<li><p>理解 Hyper-Q 的关键是任务输入队列的模式（FIFO），A1, B1, A2, B2
是输入顺序。A1 如果和 B1 存在数据依赖，那么 B1 的 kernel call 一定在 A1
完成后才进行。B1 kernel call 之后，由于不存在依赖，可以直接开始尝试 call
下一个 kernel，这时 A2 才能被调用执行。</p></li>
</ul></li>
<li><p><label><input type="checkbox" checked>GPU
的内存结构：</label></p></li>
</ul>
<p><img src="/2024/04/03/%E9%AB%98%E6%80%A7%E8%83%BD%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/maxresdefault.jpg" style="zoom:67%;"></p>
<center>
<font size="2"> Figure 1.6 Nvidia-GPU memory hierarchy </font>
</center>
<p>​ 重点说一下不常见的以及一些 memory copy 机制：</p>
<ul>
<li><p>L1 cache：首先，修正一个误区，register spilling 会首先与 L1 cache
有关（不会一溢出就往很慢的 gmem 里存）。注意，L1 与 shared memory
是在同一物理区域的（设计与电路都是一样的），我们动态设置的 shared memory
实际上就是从 L1 中抽取了部分可用空间。<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p></li>
<li><p>Constant cache: read-only cache，read only
的大块区域会被放在这里。但是... 为什么是 per SM 的？</p>
<ul>
<li><blockquote>
<p><strong>Constant Caches</strong> - are special caches pertaining to
variables declared as read-only constants in global memory</p>
</blockquote></li>
<li>说是 global memory，怎么跑到 SM 里面去了？难道别的
SM（block）不可见？明白了... 要用 cache 去理解。cache
存在的意义就是为了加速更满的memory 的存取。L1 的存在是为了和 global
memory（以及其上的 L2）打交道，也存在命中，写回等操作。而 CUDA 的
constant memory 是基于 global memory 同样的 DRAM
存储实现的（相当于，DRAM 有一块专门存 constant memory）。所以 constant
memory 也比较慢，需要一个 constant cache 来专门加速与 constant memory
gmem 的数据交互。当 SM 的所有线程都访问同一个gmem 地址时，对于 constant
cache 最友好，因为此处被取到 constant cache
之后，就可以不断被其他线程快速读取重用（broadcast）。</li>
</ul></li>
<li><p>L2 cache：L2 已经是 SM 外的 cache 了，是存储多个 SM
中，需要来回在 local shared memory 以及 global memory
中交互的数据。</p></li>
<li><p>Texture and constant memory：都是 read-only。但 texture memory 是
cache 在 L1 里的，只有 constant memory 是 cache 在 constant cache
里的。所以，为什么 constant memory 稍微快一些？（1）有 broadcast
机制（而且一般都可以用，常量嘛，很多情况下都是全局的）(2) 有单独的
cache，不用和别人抢，所以 cache miss 更少。</p>
<ul>
<li>注意 texture memory 与 CUDA 的 texture object
没有直接的联系（后者有硬件支持的bilerp）。</li>
</ul></li>
<li><p>注意 CPU 甚至还有 L3 cache... 牛逼。</p></li>
<li><p>关于更多 GPU model 介绍，可以看这个 [^2]</p></li>
</ul>
<h2 id="cpugpu-加速技巧">1.3 CPU/GPU 加速技巧</h2>
<ul class="task-list">
<li><label><input type="checkbox" checked>CPU 与 GPU 概念的对应性<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></label></li>
</ul>
<table>
<colgroup>
<col style="width: 18%">
<col style="width: 40%">
<col style="width: 40%">
</colgroup>
<thead>
<tr>
<th>GPU 概念</th>
<th>定义</th>
<th>CPU 等价概念</th>
</tr>
</thead>
<tbody>
<tr>
<td>thread</td>
<td>thread 是软件概念，别忘了：分配给一个 CUDA core
的指令流与数据。相同的指令作用于很多线程（SIMT）</td>
<td>N/A，惊讶不？</td>
</tr>
<tr>
<td>CUDA core</td>
<td>CUDA core 是硬件概念：执行 SIMT 指令流以及数据的基本单元。</td>
<td>vector lane（SIMD 指令中的向化概念）</td>
</tr>
<tr>
<td>warp</td>
<td>SM
执行并行任务的基本单元：相同指令，作用在不同数据上（小车间）。</td>
<td>vector（SIMD 指令中的向化概念）</td>
</tr>
<tr>
<td>kernel</td>
<td>需要并行处理的任务（所有任务的集合）</td>
<td>thread(s)：软件概念，一个任务可以分配到很多 threads 上，与 kernel
一样。</td>
</tr>
<tr>
<td>SM, streaming multiprocessor</td>
<td>核心处理单元，处理 block 的单元。</td>
<td>core</td>
</tr>
</tbody>
</table>
<ul class="task-list">
<li><label><input type="checkbox" checked>warp-level 原语的妙用<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></label></li>
</ul>
<p>​ 三类原语：</p>
<ul>
<li><p>数据交换：最常用的是 <code>__shfl_xxx_sync</code>
（shuffle）类，剩下的还有一些很有趣的，比如 warp vote
function：<code>__all_sync</code> (相当于在warp 之内做一个 bool 类型的
reduce，如果有一个 thread 是 false，那么所有 <code>__all_sync</code>
都会返回 false)，同样还有 <code>__any_sync</code>（任一则1），还有
<code>__uni_sync</code> （唯一则1），需要说的，没那么 straightforward
的是：</p>
<ul>
<li><code>__ballot_sync</code>
，这个相当于是：提供了一种统计方法，对于给定的线程（warp内），只要其条件成立（predicate
=
true），就会把结果对应的那一位设成1（32位int），相当于：多少predicate为真就多少位。则用
__popc 可以计算 32位 int 中有多少为 1。</li>
<li><code>unsigned int __match_any_sync(unsigned mask, T value);</code>:
给定一个 value，返回线程符合 mask，并且对应 value 等于当前输入的 value
的线程id（以mask形式返回）。</li>
<li><code>unsigned int __match_all_sync(unsigned mask, T value, int *pred);</code>
这个比 match any 复杂一些：如果所有 value（mask线程）都一致，返回对应的
mask（... 不就是输入的 mask吗）且设置 <em>pred = 1，否则返回0 且设置
</em>pred = 0... 感觉没啥用的函数。</li>
</ul></li>
<li><p><code>__activemask</code>，就这么一个原语。此原语会返回当前（时刻，调用发生时）有多少线程是
active 的（有些可能因为 branching 什么的非
active）。这个原语用来做什么... 我一开始以为只返回有多少线程是
active（数），但实际返回的是一个 mask：哪一位是1，对应的线程就是 active
的。这就很有用了，我可以使用这个 mask，在仅 active
的线程之间传输数据。</p></li>
<li><p><code>__syncwarp</code>：每个 warp
在这里会进行一次同步（为什么要这样？），何时需要 warp 级别的同步？warp
级别的同步一定是做了非同步的 warp
操作才需要吧。注意，<code>__syncwarp</code> 接受一个
mask：代表我可以只同步某几个线程，比如：</p>
<ul>
<li>我们已知 <code>__syncthreads</code> 不能写在条件语句内，因为
predicate 只要为 false，对应线程永远无法到达
<code>__syncthreads</code>，产生死锁。、</li>
<li>而有了 <code>__syncwarp</code>，我们可以指定：在 if 内，先调用
<code>__activemask</code>，对对应线程同步。else 内再先
<code>__activemask</code>，之后同步。</li>
</ul></li>
<li><p>我TM看了 CUDA-C-programming guide 的 API 文档才知道，warp reduce
根本不用自己用 <code>__shfl_xor_sync</code>写，有对应的 reduce
函数：</p>
<p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// add/min/max</span></span><br><span class="line"><span class="type">unsigned</span> __reduce_add_sync(<span class="type">unsigned</span> mask, <span class="type">unsigned</span> value);</span><br><span class="line"><span class="type">unsigned</span> __reduce_min_sync(<span class="type">unsigned</span> mask, <span class="type">unsigned</span> value);</span><br><span class="line"><span class="type">unsigned</span> __reduce_max_sync(<span class="type">unsigned</span> mask, <span class="type">unsigned</span> value);</span><br><span class="line"><span class="type">int</span> __reduce_add_sync(<span class="type">unsigned</span> mask, <span class="type">int</span> value);</span><br><span class="line"><span class="type">int</span> __reduce_min_sync(<span class="type">unsigned</span> mask, <span class="type">int</span> value);</span><br><span class="line"><span class="type">int</span> __reduce_max_sync(<span class="type">unsigned</span> mask, <span class="type">int</span> value);</span><br><span class="line"></span><br><span class="line"><span class="comment">// and/or/xor</span></span><br><span class="line"><span class="type">unsigned</span> __reduce_and_sync(<span class="type">unsigned</span> mask, <span class="type">unsigned</span> value);</span><br><span class="line"><span class="type">unsigned</span> __reduce_or_sync(<span class="type">unsigned</span> mask, <span class="type">unsigned</span> value);</span><br><span class="line"><span class="type">unsigned</span> __reduce_xor_sync(<span class="type">unsigned</span> mask, <span class="type">unsigned</span> value);</span><br></pre></td></tr></table></figure></p>
<ul>
<li>不过注意，是 int 和 uint。float
还得自定义（int/uint感觉范围并不广，在一般的科学计算里比例较小吧）</li>
</ul></li>
<li><p>warp 操作很多，甚至有 warp matrix
multiplication（<code>mma_sync</code>）以及一大堆 warp 矩阵操作<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p></li>
<li><p><label><input type="checkbox" checked>CUDA
奇技淫巧简记</label></p></li>
</ul>
<p>​
这里只做一个记录。对面试没有什么太大帮助，毕竟面试官估计不会考这么细：</p>
<ul>
<li>你知道 CUDA 可以写一些帮助编译器优化的原语吗？比如：
<ul>
<li><code>void * __builtin_assume_aligned (const void *exp, size_t align)</code>
告诉编译器，对应的 pointer 至少有 <code>align</code>
个对齐的字节。对齐：<strong><u>起始地址是某个值的倍数</u></strong>，比如
4, 8 等等。
对于对齐的数据，访问可以更快（显然，比如一个float，如果其高8位在对齐float的第八位上，而后低24位在第二个对齐float的高24位上，相当于
float 被从第一个 Byte 处切断了，float 数组的起始地址是 第三个
Byte）。一般来说，我们会希望：64位数据类型对齐到 8
的倍数上，也即起始位置是 8 * k 个 Byte 处，32 位则对齐到第 4 * k
Byte。这个原语可以让编译器认为某处就是对齐的，直接按对齐的走。</li>
<li><code>void __builtin_assume(bool exp)</code>，通过 exp
告诉编译器，与 exp
相关的表达式肯定成立，你信我，直接按照这个先验来优化。比如我们告诉编译器，某个索引不会超过某个值，编译器就会尝试去根据这个已知信息优化。</li>
<li><code>long __builtin_expect (long exp, long c)</code>，比较离谱...
写在 if
语句里<strong><u>帮助分支预测</u></strong>（？？？离谱）的。相当于：我有一个条件判断：比如
<code>if (i &gt; 0)</code> 这样的，我可以告诉编译器，啊 i &gt; 0
大多数时候都成立，你按 i &gt; 0 去预测最保险。</li>
</ul></li>
<li><label><input type="checkbox" checked>请简述一下 CPU/GPU
下对算法并行优化的方法和思路，可以给一些具体的设计例子吗？如果能结合项目最好。</label></li>
</ul>
<p>​ 直接说的话是很虚的：</p>
<ul>
<li><p>CPU 端，使用线程池（手写）或者 OpenMP
来管理任务。将任务划分成一个个包进行自动调度。尽量避免手动调用
<code>std::thread</code>，用 <code>std::async</code> 可能都比直接
<code>std::thread</code>
优雅。线程池可以高效利用并行资源（内部一般包含一个队列，一个 mutex
和一个 condition variable，实现 enqueue 和 pop
两个函数即可，通过模板化技术以及函数指针（或者是函数对象）可以实现非常灵活的任务执行器）。</p>
<ul>
<li>例子1：渲染器使用的就是线程池的实现。是这样处理的：首先将需要渲染的
images 划分为 tiles，一个 tile 内可能有 16 * 16 或者 8 * 8
个像素。每个像素都需要进行 path tracing (计算光线在场景的弹射，并且累积
radiance
contribution)，则可以启动一个线程池，每次提交的任务就是像素渲染：只给定像素坐标，场景、光源等信息在一个全局区域，所有线程可见（或者提供引用或指针），此外提供一个渲染函数（用lambda
打包的），输入除了像素坐标之外还有一些辅助信息，并且按引用捕获 RGB
buffer。每个线程负责从给定像素 trace SPP 条 paths，累积值到 RGB buffer
对应位置。尽管进行了
tiling，光追的算法逻辑决定了不同线程之间的负载必定有比较大的差异，所以用任务队列来管理，避免手动同步（如
join）带来的overhead 以及不灵活的问题。</li>
<li>例子2：本科时做过的几件事情。（1）Robomaster
大二开发基于优化的灯条2D位姿优化，计算误差的时候就可以 OpenMP
reduction。（2）大三大四写的激光雷达仿真器也是直接 OpenMP 对 for
循环并行的。</li>
</ul></li>
<li><p>CPU 端，尽可能使用 SIMD 操作（一次读取多个多字节数据，比如 4-8 个
float，这算是一种 burst mode？burst mode 描述的不是这个）。SIMD
的作用不用多说。</p>
<ul>
<li>本人论文的 DA-based distance sampling，做 RIS 时，由于 DA 的计算是
compute bound 的，我用 AVX2
指令加速了一下（快速向量exp，向量乘加以及存取）。</li>
</ul></li>
<li><p>CPU/GPU 端：尽量使用无锁数据结构。pthread 库以及 windows
线程库在操作 mutex
结构（加锁，解锁都是系统调用）时都会进入内核态，进入内核态这个操作可能带来巨大的延迟。有些库，比如
TBB 确实提供一些别的方法，比如自旋锁（spin
lock），自旋锁就是那种一直轮询状态的锁，虽然不用进入内核态，但会引入 CPU
占用的问题（开几个空转的 while (1) {} 试试，相当于 CPU
时间片全部花在在这里转了，如果里面有
<code>std::this_thread::sleep</code>，时间片还能被让出去）。所以，能避免锁的地方，最好避免锁。比如用原子操作，CUDA
和 C++ atomic 是有硬件支持的，所以不用锁实现。Taichi lang
估计也不用使用锁，毕竟都有硬件支持。</p>
<ul>
<li>原子操作：研究生阶段用得很少，基本上会尝试避免原子操作。CPU
端的例子基本没有了（我项目里很少用
<code>std::atomic</code>，机器人队里的需求有一点，但都是边缘化的），GPU
端的例子挺多的：
<ul>
<li>flash attention 的实现（我自己的实现版本），使用 atomicAdd
accumulate softmax 的分母。</li>
<li>GPU z-buffer：不同 block
将对应的深度图片段（可能重合）进行合并时，用 atomicMin
求深度图每个位置的最小值。</li>
</ul></li>
</ul></li>
<li><p>访存优化。这我不多说了，访存优化对是否并行都很重要。访存优化对于
GPU 性能提升尤其重要：控制 cache
行为，利用多级、不同速度的存储这件事，CPU 端没有给那么灵活的操作方式，而
GPU 提供了：shared memory, thread local memory (register), constant
memory, global memory 这些，如何将数据复用部分的访存优化到极致，是 GPU
访存优化的重点。</p></li>
<li><p>尽可能解除数据依赖性（说了等于白说...？怎么解除）</p></li>
<li><p><label><input type="checkbox" checked>Nsight Compute:
性能分析，和 nv-prof 的关系是什么？我用过 nvprof（可视化 kernel stream
occupancy），也用过
ncu（可以提供命令行输出的分析以及建议，说到建议，nvprof
也会给）。如果面试问，如何使用这样的工具去查看自己的 kernel
性能如何，应该怎么说？举个例子，我对我从未 profiling 过的
SGEMM（通用矩阵乘法）进行 ncu profiling，输出如下：</label></p></li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">void sgemm_kernel&lt;(int)128, (int)128, (int)8, (int)8&gt;(float *, float *, float *, float, float, int, int, int)</span><br><span class="line">  Section: GPU Speed Of Light Throughput</span><br><span class="line">  ---------------------------------------------------------------------- --------------- ------------------------------</span><br><span class="line">  DRAM Frequency                                                           cycle/nsecond                           6.43</span><br><span class="line">  SM Frequency                                                             cycle/nsecond                           1.35</span><br><span class="line">  Elapsed Cycles                                                                   cycle                      5,864,329</span><br><span class="line">  Memory [%]                                                                           %                          43.74</span><br><span class="line">  DRAM Throughput                                                                      %                           9.06</span><br><span class="line">  Duration                                                                       msecond                           4.34</span><br><span class="line">  L1/TEX Cache Throughput                                                              %                          87.49</span><br><span class="line">  L2 Cache Throughput                                                                  %                          22.96</span><br><span class="line">  SM Active Cycles                                                                 cycle                   5,209,056.57</span><br><span class="line">  Compute (SM) [%]                                                                     %                          22.37</span><br><span class="line">  ---------------------------------------------------------------------- --------------- ------------------------------</span><br><span class="line">  WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance </span><br><span class="line">        of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    </span><br><span class="line">        latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 </span><br><span class="line"></span><br><span class="line">  Section: Launch Statistics</span><br><span class="line">  ---------------------------------------------------------------------- --------------- ------------------------------</span><br><span class="line">  Block Size                                                                                                        256</span><br><span class="line">  Function Cache Configuration                                                                  cudaFuncCachePreferNone</span><br><span class="line">  Grid Size                                                                                                         512</span><br><span class="line">  Registers Per Thread                                                   register/thread                            253</span><br><span class="line">  Shared Memory Configuration Size                                                 Kbyte                          32.77</span><br><span class="line">  Driver Shared Memory Per Block                                              byte/block                              0</span><br><span class="line">  Dynamic Shared Memory Per Block                                             byte/block                              0</span><br><span class="line">  Static Shared Memory Per Block                                             Kbyte/block                           8.19</span><br><span class="line">  Threads                                                                         thread                        131,072</span><br><span class="line">  Waves Per SM                                                                                                     7.11</span><br><span class="line">  ---------------------------------------------------------------------- --------------- ------------------------------</span><br><span class="line"></span><br><span class="line">  Section: Occupancy</span><br><span class="line">  ---------------------------------------------------------------------- --------------- ------------------------------</span><br><span class="line">  Block Limit SM                                                                   block                             16</span><br><span class="line">  Block Limit Registers                                                            block                              1</span><br><span class="line">  Block Limit Shared Mem                                                           block                              4</span><br><span class="line">  Block Limit Warps                                                                block                              4</span><br><span class="line">  Theoretical Active Warps per SM                                                   warp                              8</span><br><span class="line">  Theoretical Occupancy                                                                %                             25</span><br><span class="line">  Achieved Occupancy                                                                   %                          24.97</span><br><span class="line">  Achieved Active Warps Per SM                                                      warp                           7.99</span><br><span class="line">  ---------------------------------------------------------------------- --------------- ------------------------------</span><br><span class="line">  WRN   This kernel&#x27;s theoretical occupancy (25.0%) is limited by the number of required registers See the CUDA Best  </span><br><span class="line">        Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      </span><br><span class="line">        details on optimizing occupancy. </span><br></pre></td></tr></table></figure>
<p>​ 首先介绍这个概念：GPU Speed Of Light
Throughput，指的是理论极限（speed of light
指速度上限，很生动吧，速度的物理极限是光速）。可以看出，我们这个 kernel
花在计算的时间上只有 22.37%，而 memory 占比（显存访问）为
43.74%（比较低），访存问题还是很大的。所以，GPU 才会说：" This kernel
exhibits low compute throughput and memory bandwidth
utilization"。compute 占比低，看了一下我写的 NCU profile
矩阵向量乘法，结果发现 compute
占比还是很低（22.39%），可能是正常的，说明这个任务本身就是 memory
bound。</p>
<blockquote>
<p>(SGEMM) This kernel's theoretical occupancy (25.0%) is limited by the
number of required registers See the CUDA Best Practices Guide。</p>
</blockquote>
<p>​ SGEMM 有一个较大的 local 数组（8 * 8），但好像也不至于用了特别多的
register？我看到 Registers Per Thread 都 253 ...，这么离谱？SGEMV
(矩阵向量相乘) 竟然只用了 18 个resgister，所以一个 block 里的活动 warp
可以很多...</p>
<p>​ 所以总结一下，可以先看这么一些内容：</p>
<ul>
<li><p>DRAM Throughput：小于 60% 时访存都有一定问题</p></li>
<li><p>L1/L2 cache throughput: 过小说明 cache miss
比较严重，看看内存访问 pattern 是不是比较没有规律。</p></li>
<li><p>Occupancy 部分：theoretical occupancy 与 achieved occupancy。</p>
<ul>
<li><p>SGEMM 例子中，occupancy (theoretical) 受到了 register
数量的影响。但我们如果想通过减少一些 local 变量（比如，去掉几个 int xxx
之类的）就减少 register 使用，是不太可能的（naive）。register
使用量将会受到指令数量影响：register
会被隐式地用于保存一些计算的中间结果，越是复杂的代码，使用到的 register
就越多。比如：</p>
<p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">gmem_addr = gmem_base_b + ((kid &lt;&lt; <span class="number">3</span>) + tile_r) * n + tile_c;</span><br></pre></td></tr></table></figure></p></li>
<li><p>你说上面这段用了多少寄存器？不只是有名字的变量如
<code>gmem_addr</code>，<code>tile_c</code>
之类的，中间结果通常需要被保存（一些右值）。</p></li>
<li><p>我们如果想要限制 register
用量，手动调整一般不好，因为这都是编译器设定好的，<strong><u>编译器没有那么笨</u></strong>。控制编译器数量意味着有些中间结果无法被存下来，需要重算，则反向增加了指令数量（时间开销）。这也是一种
trade-off 吧。</p></li>
</ul></li>
<li><p><label><input type="checkbox" checked>矩阵相乘、转置、相加优化（element wise
怎么优化？），矩阵。</label></p></li>
</ul>
<p>​
矩阵相乘是有大量数据复用的。在优化矩阵相乘时，一般通过分块的方法（tiling），分块相乘后相加即可。一般在
GPU 的实现中，对于大矩阵相乘（<span class="math inline">\(A\times
B\)</span>）：</p>
<ul>
<li>Thread coarsening: 一个 thread
可能需要同时处理输出矩阵的多个位置（比如 8 * 8）。我们以 8 * 8
为例：</li>
<li>一个block 处理一个大块：比如 128 * 128（输出），每个线程 8 * 8
则对应 16 * 16 = 256 线程</li>
<li>输入：由于输出的某一块，是A的某几行（与块行数一致）与 B
的某几列（与输出块列一致）相乘获得，除非中间维度特别小，一般来说我们在
thread 内部用循环将中间维度拆分为多个块。比如最终为 128 * 8 大小的块（从
A 中取出），以及 8 * 128 的块（从 B 中取出）。本例子中，由于有 256
个线程，我们可以每个线程负责复制 A 块的 4个值以及 B 块的四个值（FLOAT4
优化）</li>
<li>块存在 shared_memory
中（因为块还是比较大的）。每个线程计算的结果存在local
数组中（register）。</li>
</ul>
<p>​ 对于矩阵和向量相乘，注意使用 warp reduce 就行... 之前是用 shuffle
手写，现在 int 可以直接 reduce 了。</p>
<p>​ 矩阵相加（element-wise）操作：注意，element-wise
操作一般是不会涉及到数据复用的。所以优化空间其实不算大，一般就是：（1）thread
coarsening (2) 在 thread coarsening 的基础上，连续传输（FLOAT4）(3)
coalesed memory access（非常重要）。</p>
<p>​ 矩阵转置：CPU 明显是可以分块去做的，但 GPU
为什么要分块？为了提高缓存一致性：GPU 也是有 cache 的。我自己写了 CPU 和
GPU 分块/不分块的实现，见（1024 * 1024 float 矩阵转置） <a href="https://github.com/Enigmatisms/culina/blob/master/matmul/transpose.cu">transpose.cu</a>。如果从
CPU 计时看，差不太多（大概 10-20% 速度提升），但是从 NCU profiler
的结果看，GPU 分块的实现只需要大概一半的 cycles 数就能完成。CPU
端的话，一般分块是 7ms，不分块是 10ms，提升也挺明显的。</p>
<ul class="task-list">
<li><label><input type="checkbox" checked>cache 相关：</label></li>
</ul>
<p>​ cache 每一个 cache line 包含 3 个部分， 分别是什么作用？与 cache
的实现相关，回忆一下计组：</p>
<ul>
<li>tag（标签）：cache 肯定需要保存对应数据在主存中的地址，tag
中一部分重要内容就是主存地址（毕竟需要写回之类的）。访问 cache
时，第一步就是与缓存中所有标签对比，以确定是否命中缓存。</li>
<li>data（数据）：必不可少，缓存存的就是数据。若判定缓存命中，就可以直接从数据项中取出对应结果。</li>
<li>valid bit（有效位）：用于确定当前 cacheline
数据是否有效。数据如果过期了，可能会设置为无效，即使命中，也需要去下一级存储中查找。以下常见情况，有效位会被设置为
invalid：
<ul>
<li>缓存未被初始化时（刚上电）</li>
<li>主存被修改（比如别的核心修改了主存对应位置）</li>
<li>缓存替换（缓存满了，需要装入新数据时）</li>
</ul></li>
<li><label><input type="checkbox" checked>cache
查找的一般流程，使用多级 cache 的原因以及 cache miss
之后的流程</label></li>
</ul>
<p>​ cache查找一般来说就是三步：</p>
<ul>
<li>地址解析：CPU
发出查找请求后一般会给一个访问地址。访问地址是三部分组成的：标签 +
组地址 +
偏移量。什么意思呢？标签包含了主存地址等其他控制信息，而组地址与偏移量则完全与
cache 查找相关：cacheline
是分组的，相当于我们首先需要知道在哪个组查找，组内哪个位置，组的起始地址。</li>
<li>缓存lookup：已经确定了对应的 cacheline 了，就需要确定对应 cacheline
是否就是我们需要查找的内容：比较标签。如果不匹配，则发生 cache
miss，进入处理 cache miss 的操作。</li>
<li>数据检索（retrieval）：如果命中，并且标志位也是有效的，则取对应数据返回。</li>
</ul>
<p>​ 我们首先说一下 cache miss：cache miss
发生的条件很多，比如地址解析失败，缓存lookup 不匹配（对不上，或者
invalid），这里说一下最为 prevalent 的一些预防方案：</p>
<ul>
<li>prefetch 机制（防止 cache miss或者降低 cache miss 率）：prefetch
对于冷启动很有效（所有缓存行都无效），对于分散但体量较大的访问（需要经常切换访问位置，但切换后的开始几次访问可能数据量大且连续）也是有好处的。预加载到
cache 中。</li>
<li>缓存行替换（防止 cache miss或者降低 cache miss 率）：比如
LRU，LFU，替换缓存中最近最少或者最近最不频繁使用的项目。</li>
<li>padding（降低 cache miss 率）：不进行 padding
时可能多个地址映射到同一个 cacheline，导致对应地址总是发生修改，cache
miss 总是发生。如果可以选择合适的 padding，使得 cache
地址可错开，则可以降低 cache 换出的频率。</li>
</ul>
<p>​ 那么 cache miss 之后一般是什么流程？</p>
<p>（1）内存读请求首先发送到最近的
cache（L1），如果L1没有命中，则继续往下发（L2,L3）。</p>
<p>（2）如果继续下去仍然是 cache miss，读请求最终会来到主存</p>
<p>（3）主存接到请求会直接根据地址去查找，查找之后数据会返回到内存控制器</p>
<p>（4）各级缓存需要被更新：写回操作，更新对应项（可能一整个缓存行都会被覆盖）。如果
CPU 请求是一个缓存行，那么直接返回写回后的缓存行</p>
<p>（5）数据返回到 CPU：CPU 取用计算</p>
<p>​ 多级cache的使用原因：</p>
<ul>
<li>cache（SRAM）的成本比较高，考虑成本时，越快的 SRAM 越小。而越小的
SRAM 越容易 cache miss，cache miss
之后被迫到慢速的内存中取数据。为了提高 cache
命中的概率，降低内存访问时间的期望：</li>
</ul>
<p><span class="math display">\[
E(T) = p_1 T_1 + (1 - p_1)p_2T_2 + (1 - p_1)(1 - p_2)p_3 T_3 +
p_m\prod_{i=1}^3(1 - p_i)T_m
\]</span></p>
<ul class="task-list">
<li><label><input type="checkbox" checked>页表机制带来的开销以及如何缓解，以及页表的好处</label></li>
</ul>
<p>​
首先需要回顾虚拟内存这个概念。一句话概括就是：虚拟内存使用了外存以扩大可表示的内存范围，通过
swap 机制实现了缺页中断时的内存访问请求。</p>
<ul>
<li>一般来说，分页机制会将每个进程的虚拟内存地址划分为多个页（通常4KB，取决于操作系统），对应的物理地址会划分为一个个页框，一般来说，页框和页大小是一样的。</li>
<li>之后，维护一个页表，用于虚拟地址到实际地址的映射。</li>
</ul>
<p>​ 干巴巴的，不好理解，来看一个例子吧。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">虚拟页号    物理页框号</span><br><span class="line">0         10</span><br><span class="line">1         15</span><br><span class="line">2         20</span><br><span class="line">3         25</span><br></pre></td></tr></table></figure>
<p>​
每个页框对应的才是真正的物理地址。这个页表首先将虚拟地址映射到物理地址，映射的过程中，如果出现了缺页：也即页表中并没有对应的虚拟地址，这时会引发一个异常（page
fault），之后立刻对这个异常进行处理：</p>
<ul>
<li>到外存或者其他存储介质中调取对应的页</li>
<li>更新页表，建立缺页的虚拟地址到实际地址的映射</li>
<li>重新执行缺页的指令，使得程序可以正常执行</li>
</ul>
<p>​ 所以虚拟内存为什么可以更大？假设我们的物理地址是 32
位的，虚拟地址也是 32 位的，那么按道理来说，由于一页大小为
4KB，也即一个虚拟地址可跨 12 位地址（<span class="math inline">\(2^{12}\)</span>），则可以对应 16 TB
虚拟内存？并不是这个意思。虚拟地址被拆分为了两部分：(1) 页地址（2）页内
offset。比如 32位
地址，低12位是页内地址（没有页内地址怎么随机访问啊，傻）。所以 32
位实际能表示的地址大小仍然是 <span class="math inline">\(2^{32}\)</span>
= 4GB 的范围。那么实际是怎么使用的呢？</p>
<ul>
<li>每个进程有一个页表（映射表），就以32位地址为例。这个页表决定了此进程最多可以被分配到
4GB 内存。但注意，页表中 <strong><u>目前</u></strong>
可能只有几页，比如，1024页：那也才 4MB
啊，假设此时，此进程需要调取某个为 X
的虚拟地址，一查页表发现缺页了：立刻触发缺页中断，只到取到对应的页，再重新执行。取到对应的页的过程可能涉及到实际物理内存的换入换出：另一个进程的某块闲置内存被换出到外存上，转而换入本进程
request
的内存。这样，本进程可以“无缝”（几乎吧，缺页中断也还是比较快的，如果缺页的频率比较低）使用对应内存。那么，假设一个物理内存只有
4GB 的设备，上面运行了 4 个进程：我可以用虚拟内存技术，每个进程都分配
4GB 虚拟内存，之后就靠缺页中断不停换入换出。</li>
</ul>
<p>​
所以好处很显然：可以摆脱物理内存的限制，利用外存或者其他设备获得更大的可用内存。开销：虚拟内存的访问实际上是两步：（1）假设不考虑
cache，那么我第一步要去主存先查一波页表，本地完成内存映射之后，还需要再去主存取真正的数据，从访存方面可见已经两倍了（2）假设发生缺页中断，这就更慢了，外存和内存之间通信，即便有
DMA，速度还会比内存通信慢。</p>
<p>​ 解决方案：TLB（translation lookaside
buffer，转译后备缓冲区，或称页表缓存），如果某个虚拟地址存在于 TLB
中，我们就不用去主存查页表，可以直接从 TLB
中取出映射后的实际物理地址，通过对应物理地址直接去取页，这样也很快。另外，如果页表太大了，则也可以设置多级页表，虽然会降低访问的速度（多次映射），但是可以避免由于内存碎片化而导致的无法分配的问题。</p>
<p>​ 讲到分页，我这里还有两个需要讲的：</p>
<ul>
<li>分段：简单理解就是：段是变长的页。页大小一般固定，但段可变，所以段表不仅需要基地址以及映射方式，还需要长度这一信息。</li>
<li>CUDA 与分页机制最有关的是 pinned memory
(<code>cudaMallocHost</code>)，此部分内存分配后，页即被锁定（不用担心被换出），消除了缺页中断的可能。另一方面，这部分内存与GPU交互时是不需要走
PCIe 总线的，DMA 可以直接让 GPU 设备访问对应主存区（厉害啊）。走 PCIe
总线的基本都是 CPU 参与的传输（因为CPU要发出读写请求）。</li>
</ul>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>GPU 内存层级架构 - Cornell Virtual Workshop:
https://cvw.cac.cornell.edu/gpu-architecture/gpu-memory/memory_types [^
2]: https://cvw.cac.cornell.edu/gpu-architecture<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>https://cvw.cac.cornell.edu/gpu-architecture/gpu-characteristics/threadcore<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>https://developer.nvidia.com/blog/using-cuda-warp-level-primitives/<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#warp-matrix-functions<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>HPC</tag>
        <tag>异构计算</tag>
      </tags>
  </entry>
  <entry>
    <title>AdaPT - Volumetric Path Tracer I</title>
    <url>/2023/02/18/AdaPT-Volumetric-Path-Tracer-I/</url>
    <content><![CDATA[<h1 id="ada-path-tracer-iii">Ada Path Tracer III</h1>
<hr>
<p>​ AdaPT 进入了 volumetric path tracing
阶段。由于本人的研究方向（暂定）为散射介质渲染的研究，了解基于 particles
的（Lagrangian表征的）散射渲染是非常有必要的（烟雾渲染多有意思，虽然现在只能渲染
homogeneous 介质）。vpt相对于无介质pt的主要难点在于：</p>
<ul>
<li>volumetric path tracing 在采样层面上多了一个维度 ---
光线传播距离将不再是无穷远，需要采样其自由程</li>
<li>free space radiance
一致性不再成立，并且模型与表面散射模型有较大的区别。有许多额外计算需要完成</li>
<li>direct component 更难衡量，这意味着收敛更加困难。MIS 也不那么
intuitive 了</li>
</ul>
<table>
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 32%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;">渲染4000迭代（25s，约10亿光线）</th>
<th style="text-align: center;">渲染20000迭代（约50亿条光线）</th>
<th style="text-align: center;">渲染15000迭代</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><img src="/2023/02/18/AdaPT-Volumetric-Path-Tracer-I/pbr-balls-good.jpg"></td>
<td style="text-align: center;"><img src="/2023/02/18/AdaPT-Volumetric-Path-Tracer-I/pbr-balls-20000.png"></td>
<td style="text-align: center;"><img src="/2023/02/18/AdaPT-Volumetric-Path-Tracer-I/pbr-box-cloud.png"></td>
</tr>
</tbody>
</table>
<center>
Figure 1. 无介质的收敛性明显好很多
</center>
<p>​
话说，我写博客从来没有在一个系列上写超过两篇的文章，渲染技术系列已经三篇了，这还是头一回。</p>
<span id="more"></span>
<hr>
<h2 id="基本概念">2.1 基本概念</h2>
<h3 id="abosorption">2.1.1 Abosorption</h3>
<p>​ 吸收与<span class="math inline">\(\sigma_a\)</span>:
吸收系数（absorption cross
section），是一个PDF：<code>probability density that light is absorbed per unit distance traveled in the medium</code></p>
<ul>
<li>The units of are reciprocal distance (<span class="math inline">\(m^{-1}\)</span>). This means that can take on any
positive value; it is not required to be between 0 and 1, for
instance.</li>
</ul>
<p>​ 吸收系数的单位之所以是<span class="math inline">\(m^{-1}\)</span>，是因为如下关系： <span class="math display">\[
\begin{equation}\label{absorb}
L_o(x, w) -L_i(x, w)=-\sigma_a(x, w)L_i(x, w)dt
\end{equation}
\]</span> ​ 其中，<span class="math inline">\(dt\)</span>是微分距离（光线通过一小段散射介质），<span class="math inline">\(L_i(x, w)\)</span>为位置x，入射方向为<span class="math inline">\(w\)</span>的入射光radiance。在各向同性介质假设下，可以通过求解微分方程的方式算出：
<span class="math display">\[
\begin{equation}\label{remain}
L_o(x+w\cdot t, w) = L_i(x, w)e^{-\int^{t}_0 \sigma_a(x + w\cdot
\tau)d\tau}
\end{equation}
\]</span> ​ 以上公式就是著名的 Beer-Lambert 定理。</p>
<h3 id="emission">2.1.2 Emission</h3>
<p>​ emission：emission...
我本人挺少接触这个概念，可以认为是medium本身的一种“荧光反应”？这种现象对
output radiance 的影响公式为： <span class="math display">\[
\begin{equation}\label{emission}
dL_o(x, w) = L_e(x, w)dt
\end{equation}
\]</span> ​ 关于这个公式，我在PBR book中读到这样一段话：</p>
<blockquote>
<p>This equation incorporates the assumption that the emitted light
<span class="math inline">\(L_e\)</span> is not dependent on the
incoming light <span class="math inline">\(L_i\)</span>. This is always
true under the <strong><u>linear optics assumptions</u></strong> that
<code>pbrt</code> is based on.</p>
</blockquote>
<p>​ 我对以上公式倒是没有什么感兴趣，只是觉得这里的 linear optics
有点奇怪。emmm 什么是 linear optics assumption?
我在研一上学期的【生物医学光学】课程中曾经学到【非线性光学】的概念，我印象最深的非线性光学概念就是拉曼散射（但显然不可能出现在图形学的渲染问题中，拉曼散射比普通散射的强度低好几个数量级）。如果与某些非线性光学效应有关，我就还有很多光学知识需要补...
个人觉得可能存在这样的一种情况：我曾经读到过光致透明/光致变色的有关内容，假设
emission 与入射光有关，那么 <span class="math inline">\(L_e(x,
w)\)</span> 将会比较复杂，是入射 <span class="math inline">\(L_i(x,
w)\)</span> 的函数，建模起来就需要一些数学手段。</p>
<h3 id="out-scattering">2.1.3 Out-scattering</h3>
<p>​ out-scattering:
光线偏离原本方向，向别的方向传播而损失能量的过程。out-scattering
也是线性微分方程建模（这可能就是缺陷所在）： <span class="math display">\[
\begin{equation}\label{out-scat}
dL_o(x, w) = -\sigma_s L_i(x, w) dt
\end{equation}
\]</span> ​ 显然，我们可以把公式<span class="math inline">\(\eqref{absorb}\)</span>与公式<span class="math inline">\(\eqref{out-scat}\)</span>组合在一起，得到系数
<span class="math inline">\(\sigma_t = \sigma_a +
\sigma_s\)</span>，称之为 attenuation
或者更为熟知的【extinction】。<span class="math inline">\(\sigma_t\)</span>
是个重要概念，由它定义了两个概念:</p>
<ul>
<li>Albedo: <span class="math inline">\(\rho = \sigma_s /
\sigma_t\)</span>，从公式看也即散射相对于两种 interaction
事件发生的比例。也即发生散射事件时，散射（而非吸收）的概率</li>
<li>平均自由程：<span class="math inline">\(1/\sigma_t\)</span>。都是伏笔，还记得<span class="math inline">\(\sigma_t\)</span>的单位是<span class="math inline">\(m^{-1}\)</span>吗... 倒数的单位就是<span class="math inline">\(m\)</span>了：光线发生一次散射事件前行进的平均距离。</li>
</ul>
<p>​ emmm，有了<span class="math inline">\(\sigma_t\)</span>以及公式<span class="math inline">\(\eqref{absorb}\)</span>与<span class="math inline">\(\eqref{out-scat}\)</span>，我们可以定义一个新的
"Beer-Lambert" 公式： <span class="math display">\[
\begin{equation}\label{remain2}
L_o(x+w\cdot t, w) = L_i(x, w)e^{-\int^{t}_0 \sigma_t(x + w\cdot
\tau)d\tau}
\end{equation}
\]</span> ​ 以上公式计算的结果中，指数项被称为
transmittance（传输率），由于指数项的存在（linear
optics），传输率是可乘的（乘等于通过两端路径之和）。exp的指数项被称为光学厚度（optical
thickness）: <span class="math display">\[
\begin{equation}\label{opt-th}
\tau(x\rightarrow x&#39;) = \int_0^t\sigma_t (x+tw, w)dt
\end{equation}
\]</span></p>
<blockquote>
<p>This property is useful for volume scattering implementations, since
it makes it possible to incrementally compute transmittance at multiple
points along a ray.</p>
</blockquote>
<p>​
这也同样需要注意，我同样希望拓展的模型也具有此性质，这样的系统将会是无记忆系统，容易实现并且对并行计算是友好的。【无记忆性】</p>
<h3 id="in-scattering">2.1.4 In-scattering</h3>
<p>​ in-scattering 需要引入相函数（phase
function）概念，此概念与BSDF很像，我们可以认为BSDF是表面的相函数，BRDF则一般定义背向散射，BSDF则同时定义前向与背向散射。</p>
<p>​ PBR-book 给出了 BSDF与phase
function的一个重要不同，回顾BSDF的性质：BSDF具有“归一性质”： <span class="math display">\[
\begin{align}\label{norm1}
\int_{\Omega} L_i(x, w_o)f_r(x, w_i, w_o)\cos\theta dw_o &amp;\leq
L_i(x, w_i)\\
\int_{\Omega} f_r(x, w_i, w_o)\cos\theta dw_o &amp;\leq 1
\end{align}
\]</span> ​ 但由于 medium interaction 并没有 cosine's law，并且 phase
function并不建模能量衰减，故 phase function 是直接、完全归一化的： <span class="math display">\[
\begin{equation}\label{norm2}
\int_{S^2}p(w_i, w_o)dw_o = 1
\end{equation}
\]</span></p>
<blockquote>
<p>The main difference is that there is no cosine term since the phase
function operates on radiance rather than differential irradiance.</p>
</blockquote>
<p>​ phase function 实际上就是散射方向的PDF。关于 phase
function，这里只提一点：大多数phase function都可以用 H-G phase function
的线性组合近似<a href="#ref">[1]</a>。</p>
<h2 id="radiative-transfer-equation">2.2 Radiative Transfer
Equation</h2>
<blockquote>
<p>definitionThe light transport equation is in fact a special case of
the equation of transfer, simplified by the lack of participating media
and specialized for scattering from surfaces. <a href="#ref">[2]</a></p>
</blockquote>
<p>​ 很重要，就推导两对效应：</p>
<ul>
<li>absrption / out-scattering (radiance 减少)</li>
<li>emission / in-scattering (radiance 增多)</li>
</ul>
<p>​ 带来的影响，以及从 surface 入射的 radiance 如何对当前一点的入射
radiance 起作用。首先，这里展示无介质情况下的 light transport equation：
<span class="math display">\[
\begin{equation}\label{lte}
L_o(x, w_o) = L_e(x_h, w_o) + \int_\Omega f(x_h, w_i, w_o)L_i(x_h,
w_i)\cos\theta dw_i
\end{equation}
\]</span> ​ 其中，<span class="math inline">\(x_h\)</span>为<span class="math inline">\(x\)</span> 沿着<span class="math inline">\(-w_o\)</span> 方向交场景的最近交点（first
intersection）。此 LTE
我们很熟悉，也即emission与击中点半球上入射光反射的积分和为出射光，上一篇博客我们也分析了此公式的分解实现。但上述公式中，我们并不清楚场景的几何配置、可视信息等，而这些信息实际上在上述公式中又至关重要。例如在分析直接光照时：</p>
<ul>
<li>如果是无介质直接光照，需要trace shadow ray并且确认 shadow ray 并没有
【除了被采样光源之外的其他几何体】遮挡。</li>
<li>如果是有介质直接光照，需要进行多次 tracing：由于对应的几何可能是
null-surface (用于限制medium的假想surface)，直到 tracing 到达non-null
surface 或者光源后就停止。</li>
</ul>
<p>​ 在开始介绍 radiative transfer equation 之前，我想提一下 Geometry
term 这个东西。</p>
<h3 id="geometry-term">2.2.1 Geometry Term</h3>
<p>​ 建议先了解一下这个知识：<a href="https://math.stackexchange.com/questions/1123045/integration-with-respect-to-a-measure">The
Integral With Respect to a
Measure</a>（其中nelv的回答。关于某种度量的积分，这里的measure说的并不是概率测度）。</p>
<blockquote>
<p>Think of it physically: each measure assigns different
<em>weights</em> to given sets: consider for example the particular case
<span class="math inline">\(dμ=df(x)=f&#39;(x)dx\)</span> for a well
behaved f(x). Here you can really see the difference between the
"ordinary" measure <span class="math inline">\(dx\)</span>, which does
not care about the location of the set, and <span class="math inline">\(f′(x)dx\)</span>, which indeed does!</p>
</blockquote>
<p>​ 也即：我们关心的微元，究竟表达了什么实际意义？nelv举的例子：对于普通
<span class="math inline">\(dx\)</span> 度量的积分问题来说： <span class="math display">\[
\begin{equation}
\int_0^1dx = \int_1^2dx = 1
\end{equation}
\]</span> ​ 而如果我们的度量不是 <span class="math inline">\(dx\)</span>，而是 <span class="math inline">\(df(x)\)</span>，则显然，上述积分的结果会变成：<span class="math inline">\(f(1) - f(0)\)</span>以及 <span class="math inline">\(f(2) -
f(1)\)</span>，两者是否相等取决于函数性质。将“度量”不同导致“积分形式”不同的想法迁移到
path tracing中，我们不难找到如下的例子：</p>
<div class="tabs" id="span-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#span-unique-name-1">投影固体角（projected solid angle）</a></li><li class="tab"><a href="#span-unique-name-2">irradiance积分</a></li></ul><div class="tab-content"><div class="tab-pane active" id="span-unique-name-1"><p>​ 上篇还是上上篇已经说过了。投影固体角是为了处理 <span class="math inline">\(\cos\theta\)</span> 项的一种表征。由于在
irradiance 积分中，有： <span class="math display">\[
\begin{equation}
\int_\Omega f(x_h, w_i, w_o)L_i(x_h, w_i)\cos\theta dw_i
\end{equation}
\]</span> ​ 上述 <span class="math inline">\(\cos\theta\)</span>
可以被消去，如果将立体角变为投影立体角。简单理解就是：由于立体角实际上是某个物体【张成的3D角度】在【单位球上的投影面积】（对应2D中某线段确定的弧长），那么这个面积可以投影到单位球中由物体表面法向量确定的圆盘上（由3D面积投影为2D面积），也即：
<span class="math display">\[
\begin{equation}
d w_i^{\perp} = \cos\theta dw_i
\end{equation}
\]</span> ​
这就是一种不同的度量，面积微元由投影微分立体角决定。积分空间也会对应改变为2D圆盘而非3D半球。</p></div><div class="tab-pane" id="span-unique-name-2"><p>​
一种更加复杂的情况，虽然这种情况之前已经多次讲过（BSDF/emitter采样）。观察公式
<span class="math inline">\(\eqref{lte}\)</span> 中的 irradiance
积分，不难发现积分空间是法向量确定的半球，度量是微分立体角。我们可以将其转换为另一种度量：对某一个面光源而言，面光源上每一点对空间中某一点的
irradiance
贡献。此处：对面光源上点进行积分使用的是【面积微元】，积分空间为【光源表面】（对应emitter
sampling），而公式 <span class="math inline">\(\eqref{lte}\)</span>中的
irradiance积分，其度量已经讲过（对应了BSDF
sampling）。两个度量之间存在转化关系，转化关系的示意图见 <a href="https://enigmatisms.github.io/2023/02/11/AdaPT-Monte-Carlo-Path-Tracer-II/">上一篇博客的Figure.3</a>。</p></div></div></div>
<p>​ 度量之间的转化关系非常重要，贯穿于 path tracing 的 importance
sampling，上次读论文时看到这么一句话：</p>
<blockquote>
<p>Converting from the solid angle×length product measure to the volume
measure requires multiplication by a corresponding geometry term G. <a href="#ref">[4]</a></p>
</blockquote>
<p>​ 也即，Geometry term 可以用作度量转换。在 PBR-book <a href="#ref">[3]</a> 中，有非常详细的 geometry term 用于度量转换的例子 <a href="https://www.pbr-book.org/3ed-2018/Light_Transport_I_Surface_Reflection/The_Light_Transport_Equation#TheSurfaceFormoftheLTE">14.4.3
The Surface Form of the
LTE</a>，这里就不浪费笔墨去拾人牙慧了。这也解答了我之前在
stackexchange.cg 上<a href="https://computergraphics.stackexchange.com/questions/13273/path-tracing-how-to-deal-with-ray-hitting-an-emitter/13304#13304">提问的一个疑惑</a>
（我自己写了回答）：为什么 <span class="math inline">\(L_e\)</span>
(emission项) 并不需要 distance attenuation 或者 <span class="math inline">\(\cos\)</span> term？因为 emission evaluation
使用的度量是立体角而非面积微元。<span class="math inline">\(L_e\)</span>
本身返回的就是某个方向的 radiance (radiance 在非 volume path tracing
情况下，在两个表面点之间是不变的)。</p>
<p>​ 在 geometry term 讨论的末尾，我想顺带写一下我对最近读的一篇好文章 <a href>[4]ACM ToG 2013</a> 中某些点的理解。以其论文中的公式 <span class="math inline">\((4)\)</span> 以及对应的 equiangular-sampling
方法为例子（我还没学到 bidirectional path
tracing，所以这部分的理解可能会有误） <span class="math display">\[
\begin{equation}\label{equi}
p(t_{dc} | b, d, w_{dc})\propto G(b, c) = 1/\Vert b - c\Vert^2
\end{equation}
\]</span></p>
<center>
<img src="/2023/02/18/AdaPT-Volumetric-Path-Tracer-I/a14147b9be0a8f4e8e3d8d89294df988.jpg" style="zoom: 40%;">
</center>
<center>
Figure 2. Equi-angular sampling 方法
</center>
<p>​ 所以为什么，采样的条件分布需要如公式 <span class="math inline">\(\eqref{equi}\)</span> 所示的
bc距离平方反比有关？其中隐含了度量的转换：我们实际在 <span class="math inline">\(w_{dc}\)</span> 方向的直线上采样【距离】，但条件是
--- 对于 vertex b
而言，采样结果应当在角度上呈均匀分布。【角度（3D）】与距离之间的转换，由
<span class="math inline">\(G(b, c)\)</span>
承担：距离越远，单位角度对应的线段长度越大，在某段距离微元内采样的概率就小了。由于是3D空间，故遵循平方反比（而非2D空间下的一次反比）。</p>
<p>​
此论文中还有很多采样条件分布的计算都与度量转换有关。转换成正确的度量，在正确的空间下积分才能得到正确的结果。</p>
<h3 id="rte">2.2.2 RTE</h3>
<p>​ RTE 本身的形式与 LTE很像，但考虑了光路上
radiance的增加（in-scattering &amp; emission）以及衰减（out-scattering
&amp; absorption）。由公式 <span class="math inline">\(\eqref{remain2}\)</span>
定义的传输率（transimittance）将在接下来的叙述中被写为 <span class="math inline">\(T_r\)</span>。则我们考虑光线穿过表面进入介质时，介质中某一点朝某一方向的入射
radiance:</p>
<center>
<img src="/2023/02/18/AdaPT-Volumetric-Path-Tracer-I/Screenshot from 2023-02-18 14-42-51.png" style="zoom:90%;">
</center>
<center>
Figure 3. 光线入射介质后的 radiance
计算示意图，图中过p0直线的左侧为介质内部[5]
</center>
<p>​ 则，某一点<span class="math inline">\(p\)</span>的入射 radiance
可以被写为： <span class="math display">\[
\begin{equation}\label{rte}
L_i(p, w) = T_r(p_0\rightarrow p)L_o(p_0, -w) + \int_d
T_r(p&#39;\rightarrow p)L_s(p&#39;, -w)dt
\end{equation}
\]</span> ​ 其中，<span class="math inline">\(p&#39; =p_0
-tw\)</span>，<span class="math inline">\(t\)</span> 在<span class="math inline">\([0, d]\)</span>（<span class="math inline">\(d\)</span> 为<span class="math inline">\(p_0\rightarrow
p\)</span>的距离）上积分。上式的等号右边有两项：</p>
<ul>
<li>第一项：代表了外部光线原本传输的部分在传输到 <span class="math inline">\(p\)</span> 过程中，消耗所剩的部分（<span class="math inline">\(T_r\)</span> 建模了向外的散射与吸收）</li>
<li>第二项：光线上每一点，都是一个光源（由散射介质会产生内散射的原因决定）。而光源发出的光，自然也需要经过与第一项一样的衰减。此项隐藏了一个积分
- 内散射估计积分：</li>
</ul>
<p><span class="math display">\[
\begin{equation}\label{in-scat}
L_s(p, w) =L_e(p, w) + \sigma_s(p, w) \int_{S^2} f_p(p, w_o, w)L_i(p,
-w_o)dw_o
\end{equation}
\]</span></p>
<p>​ 其中 <span class="math inline">\(S^2\)</span>
表示完整球面（介质嘛，就不是半球面了）。故可以看出公式 <span class="math inline">\(\eqref{rte}\)</span> 包含了所有的 ray-medium
interaction 操作。不过一般来说我们不考虑
emission（会发光的烟雾很炫啊）。</p>
<p>​ emmm，也没什么神秘的对不对？重点不在于理论，在于实现：公式 <span class="math inline">\(\eqref{rte}\)</span>
存在两个积分，则需要两次采样。我们将公式 <span class="math inline">\(\eqref{rte}\)</span> 重写为没有 emission
项的二重积分形式： <span class="math display">\[
\begin{equation}\label{rte2}
L_i(p, w) =  \int_d \int_{S^2} T_r(p&#39;\rightarrow p) \sigma_s(p, w)
f_p(p, w_o, w)L_i(p, -w_o)dw_odt
\end{equation}
\]</span> ​ 写为 Monte Carlo 积分的形式，并假设 <span class="math inline">\(\sigma_s\)</span> homogeneous： <span class="math display">\[
\begin{equation}\label{rte-mc}
L_i(p, w) = \frac{\sigma_s}{N}\sum_{i=1}^N \frac{T_r(p_i\rightarrow
p)}{\text{pdf}(p_i)} \frac{f_p(p, w_o, w)L_i(p, -w_o)}{\text{pdf}(w_o,
w|p_i)}
\end{equation}
\]</span> ​ 上式的采样过程是存在顺序的：首先需要采样空间中的点（由于
phase function
可能与空间位置有关，并且是否发生体散射而非表面interaction也与采样点的位置有关），采样完空间中的点后再采样方向。整个evaluation结果需要我们使用联合分布，联合分布则可以用条件分布与边缘分布表出，并且注意，在这种简单情况下（homogeneous），<span class="math inline">\((w_o, w)\)</span> 与 <span class="math inline">\(p_i\)</span> 是独立的。</p>
<h2 id="实现流程">2.3 实现流程</h2>
<p>​ PBR
book写得太好了，第15章非常清晰。从原始的理论到采样的实现以及算法的全流程，能让人完整地看明白，唯一的遗憾就是缺少一些
volumetric path tracing 的 variance reduction 方法。目前AdaPT
中的<code>vpt</code>分支已经被合并到 <code>master</code>
分支下，虽然有结果但噪声问题还是比较严重。根据<a href="#ref">[4]</a>，方差大可能是 unidirectional volumetric path tracer
无法避免的问题：</p>
<blockquote>
<p>Volumetric path tracing with explicit shadow connections suffer from
<strong>infinite variance</strong> when participating media surrounds
light sources.</p>
</blockquote>
<p>​ 根据我的实验结果发现，情况好像确实是这样：</p>
<table>
<colgroup>
<col style="width: 49%">
<col style="width: 50%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;">Null-surface with shadow
connections</th>
<th style="text-align: center;">Explicit shadow connections &amp; media
surrounds emitters</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><img src="/2023/02/18/AdaPT-Volumetric-Path-Tracer-I/pbr-box-cloud.png"></td>
<td style="text-align: center;"><img src="/2023/02/18/AdaPT-Volumetric-Path-Tracer-I/pbr-balls-20000.png"></td>
</tr>
</tbody>
</table>
<center>
Figure 4. AdaPT的一些渲染结果
</center>
<p>​ 可以看到，上图中的右图明显符合论文<a href="#ref">[4]</a>所说的情况：shadow connections +
光源被介质包裹。所以在20000轮迭代之后（共 trace
50亿条光线，允许的最大depth为25 bounces），仍然存在 shot
noises。而左图就是单纯地收敛慢。</p>
<p>​
虽然上述算法仍然存在收敛性上的问题，但至少在debug后（真有些只有我能写出来的脑瘫bug，让我怀疑我根本不适合写代码）能达到与
mitsuba
类似的输出结果。在实现的过程中也遇到一些问题（感觉卡住的地方），下面简要说一下。</p>
<h3 id="vpt-算法流程">2.3.1 VPT 算法流程</h3>
<p>​ 算法的主要逻辑如下，在循环开始后：</p>
<ol type="1">
<li>根据 throughput 判定是否停止。可用的策略有 RR, max iteration
限制以及 min_contribution 限制</li>
<li>ray intersection -- 计算 first intersection point
以及击中位置的法向量、击中物体的 obj_id</li>
<li>根据法向量与光线的关系，判定当前光线在 free space
中还是物体中：如果在物体中，光线与法向的夹角应当小于90°，否则大于90°</li>
<li>计算当前介质，如果 <code>in_free_space</code> = True，则用 world
medium，否则用 obj_id 对应的 BSDF内部的medium</li>
<li>进行自由程采样：
<ol type="1">
<li>判定当前介质是否为散射介质，如果不是散射介质（或者是非透明的BRDF），直接转到【步骤4】</li>
<li>根据指数分布采样平均自由程 <span class="math inline">\(t_{\text{mfp}}\)</span>:
<ol type="1">
<li><span class="math inline">\(t_{\text{mfp}}\)</span> 与 ray
intersection的下一表面距离 <span class="math inline">\(t_{\max}\)</span>
对比，如果 <span class="math inline">\(t_{\text{mfp}} &lt;
t_{\max}\)</span> 则设置 <code>is_mi</code> (is medium interaction) 为
True，否则为 False</li>
<li>根据 <code>is_mi</code> 的不同，计算这段距离的 transmittance:
如果是表面 interaction，只需要 <span class="math inline">\(T_r
/{\text{pdf}}\)</span>，否则还需要乘以 <span class="math inline">\(\sigma_s\)</span></li>
</ol></li>
<li>if <code>is_mi</code> == True: 得到介质交互点
<ol type="1">
<li>计算直接光照部分：如果光源与interaction
点在同一介质内，只要不遮挡一般没有问题，不在同一介质内则根据BSDF track
ray（光线尝试从当前位置出发去击打光源，路径上如果遇到了 null-surface
则继续计算，否则若遇到 non-null surface 则直接丢弃此光线，在 track ray
的过程中需要记录 accumulated transmittance）。直接光照的 contribution
计算结束后，加到当前 radiance 上。</li>
<li>计算传播，NEE：（主要调用 sample），找到下一次应该传播的方向（phase
function采样）以及 throughput。回到步骤1</li>
</ol></li>
<li>else: 得到表面 interaction点
<ol type="1">
<li>如同正常path tracer，shadow connection / emitter evaluation 以及
BSDF 方向采样</li>
</ol></li>
<li>在累加到结果 radiance 之前，throughput 首先乘以自由程采样中计算的
transmittance</li>
</ol></li>
</ol>
<p>​ 注意，由于暂时用不到MIS，与 Monte Carlo integration
有关的项都可以先除以对应的PDF后直接输出，不需要单独输出PDF（因为用不上）。故，所有的
transmittance 都需要除以对应的PDF：</p>
<ul>
<li>自由程采样时，根据采样结果计算路径的
transmittance，需要直接除以PDF，这没有什么好说的，毕竟采样是 Monte Carlo
方法的关键步骤。</li>
<li>track rays 时（用于 direct component
evaluation），我们需要计算的PDF是整条路上<strong>都不发生介质散射</strong>（也即方向改变）的PDF。这是由于，direct
component evaluation
的光线起始点、终止点是确定的。对于无介质问题而言，直接判断是否遮挡即可。有介质问题，除了遮挡（non-null
surface
intersection）之外，还必须使得散射不发生（方向不改变）。不过这种想法是很典型的
particle-based 的想法。</li>
</ul>
<h3 id="注意">2.3.2 注意</h3>
<div class="note danger"><p>Backward
tracing类方法，请按照物理过程发生的方向理解。举个例子，自由程采样的时候，如果按照
<span class="math inline">\(\text{eye}\rightarrow
\text{emitter}\)</span> 的方向理解，会很奇怪。与 path tracing
实现时类似，我们要按 <span class="math inline">\(\text{emitter}\rightarrow \text{eye}\)</span>
的方向：光入射以后，如何与介质交互，而非我的视线如何在介质中被弯折。后者在计算上并没有那么
intuitive。</p>
<p><strong>一开始我没有按照物理过程的顺序理解，实现过程中浪费了很多时间。大概是因为我太蠢了</strong></p>
</div>
<div class="note warning"><p>Direct component shadow connection 在 volumetric path tracing
中效率很低: 只要遇到 non-null surface 就会丢弃直接 shadow
ray。对于内部为散射介质的有表面物体而言（也即，不是烟雾），其内部
radiance 也就只能等 ray 出射后，在无介质空间中计算 direct component
或者击中光源来贡献了。</p>
</div>
<div class="note info"><p>Taichi 有 bug...，debug时我想跑得快一些，迁移到 windows上时，nested
struct 的成员函数死活无法调用。深入底层 python API
后也没找到问题，后面给人提 issue 去了...（确实应该是 python - Taichi
版本兼容性问题）。</p>
</div>
<hr>
<h2 id="iii.-值得记录">III. 值得记录</h2>
<ul>
<li>关于diffusive与density estimation:</li>
</ul>
<blockquote>
<p>Section <a href="https://www.pbr-book.org/3ed-2018/Light_Transport_III_Bidirectional_Methods/Stochastic_Progressive_Photon_Mapping.html#sec:photon-mapping-theory">16.2.2</a>
will introduce the concept of density estimation, which is used to
implement a rendering algorithm known as <em>stochastic progressive
photon mapping</em> (SPPM). The underlying density estimation that
algorithm uses works well on diffuse surfaces because scattered radiance
only depends on the surface position in this case to store a 2D radiance
discretization, but for glossy surfaces it becomes preferable to switch
to other techniques such as path tracing.</p>
</blockquote>
<ul>
<li>各通道不同如何进行采样: RGB 三通道有不同的 <span class="math inline">\(\sigma_t\)</span> 如何采样？</li>
</ul>
<blockquote>
<p>However, the attenuation coefficient <span class="math inline">\(\sigma_t\)</span> in general varies by wavelength.
It is not desirable to sample multiple points in the medium, so a
uniform sample is first used to select a spectral channel i; the
corresponding scalar value <span class="math inline">\(\sigma_t^i\)</span> is then used to sample a
distance along the distribution.</p>
</blockquote>
<ul>
<li>Importance sampling heterogeneous medium (<span class="math inline">\(\sigma_t\)</span> 并非空间均匀)</li>
</ul>
<blockquote>
<p>The most commonly used method for importance sampling Equation
(15.13), is known as <strong>ray marching</strong></p>
</blockquote>
<p>​
以下是拓展了解，我们并不需要立即知道（非同质介质本身就比较困难）。对于非同质介质（注意，isotropic
/ anisotropic 为各向同/异性，homo/hetero
为同质/异质）介质而言，有几种处理办法：</p>
<ul>
<li>regular tracking: 对于每一个voxel，都进行同质假设，采用homogeneous
介质的方法</li>
<li>ray marching: 细分区间 <span class="math inline">\([0,
t_{\max}]\)</span>。在每个细分的区间上做同质假设，则可以估计整个区间上的
<span class="math inline">\(\sigma_t\)</span>
近似分布，用逆变换采样可以做到比 regular tracking
更好的采样（但是，是有偏估计，很多时候效果都不好）</li>
<li>delta tracking:</li>
</ul>
<blockquote>
<p>an alternative unbiased approach proposed by Woodcock et al. (<a href="https://www.pbr-book.org/3ed-2018/Light_Transport_II_Volume_Rendering/Further_Reading.html#cite:Woodcock1965">1965</a>)
that was originally developed to simulate volumetric scattering of
neutrons in atomic reactors. This technique is known as <em>delta
tracking</em> and is easiest to realize when the attenuation coefficient
<span class="math inline">\(\sigma_t\)</span> is monochromatic.</p>
</blockquote>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://www.pbr-book.org/3ed-2018/Volume_Scattering">PBR-book:
Chapter 11 Volume Scattering</a></p>
<p>[2] <a href="https://www.pbr-book.org/3ed-2018/Light_Transport_II_Volume_Rendering/The_Equation_of_Transfer">PBR-book:
15.1 The Equation of Transfer</a></p>
<p>[3] <a href="https://www.pbr-book.org/3ed-2018/Light_Transport_I_Surface_Reflection/The_Light_Transport_Equation#sec:pathspace">PBR-book:
The Light Transport Equation</a></p>
<p>[4] <a href="https://scholar.google.com.hk/scholar?hl=zh-CN&amp;as_sdt=0%2C5&amp;q=Joint+Importance+Sampling+of+Low-Order+Volumetric+Scattering&amp;btnG=">Georgiev
I, Krivanek J, Hachisuka T, et al. Joint importance sampling of
low-order volumetric scattering[J]. ACM Trans. Graph., 2013, 32(6):
164:1-164:14.</a></p>
<p>[5] <a href="https://www.pbr-book.org/3ed-2018/Light_Transport_II_Volume_Rendering/The_Equation_of_Transfer">PBR-book:
The Equation of Transfer</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>CG</tag>
        <tag>renderer</tag>
        <tag>Taichi lang</tag>
      </tags>
  </entry>
  <entry>
    <title>AdaPT - Monte Carlo Path Tracer II</title>
    <url>/2023/02/11/AdaPT-Monte-Carlo-Path-Tracer-II/</url>
    <content><![CDATA[<h1 id="ada-path-tracer-ii">Ada Path Tracer II</h1>
<hr>
<p>​ 本文为 <a href="https://enigmatisms.github.io/2023/02/09/AdaPT-Monte-Carlo-Path-Tracer-I/">Ada
Path Tracer I</a> 的续文。在上一篇博客中，我只是说明了 Monte Carlo
积分在path tracing中的应用以及path
tracing的理论、实现流程。并没有深入讨论 PDF
如何计算、采样如何进行、PDF的选择如何影响结果以及如何使得 path tracer
具有更高的效率。笔者在本文中对上文未讨论清楚的问题进行分析。分析过程中我果真也发现自己之前的某些理解是不对的，实现时出了问题，例如在：Lambertian
BSDF的实现、MIS 对无面积光源的处理、MIS weight计算等等方面均有瑕疵。</p>
<p>​ 本部分学习的结束标志着【基本 path tracer
实现】的完成（V1.0）。除了对BSDF进行小的修改之外（表面反射定义过于简单），下一步我将主要围绕两部分进行深入研究：</p>
<ul>
<li>Bidirectional path tracing。双向 tracer 对处理 directional /
collimated
光源十分有用，并且在caustic建模上有着更好的效果（虽然不是最好的）</li>
<li>Volumetric path tracing。主要研究匀质介质散射吸收。</li>
</ul>
<center>
<img src="/2023/02/11/AdaPT-Monte-Carlo-Path-Tracer-II/pbr-balls-multi.png" style="zoom: 80%;">
</center>
<center>
Figure 1. AdaPT
2min增量式渲染（CPU，GPU时间除以8-10）：点光源/顶部面光源与球面光源
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-pdf-confusion">II. PDF Confusion</h2>
<h3 id="讨论对象分析">2.1 讨论对象分析</h3>
<p>​ 有如下问题需要明确：Path tracer中 PDF
对结果的影响是什么？选取不正确的PDF是否会导致结果成为有偏估计？PDF针对分子中哪一项起作用？</p>
<p>​ 已知MC积分公式： <span class="math display">\[
\begin{equation}\label{mc_est}
\frac 1N \sum_{i=1}^N \frac{f(X_i)}{p(X_i)}
\end{equation}
\]</span> ​ 求期望可以得到： <span class="math display">\[
\begin{equation}\label{mc}
\frac 1N \sum_{i=1}^N E\left(\frac{f(X_i)}{p(X_i)}\right)
\end{equation}
\]</span> ​ 而上式内部的期望为： <span class="math display">\[
\begin{equation}\label{exp}
E\left(\frac{f(X_i)}{p(X_i)}\right) = \int_\Omega
\frac{f(x)}{p(x)}p(x)dx
\end{equation}
\]</span> ​ 注意，根据随机变量函数的期望公式： <span class="math display">\[
E(f(X)) = \int_\Omega f(x)p(x)dx
\]</span> ​ 可知公式<span class="math inline">\(\eqref{exp}\)</span>求解的期望是随机变量<span class="math inline">\(x\)</span>的函数<span class="math inline">\(f(x)/p(x)\)</span>的期望。其中的<span class="math inline">\(p(x)\)</span>应当仍然是<span class="math inline">\(x\)</span>的分布。那么，在Monte
Carlo积分中，或者在某个 vertex 处，<span class="math inline">\(x\)</span> 代表了什么意义？我们举个例子来说明：在
direct component estimation （next event部分），我们采样M条shadow
rays。则PDF是：<span class="math inline">\(p(x_l|e_i)p(e_i)\)</span>，注意此处的PDF是定义在面积微元上的（differential
area），而一般来说，我们需要的是“某个方向的PDF”（也即立体角定义）。首先我们需要记住立体角的物理概念：</p>
<blockquote>
<p>The point from which the object is viewed is called the apex of the
solid angle, and the object is said to subtend its solid angle at that
point.</p>
</blockquote>
<p>​ 接下来可以进行推导，见下图：</p>
<center>
<img src="/2023/02/11/AdaPT-Monte-Carlo-Path-Tracer-II/c403f4fb9d8aa590130033b601d2f54a.jpg" style="zoom: 45%;">
</center>
<center>
Figure 2. 微分立体角定义下的PDF与微分面积定义下的PDF（非光源采样）
</center>
<center>
<img src="/2023/02/11/AdaPT-Monte-Carlo-Path-Tracer-II/a83efdf5dd11f6681480ff1779c4c29c.jpg" style="zoom:45%;">
</center>
<center>
Figure 3. 微分立体角定义下的PDF与微分面积定义下的PDF（光源采样 -
实际上与上一情况类似）
</center>
<p>注意我们在direct component estimation 中，我们的实际估计目标是：
<span class="math display">\[
\int_\Omega f_r(x, w_i, w_o)L_d(x, w_i)\cos\theta dw_i\rightarrow
\frac{1}{N}\sum_{i=1}^N\frac{f_r(x, w_i, w_0)L_d(x, w_i)\cos\theta}{p}
\]</span> ​
也即我们实际应该获知各个方向上（微分立体角）的入射情况。而直接采样光源（特别是面光源）得到的PDF并不是定义在“方向上”的，而是在面积上的（面光源上某个微分面积与击中位置张成立体角），故应当进行转化。下面给出上式中分母<span class="math inline">\(p\)</span>的形式。由于<span class="math inline">\(p\)</span>实际上由面积定义的PDF转化而来，并且注意我们使用的并不是投影立体角
--- 我们需要的就是某一方向的PDF。<span class="math inline">\(p\)</span>
自然应该是 <span class="math inline">\(p(w_i)\)</span>
的形式，个人认为这与随机变量函数的期望计算有一定关系：随机变量是什么就用什么PDF（此处随机变量是立体角而不是投影立体角），并且在MIS中，我们需要与BSDF
sampling使用同一域下的PDF（BSDF
sampling使用立体角而非投影立体角）。非投影立体角下，<span class="math inline">\(p(w_e)\)</span>应该是： <span class="math display">\[
\begin{equation}\label{convert}
p(x_l|e_i)p(e_i) \frac{\Vert x_l - x\Vert^2}{\cos(w_o, n_e)}
\end{equation}
\]</span> ​
故在笔者的实现内仅仅使用了光源的normal，而没有使用击中点的normal。</p>
<p>​ 故综合以上的例子来看，公式<span class="math inline">\(\eqref{mc}\)</span>中的PDF到底是谁的PDF？就目前笔者的理解而言，笔者认为是【方向】。Path
tracing
中的积分问题几乎都可以归结为在方向上的积分（而且有时必须归结为在方向上的问题，如MIS中统一在立体角方向域上讨论）。我们不妨进一步讨论BSDF常用的两个方法中，返回的PDF：</p>
<ul>
<li><code>sample</code>
方法：由BSDF采样获得反射、透射方向以及对应的PDF</li>
<li><code>pdf</code> 方法：直接衡量某个方向的PDF，用以MIS</li>
</ul>
<p>​ 既然以上两种方法都是在衡量某个方向的PDF，那么为什么诸如 Lambertian
这样的BSDF，以上两个函数返回的PDF却与入射方向有关（cosine
weighted）？按理来说，Lambertian BSDF
向半球内的任意方向反射的可能都应相等。</p>
<div class="note danger"><p>至于为什么Lambertian PDF不是 <span class="math inline">\(1/2\pi\)</span> 而是 <span class="math inline">\(\cos\theta /\pi\)</span>，原因貌似是 importance
sampling... 我们大可以使用<span class="math inline">\(1/2\pi\)</span>对应的 uniform hemisphere
sampling，但效率不如 cosine weighted hemisphere sampling 高。</p>
</div>
<p>​ 不过，这样的PDF是否会导致有偏估计？这就设计到 importance sampling
里的一些知识了。不过在此之前，请记住：</p>
<div class="note primary"><p>Lambertian uniform PDF 为<span class="math inline">\(1/2\pi\)</span>是针对<span class="math inline">\(w\)</span>（立体角）而言，如果变换到球坐标系下，应当为<span class="math inline">\(p(\theta, \phi) = \sin\theta
/\pi\)</span>。其他同理，故一定要
<u><strong>明确PDF在哪个空间下讨论</strong></u>。</p>
<blockquote>
<p>It is important to be clear which PDF is being evaluated—for example,
for a direction on the hemisphere, we have already seen these densities
expressed differently in terms of solid angle and in terms of <span class="math inline">\((\theta, \phi)\)</span>. For hemispheres (and all
other directional sampling), these functions return values with respect
to solid angle. For the hemisphere, the solid angle PDF is a constant
<span class="math inline">\(p(w) = 1/2\pi\)</span>. <a href="#ref">[1]</a></p>
</blockquote>
<p>此外，在sampling阶段，PDF的选择是任意的。但一定需要保证：<strong><u>PDF</u></strong>
的计算结果与 <strong><u>采样方法</u></strong>
是一致的，这一点将在importance sampling中详谈。</p>
</div>
<h3 id="importance-sampling">2.2 Importance Sampling</h3>
<blockquote>
<p>As we will see in Section 13.10, it is often useful to sample from a
distribution that has a shape similar to that of the integrand being
estimated. For example, because the scattering equation weights the
product of the BSDF and the incident radiance with a cosine term, it is
useful to have a method that generates directions that are more likely
to be close to the top of the hemisphere, where the cosine term has a
large value, than the bottom, where the cosine term is small. <a href="#ref">[1]</a></p>
</blockquote>
<p>​ Importance sampling
其实是老朋友了，还记得在特龙的《概率机器人》中，particle
filter里就有“目标分布”和“建议部分”之说，并且作者称：建议分布越接近目标分布，采样效果越好，收敛越快。由于都是
Monte Carlo 方法（PF定位是 Monte Carlo 定位，Path Tracing 是 Monte Carlo
积分），故Path Tracing中如果可以获得类似公式<span class="math inline">\(\eqref{mc_est}\)</span>中的分子项的PDF，则可以提升采样效率。</p>
<p>​ 不过需要记住的是：importance sampling
的思想内核是“贡献（contribution）大的部分多采样，贡献小的部分少采样”。这完全不同于“值（value）大的地方多采样，值小的地方少采样”，我们举与PBR
book同样的例子：scattering equation： <span class="math display">\[
\int_\Omega f_r(x, w_i, w_o)L_d(x, w_i)\cos\theta dw_i
\]</span> ​ 上式中真正产生贡献的是<span class="math inline">\(f_r\times
\cos\theta\)</span>，在此乘积项大的位置应当多采样，小的位置少采样（毕竟小的位置贡献小，极端一点的例子就是镜面反射）。采样时，我们既可以选择与<span class="math inline">\(f_r\)</span>相似的 PDF，也可以选择与<span class="math inline">\(f_r\times \cos\theta\)</span>
相似的PDF，这是因为，在公式<span class="math inline">\(\eqref{exp}\)</span>中，分母人为除的PDF将会与当前sample出现的概率抵消。也即：</p>
<div class="note primary"><p>不考虑效率、认为样本数量无穷时，PDF可以是任意的，只要采样的方法与计算的PDF之间一致即可。（Dirac-delta分布除外）</p>
</div>
<p>​ 也即，我们如果使用<span class="math inline">\(1/2\pi\)</span>作为PDF，就必须要使用 uniform
hemisphere sampling，否则“抵消”将无法进行。在 Monte Carlo
积分估计式<span class="math inline">\(\eqref{mc_est}\)</span>
中，这种抵消是隐式的（所以我花了很长时间才明白）！【样本<span class="math inline">\(X_i\)</span>】按PDF <span class="math inline">\(p(x)\)</span>定义的概率 <span class="math inline">\(P(X)\)</span> 生成了出来，样本 <span class="math inline">\(x_i\)</span>
或者与此类似的样本出现的频率（可能性）其实已经包含了PDF 信息<span class="math inline">\(p(x)\)</span>，试想一个3面是4，余下三面为1、2、3的骰子，我们对其采样（投掷），得到的结果<span class="math inline">\(f(X_i)\)</span>
确实看似不包含骰子的信息，但1、2、3、4在多次采样中出现的次数却包含PDF信息。</p>
<p>​
故，有偏估计？有偏估计只会出现在采样方式与PDF不符的情况中，至少对于<code>sample</code>方法来说是这样的。<code>sample</code>方法获得的PDF并不一定与BSDF的形状相关，还可能与其他附加项有关（cosine
term）。那么这里就有一个新的问题：<code>pdf</code>方法返回的PDF是否可以与其他项有关？因为我个人的想法是这样的：<code>pdf</code>项只会使用在MIS中，MIS需要联系两种不同的域，如BSDF
sampling (solid angle)和light sampling (differential area)，而 light
sampling PDF 在经过公式<span class="math inline">\(\eqref{convert}\)</span>等号右边的分数项变换后将得到立体角定义下的
PDF，此 PDF 是否只应当与 BSDF
项相关？毕竟按照直觉理解，MIS就是为了针对【光源】以及【BSDF】都尝试计算某个方向入射是否可能，加上
cosine term 就不单单是在衡量BSDF而是在衡量 interactions
的整体贡献了。此问题的答案我们将在MIS中进行分析。</p>
<h3 id="mis">2.3 MIS</h3>
<h4 id="基本概念">2.3.1 基本概念</h4>
<p>​ Multiple importance sampling 是一种“信息融合”方法。它在 path tracing
中的一个最简单用法就是融合【BSDF sampling】以及【Emitter
sampling】，融合的要求是：</p>
<blockquote>
<p>Expressing all densities with respect to the same measure. <a href="#ref">[2]</a></p>
</blockquote>
<p>​ 下面给出 path tracing 中的两种最常用的 ray direction 采样方法：</p>
<div class="tabs" id="span-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#span-unique-name-1">BSDF Sampling</a></li><li class="tab"><a href="#span-unique-name-2">Emitter Sampling</a></li></ul><div class="tab-content"><div class="tab-pane active" id="span-unique-name-1"><p>​
BSDF采样的意思就是：根据BSDF进行采样，采样更倾向于在BSDF值大的位置进行。这样做的好处非常显然：假设BSDF本身是一个窄带分布，在衡量直接光照时如果只是在光源上取点，这些点很有可能落在BSDF峰值区域外。这将会导致我们在低贡献区域浪费大量
samples。则可知，在BSDF分布较窄、光源较大时，BSDF采样结果较好。</p></div><div class="tab-pane" id="span-unique-name-2"><p>​ Emitter采样是现阶段
AdaPT估计直接光照时的采样方法。由于对于漫反射表面而言，入射光线经过反射后将分布在整个半球上，当光源较小时（特别是点光源时），通过BSDF采样可能很难击中光源。那么我们也可以直接在光源上选点，使用所选点以及当前击中点构建shadow
rays。这种方法在BSDF分布较宽、光源较小时的采样结果较好。</p></div></div></div>
<p><span id="fig3"></span></p>
<center>
<img src="/2023/02/11/AdaPT-Monte-Carlo-Path-Tracer-II/mis1.png" style="zoom:80%;">
</center>
<center>
Figure 4. MIS结合两种采样方法有助于提升渲染质量
</center>
<p>​
复杂场景自然可能存在大/小光源以及光滑/粗糙/透射/散射的BSDF，则我们最好是找到一种方法，结合两种采样方法得到结果。这里有两种方案：</p>
<ul>
<li>简单方案：对于采样过程，我们只使用 emitter
sampling。但在结果计算阶段，原始 Monte Carlo 积分将用<span class="math inline">\(p(x)\)</span>除<span class="math inline">\(f(x)\)</span>，而此方案中，我们对结果进行加权，不计算<span class="math inline">\(f(x)/p(x)\)</span>，而是计算<span class="math inline">\(w(x)f(x)\)</span>。<span class="math inline">\(w(x)\)</span>称为 MIS 权重。</li>
<li>复杂方案：采样过程同时实现 BSDF sampling 以及 emitter
sampling，对于两种方法采样的结果，分别计算权重，最后的结果为：<span class="math inline">\(w_1(x)f_{\text{BSDF}}(x)+w_2(x)f_{\text{emitter}}(x)\)</span>。仅从理论上看，这样的方法应该可以有更好的收敛性，因为上一方案仅仅在BSDF/emitter
PDF结果冲突时进行重加权，并不帮助获得更好的样本。例如我们不管怎么在光滑表面上采样，落在specular
lobe中的样本总是不够多的，虽然最后的权重低，不会有太大错误，但无助于加速收敛。本方案确实也相对复杂，一条shadow
rays需要两次 ray intersection
操作。不过我们可以通过随机策略选择的方式，随机使用其中一种策略以降低计算量。</li>
</ul>
<p>​
如果每次从多种采样方法的每种方法中采样至少1个样本，则对应方法被成为“multi-sample
estimator”<a href="#ref">[2]</a>，形式如下。其中，<span class="math inline">\(n_i\geq 1\)</span> 为第i种采样方法的样本数，<span class="math inline">\(w_i(·)\)</span>为对应方法的权重函数。 <span class="math display">\[
\begin{equation}\label{multi}
F = \sum_{i=1}^n\frac
{1}{n_i}\sum_{j=1}^{n_i}w_i(X_{i,j})\frac{f(X_{i,j})}{p_i(X_{i,j})}
\end{equation}
\]</span> ​
以上方法在满足一定条件下一定可以根据每一种无偏采样估计方法构建新的无偏估计方法，基本条件为：(1)
<span class="math inline">\(\sum_i w_i(x) = 1, \text{ if } f(x)\neq
0\)</span>， (2) <span class="math inline">\(w_i(x) = 0, \text{ if }
p_i(x) = 0\)</span>。具体的证明以及推导见 <a href="#ref">[2]</a></p>
<p>​
如果每次随机选择某种采样方法，采样一个样本，则对应方法被称为“one-sample
estimator”<a href="#ref">[2]</a>。AdaPT与mitsuba(2/3)采用的则是这种方法，但区别是
mitsuba 使用的是 power heuristic 而 AdaPT 采用的是 balance
heuristic（之后会说）。具体形式如下： <span class="math display">\[
\begin{equation}\label{mono}
F = \frac{w_I(X_I) f(X_I)}{c_I p_I(X_I)}
\end{equation}
\]</span> ​ <span class="math inline">\(I\)</span>
为随机变量，表示随机选择多种采样策略中的一种，<span class="math inline">\(c_I\)</span> 为选择策略<span class="math inline">\(I = i\)</span>
的概率。。AdaPT与mitsuba(2/3)采用的方法为 one-sample
的极端情况：只用一种方法进行sampling，但对sampling结果进行MIS
加权。相当于emitter、BSDF
sampling同时存在，记为策略I与II，而选择策略I的概率为1，选择策略2的概率为0。</p>
<h4 id="heuristics">2.3.2 Heuristics</h4>
<p>​ 权重函数的选择对于结果的方差有很大的影响。最极端的两个例子：</p>
<ul>
<li>某一策略的权重为1，其他策略为0。相当于固定某一种策略进行采样，这当然会引起一些问题，见<a href="#fig3">图4</a></li>
<li>策略权重一致，假设有N种策略，则每个策略的权重为常数 <span class="math inline">\(1/N\)</span>。这种... 并不好，由于方差具有可加性<a href="#ref">[2]</a></li>
</ul>
<p>​ 下面，笔者不加证明地给出一个较好的权重启发函数，其被称为“balance
heuristic”: <span class="math display">\[
\begin{equation}
w_i(x)=\frac{n_ip_i(x)}{\sum_k n_kp_k(x)}
\end{equation}
\]</span> ​ 也即：假设某个样本<span class="math inline">\(x\)</span>原本来自策略<span class="math inline">\(i\)</span>，我们不仅需要计算样本在此策略下被采样出的PDF，也需要计算在其他策略下被采样的PDF（所以<code>pdf</code>方法就有用了），最后的权重是本策略PDF在所有策略PDF之和中的比重。这样的函数在机器学习领域比较常见（可能会包装一下，比如softmax），所以很直观，其背后的intuition（话说，这个词翻译过来就是没那个味道）也很合理：如果某个策略拥有较大的PDF，而其他策略相对较小，则优先选用对应策略。</p>
<p>​ 注意，在one-sample
的极端情况中，有些策略存在但从来不进行采样，但这样的PDF也是需要计入的。例如AdaPT与mitsuba中，在计算直接光照时都使用
emitter sampling，但采样结果都会用BSDF <code>pdf</code> 计算BSDF
PDF。最后的权重则为： <span class="math display">\[
\begin{equation}\label{weights}
w_{\text{AdaPT}} = \frac{P_{\text{emitter}}}{P_{\text{emitter}} +
P_{\text{BSDF}}},w_{\text{mitsuba}} =
\frac{P^2_{\text{emitter}}}{P^2_{\text{emitter}} + P^2_{\text{BSDF}}}
\end{equation}
\]</span> ​ <a href="#ref">[2]</a> 分析了 balance heuristic
与其他heuristic函数的方差关系，本文在此处引用其公式： <span class="math display">\[
\begin{equation}
V[F_{\text{balance}}] - V[F] \leq \left(\frac{1}{\min_i n_i} -
\frac{1}{\sum_i n_i} \right)\mu^2
\end{equation}
\]</span> ​ 其中<span class="math inline">\(\mu =
E[F]\)</span>，也即需要估计的积分。一般来说，balance heuristic
已经是一个很好的heuristic函数了，其他heuristic函数相对 balance heuristic
而言具有方差下界（方差自然是越小越好，但就算是下界也差不了多少）。</p>
<p>​ 其他的 heuristic 函数就深入了，我只简单讲讲其中的power
heuristic。power heuristic函数正如公式<span class="math inline">\(\eqref{weights}\)</span>中 mitsuba
部分，它在原有的PDF上进行了幂操作。背后的intuition是：希望PDF变小的速度更快，以使得某一小PDF策略对权重产生的影响变得更小。具体的案例分析见<a href="#ref">[2]</a>的【9.2.3.1 Low-variance problems: examples and
analysis】。在这里，我不得不说，英语确实很重要，图形学有很多很棒的资料都没有中文翻译。那些教育局的领导拍拍脑袋就觉得高考取消英语有助于提高学生对于传统文化的认同与民族自信心，这种想法纯属多余，对理工类学生来说尤其如此。如果自信不是比出来的，而是闭门造车养出来的，那这种自信无疑非常脆弱。</p>
<p>​ 不过<a href="#ref">[2]</a>中也分析了，在 one-sample
的情况下，balance heuristic 的表现将比 power heuristic
好（所以为什么mitsuba不用呢）。</p>
<h4 id="上文问题的答案">2.3.3 上文问题的答案</h4>
<blockquote>
<p><code>sample</code>方法获得的PDF并不一定与BSDF的形状相关，还可能与其他附加项有关（cosine
term）。那么这里就有一个新的问题：<code>pdf</code>方法返回的PDF是否可以与其他项有关？</p>
</blockquote>
<p>​
答案是，主不在乎。对MIS而言，PDF只需要是对同一定义域下的某个随机变量而言即可。MIS权重只是一个系数，只要满足条件就不会影响无偏估计性。加cosine项一般意味着
BSDF PDF的峰值整体变窄了（<span class="math inline">\(f_r \times
\cos\theta\)</span> 只会比 <span class="math inline">\(\cos\theta\)</span>
窄），从直觉上理解也即在此情况下，glossy
reflection边缘（与入射与法向角度较大时）更倾向于使用 emitter
sampling。这也是合理的，毕竟 glossy reflection 的占比与 diffusive
reflection 占比在边缘处很接近。</p>
<hr>
<h2 id="reference">Reference</h2>
<p><span id="ref"></span></p>
<p>[1] <a href="https://pbr-book.org/3ed-2018/Monte_Carlo_Integration/2D_Sampling_with_Multidimensional_Transformations">PBR-Book:
13.6 2D Sampling with Multidimensional Transformations</a></p>
<p>[2] <a href="https://graphics.stanford.edu/courses/cs348b-03/papers/veach-chapter9.pdf">Stanford
graphics: Chapter 9 Multiple Importance Sampling</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>CG</tag>
        <tag>renderer</tag>
        <tag>Taichi lang</tag>
      </tags>
  </entry>
  <entry>
    <title>AdaPT - Monte Carlo Path Tracer I</title>
    <url>/2023/02/09/AdaPT-Monte-Carlo-Path-Tracer-I/</url>
    <content><![CDATA[<h1 id="ada-path-tracer-i">Ada Path Tracer I</h1>
<p>​ Path
tracing背后的概率与数学理论较为复杂，如果不深入理解则很难进行正确的实现，更勿论在此基础上进行创新了。结合笔者在实现过程中的一些体会，笔者认为非Whitted光线追踪渲染器有一个这样的特点：即使是很大的逻辑错误可能也很难使用定性的方法观察出来，最后的错误输出可能与正确输出仅有很小的差别，甚至有的时候根本看不出来（例如，算法收敛慢时我可能倾向于认为是自己没有用太多的variance
reduction方法以及深入的采样技术，而不会认为我代码有逻辑错误）。故本文作为
Path Tracing
系列的第一部分文章，将尽可能深入讨论背后的理论知识以及其理解。理解是为实现、创新服务的，任何不到位的地方都将导致实现过程中的卡顿，故此处我将尽力覆盖这两周用零碎事件写<a href="https://github.com/Enigmatisms/AdaPT">渲染器:
AdaPT</a>时所遇到的问题。</p>
<blockquote>
<p>写文档是很烦人的一件事，如果我本身很闲，不用为了各种学业、科研、个人资本等等事情考虑的话，我当然还是非常愿意写博客、写文档的。可惜写博客写文档从现在来看并没有实际的价值，只是我个人的自嗨。
--- 2023.2.8 何千越</p>
</blockquote>
<table>
<colgroup>
<col style="width: 51%">
<col style="width: 48%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;">"The cornell spheres"</th>
<th style="text-align: center;">"The cornell boxes"</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><img src="/2023/02/09/AdaPT-Monte-Carlo-Path-Tracer-I/adapt-cornell-sphere.png"></td>
<td style="text-align: center;"><img src="/2023/02/09/AdaPT-Monte-Carlo-Path-Tracer-I/adapt-cornell-box.png"></td>
</tr>
</tbody>
</table>
<center>
Figure 1. Ada-Path-Tracer 渲染结果（20s内）
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-基本概念与基本应用">II. 基本概念与基本应用</h2>
<h3 id="monte-carlo积分">2.1 Monte Carlo积分</h3>
<p>​
一般来说，积分要比求导困难一些。这是因为很多函数（作为导数）的原函数很难，而与导数不同的是，数值导数可能往往只需要两个值就能近似，积分则可能需要巨量值，<strong>尤其</strong>
是在高维空间中（多重积分）。</p>
<p>​
考虑到随机算法有时可以加速某些迭代类算法的收敛，在积分计算问题上，我们也可以尝试使用随机算法。下面引出问题：设待估计函数
<span class="math inline">\(f(x)\)</span> 在区间 <span class="math inline">\([a, b]\)</span>上的积分为： <span class="math display">\[
I = \int_a^b f(x) dx
\]</span> ​ 设有一随机估计器<span class="math inline">\(\hat{I}\)</span>，此估计器用于估计<span class="math inline">\(I\)</span>，则<span class="math inline">\(\hat
{I}\)</span> 应当是无偏估计。并且我们希望 <span class="math inline">\(\hat{I}\)</span>
是最有效的估计，也即多次估计的方差最小（这个问题将在第三章讨论）。不难看出，如下估计子是无偏的：
<span class="math display">\[
\hat{I}=\frac{1}{N}\sum_{i=1}^N\frac{f(X_i)}{p(X_i)}
\]</span> ​ 根据如下推导可以非常轻易地获知，注意<span class="math inline">\(f(X_i)\)</span> 是随机变量，<span class="math inline">\(p(X_i)\)</span>为随机变量<span class="math inline">\(X_i\)</span>取值一定时的PDF。 <span class="math display">\[
\begin{align}
E(\hat{I}) &amp;= E\left( \frac{1}{N}\sum_{i=1}^N\frac{f(X_i)}{p(X_i)}
\right)=\frac{1}{N}\sum_{i=1}^N E\left(\frac{f(X_i)}{p(X_i)} \right)\\
&amp;=\frac{1}{N}\sum^N \int_\Omega \frac{f(x)}{p(x)}p(x)dx =
\frac{1}{N}\sum^N \int f(x)dx = \int f(x) dx \label{der1}
\end{align}
\]</span> ​ 虽然，除以PDF这种事情...
并不是一眼就能知道其背后的数学直觉的。关于数学直觉，外网有很多解释Monte
Carlo积分的文章，这里只讲一种最简单的入门级理解方法：假设<span class="math inline">\(f(X_i)\)</span>在<span class="math inline">\([a,
b]\)</span>上均匀分布，那么PDF就成了<span class="math inline">\((b-a)^{-1}\)</span>，除以<span class="math inline">\(p(x)\)</span>则成了乘以<span class="math inline">\((b - a)\)</span>。则每个样本相当于计算<span class="math inline">\(f(x) \times (b -
a)\)</span>（某个矩形的面积），进行多次面积估计并平均则可以得到结果。如果把均匀分布换为其他任意分布也有一样的结果。Monte
Carlo积分非常有用，它使得我们可以处理难以进行积分的函数。</p>
<h3 id="在光线追踪中的应用">2.2 在光线追踪中的应用</h3>
<p>​ 难以积分的函数？举个例子，空间中某一点的 Radiance 计算公式： <span class="math display">\[
\begin{equation}\label{radiance}
L_o(x, w_o) = L_e(x, w_o) + \int_\Omega L_i(x, w_i) f_r(w_i, w_o, x)
\cos\theta dw_i
\end{equation}
\]</span> ​ 其中<span class="math inline">\(w_i\)</span>为入射光方向，<span class="math inline">\(w_o\)</span>为出射方向，<span class="math inline">\(x, n\)</span>分别为光线击中点与击中点法向量。<span class="math inline">\(\cos(a,
b)\)</span>代表了两个向量之间的夹角余弦值（也即归一化后的内积），<span class="math inline">\(L_{e}\)</span>则为击中点为<span class="math inline">\(x\)</span>，入射方向为<span class="math inline">\(w_i\)</span>的
radiance。上式是将各个入射方向的光进行积分：先按cosine规则进行衰减，后按照BSDF进行“入射到出射的mapping”加权积分。公式<span class="math inline">\(\eqref{radiance}\)</span>右边的“各方向入射irradiance”部分是<strong>很难衡量的</strong>：多光源，多次反射，遮挡（包括shadowing以及masking），解析解绝对不要想。则我们可以考虑使用Monte
Carlo积分，把积分换为： <span class="math display">\[
\begin{equation}\label{discrete}
\frac{1}{N}\sum_{j=1}^N  \frac{L_{i,j}(x, w_{i,j}) f_r(w_{i,j}, w_o, x)
\cos\theta}{p(?)}
\end{equation}
\]</span> ​ 如果，我们可以设法计算<span class="math inline">\(L_{i, j},
f_{r}\)</span> 以及 <span class="math inline">\(p(?)\)</span>，一切将变得“轻松”。好，那么
<strong>p(?)</strong> 究竟是什么？我应该求解什么的分布？是<span class="math inline">\(w_i\)</span>，还是<span class="math inline">\(L_{i,j}(x, w_{i,j}) f_r(w_{i,j})\)</span>
还是整个分子项？（注意<span class="math inline">\(\cos\theta\)</span>也是<span class="math inline">\(w_i\)</span>的函数，因为<span class="math inline">\(\theta\)</span>是 <span class="math inline">\(w_i\)</span> 与法向量 <span class="math inline">\(n\)</span> 的夹角），三种情况的分布是不同的 ---
随机变量函数的分布不一定等于原分布。从公式<span class="math inline">\(\eqref{der1}\)</span>可以知道：<span class="math inline">\(p(x)\)</span>应当是<span class="math inline">\(f(x)\)</span>的分布，才能得到无偏的估计。此处的
<span class="math inline">\(f(x)\)</span>
显然是整个分子项。下面，我来重点讨论一下分子的联合分布（学了点随机过程还是...
有点作用的，虽然忘得差不多了）。</p>
<div class="note primary"><p>​ 分子项将需要被 <strong><u>分解</u></strong> 为两部分：</p>
<ul>
<li>直接光照（direct component）：采样光源与一次反射</li>
<li>间接光照（indirect
component）：采样光线弹射方向，使得光继续在空间中传播</li>
</ul>
<p>​ 拆分之后，两部分的PDF计算是不一样的。一定要注意，分子项的三部分<span class="math inline">\(L_i, f_r, \cos
\theta\)</span>并非全都是随机变量，并非全都会有附属的分布（PDF）。直接光照中，$f_r,
<span class="math inline">\(不是随机变量，不需计算其分布；间接光照中由于\)</span>L_i$并非即刻计算（需要后续弹射计算），故不计算此分布。<u><strong>分解思想我将在2.3节中详细介绍</strong></u>。</p>
</div>
<p>​
我现在的渲染器（截至2023.2.7）也才只写到透明折射物体（非散射）部分，等到散射部分加入后，radiative
transfer equation（RTE）将会更加复杂。在更加复杂的函数作为被积函数</p>
<h3 id="分解法与分布变换---从理解到实现">2.3 分解法与分布变换 -
从理解到实现</h3>
<h4 id="直觉理解">2.3.1 直觉理解</h4>
<p>​ 从公式<span class="math inline">\(\eqref{discrete}\)</span>来看，光线追踪似乎是一个指数爆炸式的递归过程：光线在每一个击中点都发出N条光线，那么弹射<span class="math inline">\(n\)</span>次意味着<span class="math inline">\(N^n\)</span>条光线。但我们可以将其简化：只trace一条光线。这种方案被称为：path
tracing。注意，此处我们考虑的是单向（unidirectional）path
tracing，并且方向是从 <u><strong>相机（sensor）到光源</strong></u>。</p>
<p>​
回到2.2中的问题：直接光照与间接光照的分解问题。直接光照为光源发出的光仅经过一次弹射就到达sensor的部分，间接光照则需要更多次弹射。但，对于整条路径：<span class="math inline">\(v_s, v_1, v_2, ..., v_n\)</span> 而言（<span class="math inline">\(v_s\)</span>为传感器，<span class="math inline">\(v_n\)</span>为第n次光线与场景相交），在某一处的<span class="math inline">\(v_j\)</span>的直接光照将变为在某一处<span class="math inline">\(v_i (i&lt;j)\)</span>处的间接光照：</p>
<pre class="mermaid">
graph RL

A(...)--&gt;|indirect from v...|B(v3)--&gt;|indirect from v3|C(v2)--&gt;|indirect from v2|D(v1)--&gt;E(sensor)
F(direct v1)--&gt;D
G(direct v2)--&gt;C
H(direct v3)--&gt;B

</pre>
<center>
Figure 2. 光照的递归分解模型
</center>
<p>​ 故事实上，我们没有必要直接去讨论间接光照，间接光照
<strong><u>就是此节点后节点上的直接光照</u></strong>。故我们只需要讨论：</p>
<div class="tabs" id="span-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#span-unique-name-1">直接光照</a></li><li class="tab"><a href="#span-unique-name-2">间接传输</a></li></ul><div class="tab-content"><div class="tab-pane active" id="span-unique-name-1"><p>​ 每一个节点处的直接光照。如何计算？采用Monte
Carlo积分（下式将与距离衰减，光源出射衰减项整合到了<span class="math inline">\(L\)</span>中）：</p>
<p><span class="math display">\[
\begin{equation}
L_d(x, w_o) = \frac 1N \sum_{i=1}^N \frac{f_r(x, x_{l, i}\rightarrow x,
w_o) L(x_{l, i},x_{l, i}\rightarrow x )\cos (x_{l, i}\rightarrow x,
n_l)}
{p(x_{l, i})}
\end{equation}
\]</span> ​
最理想的情况当然是进行积分：对每一个光源，光源上的每一个点（假设是有面积光源）<span class="math inline">\(x_l\)</span>，计算此点照射在<span class="math inline">\(x\)</span>点（当前vertex）处的irradiance（与cosine项相乘），结果乘以BRDF（BxDF，可能是别的函数）转为输出光。实现时则在所有光源上取共N个点（shadow
rays），计算每个采样点的分布<span class="math inline">\(p(x_{l,
i})\)</span>以及上式中其他部分，最后平均。</p></div><div class="tab-pane" id="span-unique-name-2"><p>​
光线需要传输，<strong><u>间接光照的radiance是传过来的</u></strong>。假设我们有一条光路击中<span class="math inline">\(v_j\)</span>，也即<span class="math inline">\(v_{j-1}\rightarrow
v_j\)</span>，则接下来需要知道三件事：</p>
<ul>
<li><strong><u>新的传输方向计算：</u></strong> 什么样的光击中<span class="math inline">\(v_{j}\)</span>点后有很大概率可以传输到<span class="math inline">\(v_{j-1}\)</span>？注意，在backward
tracing中，我们从相机开始trace rays，方向是<span class="math inline">\(v_{j-1}\rightarrow
v_j\)</span>，但实际情况是：光源（位于<span class="math inline">\(v_{j+1}\)</span>）发射光击中<span class="math inline">\(v_j\)</span>，<span class="math inline">\(v_j\)</span> 处产生材质/介质
interaction后将光源的光反射到 <span class="math inline">\(v_{j-1}\)</span> 处。故我们需要知道的实际是：<span class="math inline">\(v_{j +
1}\)</span>可能在什么位置？也即，如果已知<span class="math inline">\(v_{j-1}\rightarrow v_j\)</span>，我们需要知道<span class="math inline">\(v_{j+1}\)</span>在什么位置才能使得由此点发出的间接光照可以通过
<span class="math inline">\(v_{j+1}\rightarrow v_{j }\rightarrow
v_{j-1}\)</span> 传输？假设我们考虑<span class="math inline">\(v_{j}\)</span>位于完美的镜面上，则根据一般的光路可逆原理，<span class="math inline">\(v_{j+1}\rightarrow v_j\)</span> 一定在 <span class="math inline">\(v_{j-1}\rightarrow v_j\)</span>
的反射方向上。更加一般的情况则需要视BSDF而定。</li>
<li><span class="math inline">\(v_{j+1}\rightarrow v_j\)</span>
的“可能性”（PDF值）：还是以镜面为例，我们必然会在反射方向附近（假设镜面不是完美的）采样新的光线方向。每个方向都有其可能性值（PDF），例如当光线垂直镜面入射时，在平行镜面方向的可能性几乎为0。</li>
<li><strong><u>传输率计算：</u></strong>
我们的光线追踪器不可能只考虑完美镜面。故 <span class="math inline">\(v_{j+1}\rightarrow v_{j}\)</span>
传输的radiance将很可能在 <span class="math inline">\(v_j\)</span>
处根据BSDF进行衰减，衰减后的值成为 <span class="math inline">\(v_{j}\rightarrow v_{j-1}\)</span>
上传输的radiance。 传输率会被称为：throughput，在我的代码里，则称为
contribution。</li>
</ul></div></div></div>
<p>​
有了以上两个部分：（1）直接光照（2）间接传播的方向、PDF以及传输率，我们就可以类似图2这样，逐层递归分解光。所以，我可以说：最后到达相机的光，是【击中光源的光<span class="math inline">\(L_e\)</span>】以及每一个节点上、可能经过多次弹射的【直接光照】。（注意，BunnyKiller（Jarabo
2014）中并没有计算<span class="math inline">\(L_e\)</span>，所以它看不到面光源的样子...
代码中也有很多错）</p>
<div class="note danger"><p>​ 注意，在面光源情况下，我们不trace shadow
rays（不计算积分部分），只计算<span class="math inline">\(L_e\)</span>（击中光源后部分）也是可以完成正确渲染的，<u><strong>但是，收敛会慢很多很多。</strong></u>笔者之前的代码中有个bug，shadow
rays全是错的，direct
component全部为0，也得到了对的结果，但收敛一直很慢，MIS加上了也很慢；之后才发现
direct component 根本没有算，修改后简直就是“光速收敛”。故这也印证了我在
introduction
中所讲的：即使代码错了，结果也可能对（或者错误肉眼看不出来）。这就是此类渲染器
debug 的困难之处。</p>
</div>
<h4 id="计算过程">2.3.2 计算过程</h4>
<p>​
废话了很多，现在我来讨论一下两部分的计算。这里我们举两个非常常见的例子：点光源与面光源，并且我们假设场景中最多有两个光源（不失一般性）。则某一处的出射光线可以被分解为直接与间接光照（不考虑自发光）：
<span class="math display">\[
\begin{equation}
L_o(x, w_o) = \int_\Omega L_{in}(x, w_i) f_r(w_i, w_o, x) \cos\theta
dw_i + \sum_{i=1}^M\int_A f_r(x, x_{l, i}\rightarrow x, w_o)L(x, x_{l,
i}\rightarrow x)\cos\theta dA(x_{l, i})
\end{equation}
\]</span> ​ 第一部分：间接光照，第二部分：M个光源上每一点在<span class="math inline">\(x\)</span>处的直接光照，<span class="math inline">\(L_{in}\)</span>包含了<span class="math inline">\(G\)</span>： <span class="math display">\[
G(x_{l, i}\leftrightarrow x) = V(x_{l, i}\leftrightarrow
x)\frac{|\cos(w_i, n)(\cos{(w_{i}, n_e)})|}{\Vert x_{l, i} -x\Vert ^2}
\]</span> ​ 其中：</p>
<ul>
<li><span class="math inline">\(V(·)\)</span>项就是visibility项，需要光源与击中点之间没有遮挡物，此项一般无需采样（直接判断）。</li>
<li>cosine term的第一项很熟悉了，光源入射面的cosine衰减。</li>
<li>第二项为<span class="math inline">\(\cos(w_{i},
n_e)\)</span>，其中<span class="math inline">\(n_{e}\)</span>为光源出射位置的法向量（例如面光源的面法相）。这项看起来有点奇怪，实际上与一种叫做“projected
solid
angle”有关，解释见下引用块以及一张图。由于光源输出光按照立体角定义（radiance与irradiance），光源radiance若本身含有cosine项，可以将此项移动到立体角部分。</li>
</ul>
<blockquote>
<p>Projected solid angle has meaning primarily for a small Lambertian
source, which has intensity that varies as the cosine of the angle with
the surface normal [1]</p>
</blockquote>
<center>
<img src="/2023/02/09/AdaPT-Monte-Carlo-Path-Tracer-I/Schematic-illustration-of-projected-differential-solid-angles-for-normal-red-and.png" style="zoom: 67%;">
</center>
<center>
Figure 3. 投影立体角示意图[3]
</center>
<p>​ 写成代码可实现的离散情况（用Monte Carlo积分表示）： <span class="math display">\[
\begin{align}
L_o(x, w_o) = \frac 1N \sum_{j=1}^N \frac{L_{in}(x, w_{i, j}) f_r(w_{i,
j}, w_o, x) \cos\theta}{p(w_{i, j})} + \notag \\
\frac{1}{N_s}\sum_{j=1}^{N_s}\frac{L_{l, j}(x, x_{l, j}\rightarrow x)
f_r{(x, x_{l, j}\rightarrow x, w_o)}\cos\theta}{p(x_{l, j}|e_j)p(e_j)}
\end{align}
\]</span></p>
<h5 id="直接光照的计算">2.3.2.1 直接光照的计算</h5>
<p>​
（1）首先采样光源，比如：两个点光源选一个。一般来说我们用等概率选择不同光源（面光源可能需要根据面积进行加权）。此处会返回一个PDF：选光源总有概率吧，例如两个光源时一般用<span class="math inline">\(0.5\)</span>，记为<span class="math inline">\(p(e_i)\)</span></p>
<p>​
（2）在采样后的光源上进行点采样：点光源不用采样（只有一个点嘛），面光源则根据实现不同有所变化。例如在我的代码中，我的面光源是可以attach到某个物体上的（比如发光的墙、盒子、球等等），物体表征如果为<code>mesh</code>，则需要首先采样面片，此后再在面片上采样点，而如果是显式几何表征（比如一个矩形），则为面积的倒数（均匀分布假设）。记此概率为
<span class="math inline">\(p(x_l|e_i)\)</span>，注意此概率为给定光源之后的条件概率。</p>
<p>​
（3）要用什么概率计算？角度积分与面积积分是完全不同的。如果仅仅是在面光源上采样，当然可直接使用<span class="math inline">\(p(x_l|e_i)p(e_i)\)</span>计算PDF，但
<u><strong>如果要进行MIS（mutiple importance
sampling）</strong></u>，就必须将光源采样与BSDF采样转化到同一个空间下讨论。这个部分我们留到第三章说。</p>
<p>​ （4）多光源或者是大型面光源时，尽量多使用一些shadow
rays，有助于收敛。</p>
<p>​ 以上技术就是著名的：”Next Event Estimation“</p>
<blockquote>
<p>Idea: follow each ray via multiple indirect bounces, but at each
bounce, compute the direct lighting from light source surfaces!</p>
<ul>
<li>Detected light at each bounce is no longer dependent on
coincidence</li>
<li>This is what we refer to as Next Event Estimation</li>
</ul>
</blockquote>
<h5 id="间接弹射的计算">2.3.2.2 间接弹射的计算</h5>
<p>​
（1）根据来自sensor方向的入射光线、法向量以及BSDF，采样出射方向（backward
tracing意义上的出射，实际我们在确定物理意义上的入射，<strong><u>这点需要清楚理解！</u></strong>）。</p>
<p>​
（2）既然是采样，我们可以在采样过程中算出对应的PDF。注意，采样的PDF值应当是<span class="math inline">\(f_r(x, w_i, w_o)\cos\theta\)</span>
的PDF值（但采样所用的分布可以是任意的，但越像<span class="math inline">\(f_r(x, w_i, w_o)\cos\theta\)</span>
越好，但这个内容与Importance
sampling有关，本篇博客就不细讲了），而不是简单地与<span class="math inline">\(f_r(x, w_i,
w_o)\)</span>有关。为什么呢？我们实际想采样的是<span class="math inline">\(w_o\)</span>
(我们需要一个出射方向)，但是与出射方向有关的函数则是<span class="math inline">\(f_r\)</span> 以及 <span class="math inline">\(\cos\theta\)</span>
（由于只讨论传输率，故没有<span class="math inline">\(L_i\)</span>这一项）。</p>
<p>​ （3）计算传输率。此处注意，<span class="math inline">\(\cos\theta\)</span>
是出射方向与法线之间的夹角（多次说过，backward
tracing的出射是物理意义上的光源入射）。</p>
<p>​
（4）注意！不管实现什么BRDF/BSDF，一定要使得结果满足能量守恒：传播过程不会导致能量越来越大。</p>
<h5 id="能量守恒">2.3.2.3 能量守恒</h5>
<p>​ 开始时我的代码不满足能量守恒，传播会导致 radiance
越来越大（最后画面全白，出现inf/NaN）。刚开始时我还非常疑惑：除以PDF时，如果有非常小的PDF，难道不会将radiance放得很大吗？但事实上这样的担心并不存在，由于
BSDF
有放缩系数。我开始认为：BSDF应当是一个相对值函数：最大反射/透过率的位置的值为1，其余位置小于1。但实际上
BSDF 需要归一化，关于归一化，这里有两个非常好的回答（与博客）<a href="#ref">[4]</a> <a href="#ref">[5]</a>。</p>
<p>​ 有关Lambert's Cosine
Law的问题，这里我也简单说一下（由于这个问题当时也困扰了我很久）。首先，是半球积分的概念。我们在讨论时常常使用<span class="math inline">\(w_i/w_o\)</span>来代替方向。而对应的 <span class="math inline">\(dw\)</span> 则是 <u><strong>对应某个方向<span class="math inline">\(w\)</span>的微分立体角</strong></u>（differential
solid
angle）。立体角！并不是一个很好讨论的玩意，你说如何用它进行积分？我也不知道，我们需要将其展开为熟悉的多重积分（在笛卡尔坐标系下或者球坐标系下）。注意微分立体角与球坐标系（<span class="math inline">\(\theta\)</span> 为zenith angle，或者说是elevation
angle，<span class="math inline">\(\phi\)</span> 是 azimuth
angle）之间的转换： <span class="math display">\[
\begin{equation}
dw = \sin\theta d\theta d\phi
\end{equation}
\]</span></p>
<center>
<img src="/2023/02/09/AdaPT-Monte-Carlo-Path-Tracer-I/shad-light-beam7.png" style="zoom:100%;">
</center>
<center>
Figure 4. scratchpixels上的立体角-球坐标系转换 --- 很像投影立体角对吧[5]
</center>
<p>​ 注意范围，俯仰角<span class="math inline">\(\theta\in[0,
\pi/2]\)</span>, 方位角<span class="math inline">\(\phi \in [0,
2\pi)\)</span>。此 <span class="math inline">\(\sin\)</span>
项的存在解释了normalization factor计算中，直接用 <span class="math inline">\(d\theta d\phi\)</span> 算出的结果不对的原因。</p>
<p>​ 而BSDF的能量守恒则可以这么定义： <span class="math display">\[
\begin{equation}\label{bsdf_norm}
\int_\Omega f_r(x, w_i, w_o)\cos\theta  d w_i\leq 1
\end{equation}
\]</span> ​ 此外，个人认为还有一种定义方法： <span class="math display">\[
\begin{equation}\label{nq}
\int_\Omega L_o(x, w_o) d w_o\leq \int_\Omega L_i(x, w_i) d w_i
\end{equation}
\]</span> ​ 这个给出一个 Lambertian 表面的例子：</p>
<blockquote>
<p>A surface with a Lambertian BRDF has the characteristic that
<strong>independent of the direction from which one looks at that
surface</strong>, one receives the <strong>same amount of reflected
energy</strong> (i.e. a diffuse surface point looks the same from all
possible directions) <a href="#ref">[4]</a></p>
</blockquote>
<p>​ <a href="#ref">[4]</a>处的思想见下图。下图可以表示两种情况：</p>
<center>
<img src="/2023/02/09/AdaPT-Monte-Carlo-Path-Tracer-I/cad.png" style="zoom:50%;">
</center>
<center>
Figure 5.
建筑师老爹用CAD帮我画的示意图：等直径光柱以不同角度入射一平面/某一像素的视角范围
</center>
<ul>
<li>等直径光柱以不同角度入射一平面：可知角度越大，单位微元内入射光强度越小。这就是
Lambert's Cosine Law 的由来。也是path tracing算法中每一项BSDF（除了
delta 类 BSDF，如镜面）都需要乘的 cosine 项</li>
<li>某一像素的视角范围。为了简单起见，像素的 FOV
原本为锥形，在距离较远时直接简化为等宽的柱体。可知，入射角度越大，截面积越大（对应的
radiance 自然就更多？）。但实际上我们求 radiance
时是在柱内求平均而非求和（或者面积积分），故这种解读实际上并不影响结果（事实上，我所知道的renderer中貌似都没有除以<span class="math inline">\(\cos\theta_i\)</span>的操作）</li>
</ul>
<p>​ 我们结合 Lambertian 表面的定义：各方向观察同一点，radiance
应当一致。则可以得到： <span class="math display">\[
\begin{align}\label{lambert}
&amp;\int_\Omega \cos\theta \rho_d d w_o   \\
&amp;=\rho_d\int_\Omega  \cos\theta  d w_o \\
&amp;=\rho_d\int_0^{2\pi} \int_0^{\pi/2}   \sin\theta \cos\theta d\theta
d\phi  \\
&amp;=\rho_d\pi
\end{align}
\]</span> ​ 故由于上式需要小于等于1，则Lambertian对应的 normalization
factor 是 <span class="math inline">\(\pi\)</span>（对应<span class="math inline">\(\frac{\rho_d}{\pi}\pi=\rho_d\)</span>），对应其BSDF为
<span class="math inline">\(\rho_d / \pi\)</span>（也即是均匀的）。</p>
<hr>
<h2 id="todo">Todo</h2>
<p>​
最有趣的（也是比较恶心的部分），当属采样以及进行BSDF的设计。如何设计正确的BSDF
---
正确归一化的BSDF函数，高效率的采样以及正确的PDF是我们需要关注的重点问题（也是当前我对算法理解的最大障碍，估计也是后续工作需要重点掌握的基础知识）。举个例子：Lambertian
PDF 为什么是 <span class="math inline">\(\cos\theta
/\pi\)</span>？以及其 cosine weighted
采样为什么要这样设计？很惭愧，脑子不好使，确实一时半会儿答不出来。故这部分将成为下一篇博客的重点。</p>
<hr>
<h2 id="references">References</h2>
<p><span id="ref"></span></p>
<p>[1] <a href="https://graphics.stanford.edu/courses/cs348b-01/course29.hanrahan.pdf">AdaPT-Monte-Carlo-Path-Tracer-I</a></p>
<p>[2] <a href="https://www.cg.tuwien.ac.at/sites/default/files/course/4411/attachments/08_next%20event%20estimation.pdf">Bernhard
Kerbl - Rendering: Next Event Estimation</a></p>
<p>[3] Wang, Zhen, et al. "Theoretical extension of universal forward
and backward Monte Carlo radiative transfer modeling for passive and
active polarization observation simulations." <em>Journal of
Quantitative Spectroscopy and Radiative Transfer</em> 235 (2019):
81-94.</p>
<p>[4] <a href="https://computergraphics.stackexchange.com/questions/7578/brdf-normalization">CG
stack exchange: BRDF normalization</a></p>
<p>[5] <a href="https://www.scratchapixel.com/lessons/3d-basic-rendering/introduction-to-shading/diffuse-lambertian-shading.html">Scratchpixel:
Introduction to shading</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>CG</tag>
        <tag>renderer</tag>
        <tag>Taichi lang</tag>
      </tags>
  </entry>
  <entry>
    <title>Taichi-Learning-II</title>
    <url>/2023/01/15/Taichi-Learning-II/</url>
    <content><![CDATA[<h1 id="taichi-lang-ii">Taichi Lang II</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​
深入了解Taichi语言，简单的并行算法设计无法满足我（毕竟真要说并行算法设计，Taichi所需的工作量与CUDA暂时没办法比）。Taichi中重要的两个features：稀疏数据结构（SSDS），可微编程（differentiable
programming）目前对我而言比较重要的就是SSDS，可微编程...
可微渲染可能可以用到，但是本身实在是太复杂了...
我一直觉得，不动手就学不到真正的知识，所以还是给自己布置了一道题，并且要求将SSDS以及在第一篇博客完成后学到的内容整合到此题的解答中。本文是最后一篇Taichi
入门博客，关于一些进阶的用法以及特性，以及在实现题目：flocking
simulation（鸟群模拟）中所学到的一些知识。文末附有flocking
sim的视频。</p>
<p>​ 预计我下一步将会使用Taichi写一个带有participating media功能的path
tracer（3D，之前Rust + CUDA写了一个没开源的2D
tracer，只能看光路，不能看渲染结果（毕竟是2D）），以加深我对光线追踪算法的理解。不过这是个大项目，简单版本的也至少涉及到mesh的读取、加载、光线弹射、采样、介质实现、蒙特卡洛积分等等...
想想就刺激。</p>
<table>
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;">frame 52
(红色为掠食者，白色为普通鸟)</th>
<th style="text-align: center;">frame 58
(红色为掠食者，白色为普通鸟)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><img src="/2023/01/15/Taichi-Learning-II/000052.png" alt="000052"></td>
<td style="text-align: center;"><img src="/2023/01/15/Taichi-Learning-II/000058.png" alt="000058"></td>
</tr>
</tbody>
</table>
<center>
Figure 1. Flocking simulation with predators (64 regular boids (this is
not a typo) and 4 predators)
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-type-system">II. Type System</h2>
<h3 id="type-system">2.1 Type System</h3>
<h4 id="prerequisites-casting">2.1.1 Prerequisites &amp; Casting</h4>
<p>​
其实这部分并没有太多可以说的，只有些零零碎碎的点需要提醒，我在实现的时候没有遇到太多有关类型的问题。首先需要说明的是，Taichi是静态强类型语言，所以类型不能乱来。虽然其撰写时的语法就是Python，但由于没有显式类型声明，类型推断以及隐式类型转换可能导致非常多的问题。首先说一下
type alias 以及一些入门级前置知识：</p>
<ul>
<li>Type alias实际上是Taichi default
types可以使用的别名，例如不进行特殊设置（<code>ti.init</code>时），<code>float = ti.f32</code>，<code>int = ti.i32</code>，<code>float, int</code>分别为<code>ti.f32, ti.i32</code>的
type aliases</li>
<li>Taichi有两大类类型：primitive
types，就是基础类型，诸如<code>f32, i32, u8</code>等等，没有boolean
type（用<code>i32</code>代替）。另一类是 compound
types，也即复杂的数据结构：vector，matrix（vector就是matrix），<code>ndarray</code>以及struct（其实我现在都还没怎么用到<code>ndarray</code>）。上一篇博文中，我简要分析了一下field与<code>ndarray</code>的区别：<code>ndarray</code>不允许在kernel内进行非compile-time-known的indexing操作。这主要是因为，<code>ndarray</code>是compound
type（具有明确的类型），而field不具有明确的类型（是一个复杂container）。</li>
</ul>
<p>​
此外，在上篇博客中忘记说了，我在开始学Taichi时曾经碰到这样的问题：</p>
<ul>
<li>教程中简单的examples全都将field设为全局变量。使用全局变量并不是好习惯，并且很丑（封装性很差）</li>
<li>开始时我想<strong><u>将field作为参数传入kernel函数</u></strong>。但是遇到了type
annotation的问题：我无法找到field的type定义：从我现在所学的知识来看，可能确实找不到，毕竟field不是两大类型中的任意一种。</li>
</ul>
<p>​
于是我觉得：说不定作者并不想让field传来传去呢？于是之后的三个小demo全部改成了使用<code>@ti.data_oriented</code>的class。<strong><u>但field无法当参数传递是个错误的想法</u></strong>，我犯这个错误是因为两天的入门学得太浅。此概念实际与Taichi
metaprogramming关系非常密切，这里说到field的类型就忍不住跑了个题...，下面说说casting。</p>
<p>​ <code>ti.cast</code>可以执行类型转换（在compile
time对某个变量强制赋予某个类型，以免implicit casting / type
inference造成的类型错误）</p>
<div class="note danger"><p>​
但是注意，此函数只能在<code>ti.init</code>之后使用，并且返回值并不是primitive
types：</p>
<ul>
<li>返回值类型是<code>ti.Expr</code>（个人对Expr的理解类似Eigen库，表达式模板运算，惰性计算，compile），与下面所表达的意思比较一致：先生成类似表达式模板的东西（相当于知晓接下来要进行什么操作），并且由于Taichi对于platform敏感，乘法操作在不同的backend下实现可能不同，所以总是先生成一个Expr，Expr中的乘法操作会根据backend进行不同的调用。</li>
</ul>
<blockquote>
<p><a href="https://forum.taichi-lang.cn/t/what-does-expr-stands-for/78">来自这里</a>:
In fact, when you type <code>x * 2</code>, it’s not evaluated
immediately. That’s why we need x to be <code>Expr</code>. What
<code>Expr</code> express is not a value, but an instruction.</p>
</blockquote>
</div>
<p>​
在上一篇博客中，我也提到了<code>Expr</code>导致的一些误解（例如直接使用看似为integer的变量为什么无法直接indexing），个人觉得应该与惰性计算有一定的关系。故在<code>kernel</code>函数中，一般无法调用<code>numpy</code>等函数（计算张量、数值而非表达式运算），而Taichi函数有处理表达式以及立即数（可以理解为<code>constexpr</code>运算么）的能力。</p>
<ul>
<li><code>ti.i32, ti.f64</code>这样的操作也可以进行casting，并且由于<code>int, float</code>是对应的default
types，故也可以直接使用作为casting方法，例如<code>ti.f32(1)</code></li>
</ul>
<div class="note info"><p>​ Taichi中能type annotation的地方尽量type
annotation，并且不要写得太像python（例如让解释器进行自动类型转换），该手动强制类型转换的地方尽量手动转：（1）隐式类型转换经常出问题（2）不出问题也有可能因为损失精度而在编译阶段报一堆烦人的warnings</p>
</div>
<h4 id="compound-types">2.1.2 Compound Types</h4>
<p>​
vector以及matrix就不多说了，这里只提一个与性能相关的点，个人觉得有点坑（不看文档是不知道的）：</p>
<div class="note "><p>​
Matrix以及vector操作在compile时会进行unrolling：<code>a = [[1, 2, 3], [4, 5, 6]]</code>会成为对应index的赋值（刚学到这里的时候我觉得非常怪：明明是spatially
neighboring的数据，这样不会影响效率吗？可以SIMD吗？答案是：确实会影响效率）</p>
<blockquote>
<p>Operating on larger matrices (for example <code>32x128</code>) can
lead to <strong>longer compilation time</strong> and <strong>poorer
performance</strong>. For performance reasons, it is recommended that
you keep your matrices small. (So bad)</p>
</blockquote>
</div>
<p>​
Struct这玩意，熟悉C的同志们应该并不陌生（？奇妙的逻辑）。但就我当前对struct的理解（涉及到advanced
container的部分内容，如SoA以及AoS），想要追求性能机制时对于struct的使用需要慎之又慎：我们知道，struct存在的意义就是让数据更有组织，每个具名域表达一个清晰的含义，如：<code>name</code>,
<code>age</code>等等。但由于struct在物理实现上是空间连续的结构，空间连续性以及内存的分页机制将产生一系列的问题，具体的讨论留到<a href="#3-1">【第三节3.1 SoA vs.
AoS】</a>。我在这里说这个是想强调：按照我的理解，我并不推荐无脑照搬C/C++那一套封装数据一定就得上struct甚至class的思想。</p>
<p>​ 首先，如何创建一个high level compound type struct捏？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ti.types.struct(a = type_1, b = type_2, ...)</span><br></pre></td></tr></table></figure>
<p>​ 其中，<code>type_1</code>以及<code>type_2</code>可以是primitive
types或者compound
types，注意上述代码返回了一个特定的类型（一个struct类型，而非struct实例）。由于struct也是compound
type，struct的复合是可以的，但貌似struct的构造必须使用keyword
arguments（即便按顺序，不使用keyword
arguments，则需要将内部struct展开，比如看下面一个例子）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vec2 = ti.types.vector(<span class="number">2</span>, <span class="built_in">float</span>)</span><br><span class="line">inner_type = ti.types.struct(weight = <span class="built_in">int</span>, center = vec2)</span><br><span class="line">ball_type = ti.types.struct(desc = inner_type, radii = vec2)</span><br></pre></td></tr></table></figure>
<p>​
以上例子定义了一个椭球（由于radii是二维向量，意味着可以长短轴可以不同长度）。如果要进行构造，有两种办法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ball_1 = ball_type(desc = inner_type(<span class="number">2</span>, vec2([<span class="number">1</span>, <span class="number">3</span>])), radii = vec2([<span class="number">0.5</span>, <span class="number">0.5</span>]))</span><br><span class="line">ball_2 = ball_type(<span class="number">2</span>, vec2([<span class="number">1</span>, <span class="number">3</span>]), vec2([<span class="number">0.5</span>, <span class="number">0.5</span>]))</span><br></pre></td></tr></table></figure>
<p>​ 第一种构造方法需要限定keyword arguments，直接这样构造是不行的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ball_1 = ball_type(inner_type(<span class="number">2</span>, vec2([<span class="number">1</span>, <span class="number">3</span>])), vec2([<span class="number">0.5</span>, <span class="number">0.5</span>]))</span><br></pre></td></tr></table></figure>
<p>​ 会报如下错：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TypeError: int() argument must be a string, a bytes-like object or a number, not &#x27;Struct&#x27;</span><br></pre></td></tr></table></figure>
<p>​ 只能说很奇妙，与C++确实比较不同，C++就没有explicit keyword
argument这一说。而<code>ti.dataclass</code>则提供了如同rust一般的struct定义方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ti.dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Ball</span>:</span><br><span class="line"><span class="meta">	@ti.dataclass</span></span><br><span class="line">	<span class="keyword">class</span> <span class="title class_">Inner</span>:</span><br><span class="line">		center: vec2</span><br><span class="line">		radius: <span class="built_in">float</span></span><br><span class="line">	inner: Inner</span><br><span class="line">	weight: <span class="built_in">int</span></span><br></pre></td></tr></table></figure>
<p>​ 使用冒号进行type annotate（当做type
definition），这一点与Rust很像，此后不用任何其他方法（当做struct用就好了，实际上其类型也是<code>Struct</code>）。原始Python则不支持这么做：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Test</span>:</span><br><span class="line">    	a: <span class="built_in">int</span></span><br><span class="line"><span class="comment"># test = Test(1)		 当然是会报错的</span></span><br><span class="line">test = Test()</span><br><span class="line">test.a							<span class="comment"># 只留type hint的话，a当然是NoneType（没有定义，只有“声明”当然没有用）</span></span><br></pre></td></tr></table></figure>
<p>​
但很可惜的是，<code>dataclass</code>定义的struct（在Python中是带有<code>@ti.dataclass</code>修饰的class）并不支持继承，一定程度上限制了应用吧？（至少在我的flocking
simulation中，我曾经想使用<code>dataclass</code>修饰类作为基类，但发现这玩意已经是<code>final</code>了），这个例子我在第三节会简单介绍一下。</p>
<hr>
<h2 id="iii.-spatially-sparse-data-structure-实例分析">III. Spatially
Sparse Data Structure 实例分析</h2>
<h3 id="background">3.0 Background</h3>
<p>​ 本节所介绍的内容为 Taichi 中最重要的部分之一，基础知识部分参见 <a href="https://docs.taichi-lang.org/docs/field">Taichi Lang Docs: Data
Containers</a>。Taichi
做这样的设计有充分的理由：稀疏的数据结构（Spatially Sparse Data
Structure -
SSDS）需要有更加有效的并行操作实现。举个例子，笔者在研一上（也就是这个学期）时陷在CUDA中，因为写CUDA就像炒期货：风险巨大（调参困难，并且需要充分的内存、逻辑设计才能快）但可以给人一种巨大的成就感（前提是写出来能跑、结果对、速度快、能正确链接到Rust上进行可视化）。CUDA中就有两个重要的feature限制了稀疏数据结构的使用：</p>
<ul>
<li>CUDA中的内存操作（这一点非常深，我也只能算门外汉）：比如memory
coalescing (“have consecutive threads access consecutive memory
addresses”[1]) 以及内存带宽优化等。要好理解的话，假设有一个C++
vector以及C++
deque存在GPU上，由于vector是连续内存，读取对内存操作是友好的（在CPU上也是，特别是有分页机制时）要基于vector做稀疏存储结构，则需要一定的辅助结构（如boolean
flags）。而deque可以做到稀疏（由于其非连续读取，虽然iterator的使用隐藏了这一点），但分散的内存不便于内存操作的优化。</li>
<li>warp
divergence：基于flag、bitmask等的数据结构可以通过判定某块区域是否valid达到对于invalid块不进行内存分配的目的。但在GPU代码中，判断应当尽可能避免（除非另一个branch是NOP），否则就会产生divergence
serialization问题。</li>
</ul>
<p>​ 强如Nvidia，设计出来的CUDA，也不是特别适合SSDS...
所以Taichi出手了。SSDS的应用广泛性不用多说，例如基于voxels的NeRF，强一点可以使用coarse-to-fine
resolutions的层级voxels，弱一点的做一个empty voxel
culling总是可以的吧？这些都涉及到将一个dense的内存块变为sparse的操作（或者是内存的分级管理），Taichi则有这样的API（或者内部特性）。</p>
<p><img src="/2023/01/15/Taichi-Learning-II/sparse_grids_3d.jpg"></p>
<center>
Figure 2. SSDS Taichi official examples: fluid particle / multi-res grid
mixture representation simulation[2]
</center>
<p>​
光看文档是没用的（再次quote西交刘龙军老师的话：”读论文不复现等于白读“）。确实，读书与上课会给人一种你已经学会了的错觉，但停留于”知道了、了解了“等级的”学会“是没用的，只能用于吹逼；我们应当时刻追求”会用，深入实验了“等级的”学会“。所以我给自己Taichi入门级别学习定的最后一个作业是：Flocking
simulation (<a href="http://www.red3d.com/cwr/boids/">Craig Reynolds'
Boid
Algorithm</a>)。我很早之前就注意到这个算法了（当时才大四，在学Rust，苦于不知道用什么可视化库的时候），问题参考【<a href="First%20rust%20program%20%7C%20flocking%20simulation.">Reddit:
First rust program | flocking
simulation.</a>】，但我并不想去复现它。对于简单的算法，复现别人的复现（复现<span class="math inline">\(^2\)</span>）并没有太大的意思，尝试用自己的理解写出算法才是有趣的事情。于是我只参考了其美术设计（确实，nannou看起来挺高大上的），用Taichi写了一个flocking
simulation（可能与Craig Reynolds' Boid
Algorithm不太像，毕竟我只用了其最抽象的思想，什么separation,
alignment以及cohesion，具体这几个鸟群性质怎么实现都得自己设计）。我在本小项目中尝试使用SSDS加速邻近搜索（neighbor
search），道理是挺有道理的，但没有做过profiling看具体的加速效果。</p>
<blockquote>
<p>Boid: Bird-roids 或是bird的一种带有口音的读法。</p>
</blockquote>
<center>
<img src="/2023/01/15/Taichi-Learning-II/flocking.png" style="zoom:50%;">
</center>
<center>
Figure 3. Flocking simulation with multiple predators
</center>
<h3 id="soa-vs.-aos">3.1 SoA vs. AoS</h3>
<p><span id="3-1"></span></p>
<div class="tabs" id="span-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#span-unique-name-1">SoA</a></li><li class="tab"><a href="#span-unique-name-2">AoS</a></li></ul><div class="tab-content"><div class="tab-pane active" id="span-unique-name-1"><p>​ Struct of Arrays（SoA）:
意思是一个struct中的变量是array（比如一个struct中有好几个数组），很显然对于struct中的每一个Array，内部元素都是空间临近的（直接邻近）。而不同array的内存可以分配在不同的位置，没有空间邻近性。</p></div><div class="tab-pane" id="span-unique-name-2"><p>​ Array of
Struct（AoS）的意思是：某个array的元素是一个struct。很明显，Array of
struct中，单个struct内部的元素之间是空间邻近的（由于struct需要连续的内存区），而不同的struct
element之间只有有限的邻近性，举个例子：一个struct中含有<code>double a</code>,
<code>double b</code> ,
<code>std::shared_ptr&lt;xxx&gt; c</code>，那么即使是相邻的两个struct中的变量<code>a</code>都可能相距几十个字节。</p></div></div></div>
<p>​
正如我在第二节时所说的：SoA与AoS需谨慎选择，GPU背后的intuition已经提了，而现代CPU内存也存在选择问题。当有内存分页机制（或者什么分段、段页）时，对于某块内存的取出是将其所在的页整个取出（如果我微机原理没记错的话）。如果所需的数据空间较为分散，频繁地调页将会浪费memory
bandwidth：试想你为了SIM卡卡针去买了一部又一部的手机...
就为了里面赠送的卡针，顶级买椟还珠行为 ---
调一整页只为了其中的一小部分内容。此外，cache
coherence也是一大考虑。频繁地更换在cache中的页将会导致大量cache
miss，那就慢了啊。</p>
<p>​
假设struct存储了某个个体中我们需要的信息，如果要追求极致速度，我们应该根据计算所需信息的内存分布选择SoA/AoS。举个例子：</p>
<ul>
<li>struct中存储了位置，速度，加速度信息，我需要根据匀加速模型更新每一个个体的位置。一般来说，这种情况使用AoS比较好，<strong><u>因为计算使用的是struct的内部信息</u></strong>
--- 意味着我们需要struct的内部信息邻近性</li>
<li>我的Flocking
simulation：需要存储所有boids的角度、位置。例如当我希望邻近boids之间有相近的角度时，我需要访问其他boids的角度以及位置，此时使用SoA会比较好：利用同种类型的数据之间的邻近性，由于不同种类数据之间可能无法进行直接运算。</li>
</ul>
<p>​ 我当时就没有把boid写成struct，而是进行了以下实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.ang_vel 		= ti.field(ti.f32, self.boid_num)</span><br><span class="line">self.angles 		= ti.field(ti.f32, self.boid_num)</span><br><span class="line">self.pos 			= ti.Vector.field(<span class="number">2</span>, ti.f32, self.boid_num)</span><br><span class="line">self.dirs 			= ti.Vector.field(<span class="number">2</span>, ti.f32, self.boid_num)</span><br></pre></td></tr></table></figure>
<p>​
角速度、角度、位置以及2D朝向（2D朝向用于结果绘制）都是分开存储的，虽然在计算角度时常常需要<code>angles</code>以及<code>ang_vel</code>，但其实这种不同类型的数据计算还是挺有独立性的。不过，AoS可能导致代码可读性变差（struct确实很有组织，正如我们存储人的身份信息时，一般都是把每个人作为一个单独的实例，内部有完整的各信息条目，而不会什么”年龄存一起，姓名分开并一起存在另外一个地方“）。</p>
<h3 id="ssds">3.2 SSDS</h3>
<p>​
有四种node（四种SSDS支持的数据结构）：（1）Dynamic（本文不讲，原因见后）（2）Pointer：指针类型，每个区都可以指向完全没有空间规律性的地址（3）bitmasked：每个存储区存在一个1bit的flag，以指示当前存储区是否active（inactive的存储区将不会耗费除bit
flag之外的内存）（4）dense：可以理解为field，无条件active的存储区，仅有dense的结构不是稀疏的。下面，给出官方教程的一个例子，关于具体的语法以及API的使用我就不说了，本博客也不是那种抄别人文档，代替读者paraphrase一下之后还给读者的那种答辩博客（虽然我博客内容质量也不行，但不至于开始就是答辩）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = ti.field(ti.i32)</span><br><span class="line">y = ti.field(ti.i32)</span><br><span class="line">z = ti.field(ti.i32)</span><br><span class="line">S0 = ti.root</span><br><span class="line">S1 = S0.pointer(ti.i, <span class="number">4</span>)</span><br><span class="line">S2 = S1.dense(ti.i, <span class="number">2</span>)</span><br><span class="line">S2.place(x, y) <span class="comment"># S3: x; S4: y</span></span><br><span class="line">S5 = S1.dense(ti.i, <span class="number">2</span>)</span><br><span class="line">S5.place(z) <span class="comment"># S6: z</span></span><br></pre></td></tr></table></figure>
<p>​
文档给出了存储结构图（注意，我觉得官方文档的图有问题，见下图的红框）。官方文档的红框区域中，靠上方的两个cell是2，下方两个为3，我感觉这是不对的，毕竟这违反了place的含义。</p>
<center>
<img src="/2023/01/15/Taichi-Learning-II/structure.png" style="zoom:67%;">
</center>
<center>
Figure 4.
层级结构图（灰色的container部分，被红框框住的区域为官方文档画错的区域）
</center>
<p>​
如果真想要深入学习Taichi，这张图的含义必须要完全看明白并且能与代码对上。按照图论中对树的理解开始即可，S0为根结点，根节点处有四个子树，每个子树都是一个pointer，所有子树归为S1层。S1层上每个子树上，挂两个子树，每个子树是一个dense存储区。对S2层而言，这一层是叶结点了，叶节点可以直接与某个field挂钩
---
确定每个叶子元素是什么类型，在这里是<code>i32</code>。注意：<code>x.place(y)</code>函数可以理解为：将x所含有的层级结构，应用在变量y确定的存储区域上，存储区域的类型与y本身有关。下面我着重说一下flocking
simulation中所需要的SSDS。</p>
<p>​
我们知道（你知道吗），邻近搜索是一件很烦人的事情，特别是在元素较多的时候，因为对于人类来说邻近搜索简单直观：我要找出我附近的人并不要求我把我到所有中国境内的人的距离全部测一遍。而计算机比较暴力，简单地查找邻居需要基于距离度量。那用稀疏数据结构就是一种可行的加速手段，以搜索附近的人为例，我只要找出我当前所在县市周围县市人进行计算即可。Flocking
simulation中我使用SSDS实现了稀疏grid（两层）：</p>
<ul>
<li>第一层，是2D pointer grid：代表了我对2D空间的划分 --- 划分为<span class="math inline">\((W/D) \times
(H/D)\)</span>个2Dgrid，每个grid大小为<span class="math inline">\(D\times
D\)</span>。那么对于一个boid，它只需要搜索自己所在的 +
邻近的（我代码内取8-邻域）grid即可</li>
<li>第二层，1D
bitmasked：由于我不知道会有多少只boid落在同一个grid中，所以我只能在开始时设置一个大的存储区（比如64
boids对应每个grid中需要有64个存储区）。使用dense显然...
不好，我可能根本用不到这么多存储区域，除非我代码写得有问题，鸟喜欢聚在同一个地方。bitmasked则是一个很好的选择，相当于有条件的dense结构</li>
</ul>
<p>​
第一层用pointer或者bitmasked都行，bitmasked是空间邻近的结构，pointer是离散存储的结构，在本用例中并没有太大的区别。用dense则不行：有些grid中可能一只boid都没有，没必要浪费这个内存。第二层的设计稍微有点tricky（可能是我想复杂了），理由如下：</p>
<ul>
<li>boid在grid中的位置也是2D的，那么2D存储在1D的结构上自然要赋予一个地址值（或者下标索引）</li>
<li>Taichi喜欢lock-free操作（貌似在Taichi中也没有找到mutex）</li>
</ul>
<p>​ 于是我的第一版实现是这样的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.mask_grids = ti.field(ti.u8)      <span class="comment"># storing indices (atomic_add will return the original index, which is thread-safe)</span></span><br><span class="line">self.sn_handle  = ti.root.pointer(ti.ij, (grid_x + <span class="number">2</span>, grid_y + <span class="number">2</span>))</span><br><span class="line">self.atom_ptr   = ti.field(ti.u8, (grid_x, grid_y))     <span class="comment"># atomic dynamic indices for bitmask (no offset needed)</span></span><br><span class="line">self.sn_handle.bitmasked(ti.k, <span class="number">128</span>).place(self.mask_grids, offset = (-<span class="number">1</span>, -<span class="number">1</span>, <span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<p>​ <code>mask_grids</code>最终是<span class="math inline">\((W/D,H/D,C)\)</span>大小的，其中C是每个grid能存储的boid数量上限，这个变量是我们用于邻近查找所需的变量。<code>atom_ptr</code>是一个原子操作数据，用于存储每个grid当前记录的boid数量。<code>atom_ptr</code>不仅有记录数量的能力，在并行计算时可以用于获取存储位置的数组下标：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">id_x, id_y = <span class="built_in">int</span>(new_pos[<span class="number">0</span>] / self.radius), <span class="built_in">int</span>(new_pos[<span class="number">1</span>] / self.radius)</span><br><span class="line">index = ti.atomic_add(self.atom_ptr[id_x, id_y], <span class="number">0x01</span>)</span><br><span class="line">self.mask_grids[id_x, id_y, <span class="built_in">int</span>(index)] = ti.u8(idx)          <span class="comment"># store the index of the boid</span></span><br></pre></td></tr></table></figure>
<p>​
上面三行中，第一行先计算了grid坐标，此后<code>ti.atomic_add</code>将对应位置的计数+1，注意
<strong><u>其返回了+1之前的数组大小</u></strong>，可以直接当成我们的index使用。由于+1
/ 返回原始值这个类似replace的操作是原子的，所以相当于我们可以进行lock
free的动态大小存储。</p>
<p>​
或许有人会说：为什么要这么复杂，我不能这样处理吗？既然是bitmasked，假设当前boid的id是k，那我只需要在<code>masked_grid[i, j, k]</code>处存储（或者activate）就可以了，根本不需要知道有多少boid、不需要<code>atom_ptr</code>以及原子操作啊？反正Taichi的
struct-for loop会自动遍历稀疏的active区域。</p>
<div class="note warning"><p>​
<strong>不行！</strong>我们要实现的是手动for循环（三层），最外面的两层是在遍历当前grid以及其周围8-邻域grids，而最内层是在遍历存储在对应grid中的所有boid（记录的indices）。
struct-for loop
据我所知，不支持手动以及分步indexing（你写range限定范围是不行的，<code>[i,j][k]</code>这样的分步indexing方式也是不支持的）。</p>
</div>
<p>​
此外，这里简单提一下与meta-programming有关的内容。Taichi的meta-programming貌似并没有C++/Rust那么复杂，并不涉及到非常底层的类型推断、泛型等问题。Taichi中的<code>ti.template()</code>与field作为函数参数输入有关，由于field是复杂的data
container，其可以是scalar container，也可以是vector / matrix
container，内部的类型也是可变的，作为matrix
container时维度也是可变的。如果没有<code>ti.template()</code>而是要清楚地
type annotate
输入类型，会很繁琐，并且也不方便代码复用。使用<code>ti.template()</code>作为
type hint 可以方便输入不同类型的field。此外，如果需要达到 shape
agnostic，可以使用<code>grouped</code>方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> I <span class="keyword">in</span> ti.grouped(y):</span><br><span class="line">    x[I] = y[I]</span><br></pre></td></tr></table></figure>
<p>​
可以避免：一维时<code>x[i]</code>，二维时<code>x[i, j]</code>，三维时<code>x[i, j, k]</code>这样与shape有关的写法。</p>
<p>​ 最后注意：</p>
<ul>
<li>dynamic
node在当今的1.3.0版本已经deprecated，所以不用特别关注。即将到来的1.4.0版本中，pointer以及bitmasked也将不再支持。我很好奇官方会推出什么替代方案。</li>
<li><code>@ti.pyfunc</code>是已经deprecated的修饰符，虽然博文I中提到了，但我自己用了之后总是有warnings。</li>
<li>offset是很有用的功能，在field中，可以直接作为初始化参数设置offset，而对于SSDS，则在place阶段进行设置。offset可以实现padding，使得实现者无需考虑padding之后index的改变问题（这个学期写视频处理和宽带通信课的patch
matching的时候老折磨了，padding之后的index得认真推）</li>
<li>虽然我们只需SSDS最终的叶节点有想要的层级结构，适当地保存一些非叶节点作为handle，对于每次迭代需要清零的情况，可以使用handle直接执行：<code>deactivate_all()</code>方法以递归地deactivate当前以及所有子结点。</li>
</ul>
<h3 id="关于逻辑">3.3 关于逻辑</h3>
<p>​ 自己看代码吧，主要逻辑是这样的：</p>
<ul>
<li>角速度控制：直接控制的是角速度，角度更新根据角速度乘以系数。平滑随机方向：正常情况下boid的轨迹是随机的，但由于随机性体现在角速度上并且经过了很强的指数平滑，角度将会较为平滑地变化，轨迹是连续平滑的。有关随机性的实现，见基类<code>boid_random_vel</code>函数</li>
<li>超界转向：参考<code>oob_angular_acc</code>，即超界后将会计算一个目标角度（当前位置到图像中心的方向角），随后使用P控制扭转方向</li>
<li>Alignment：搜索邻近boid，根据距离加权角度（由于角度加权存在奇异性问题，故加权方向向量后atan2函数转为角度）</li>
<li>Separation &amp;
Cohesion：两者实现在一起，都需要计算当前位置到局部质心的方向向量。Separation倾向于原理局部质心，而cohesion倾向于靠近局部质心。接近与远离依靠目标角的方向实现：接近即目标角指向局部质心，远离即目标角指向局部质心方向旋转180°后的结果。当前应当接近、远离按当前位置距离质心的距离确定，参考粒子间作用力模型，实现是一个不对称截断（clamp）的平移后tanh函数。</li>
<li>普通鸟与掠食者（普通鸟就是鸽子，<code>Pigeon</code>类），掠食者之间不会相互作用或者配合。普通鸟存在警戒范围，倾向于远离警戒范围内的掠食者（的质心），而掠食者将在掠食范围内追踪距离最近的普通鸟。</li>
<li>掠食者可以进行自动控制，也可以选其一进行鼠标控制（跟踪鼠标方向）</li>
</ul>
<hr>
<h2 id="iv.-传统艺能-结果">IV. 传统艺能-结果</h2>
<p>​
结果如下，45FPS的样子（注意，如果使用<code>arch = ti.gpu</code>，需要把代码中的<code>atom_ptr</code>类型从u8换为i32，貌似GPU不支持u8
<code>atomic_add</code>，我记得也是这样，有些数据类型，有符号的原子操作存在，无符号则不存在）。</p>
<video src="video.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<center>
Figure 5. 什么鸟视频
</center>
<p>​ 如果你感兴趣，安装Taichi之后可以自己clone我的 <a href="https://github.com/Enigmatisms/learn_taichi">learn_taichi</a>
库，在learning_examples中，<code>flocking_sim.py</code>可以直接运行。参数在<code>if __name__ == "__main__"</code>后。如果需要开启鼠标控制其中一只掠食者，请将<code>line 262</code>的<code>last_one_human</code>改为True。注意，当前代码暂不支持无掠食者（在我前几个commit中应该是有无掠食者的，现在的代码稍微有点复杂）。</p>
<p>​ 最后提一句，如有有兴趣，看<a href="https://docs.taichi-lang.org/docs/overview">官方文档</a>，官方文档质量非常高。看完就自己写写，文档不是看会的，是用会的。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://stackoverflow.com/questions/5041328/in-cuda-what-is-memory-coalescing-and-how-is-it-achieved">In
CUDA, what is memory coalescing, and how is it achieved?</a></p>
<p>[2] <a href="https://docs.taichi-lang.org/docs/sparse">Taichi Lang
Docs v1.3.0: Spatially Sparse Data Structures</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>Taichi lang</tag>
        <tag>CUDA</tag>
        <tag>LLVM</tag>
      </tags>
  </entry>
  <entry>
    <title>Taichi Learning I</title>
    <url>/2023/01/11/Taichi-Learning-I/</url>
    <content><![CDATA[<h1 id="taichi-lang-i">Taichi Lang I</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​ 巨佬们的工作（胡渊明，李子懋 both from MIT CSAIL）：</p>
<ul>
<li>Taichi: A Language for High-Performance Computation on Spatially
Sparse Data Structures. ToG 2019</li>
</ul>
<p>​
刚好最近工作与图形学高度相关，并且一直觉得自己Python方面的技术栈太浅了（语法、代码加速了解得不够深入），于是想了解一下这个语言（与Python高度耦合）。这个语言在前年七月我刚开始做毕设的时候Dinger就在絮絮叨叨说Taichi怎么怎么香了，当时也玩了几个demo，但没有去了解语言本身。最近开始了解后觉得，要深入了解这个语言还是需要一些外围知识的辅助（比如，学了CUDA、LLVM等则会觉得接受其设计思想是一件比较容易的事情）。学这个语言的目标当然是用Taichi写一个简单的
path tracer
出来叻...。本文的主要内容有：（1）这几天学习时遇到的问题（2）一些Taichi底层原理（3）Python
decorator补充（4）自己做的一些小demo。</p>
<center>
<img src="/2023/01/11/Taichi-Learning-I/logo.png" style="zoom: 50%;">
</center>
<center>
Figure 1. 混元形意太极 闪电五连鞭
</center>
<span id="more"></span>
<h2 id="ii.-taichi-scope">II. Taichi scope</h2>
<h3 id="概念-调用问题">2.1 概念 &amp; 调用问题</h3>
<p>​ 首先，我们需要明确Taichi scope与Python
scope的定义（之后会给出一些由于我没有彻底搞清楚定义而犯错的例子）。根据官方文档：</p>
<div class="note warning"><ul>
<li>The code inside a kernel or a Taichi function is in the <em>Taichi
scope</em>. The code in the Taichi scope is
<strong><u>compiled</u></strong> by Taichi's runtime and
<strong><u>executed in parallel</u></strong> on multi-core CPU or GPU
devices for high-performance computation. The Taichi scope corresponds
to the <code>__device__</code> side in CUDA.</li>
<li>Code outside of the Taichi scope is in the <em>Python scope</em>.
The code in the Python scope is native Python and executed by Python's
<strong><u>virtual machine</u></strong>, <em>not</em> by Taichi's
runtime. The Python scope corresponds to the <code>__host__</code> side
in CUDA.</li>
</ul>
</div>
<p>​ 我进行了一些小标注（<code>__device__</code>,
<code>__host__</code>）。就语言特性而言，与我的理解（类似CUDA）基本是一致的，甚至连kernel
call的方式也非常类似：kernel function只能在Python
scope中被调用，不可以在kernel或者<code>ti.func</code>中进行调用。CUDA实际上支持这一操作（dynamic
parallelism），但需要特殊的编译技术以及足够高的arch（而且从我之前的经验来看，动态并行的kernel调kernel技术不一定有多快）。</p>
<p>​ 下面给出一个例子以说明如下问题：</p>
<blockquote>
<p>A kernel can take multiple arguments. Note that you <em>cannot</em>
pass any arbitrary Python object to a kernel because Python objects can
be <strong>highly dynamic</strong> and may hold data that Taichi's
compiler cannot recognize.</p>
</blockquote>
<p>​ 我在写SDF marching squares时由于有如下需求：</p>
<ul>
<li>可视化的SDF颜色是不同物体颜色的混合，混合策略基于SDF（或者距离值）的大小。如果是简单的SDF
marching
squares算法，只需要把不同物体SDF加在一起即可。但由于有颜色混合需求，每一个物体的SDF需要被保存（以供后续使用，重算当然会更耗时）</li>
<li>我一开始直接用一个Python <code>list</code>
存储<code>taichi.field</code>，相当于：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sdf_maps = [ti.field(dtype = ti.f32, (width, hieght)) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(ball_num)]</span><br></pre></td></tr></table></figure>
<p>​ 一开始，我在Python
shell中进行了简单的验证（是否会报错，是否可以修改其中的项），发现无问题。在实际运行时则报错（报错信息大概是）。首先简单提一下报错处的逻辑：</p>
<ul>
<li><code>@ti.kernel</code>
函数，函数传入一个<code>i32</code>（作为当前处理物体的index）。那么如果需要计算对应index物体的SDF，则需要<code>sdf_maps[index]</code>，将field从list中取出。</li>
</ul>
<p>​ 很快啊，直接报错：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TypeError: list indices must be integers or slices, not Expr</span><br></pre></td></tr></table></figure>
<p>​
我大为不解。我传入的index都已经进行annotation叻，为什么说index是一个表达式？各种尝试无果，最后把<code>list of 2D ti.field</code>
换成了一个3D <code>ti.field</code>（我一开始的color
mapindexing也是这样的）。一个minimal的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ti.init()</span><br><span class="line">glob = [ti.field(ti.f32, (<span class="number">20</span>, <span class="number">20</span>)) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>)]</span><br><span class="line"></span><br><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">indexing</span>(<span class="params">idx: <span class="built_in">int</span></span>):</span><br><span class="line">    field = glob[idx % <span class="number">8</span>]</span><br><span class="line">    <span class="keyword">for</span> i, j <span class="keyword">in</span> field:</span><br><span class="line">        field[i, j] = <span class="built_in">float</span>(idx)</span><br><span class="line">        </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">64</span>):</span><br><span class="line">    indexing(i)</span><br></pre></td></tr></table></figure>
<p>​
第五行的<code>idx: int</code>换成<code>idx: ti.i32</code>结果都是一样的。从报错的位置来看：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ast\ast_transformer.py&quot;, line 250, in build_Subscript get_ref=get_ref)</span><br><span class="line">impl.py&quot;, line 149, in subscript return value[_indices[0]]</span><br></pre></td></tr></table></figure>
<p>​ 应该是在进行一些魔法编译或者LLVM转换。对此，Github的一个issue是<a href="https://github.com/taichi-dev/taichi/issues/2104">[这样解释的]</a>。</p>
<blockquote>
<p>This is because Taichi doesn't like Python lists as data storage. The
<code>Expr</code> here is acutually a <strong>Taichi integer</strong>,
not Python integer, therefore cannot pass (原文打错了，达成了ass♂) as
index to a Python list.</p>
</blockquote>
<p>​ なるほど!
此即一个典型的例子：Python与Taichi数据结构最好不要混用。Python可以轻易访问Taichi的数据结构（比如在<code>ti.init</code>之后创建一个<code>ti.Vector.field</code>，通过indexing可以很简单访问），但在kernel中却无法很好地对Python的动态数据结构进行访问。而且动态意味着，编译时所处理的内容都是不确定的，谁能知道for循环内要对什么样的变量进行遍历呢？</p>
<p>​ 顺便提一句，kernel要求还挺多：</p>
<ul>
<li>只能有一个return语句（很久之前的CUDA好像也是这样的）</li>
<li>只能返回一个变量（不像python可以pack成一个tuple）</li>
<li>返回变量的元素不要超过30（... 为什么，出于性能考虑么）</li>
<li>返回值可以进行类型转换（比如我返回一个Vector，但是返回的type
annotation是i32... 这样的cast做不到）</li>
<li>kernel函数输入变量有大小限制（啊这）：OpenGL为32个element，其他为64个。</li>
<li>kernel会将全局变量视为常量（不当指针），应当只有field做得到非常量：<code>Vector</code>,
<code>Matrix</code>, <code>Ndarray</code>
都是无法进行kernel内indexing的，会报错如下错误。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">AssertionError: __getitem__ cannot be called in Taichi-scope</span><br></pre></td></tr></table></figure>
<div class="note danger"><p>​ 关于这一点，我多嘴几句。Taichi有强制 loop unrolling 机制（使得for
loop无需判断循环条件，更快），所以在kernel中的 Vector,
Matrix，其indices都需要是编译期常量（compile-time
constants）。也即：</p>
<ul>
<li>field 可以使用变量进行indexing操作</li>
<li>Vector，Matrix在Taichi
scope中只能用常量进行indexing。不是特别方便，阻止了任意的向量、矩阵操作（只能使用内置的函数操作），CUDA至少还有很高的自由度（对应的开发难度当然也比较高）。</li>
</ul>
</div>
<ul>
<li>scope local variable，看下面一个例子：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vec = ti.Vector([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">@ti.kernel</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_vec</span>():</span><br><span class="line">    <span class="comment"># global vec</span></span><br><span class="line">    vec = ti.Vector([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Process started: <span class="subst">&#123;vec&#125;</span>&quot;</span>)</span><br><span class="line">set_vec()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Process completed: <span class="subst">&#123;vec&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>​
输出将会全都是<code>[1 2 3]</code>。感觉很奇怪？不奇怪，对Pythoner来说很奇怪：C/C++中重名的local
variable优先级都会更高，由于Taichi是编译式的，<code>vec</code>在kernel内定义了一个重名的local
variable，改变它的值当然不会影响global变量。而如果你想要改变global变量，在Python中我们学过<code>global</code>关键字，但在Taichi中被ban叻（会报错）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Unsupported node &quot;Global&quot;</span><br></pre></td></tr></table></figure>
<p>​ 而<code>@ti.func</code>的要求则很宽松。</p>
<h3 id="反向问题---python-scope做不到的事">2.2 反向问题 - Python
scope做不到的事</h3>
<p>​ 最简单的：Python
scope中无法调用<code>@ti.func</code>修饰的函数，正如CUDA中，CPU无法调用<code>__device__</code>声明的函数而只能由<code>__global__</code>或者另一个<code>__device__</code>函数调用一样。从现在遇到的问题来看，这部分可以说的内容并不多：</p>
<ul>
<li><code>ti.random</code> 不可在python
scope中被调用（此外需要说明的是，这个函数只接受primitive types,
比如float, int之类的，假设我需要一个random
matrix，最简单的办法可能是用<code>numpy</code>再利用Taichi的<code>from_numpy</code>接口）。</li>
<li>原子操作（<code>atomic_xxx</code>系列），看下面一个例子：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test_atomic</span>():</span><br><span class="line">    field = ti.field(ti.i32, (<span class="number">20</span>, <span class="number">20</span>))</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @ti.kernel</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">increment</span>():</span><br><span class="line">         <span class="keyword">for</span> i, j <span class="keyword">in</span> field:</span><br><span class="line">             ti.atomic_add(field[i, j], <span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">    increment()</span><br><span class="line">    ti.atomic_add(field[<span class="number">0</span>, <span class="number">0</span>], <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>​
注意，第九行可以顺利执行，结果也是正确的（虽然这里用原子操作并没有什么意义，原始代码就不会有什么race
condition）。而第十行会报错：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">...\taichi\lang\ops.py&quot;, line 1235, in atomic_add</span><br><span class="line">    expr.Expr(_ti_core.expr_atomic_add(x.ptr, y.ptr), tb=stack_info()))</span><br><span class="line">AttributeError: &#x27;int&#x27; object has no attribute &#x27;ptr&#x27;</span><br></pre></td></tr></table></figure>
<p>​ 个人认为原因与kernel编译机制有关：直接在Python
scope中运行使用的是Python虚拟机以及解释器，可能不存在指针这种玩意？而如果在Taichi
scope中执行，会先编译并转为对应backend（如果是C++后端则可以有指针设计）。这个例子中，原子操作并没有被直接禁止（<code>ti.random</code>则直接报错说不能在Python
scope中被调用）。</p>
<p>​
此外注意，某些函数在<code>ti.init</code>调用之前不能调用（可能，所有函数吧），举个例子：<code>ti.field</code>创建一个field，这个函数不能先于<code>ti.init</code>调用，但<code>ti.Vector</code>之类的数据结构（Taichi基本结构，在<code>ti.types</code>中可以找到类型的，是可以的）：</p>
<ul>
<li>比如<code>ti.VectorNdarray</code>，<code>ti.MatrixNdarray</code>，在<code>ti.types</code>中没有，虽然在没有init时调用不会告诉你<code>May be call ti.init() first?</code>，但由于在构造函数中都有：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.arr = impl.get_runtime().prog.....</span><br></pre></td></tr></table></figure>
<p>​
<code>get_runtime()</code>在<code>ti.init</code>被调用前是<code>None</code>，所以其实隐式要求了init。</p>
<h3 id="泛型与编译过程">2.3 泛型与编译过程</h3>
<p>​
我还没有深入到泛型的使用，故本节只简单提一些设计以及逻辑层面的内容。</p>
<h4 id="why-type-annotation">2.3.1 Why type annotation</h4>
<p>​ C++的泛型还不是特别熟（use case不多，练得少，设计泛型小项目有点...
困难？费脑子？），只能进行一些基础编程。唔，现在接触了三种泛型，三种都是浅尝辄止（淦，感觉万金油什么都不会捏）：</p>
<ul>
<li>C++ meta-programming</li>
<li>Rust generics (Rust太久没写了，有点忘了)</li>
<li>Taichi meta-programming</li>
</ul>
<p>​ （<strong><u>正文开始</u></strong>）官方文档上有这样的一段话：</p>
<div class="note info"><ul>
<li>Type hinting in Python is recommended, <em>not</em> mandatory.</li>
<li>Taichi makes it mandatory that you type hint the arguments and the
return value of a kernel unless it does not have an argument or a return
statement.</li>
</ul>
</div>
<p>​ 也即要求进行显式的type annotation（在编译时Taichi
backend编译相当于类型声明）。为什么要这样？原因其实很简单，类型推断不是一件简单的事情。我们在C++中接触了很多类型推断的case，举个例子：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Ty1&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">inference_case1</span><span class="params">(Ty1&amp; val)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span>&amp; a = <span class="number">1</span>;</span><br><span class="line"><span class="built_in">inference_case1</span>(a);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Ty2&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">inference_case2</span><span class="params">(Ty2 val)</span></span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> b = <span class="number">2</span>;</span><br><span class="line"><span class="built_in">inference_case2</span>(b);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Ty3, <span class="keyword">typename</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">inference_case3</span><span class="params">(<span class="type">const</span> std::vector&lt;Ty3&gt;&amp; vec, T idx)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> vec.<span class="built_in">begin</span>() + idx;</span><br><span class="line">&#125;</span><br><span class="line">std::vector&lt;<span class="type">size_t</span>&gt; vec = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;;</span><br><span class="line"><span class="type">uint32_t</span> idx = <span class="number">2</span>; </span><br><span class="line"><span class="keyword">auto</span> result = <span class="built_in">inference_case3</span>(vec, idx);</span><br></pre></td></tr></table></figure>
<p>​
问上述<code>Ty1</code>，<code>Ty2</code>，<code>idx</code>分别推导出来是什么类型？这里只给出结论，不清楚的话自己去补：<code>Ty1 = const int</code>，<code>Ty2 = int</code>，<code>std::vector&lt;int&gt;::const_iterator</code>。但从这样的简单例子可以发现（我的目前的理解，可能是错的，毕竟我泛型学得不深），C++可以进行类型推断一定在于参与推导的类型一定是编译期可知的（直接，或间接）。对于Taichi而言，由于kernel
function是从Python
scope中调用的，Python作为弱类型动态语言，类型是不定的，你要让Taichi编译器无中生有，从你都不一定知道是个啥的类型中推出来简直是强人锁♂男。所以参数、返回值需要强制type
hint（返回值的话，我总感觉可以推出来的样子？乍一想脑子里没有很好的无法推出的例子...）。</p>
<h4 id="编译过程在做什么">2.3.2 编译过程在做什么</h4>
<p>​ 粗浅理解一下，这里只提一些重要过程：</p>
<pre class="mermaid">
graph LR

A(Python code)--&gt;|AST transformation|B(Python&#x2F;Taichi AST)--&gt;|Optimization &#x2F; compile|C(Taichi IR)--&gt;|Optimization &#x2F; compile|D(Kernels)

</pre>
<center>
Figure 2. 编译过程重要事件（个人理解）
</center>
<p>​ 首先是AST transformation（Abstract Syntax Tree），相当于将Python
code组织成更容易分析、跟踪的表征（比如，清楚地记录每个symbol在第几行第几列，属于调用、函数名、变量还是什么其他的类型），这是Python
code在进入解释器之前的一步重要操作（可以看作是一种“编译”），详见<a href="https://medium.com/@wshanshan/intro-to-python-ast-module-bbd22cd505f7">[这篇文章]</a>。Taichi也会生成对应的AST，对AST进行分析，生成Taichi中间表示（IR
- intermediate
representation），与LLVM不同，Taichi中间表示更加“高级”（high-level），粒度更大、更加抽象，所以保留了很多原有的信息，对Taichi
IR先进行一次优化可以得到更好的优化效果：</p>
<center>
<img src="/2023/01/11/Taichi-Learning-I/image-20230111101008259.png" alt="image-20230111101008259" style="zoom:67%;">
</center>
<center>
Figure 3.
可分析度与优化力度的trade-off：越底层越容易进行优化，但越顶层信息越多、可以进行优化质量越高
</center>
<p>​
胡渊明在其PPT中提了一些有趣的点，用以佐证“信息越多，优化机会越多”这一观点：</p>
<ul>
<li>指针名不可相互覆盖：<code>a</code>就是<code>a</code>，<code>b</code>就是<code>b</code>，除非两者相同，否则两者不会指向同一位置</li>
<li>内存访问全经手<code>field[indices]</code>：C中的指针可以灵活地cast，“几乎任意地”指向任何object，这会给优化造成麻烦，而Taichi中，指向的object以及类型都是固定的（const以及类型已知的指针）</li>
<li>修改存储信息的唯一方法：<code>field[indices]</code>（灵活性换速度）</li>
<li>读操作不会修改任何内容：不报错，也不会在超界时“智能地”new一个object出来</li>
</ul>
<h4 id="interesting-bls">2.3.3 Interesting BLS</h4>
<p>​ 此处真就几句话带过：Block local
storage（目前还没用到，但读docs时看到这个feature，觉得非常有意思），假如你明白CUDA内存机制，这个概念就非常简单，下面以CUDA内存机制进行类比：</p>
<ul>
<li>GPU的两类内存：global
memory（顾名思义，任何block、线程均可访问），shared
memory（一个block内的线程共享，不同block之间不可相互访问）</li>
<li>global memory巨慢无比，shared memory访问速度可达global
memory的20-100倍（通常，10个cycles内，相比于200cycles以上的global
memory）</li>
<li><strong><u>需要反复读取或者写入的变量</u></strong>：如果不存在寄存器上，就可以存在shared
memory上加速访问。</li>
</ul>
<p>​ Taichi也有类似操作，见下图，这里我就不展开讲了：</p>
<p><img src="/2023/01/11/Taichi-Learning-I/image-20230111105501475.png" alt="image-20230111105501475" style="zoom: 67%;"></p>
<center>
Figure 4. CUDA！（幻视）
</center>
<p>​
虽然Taichi没有CUDA底层那么灵活，但它效率高啊，我是经历过这种事情的（见下图），之后需要好好研究一下<code>ti.cache_shared</code>以及一些进阶加速写法。</p>
<p><img src="/2023/01/11/Taichi-Learning-I/image-20230111105638243.png" alt="image-20230111105638243" style="zoom: 75%;"></p>
<center>
Figure 5. 感觉像是中译英词数爆炸
</center>
<hr>
<h2 id="iii.-python盲区---decorator">III. Python盲区 - decorator</h2>
<p>​
遥想公瑾当年，看不懂decorator的燃情岁月，仿佛就在昨天。当年对语言、算法的敏感度都没有今天那么高（相对高，绝对低），看不明白是很正常的事情，加上笔者比较笨、急躁，看两眼就润了...</p>
<p>​
decorator其实很简单，不懂的时候觉得装逼，懂了就觉得挺语法糖的（毕竟减少了代码重复率），对于简单的用法，其本质就是：由于函数也是object，可以赋值来赋值去的，一个“修饰函数”可以接收函数object作为参数，在原函数的基础上增加一些功能（但保持原函数代码不变性），内部实现就是一个函数wrapper：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_notify</span>(<span class="params">init_func</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inner_wrapper</span>(<span class="params">*args, **kwargs</span>):		<span class="comment"># I will skip this unpacking syntax</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Intialization process started.&quot;</span>)</span><br><span class="line">        ret = init_func(*args, **kwargs)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Intialization process completed.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> ret</span><br><span class="line">   	<span class="keyword">return</span> inner_wrapper</span><br><span class="line">        </span><br><span class="line"><span class="meta">@init_notify</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">initialize</span>():</span><br><span class="line">    <span class="comment"># some bad-ass class initialization code</span></span><br></pre></td></tr></table></figure>
<p>​
实际上，<code>@init_notify</code>过程就是把initialize包了一层，等同于<code>init_notify(initialize)</code>，但是<code>init_notify(initialize)</code>写法也太函数式叻（假设我有很多wrapper，每个都要包一层，看起来就跟洋葱似的）。注意，如果修饰器要带参数输入（带参数修饰），则更加复杂，由于作为修饰器本身的函数只能接收一个参数：<code>@init_notify</code>
是修饰器函数，其本身的参数就是下面的initialize函数，跟在<code>@</code>后面的这一块是一个
<strong><u>单一参数函数</u></strong>，那么我们只需要设计一个函数，返回一个单一参数函数但同时支持输入我们需要的内容就可以：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">notify</span>(<span class="params">name: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_notify</span>(<span class="params">init_func</span>):</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">inner_wrapper</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;name&#125;</span> process started.&quot;</span>)</span><br><span class="line">            ret = init_func(*args, **kwargs)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;name&#125;</span> process completed.&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> ret</span><br><span class="line">        <span class="keyword">return</span> inner_wrapper</span><br><span class="line"><span class="keyword">return</span> init_notify</span><br></pre></td></tr></table></figure>
<p>​
调用很简单：<code>@notify("Initialization")</code>。别以为这里的修饰器函数带了参数，修饰器函数不是<code>notify</code>，而是<code>notify</code>的返回值（一个单参数函数）。</p>
<p>​
参考Taichi的源码，查了一下<code>@ti.func / @ti.kernel</code>，代码中用到了<code>functools</code>的<code>wraps</code>函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@functools.wraps(<span class="params">func</span>)</span></span><br></pre></td></tr></table></figure>
<p>​
这个函数的作用就是将输入函数的部分信息迁移到修饰后函数，由于修饰后函数实际上是返回的<code>inner_wrapper</code>函数，其名字（<code>__name__</code>），help文档（<code>__doc__</code>）都无了，故可以用<code>wraps</code>函数修饰<code>inner_wrapper</code>（直接在<code>def inner_wrapper</code>上方加<code>@functools.wraps(func)</code>）。</p>
<div class="note warning"><p>​
注意，Taichi的修饰器函数貌似有两个输入参数。有默认参数则没有问题，代码中也给出了True的修饰方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>(<span class="params">fn, is_real_function=<span class="literal">False</span></span>):</span><br><span class="line">    	<span class="comment">#...</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">real_func</span>(<span class="params">fn</span>):</span><br><span class="line">    <span class="keyword">return</span> func(fn, is_real_function=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>​
也就是说：<code>@real_func</code>就行了。不过我现在还没查到什么是real
function</p>
</div>
<p>​
这里提供一个小sidenote：<code>@pyfunc</code>修饰：表示被修饰函数可以在Taichi
 Python scope中调用：</p>
<ul>
<li>在Taichi scope中调用时，会进行编译</li>
<li>在Python scope中调用时，直接就是原始Python
code的执行方式。这么看来，相当于<code>__device__ __host__</code>修饰的CUDA函数，可以同时在host以及device上调用，不过CUDA会编译生成两份代码（一份是NVCC编译生成的GPU代码，另一部分是C编译器生成的CPU代码）。</li>
</ul>
<hr>
<h2 id="iv.-show-cases">IV. Show Cases</h2>
<p>​
很垃圾的玩意，刚学，技术很差。不过Taich确实强，SDF这个比我之前用OpenCV写得快多了（虽然逻辑不是特别一样，但功能更强了，OpenCV那一版本只能绘制zero
level set，这一版本我可以混合颜色）。具体的代码见：<a href="https://github.com/Enigmatisms/learn_taichi">Github:
Enigmatisms/learn_taichi</a></p>
<table>
<colgroup>
<col style="width: 64%">
<col style="width: 35%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;">Distance Field visualization</th>
<th style="text-align: center;">SDF marching squares</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><img src="/2023/01/11/Taichi-Learning-I/DF.gif" style="zoom:166.67%;"></td>
<td style="text-align: center;"><img src="/2023/01/11/Taichi-Learning-I/ms-sdf.gif"></td>
</tr>
</tbody>
</table>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] Hu, Yuanming, et al. "Taichi: a language for high-performance
computation on spatially sparse data structures." <em>ACM Transactions
on Graphics (TOG)</em> 38.6 (2019): 1-16.</p>
<p>[2] <a href="https://yuanming.taichi.graphics/publication/2020-life-of-kernel/life_of_a_taichi_kernel.pdf">Yuanming
Hu: Life of a Taichi Kernel</a></p>
<p>[3] <a href="https://yuanming.taichi.graphics/publication/2020-taichi-tutorial/taichi-tutorial.pdf">Hu,
Yuanming. "The Taichi Programming Language: A Hands-on Tutorial." ACM|
Special Interest Group on Computer Graphics and Interactive Techniques
Conference Courses, 2020.</a></p>
<p>[4] <a href="https://docs.taichi-lang.org/">Taichi lang docs</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>Taichi lang</tag>
        <tag>CUDA</tag>
        <tag>LLVM</tag>
      </tags>
  </entry>
  <entry>
    <title>Rust C++小记录</title>
    <url>/2022/08/20/Rust-C-%E5%B0%8F%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<h1 id="rustc">Rust/C++</h1>
<hr>
<p>​
很久之前（3个月前吧）写的文档了，当时还在学Rust以及零零散散地学一些C++STL库用法（哪知《effective
modern
C++》这般好书？）。Rust部分的记录还挺有趣的，C++部分就没有那么有趣了。索性就贴在此处，供日后查阅。（不过很长啊，这叫snippet？）</p>
<span id="more"></span>
<hr>
<h2 id="rust-部分">Rust 部分</h2>
<ul class="task-list">
<li><label><input type="checkbox" checked>包管理：lib.rs与mod.rs的区别是什么？我在mod.rs或者lib.rs中写什么内容，会如何影响整个包？比如我是否可以在lib.rs或者mod.rs中进行全局的use？</label></li>
</ul>
<p>​
个人认为可以这么理解：<code>lib.rs</code>声明了一个crate中所包含的模块，比如下面这个例子：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">src/</span><br><span class="line">├── add.rs</span><br><span class="line">├── sub.rs</span><br><span class="line">├── main.rs</span><br><span class="line">└── lib.rs</span><br></pre></td></tr></table></figure>
<p>​ 则<code>add,rs</code>
以及<code>sub.rs</code>是此crate的两个模块，在<code>lib.rs</code>对此两模块的“存在性”进行声明。一般是：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">mod</span> add;		<span class="comment">// 可以加pub</span></span><br><span class="line"><span class="keyword">mod</span> sub;		<span class="comment">// 可以加pub</span></span><br></pre></td></tr></table></figure>
<p>​
对于与这些模块处于同一目录的<code>main.rs</code>，可以不需要<code>lib.rs</code>就在<code>main.rs</code>中通过<code>mod xxx;</code>的方式声明模块。但如果可执行文件与模块不在同一目录下，貌似（据我所知）只能通过：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">use</span> crate_name::add;</span><br><span class="line"><span class="keyword">use</span> crate_name::sub;</span><br></pre></td></tr></table></figure>
<p>​
这样的方式调用模块。这样调用模块必须通过<code>lib.rs</code>对模块进行声明！否则编译将出现：找不到模块
的错误。而另一方面，<code>mod.rs</code>是什么？有什么作用？对于一个大型的模块，我们很可能将其拆为多个文件。比如<code>add.rs</code>，我们将其拆分为：<code>add_inplace.rs</code>，<code>add_2_digits.rs</code>，<code>add_more_than2.rs</code>三个文件，我们可以将三个文件按照如下所示的方式进行整理：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">src</span><br><span class="line">├── add</span><br><span class="line">...			├── add_inplace.rs</span><br><span class="line">			├── add_2_digits.rs</span><br><span class="line">			└── add_more_than2.rs</span><br></pre></td></tr></table></figure>
<p>​
此时我们需要<code>mod.rs</code>来同一整个模块内部的所有子模块。在<code>add/</code>中建立叫做<code>mod.rs</code>的文件，或者与<code>add/</code>同级建立<code>add.rs</code>目录，内部声明子模块：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">mod</span> add_inplace;</span><br><span class="line"><span class="keyword">mod</span> add_2_digits;</span><br><span class="line"><span class="keyword">mod</span> add_more_than2;</span><br></pre></td></tr></table></figure>
<p>​
故简单来说：<code>lib.rs</code>声明一个crate下的所有模块，<code>mod.rs</code>声明一个模块下的所有子模块。</p>
<p>​ P.S:
在use语句引入的模块名过长时，可以使用<code>as</code>重命名。例如假设有个叫做<code>numpy</code>的模块，我们可以<code>use numpy as np;</code></p>
<hr>
<ul>
<li><p><label><input type="checkbox" checked>const 与
static在Rust中的具体含义，与全局变量之间的关系</label></p></li>
<li><p>static定义的值一般是全局变量，具有超长声明周期。注意由于static定义全局
<strong><u>变量</u></strong>，其结果是有地址的。</p></li>
<li><p>const定义的是真正的常量，是compile
time可知的值，类似于C++中的<code>constexpr</code>（大多数情况下，constexpr都是compile
time
variable）。对应地，Rust也存在<code>const fn</code>，作用类似于C++的<code>constexpr</code>函数。如果要使得一个函数输出const值，则此函数需要是<code>const fn</code>。</p></li>
<li><p>在C++中，如果编译器发现我们在给一个<code>constexpr</code>值取地址（<code>&amp;</code>），则编译器将会给此值分配一个地址，否则一般来说，<code>constexpr</code>值不会占用内存。</p></li>
</ul>
<hr>
<ul class="task-list">
<li><label><input type="checkbox" checked>iter()
与for循环：</label></li>
</ul>
<p>​
一般来说，除非变量已经是iterator（或者IntoIter等等），for循环一般都是针对<code>x.into_iter()</code>，<code>x.iter_mut()</code>，<code>x.iter()</code>三种形式进行的：</p>
<ul>
<li><code>into_iter</code>返回值视上下文而定。比如某个容器中持有的是reference，那么将返回reference，是值就返回值。<code>into_iter</code>在遍历过程中将发生move，原容器将被consumed，不再有效，但返回的是具有所有权的内容。</li>
<li><code>iter</code>与<code>iter_mut</code>一般则（分别）返回immutable
references 以及 mutable references，不会消耗原有容器。</li>
</ul>
<p>​ iterator内部具有很多有用的函数：</p>
<ul>
<li><code>advance_by</code>：与<code>next</code>不同，<code>advance_by</code>是非单步的移动，可以传入一值确定iterator前进的步数。超过返回返回Err。</li>
<li><code>all</code>与<code>any</code>，两个函数均可以传入闭包，用以判定每一个元素是否满足要求。含义与python的<code>all</code>与<code>any</code>一致。</li>
<li>（常用）<code>collect</code>，个人感觉类似于<code>from_iter</code>。事实上，此函数返回一个<code>FromIterator</code>。也即可以由iterator构造一些数据结构，如vec。比如：</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">vector</span>: <span class="type">Vec</span>&lt;<span class="type">usize</span>&gt; = (<span class="number">0</span>..=<span class="number">10</span>).<span class="title function_ invoke__">map</span>(|x| &#123;x * x + <span class="number">2</span> * x&#125;).<span class="title function_ invoke__">collect</span>();</span><br></pre></td></tr></table></figure>
<p>​
其中，左边的type是必须要确定的，否则collect无法得知自己应该返回什么类型。</p>
<ul>
<li><code>chain</code>：类似于<code>extend</code>或者<code>concatenate</code>。<code>a.iter().chain(b.iter())</code>将返回串联的iterator，用于遍历等。</li>
<li><code>cycle</code>：将iterator首位串接，使得iterator成为环状</li>
<li>（常用）<code>filter</code>：传入闭包，返回一个新的iterator，新的iterator中只含有闭包函数确定的值。比如一个判定偶数的函数等。</li>
<li>（常用）<code>filter_map</code>：传入闭包，此闭包函数返回<code>Option</code>。对于返回值为<code>Some&lt;T&gt;</code>的值，将被放入返回的迭代器中。相当于<code>.filter().map()</code></li>
<li><code>flatten</code>：当结构中存在nested
iterator时，可以使用此flatten展平。例如：<code>Vec&lt;Vec&lt;i32&gt;&gt;</code>，可以用flatten先展开（<strong><u>返回IntoIterator</u></strong>），再collect。</li>
<li>（常用）<code>fold</code>：对此iterator进行一个压缩操作，例如<code>(0..10).fold(0, |acc, x|&#123;acc + x&#125;)</code>可以求累加操作。</li>
<li>（常用）<code>for_each</code>：传入一个闭包，对每一个元素执行操作。</li>
<li>（常用）<code>last</code>：不过注意，这应该是一个O(n)操作</li>
<li>（常用）<code>nth</code>：<code>last</code>就是<code>nth</code>的一个特例而已</li>
<li><code>partition</code>：consume此iterator，并返回<strong><u>两个</u></strong>collection（比如两个vec）。<code>partition</code>传入一个闭包，可以认为此闭包函数返回值为true的元素在一个collection中，反之则在另一个collection中。注意，由于对于<code>iter()</code>返回的iterator而言，如果原容器内部元素的类型是<code>T</code>，那么iterator的<code>Self::Item</code>就是<code>&amp;T</code>。而partition输入的闭包要求传入<code>&amp;Self::Item</code>，也即最后，输入将会是<code>&amp;&amp;T</code>，此时可以在闭包函数参数前加<code>&amp;</code>用于dereference</li>
<li><code>product</code>：相当于返回单值的<code>cumprod</code></li>
<li><code>reduce</code>：使用某一函数将值压缩为一个（与fold几乎是一致的，只不过不需要提供初值）</li>
<li>（常用）<code>rev</code>：反向迭代。并且注意反向迭代器与正向迭代器不是同一个类型。</li>
<li><code>skip</code>：输入一个值n，迭代器将从start+n开始（跳过初始值）。<code>skip_while</code>：输入一个闭包（返回true
| false），直到闭包返回false之前的所有值都会被跳过。</li>
<li><code>step_by</code>：相当于python range(0, end, step)</li>
<li>（常用）<code>take</code>：传入一个值n，迭代器最多取到start+n
（<code>skip</code>的对称操作）。<code>take_while</code>：输入闭包，直到闭包返回false之前的所有值都会被取出到新的iterator中。注意此take与Option的take不同，Option的take应该会使得原值为None（可以认为这是某种意义上的consume），但iterator的take不会修改或消耗原值</li>
<li>（常用）<code>zip</code>与<code>unzip</code>：类似于python，<code>zip</code>将两个迭代器打包成一个迭代器，此迭代器是两个迭代器元素的tuple。unzip则将这样的迭代器重新拆为两个容器（不一定是迭代器，可以是Vec）</li>
</ul>
<hr>
<ul class="task-list">
<li><label><input type="checkbox" checked>Rust中的闭包以及程序中的闭包概念</label></li>
</ul>
<p>​
曾经我想搞清楚为什么我无法确定closure的类型，问题是这样的：我想返回某个iterator经过map后的结果，如：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">map_test</span>() <span class="punctuation">-&gt;</span> &lt;?&gt; &#123;</span><br><span class="line">    (<span class="number">0</span>..<span class="number">10</span>).<span class="title function_ invoke__">map</span>(|i| &#123;i * <span class="number">2</span>&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
但是一直无法写对返回值。<code>rust-analyzer</code>告诉我，返回值应该是<code>Map&lt;Range&lt;i32&gt;, |i32| -&gt; i32&gt;</code>。我尝试填在返回值type
annotation中，报错，无法直接填<code>Map&lt;Range&lt;i32&gt;, |i32| -&gt; i32&gt;</code>，编译器无法解析<code>|i32| -&gt; i32</code>（存在语法错误）。后来我又尝试了一些魔法，诸如：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">map_test</span>&lt;T&gt;() <span class="punctuation">-&gt;</span> Map&lt;Range&lt;<span class="type">i32</span>&gt;, T&gt; <span class="keyword">where</span> T: <span class="title function_ invoke__">Fn</span>(<span class="type">i32</span>) <span class="punctuation">-&gt;</span> <span class="type">i32</span> &#123;</span><br><span class="line">    (<span class="number">0</span>..<span class="number">10</span>).<span class="title function_ invoke__">map</span>(|i| &#123;i * <span class="number">2</span>&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
还是不行。报错大意：返回值是<code>map(closure xxxxx （文件名，行列号）)</code>而需要<code>T</code>。也就是说，返回值类型不匹配。</p>
<p>​
之后我在stackoverflow上偶然看到这样的问题：有人想把匿名闭包推入Vec中，但是Vec无法解析匿名闭包的类型。下面的佬这么回答到：</p>
<blockquote>
<p>Each closure has an <strong><u>auto-generated, unique, anonymous
type</u></strong>. As soon as you add the first closure to the vector,
that is the type of all items in the vector. However, when you try to
add the second closure, it has a <strong><u>different auto-generated,
unique, anonymous type</u></strong>, and so you get the error
listed.</p>
</blockquote>
<p>​ 也就是说，确定closure的类型貌似是不可能的。虽然如下代码：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">f1</span> = |i: <span class="type">i32</span>| <span class="punctuation">-&gt;</span> <span class="type">i32</span> &#123;i * <span class="number">2</span>&#125;;			<span class="comment">// Ok</span></span><br><span class="line"><span class="keyword">let</span> <span class="variable">f2</span> = |i: <span class="type">i32</span>| &#123;i * <span class="number">2</span>&#125;;						<span class="comment">// Ok</span></span><br><span class="line"><span class="keyword">let</span> <span class="variable">f3</span> = |i| <span class="punctuation">-&gt;</span> <span class="type">i32</span> &#123;i * <span class="number">2</span>&#125;;			      <span class="comment">// Err</span></span><br></pre></td></tr></table></figure>
<p>​
前两句可以通过编译，<code>rust-analyzer</code>也会推导出<code>|i32| -&gt; i32</code>的类型来，但想要给<code>f1</code>等变量进行type
annotation是做不到的。此外注意，如果闭包的输入不进行type
annotation（如<code>f3</code>），将会报错。而输出类型可以不要（编译器可以推导出来）。</p>
<hr>
<ul class="task-list">
<li><label><input type="checkbox" checked>Trait &amp; impl &amp;
Box&lt;dyn TraitObject&gt;</label></li>
</ul>
<p>​ Rust Programming
Language一书全面地介绍了trait的性质。其基本使用方法是：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">trait</span> <span class="title class_">TraitName</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">your_method</span>(&lt;args...&gt;) <span class="punctuation">-&gt;</span> ReturnType;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
也即我们可以自定义Trait（替换TraitName），并且限定此trait中的接口。所有具有此trait的类型，都需要自定义这些接口。可以理解为：Trait类似于基类，其中存在虚函数。我们在学习链表时已经接触过，如果需要链表具有迭代器，需要：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">impl</span>&lt;T&gt; <span class="built_in">Iterator</span> <span class="keyword">for</span> <span class="title class_">LinkIterator</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">type</span> <span class="title class_">Item</span> = ...;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">next</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;<span class="keyword">Self</span>::Item&gt; &#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>
<p>​
也即使得类型<code>LinkIterator</code>具有特性Iterator。类似于虚函数实际上是可以有默认定义的，trait
method也可以在定义trait时定义默认实现。对于使用此特性的类型，如果要使用默认方法，在<code>impl</code>块中不重定义此trait
method即可。特性中的方法，可以类似于结构体方法进行调用<code>.method()</code>，并且，特性方法是可以在类型之间共享的。</p>
<p>​
更有趣的来了：在C++泛型编程中，假设我有这样的一个模板函数，此模板函数接受一个类型T，我需要调用类型T中的某个方法<code>.method()</code>，也即类型T必须保证其实现了此方法，应该怎么做？以个人的理解：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SomeBaseClass</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">SomeBaseClass</span>(<span class="type">int</span> val): <span class="built_in">val</span>(val) &#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">printVal</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;val is %d\n&quot;</span>, val);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">    <span class="type">int</span> val;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SomeClass</span> : <span class="keyword">public</span> SomeBaseClass &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">SomeClass</span>(<span class="type">int</span> val): <span class="built_in">SomeBaseClass</span>(val) &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MutatedClass</span> : <span class="keyword">public</span> SomeBaseClass &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">MutatedClass</span>(<span class="type">int</span> val): <span class="built_in">SomeBaseClass</span>(val) &#123;&#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">printVal</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;mutated class val is %d\n&quot;</span>, val);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">callPrintVal</span><span class="params">(<span class="type">const</span> SomeBaseClass&amp; base)</span> </span>&#123;</span><br><span class="line">    base.<span class="built_in">printVal</span>();</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">SomeClass <span class="title">class1</span><span class="params">(<span class="number">5</span>)</span></span>;</span><br><span class="line">    <span class="function">MutatedClass <span class="title">class2</span><span class="params">(<span class="number">6</span>)</span></span>;</span><br><span class="line">    <span class="built_in">callPrintVal</span>(class1);</span><br><span class="line">    <span class="built_in">callPrintVal</span>(class2);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
这样可以使得所有继承了<code>SomeBaseClass</code>的子类可以进行调用。而Rust没有struct的继承，也不能这样隐式转换类型，如果我们需要实现类似的功能，使得函数可以操作某一个实现了某一功能的全体类型，应该怎么做？答案是：使用<code>impl TraitObject</code>作为参数，或者使用trait
bounds:</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">some_func</span>(item: &amp;<span class="keyword">impl</span> <span class="title class_">TraitObject</span>) &#123;</span><br><span class="line">    item.<span class="title function_ invoke__">method</span>();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">some_func</span>&lt;T: TraitObject&gt;(item: &amp;T) &#123;</span><br><span class="line">    item.<span class="title function_ invoke__">method</span>();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">some_func</span>&lt;T&gt;(item: &amp;T) <span class="keyword">where</span> T: TraitObject &#123;</span><br><span class="line">    item.<span class="title function_ invoke__">method</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
故只要知道第一种写法与后两种写法具有类似的功能，只不过后两种写法传入的是类型。而Book则给出了一个具体的区别：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">notify</span>(item1: &amp;<span class="keyword">impl</span> <span class="title class_">Summary</span>, item2: &amp;<span class="keyword">impl</span> <span class="title class_">Summary</span>) &#123;...&#125;</span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">notify</span>&lt;T: Summary&gt;(item1: &amp;T, item2: &amp;T) &#123;...&#125;</span><br></pre></td></tr></table></figure>
<p>​
上下两行代码均可以接受任意实现了Summary特性的类型，但是第二个函数显式要求了两个参数item1，item2具有相同的类型。</p>
<p>​ 另一个有趣的方面：返回值是impl
TraitObject时？意义类似：我们希望返回值实现了此特性<code>TraitObject</code>。所以我们可以用此方法解决闭包中提到的返回map(闭包)问题：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">map_test</span>() <span class="punctuation">-&gt;</span> <span class="keyword">impl</span> <span class="title class_">Iterator</span> &#123;</span><br><span class="line">    (<span class="number">0</span>..<span class="number">10</span>).<span class="title function_ invoke__">map</span>(|i| &#123;i * <span class="number">2</span>&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
但返回值的type提示是：<code>impl Iterator</code>。并且当我想按如下方式进行遍历时，报错了：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">result</span> = <span class="title function_ invoke__">map_test</span>();</span><br><span class="line"><span class="keyword">for</span> <span class="variable">x</span> <span class="keyword">in</span> result.<span class="title function_ invoke__">iter</span>() &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 原因很简单：<code>.iter()</code>是
<strong><u>非Iterator对象</u></strong>返回实现了Iterator特性对象时的方法。而由于实现了Iterator特性的对象，可以直接使用for循环遍历，也不必使用<code>.iter()</code>。（事实上，只需要看看<code>result.next</code>存不存在就知道了）。用Rust
Reference的一段话总结一下就是：</p>
<blockquote>
<p><code>impl Trait</code> provides ways to specify <strong><u>unnamed
but concrete types that implement a specific trait</u></strong>. It can
appear in two sorts of places: argument position (where it can act as an
anonymous type parameter to functions), and return position (where it
can act as an abstract return type).</p>
</blockquote>
<hr>
<ul class="task-list">
<li><label><input type="checkbox" checked>move：这玩意是干什么的？可以显式转移所有权？</label></li>
</ul>
<p>​ Rust Book如是解释move关键字：</p>
<blockquote>
<p>Capture a closure's environment by value.</p>
<p><code>move</code> converts any variables captured by reference or
mutable reference to variables captured by value.</p>
</blockquote>
<p>​
也即强制持有closure从环境中捕获的变量，将变量所有权转移给closure。关于这一切的解释，stackoverflow上有一个<a href="https://stackoverflow.com/questions/62252966/why-is-the-move-keyword-necessary-when-it-comes-to-threads-why-would-i-ever-n">非常清晰的回答</a>（排名前二的回答都很清晰易懂），并且二楼还顺带介绍了一下<code>FnOnce</code>，<code>Fn</code>，<code>FnMut</code>特性。</p>
<hr>
<ul class="task-list">
<li><label><input type="checkbox" checked>dyn：什么时候用？用来做什么？</label></li>
</ul>
<p>​
很有趣的一个关键字。已知使用<code>impl TraitObject</code>，函数可以返回一个任意实现了<code>TraitObject</code>的类型。但如果我们需要持有数个这样的类型，将其存在容器里应该怎么办呢？尝试：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">vec</span>: <span class="type">Vec</span>&lt;<span class="keyword">impl</span> <span class="title class_">TraitObject</span>&gt; = Vec::<span class="title function_ invoke__">new</span>();	<span class="comment">// Error: `impl Trait` only allowed in function and inherent method return types, not in variable binding</span></span><br><span class="line"><span class="keyword">let</span> <span class="variable">vec</span>: <span class="type">Vec</span>&lt;TraitObject&gt; = Vec::<span class="title function_ invoke__">new</span>();	<span class="comment">// Error: trait objects must include the `dyn` keyword</span></span><br></pre></td></tr></table></figure>
<p>​
这有两个错：（1）Vec并不知道实现了TraitObject的类型都有些什么，类型是
<strong><u>动态的</u></strong>，故需要使用<code>dyn</code>。（2）实现了<code>TraitObject</code>的类型并没有确定的大小（trait
bound
<code>Sized</code>没有被满足），故无法放在Vec中。故综上所述，正确的书写应该是：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">vec</span>: <span class="type">Vec</span>&lt;<span class="type">Box</span>&lt;<span class="keyword">dyn</span> TraitObject&gt;&gt; = Vec::<span class="title function_ invoke__">new</span>();	<span class="comment">// 动态类型 + Box（堆分配）确定大小</span></span><br></pre></td></tr></table></figure>
<hr>
<ul>
<li><p><label><input type="checkbox" checked>self与Self的区别</label></p></li>
<li><p>Self是当前object自身的类型（注意，Rust中只有与类型、特性有关的内容才会有首字母大写，语法提示甚至不建议你使用驼峰命名法）</p></li>
<li><p>self：当前object</p></li>
<li><p><label><input type="checkbox" checked>一些函数或者用法：</label></p></li>
</ul>
<p>​
这里主要讲一下<code>to_owned</code>函数。<code>to_owned</code>是特性<code>std::borrow::ToOwned</code>提供的方法。官方文档是这样说的：</p>
<blockquote>
<p>A generalization of <code>Clone</code> to borrowed data.</p>
<p>Some types make it possible to go from borrowed to owned, usually by
implementing the <code>Clone</code> trait. But <code>Clone</code> works
only for going from <code>&amp;T</code> to <code>T</code>. The
<code>ToOwned</code> trait generalizes <code>Clone</code> to construct
owned data from any borrow of a given type.</p>
</blockquote>
<p>​
这里不多说了。文档举了两个例子说明clone只能由<code>&amp;T</code>转<code>T</code>，而<code>to_owned</code>灵活多变：</p>
<ul>
<li><code>&amp;str</code>通过<code>to_owned</code>方法转为<code>String</code>
 <code>&amp;[i32]</code>（slice）通过<code>to_owned</code>转化为Vec。</li>
</ul>
<hr>
<h2 id="c部分">C++部分</h2>
<p>​ 最近在看C++与Rust的asynchronous
programming部分，加上好久没有写多线程程序了，故简单回顾一下一些基础库。<code>future</code>在这就不提了。</p>
<h3 id="unique_lock---lock_guard---shared_mutex---scoped_lock">unique_lock -
lock_guard - shared_mutex - scoped_lock</h3>
<p>​ 在讨论到这些锁的时候会讨论到一个概念：RAII（resource acquisition is
initialization），RAII的好处是（只是浅显地了解一下）：</p>
<ul>
<li><strong>RAII avoids using objects in an invalid state.</strong>
<strong>RAII simplifies cleanup after partial construction.</strong>[1]
比如如果构造函数失败了，此object将不会进行析构（资源在构造函数结束就已经被释放了）</li>
<li><strong><u>RAII is about
scopes</u></strong>。具体指：获取资源时调用constructor，资源无效时（比如删除，或者在范围外）自动调用析构函数。</li>
<li>RAII是另一种形式的garbage collector，用于申请以及释放资源。</li>
</ul>
<p>​ lock的RAII feature则具体指的是以下几个例子：</p>
<ul>
<li>std::lock 与
std::unlock都做不到RAII，因为本质上他们是对一个存在的锁对象进行操作。没有RAII意味着如果上锁了，就必须要手动解锁，否则可能出现问题</li>
<li>std::lock_guard与std::unique_lock都有RAII属性：lock_guard不仅仅是自动解锁，在构造时还会自动上锁。unique_lock则提供了deferred选项，使得其在构造时不立刻上锁。自动解锁是一个值得拥有的属性。</li>
</ul>
<h5 id="stdunique_lock">std::unique_lock</h5>
<p>​ unique_lock通常与conditional variable一起使用。由于conditional
variable（简称cv）使用时通常需要等待一个锁（对应的状态）变为可用：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">cv.<span class="built_in">wait</span>(mut);</span><br></pre></td></tr></table></figure>
<p>​
如果<code>mut</code>是普通的mutex，这里会有一个问题：如果wait过程中发生了错误，就会造成mut无法在wait结束进行unlock，这使得出错之后，很难进行exception
handling（emmm，大概这就是not exception
safe?）。如果使用unique_lock作为mut，unique_lock可以利用RAII特性在exception时进行解锁。并且unique_lock可以很好地保证自身是持有mutex的，以免已有的mutex被删除、move后，尝试对一个不存在的锁进行操作。</p>
<p>​
unique_lock也可以手动解锁（unlock方法）。lock_guard就没那么方便了。</p>
<p>​ 这里补充一下，std::unique_lock以及mutex本身是否可以被引用呢？</p>
<h5 id="stdscoped_lock-stdlock_guard">std::scoped_lock &amp;
std::lock_guard</h5>
<p>​
stackoverflow上有不止一条答案称std::scoped_lock强于std::lock_guard，建议是：</p>
<blockquote>
<ol type="1">
<li><code>lock_guard</code> if you need to lock exactly 1 mutex for an
entire scope.</li>
<li><code>scoped_lock</code> if you need to lock a number of mutexes
that is not exactly 1.</li>
<li><code>unique_lock</code> if you need to unlock within the scope of
the block (which includes use with a
<code>condition_variable</code>).</li>
</ol>
</blockquote>
<p>​
scoped_lock的实现上更倾向于进行多mutex操作（scoped_lock具有可变个数参数模板），unique_lock则已经说了：在与cv一起使用时最大的好处是exception
safe并且保证锁的持有（不持有就报错），并且可手动解锁。lock_guard像是一个特例化的scoped_lock。</p>
<p>​
不得不说stackoverflow是一个好网站，会有顶尖C++开发者回答你的问题，甚至包括STL标准委员会的大哥：</p>
<blockquote>
<p>When I brought it up in committee, the answer was "nothing." ---<a href="https://stackoverflow.com/users/576911/howard-hinnant">Howard
Hinnant</a></p>
</blockquote>
<h5 id="stdshared_mutex">std::shared_mutex</h5>
<p>​ shared_mutex
使用场景很明确：读者写者模型。多个读者读时，mutex可以多次上锁（内部有锁计数器？）只有计数器为0时，写者才能写。那么不使用shared_mutex应该如何实现呢？计数器mc锁以及一个计数器cnt</p>
<p>​ 对于读者而言：</p>
<pre class="mermaid">
graph TB

A(mc.lock)
B(cnt+&#x3D;1)
C(mc.unlock)
D(READ)
E(mc.lock)
F(cnt-&#x3D;1)
G(mc.unlock)
A--&gt;B--&gt;C--&gt;D--&gt;E--&gt;F--&gt;G

</pre>
<p>​ 对于写者而言：</p>
<pre class="mermaid">
graph TB

graph LR;
A(mc.lock);
B(cnt&#x3D;&#x3D;0 ?);
C(READ);
D(mc.unlock);

A--&gt;B--&gt;|Yes|C--&gt;D
B--&gt;|No|D

</pre>
<p>​
应该不会存在死锁的问题。对于shared_mutex而言，上述功能被直接包含在了此数据结构中。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1]
https://stackoverflow.com/questions/712639/understanding-the-meaning-of-the-term-and-the-concept-raii-resource-acquisiti#:~:text=RAII%20avoids%20using%20objects%20in,we%20even%20use%20the%20object.&amp;text=There%20are%20three%20error%20cases,but%20copying%20the%20files%20failed.</p>
]]></content>
      <categories>
        <category>snippet</category>
      </categories>
      <tags>
        <tag>Rust</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>Ref NeRF复现</title>
    <url>/2022/08/13/Mip-NeRF-Ref-NeRF/</url>
    <content><![CDATA[<h2 id="ref-nerf复现">Ref NeRF复现</h2>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​ 科研恢复性训练。之前把CUDA加速的全并行shadow
caster写完了，算是复习了CUDA、Rust以及FFI的使用。深度学习方面就以复现Ref
NeRF为一个小任务。论文<a href="https://dorverbin.github.io/refnerf/">CVPR 2022 Best Student
Honorable Mention: Ref NeRF - Structured View-Dependent Appearance for
Neural Radiance
Fields</a>对反射现象进行了良好的建模。之前我一直在研究折射现象的NeRF建模，就折射建模思路而言，此文对我有很大的启发。并且个人认为，基于Ref
NeRF以及mip
NeRF作为框架是比较好的选择（除此之外就是要考虑如何让训练变快了，Instant
NGP当然是不二选择）。当然，由于在复现过程中也遇到了许多问题，本文在阐述复现思路以及论文理解的同时，也会探讨踩过的坑。目前，Ref
NeRF的复现结果还没有达到令我满意的程度，只是具备雏形，毕竟融合两篇文章的idea可能导致冲突，深度学习这种玄学就更是这样了，模型炸了都不知道从哪一个先开始。复现见
<a href="https://github.com/Enigmatisms/NeRF">Enigmatisms/NeRF</a></p>
<p><img src="/2022/08/13/Mip-NeRF-Ref-NeRF/ezgif-1-8207b1faa2.gif"></p>
<center>
Figure 1. Ref NeRF半成品(Shinny Blender -
Helmet)。从左至右：RGB、depth与“奇怪的法向量”
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-论文梳理">II. 论文梳理</h2>
<h3 id="ref-nerf的建模">2.1 Ref NeRF的建模</h3>
<p>​ Ref NeRF建模了表面反射，此工作比之前所看过的一篇处理反射的NeRF（<a href="https://arxiv.org/abs/2111.15234">NeRFReN</a>）更有价值。个人认为，Ref
NeRF可以被认为是一个不完整的光线传播模型，较好地解决了反射问题，只需要加上折射部分就可以使得NeRF处理基本的光线传播现象。本文对Ref
NeRF的主要思路进行梳理，并且基于笔者对本论文的理解，在之前实现的NeRF（mip
NeRF 360）基础上，增加Ref NeRF模块。</p>
<p>​ Ref
NeRF处理的首要问题是光线的反射问题，反射一般分为两种：镜面反射（specularity）以及漫反射（diffusion）。那么根据Phong反射模型（以及之前学过半吊子图形学基础），被观察到的光线（强度）将为：
<span class="math display">\[
\begin{equation}\label{phong}
I_o=k_aI_a+\sum_{i}k_d\left( l_i\cdot n\right)I_i+\sum_i k_s(r_i\cdot
v)^pI_i
\end{equation}
\]</span> ​ 其中，下标为a的部分与环境光（ambient
light）有关；下标含有d则与漫反射有关，而下标含有s则与镜面高光有关。为了更好地解释Ref
NeRF的反射模型处理以及回顾一下Phong模型这个基础模型，这里对公式<span class="math inline">\(\eqref{phong}\)</span>模型简单解释：</p>
<ul>
<li>第一项代表环境光对观察结果的影响：环境光只对结果产生常数offset</li>
<li>第二项代表了所有光源在物体上产生的漫反射。漫反射与观察方向无关，只要能观察到，就是“恒定”的。光源i
(<span class="math inline">\(l_i\)</span>为其发射的某一光线的方向）发射光越是能垂直表面（与法向平行），漫反射越强。</li>
<li>第三项代表了镜面高光：不一定是完全的镜面反射（所以称之为镜面高光），可以稍显模糊，但是其强度是与视角有关的。<span class="math inline">\(r_i\)</span>代表了反射光线的方向，<span class="math inline">\(v\)</span>则代表了观察方向。两者重合（点乘结果接近1）时，反射较强。指数p用于加强衰减，可知p越大，<span class="math inline">\((r_i\cdot
v)^p\)</span>变化越快。也即视线与反射方向重合发生变化时，镜面高光的变化越明显。</li>
</ul>
<p>​ Ref NeRF对于后两个部分都进行了建模： <span class="math display">\[
\begin{equation}\label{ref}
L_{out}(\hat{\omega_{o}})\propto \int
L_{in}(\hat{\omega_{i}})p(\hat{\omega_{i}}\cdot\hat{\omega_{r}})d\hat{\omega_{i}}=F(\hat{\omega_{r}})
\end{equation}
\]</span> ​ 其中<span class="math inline">\(\hat{\omega_{o}}\)</span>是观察方向（相机到物体），<span class="math inline">\(\hat{\omega_{i}}\)</span>是光线的入射方向（光源到物体），<span class="math inline">\(\hat{\omega_{r}}\)</span>是观察方向在物体上的反射（可以认为是相机按照<span class="math inline">\(\hat{\omega_{o}}\)</span>方向发射光后反射的方向）。那么显然，<span class="math inline">\(\hat{\omega_{i}}\cdot\hat{\omega_{r}}\)</span>就是公式<span class="math inline">\(\eqref{phong}\)</span>中的 <span class="math inline">\(r_i\cdot
v\)</span>。在此工作中，函数p等均是神经网络（学出来的反射，强），并且作者强调，此函数就是反射方向
<span class="math inline">\(\hat{\omega_{r}}\)</span>的函数（内部包含了观察视角方向信息）。反射方向的求解非常简单，这里不赘述。不过我不禁思考，如果把作者的反射模型从Phong模型换成Bling
Phong模型会怎么样？在复现中笔者进行了尝试，结果见实验部分。</p>
<p>​ 作者花大力气改造原始NeRF的directional MLP，spatial
MLP则只是输出了一些新的辅助信息。directional MLP必须要能够输出真正的view
dependent颜色。作者认为：spatial
MLP也需要直接预测颜色，但是此颜色应该是受环境光、漫反射等影响产生的（由公式
<span class="math inline">\(\eqref{phong}\)</span>可知，环境光与漫反射均与视角无关），视角不变的颜色。严格来说，此部分颜色并非albedo（由于漫反射存在）。而directional
MLP应当产生镜面高光部分。作者对directional MLP作了如下修改：</p>
<h3 id="directional-mlp修改">2.2 directional MLP修改</h3>
<p>​ 首先，作者做了一个类似于mip NeRF中光锥处理的操作。mip
NeRF中，为了达到mip
map的效果，作者将点采样变为了光锥采样，以考虑整个光锥中的所有信息。Ref
NeRF中，作者认为“反射”也不能仅仅考虑单个反射方向。由于物体实际是凹凸不平的，并非完美的镜面，表面法向量并非完全一致。可以认为，物体表面的凹凸起伏（噪声），使得反射发生了一些改变（distortion），物体表面噪声的概率分布，经过反射的数学操作后被映射成了新的分布。并且：</p>
<ul>
<li>新的分布应该是各方向对称的。由于我们并不知道物体表面能有什么样的各向异性特征。</li>
<li>法向量分布的期望应该是 <span class="math inline">\(\hat{\omega_{r}}\)</span>，也即根据求得的表面法向量以及观察方向求出的反射方向。其背后的intuition（总觉得，不应该翻译成直觉，故我这里用了一个英文单词，以表示：我觉得这里用中文表达不了那种意思）很好理解。</li>
<li>法向量的方差应该受到物体表面粗糙程度进行控制。表面越粗糙，方差越大（法向量分布较广、分散）。这很符合现实。</li>
</ul>
<p>​ 作者使用了一种叫做 von
Mises-Fisher（简写为vMF）的概率分布。此分布的pdf非常像高斯分布pdf，估计也有差不多的性质。个人推测作者选这个函数是为了方便进行后续的数学推导以及近似，就像mip
NeRF中，将光锥用混合高斯模型进行近似一样。有了此分布，自然需要使用积分将所有可能的反射方向考虑进去。当然不是直接求期望（求出来就是
<span class="math inline">\(\hat{\omega_{r}}\)</span>，就直接trivial了）。考虑到，在将
<span class="math inline">\(\hat{\omega_{r}}\)</span> 输入到directional
MLP之前，需要进行positional encoding。在mip NeRF中，positional
encoding参与了积分，在此处实际上也类似：我们需要在高维空间中求每一维度的期望。但作者并没有用sinusoidal
positional encoding，而是使用球谐函数（spherical
harmonics）对方向进行表示。最后对每一维球谐函数进行积分： <span class="math display">\[
\begin{equation}\label{sphere}
\mathbb{E}_{\hat\omega\sim{\text{vMF}(\hat{\omega_{r}},\kappa)}}[Y^m_{l}(\hat\omega)]\approx
\exp(\frac{-l(l+1)}{\kappa})Y^m_{l}(\hat\omega)
\end{equation}
\]</span> ​ 其中，<span class="math inline">\(\kappa\)</span>为表面粗糙度的倒数（此值越大，越光滑），<span class="math inline">\(Y^m_{l}(\hat\omega)\)</span>表示球谐函数（m，l都表示了其阶）。不难从公式<span class="math inline">\(\eqref{sphere}\)</span>看出，积分近似后的球谐encoding实际上多了一个系数，此系数受到球谐阶（频率的指数）以及表面光滑程度（<span class="math inline">\(\kappa\)</span>）的影响。显然，<span class="math inline">\(\kappa\)</span>越小，对于高阶（频）球谐影响越大。这也就反映了这样一个事实：<u><strong>光滑程度</strong></u>减小，高低频信息均有所衰减，但<u><strong>高频信息</strong></u>衰减更严重。通过
<span class="math inline">\(\kappa\)</span>就能直接影响输出结果中镜面高光的强度（模糊性以及保留细节多少）。</p>
<p>​ 当然作者不仅仅给directional MLP提供了<span class="math inline">\(\hat{\omega_{r}}\)</span>，如公式 <span class="math inline">\(\eqref{phong}\)</span>所示第二项的<span class="math inline">\(l_i\cdot n\)</span>也被传入网络（<span class="math inline">\(d\cdot
n\)</span>，d为观察方向，n为法向量），这并不是要建模漫反射，而是考虑到一些稍微复杂一些的效应，如菲涅尔效应（并非全反射，部分反射部分折射，反射所占的比例需要另外计算）等等。</p>
<h3 id="法向量估计">2.3 法向量估计</h3>
<p>​ 作者使用volume density的梯度可以估计法向量，但作者说：</p>
<blockquote>
<ol type="1">
<li>normal vectors estimated from its volume density gradient as in
Equation 3 are often extremely noisy</li>
<li>NeRF tends to "fake" specular highlights by embedding emitters
inside the object and partially occluding them with a "foggy" diffuse
surface</li>
</ol>
</blockquote>
<p>​
确实，（1）很显然，已经有很多论文做这方面的工作了，不是添加正则化项就是采用一些表面重建技术获得好的表面。（2）的话通常也是由“集中性”正则化项解决的（只不过作者的想法不太一样）。</p>
<ul>
<li><p>问题（1）的解决（<strong><u>prediction
penalty</u></strong>）：通过spatial MLP预测某一点的法向量<span class="math inline">\(\hat{n}\)</span>，与梯度法向量<span class="math inline">\(n&#39;\)</span>求MSE： <span class="math display">\[
  \begin{equation}
  L_{n}=\sum_{i}w_i\Vert \hat{n}_i-n&#39;_i\Vert
  \end{equation}
  \]</span> 由于<span class="math inline">\(\hat{n}\)</span>相对比较光滑，而<span class="math inline">\(n&#39;\)</span>是对不光滑的density求的一阶导，就更不光滑了。用光滑数据帮助不光滑的梯度进行学习，可以起到对梯度的光滑作用。但为什么<span class="math inline">\(\hat{n}\)</span>比较光滑？这是作者说的，其实我比较纳闷，毕竟这玩意是学出来的。我的理解是：可以认为，此处需要网络也同时将<span class="math inline">\(n&#39;\)</span>学出来（利用<span class="math inline">\(n&#39;\)</span>作为监督）。但是网络的表示能力有限，特别是参数较少时，只能达到对<span class="math inline">\(n&#39;\)</span>低频部分的学习。</p></li>
<li><p>问题（2）的解决（<strong><u>orientation
loss</u></strong>）：作者设计了一个正则化项：此正则化惩罚反向法向量，也即“背面”。但也不是盲目对背面进行惩罚，毕竟volume
sampling过程中是可以在有效的背面进行采样的，故用下式： <span class="math display">\[
  \begin{equation}\label{reg}
  R_o=\sum_i{w_i\max(0,\hat{n}_i\cdot d)}
  \end{equation}
  \]</span> 其中 <span class="math inline">\(w_i\)</span>
为点weight值，<span class="math inline">\(d\)</span>为光线方向。此处也即惩罚
法向量与光线方向相同部分。并且与weight有关，这就说明：被遮挡的有效背面不会被影响（weight低），而fake
surface（在半透明surface后的embedded
emitter表面）将会被惩罚（其density衰减方向与光线方向一致）</p></li>
</ul>
<p>​
作者自己也解释了一下，为什么这两个loss结合在一起就work了：网络对于法向量的预测（<span class="math inline">\(\hat{n}\)</span>），与density梯度对应的法向量<span class="math inline">\(n&#39;\)</span>之间的关系大致有两种：</p>
<ul>
<li><span class="math inline">\(\hat{n}\)</span> 偏离 <span class="math inline">\(n&#39;\)</span>。那么此时，prediction
penalty较大，网络偏向于使得两者相等，则可以达到平滑梯度的目的。</li>
<li><span class="math inline">\(\hat{n}\)</span> 很接近 <span class="math inline">\(n&#39;\)</span>。那么此时，由于 <span class="math inline">\(\hat{n}\approx
n&#39;\)</span>，我们可以认为公式<span class="math inline">\(\eqref{reg}\)</span>作用在<span class="math inline">\(n&#39;\)</span>上。这也就达到了惩罚的目的。</li>
</ul>
<h3 id="扩展知识">2.4 扩展知识</h3>
<h4 id="一些物理概念">2.4.1 一些物理概念</h4>
<p>（1）能量，功率与辐射通量</p>
<p>​
能量的单位一般采用（J），而功率则是单位时间内的能量（J/s，定义为W），此概念与通量（flux）是同一个概念。与接收能量的面积没有关系。</p>
<p>（2）辐照度与辐出度</p>
<p>​
辐照度（irradiance）与辐射度（radiosity）是两个类似的概念，与面积有关。单位面积的通量（或者说，功率），单位是：<span class="math inline">\(W/m^2\)</span>。注意，此面积是光照的“正对面积”，也即需要进行投影处理。当表面法向量与光线入射（出射）方向垂直时，辐照度以及辐射度最大。当然，以上讨论仅限于面平行光源。对于点光源而言，其辐照（射）度与距离的关系遵循平方反比定律（距离越远，辐照（射）度越低）。</p>
<p>（3）立体角与辐射强度（intensity）</p>
<p>​ 立体角表达的物理意义是：1立体角对应在单位球上截取的大小为<span class="math inline">\(r^2\)</span>，其中<span class="math inline">\(r\)</span>为球的半径。也即： <span class="math display">\[
\begin{equation}
\Omega = \frac{A_{sr}}{r^2}{\text{sr}}
\end{equation}
\]</span> ​ <span class="math inline">\(\text{sr}\)</span>是单位，而不是变量或常量。其中<span class="math inline">\(A_{sr}\)</span>则是对应大小的球面切片面积。有了立体角之后，可以使用立体角
+ 3D点 +
3D方向来描述任意光线。光线从给定的3D点出射，方向是给定的3D方向，<u><strong>光锥的形状</strong></u>由立体角确定。通过单位立体角的辐射功率（通量）称为辐射强度，单位是<span class="math inline">\(W/\text{sr}\)</span>。辐射强度描述的是光源的属性，而非空间中某一点受光照的特性。故给定某一光源，不考虑空间中的其他因素的影响，空间中任意一点的辐射照度都是一样的。</p>
<p>（4）辐射率（radiance）</p>
<p>​
搞NeRF也有一段时间了，还没有搞清楚radiance的意义。此前只是将radiance当作是观察到的物体的颜色，而现在这里将对辐射率的物理含义进行介绍。上文已经介绍了辐射强度的概念，并且可知，辐射强度与空间特性无关，只与光源有关，而我们又希望获得某一光源在空间中某一位置可产生的影响。则定义辐射率：单位时间、单位面积、单位立体角通过的光能。也即单位面积、单位立体角的功率。单位是：<span class="math inline">\(W(m^2
\text{sr})^{-1}\)</span>。光源辐照能力改变（如灯光的亮暗），反映于功率变化（<span class="math inline">\(W\)</span>）。而光源的“能量聚集度”（可以想象一个可以调焦的手电筒）反映在辐射强度上（影响单位为
<span class="math inline">\(\text{sr}\)</span>
的项）。物体距离光源的远近则反映在面积项上（平方反比）。这也恰好与成像结果直接相关，故可以将radiance理解为空间中一点成像的结果（如RGB值）。</p>
<h4 id="光场">2.4.2 光场</h4>
<p>​ 四维光场是否只是一个近似？四维光场认为，在empty
space内部，radiance（也就是产生的RGB值）是恒定的。也就是说，无论我从此光线上的哪一点开始积分，最后得到的RGB值都是一样的，此RGB值与光线上的积分距离（或是深度）无关。那么这样可以从五维的光场建模中，去掉一个维度，实际则为四维的。个人更愿意将“四维”理解为一个五维空间中的四维流形，因为此深度维度并非五维度基中之一，也不能用其线性组合描述。理解了四维光场的由来，我们回头检查一下假设：<strong><u>空域内部radiance为常数</u></strong>。正常情况下：无半透明物体或者介质，这是成立的。引入半透明物体与介质后（比如混浊溶液，胶体，雾），个人认为此假设不成立，那么表四光场还是应该使用五维函数。</p>
<h3 id="球谐函数的使用">2.5 球谐函数的使用</h3>
<p>​
打开维基百科，查之。woc，我看到了什么。总之很复杂了，本人本科所学的数学知识不够用（或者说是遗忘了）。关于球谐函数本身的理解，个人的看法是：类似于傅里叶变换，展开成基函数的线性组合（这些基函数独立分析时其实形式较为简单，但组合起来就能表示非常丰富的内容），并且不像泰勒展开（泰勒展开的物理意义不甚好理解），球谐函数有<strong><u>频率</u></strong>概念，并且三维空间中的球谐函数仍然很好理解，非常具有物理直观性。如果想要知道如何初步理解，这里推荐<a href="https://zhuanlan.zhihu.com/p/351289217">【知乎：球谐函数介绍（Spherical
Harmonics）】</a>，我就不赘述了。下面只给出结论，实球谐函数的形式如下：
<span class="math display">\[
\begin{equation}\label{real_sh}
Y_{lm}(\theta,\phi)=\begin{cases}
(-1)^m\sqrt{2\frac{(2l+1)}{4\pi}\frac{(l-|m|)!}{(l+|m|)!}}P_l^{|m|}(\cos\theta)\sin(|m|\phi),
\text{ if }m &lt;0\\
\sqrt{\frac{2l+1}{4\pi}}P_l^m(\cos\theta),\text{ if }m=0\\
(-1)^m\sqrt{2\frac{(2l+1)}{4\pi}\frac{(l-m)!}{(l+m)!}}P_l^{m}(\cos\theta)\cos(m\phi),
\text{ if }m &gt;0\\
\end{cases}
\end{equation}
\]</span> ​ 其中，<span class="math inline">\(\phi,\theta\)</span>是方位角（azimuthal
angles），<span class="math inline">\(l,m\)</span>为此球谐函数的阶？（此处实际上涉及到一个微分方程求解问题，此二变量与解的个数有关）。另外，比较令人疑惑的是
<span class="math inline">\(P^{|m|}_l\)</span>，这实际上代表的是伴随勒让德多项式（associated
Legendre polynomials）。这里，<a href="https://en.wikipedia.org/wiki/Associated_Legendre_polynomials">Wikipedia</a>会告诉你勒让德多项式的奇妙性质，但是我不关心（说实在的，一开始看到这样的公式我还在想应该如何高效实现这么多微分）。这里直接给出维基上写的闭式公式：
<span class="math display">\[
\begin{equation}\label{legendre}
P^m_l(x)=(-1)^m\cdot2^l\cdot(1-x^2)^{m/2}\sum^l_{k=m}\frac{k!}{(k-m)!}\cdot
x^{k-m}\cdot \pmatrix{l\\k} \pmatrix{\frac{l+k-1}{2}\\l}
\end{equation}
\]</span> ​
此公式的代码实现就简单多了，我们只需要关心最后的求和项。求和项中涉及到求组合数，可以选择使用lookup
table，预先计算一个大小为 <span class="math inline">\(2^L\cdot
2^L\)</span>的矩阵（L应该不会很大）。那么： <span class="math display">\[
\begin{equation}
\frac{k!}{(k-m)!}\cdot x^{k-m}
\end{equation}
\]</span> ​
应该如何计算？能不用for循环就不用for循环（多用GPU操作！！）。观察容易知道：求和项中的首项是<span class="math inline">\(m!x^0\)</span>，此后每一项与前一项的关系是： <span class="math display">\[
\begin{equation}
T_{k+1}=T_{k}\cdot x\cdot \frac{k+1}{k+1-m}
\end{equation}
\]</span> ​ 故我们应该有这样的一个张量（一行，<span class="math inline">\(l-m\)</span>列）：第一列是 <span class="math inline">\(m!\)</span>，此后所有列是：<span class="math inline">\([\frac{m+1}{1}x,\frac{m+2}{2}x,\frac{m+3}{3}x,...,\frac{l}{l-m}x]\)</span>。那么实现就是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># device 某个传入函数的张量t的t.device</span></span><br><span class="line">rare = (torch.arange(m+<span class="number">1</span>,l+<span class="number">1</span>, device = device) / torch.arange(<span class="number">1</span>,l-m+<span class="number">1</span>, device = device)).unsqueeze(<span class="number">0</span>) * x</span><br><span class="line">whole = torch.cat([torch.ones(<span class="number">1</span>, <span class="number">1</span>, device = device) * m_factorial, rare], dim = -<span class="number">1</span>)</span><br><span class="line">whole_prod = torch.cumprod(whole, dim = -<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>​ 此后，根据lookup或者在线求解公式<span class="math inline">\(\eqref{legendre}\)</span>中的组合数，就能求得求和式中的每一项，进而也就求出了整个多项式。但这只是针对
<span class="math inline">\({m,l}\)</span>求出了结果，而 <span class="math inline">\(m,l\)</span>
如何进行并行计算我就不懂了。不过其实也没必要懂：</p>
<ul>
<li>NeRF的positional encoding，不同的相位（<span class="math inline">\(\sin,\cos\)</span>）以及不同的频率是串行计算最后concatenate的</li>
<li>大可以自定义CUDA算子，写一个forward再写一个backward函数。forward好写而backward不好写罢了（这玩意显然是有闭式解的，推起来比较麻烦），故CUDA自定义算子：全并行但费脑子（哈，而且还不一定有pytorch快，例如之前我用thrust的sort库对比pytorch的张量sort，前者就比后者慢），pytorch实现弱并行，但不费脑子。</li>
</ul>
<p>​
球谐函数的使用也说明了，我们在处理<strong><u>方向</u></strong>时，需要将三维的方向转化为二维的方向角（才能喂给球谐函数，当然，球谐函数确实有笛卡尔坐标系表示，但这不是我们的讨论范畴）。下面，笔者简单讨论一下文中球谐函数在vMF分布下的期望求解（论文附录部分）。作者要证明：
<span class="math display">\[
\begin{equation}
\mathbb{E}_{\hat \omega\sim
\text{vMF}({\hat\omega_r,\kappa})}[Y_l^m(\hat\omega)]=
A_l(\kappa)Y_l^m(\hat\omega_r)
\end{equation}
\]</span> ​ 我们只讨论上式中<span class="math inline">\(A_l(\kappa)\)</span>怎么来的，而<strong><u>不关心</u></strong>（所以在这不推导）<span class="math inline">\(A_l(\kappa)\)</span>如何近似为那个只与<span class="math inline">\(l,\kappa\)</span>有关的指数形式（近似的推导部分，但凡有点耐心。。。emmm）。首先，作者把积分空间进行了线性变换：进行了旋转。将
<span class="math inline">\(\hat\omega_r\)</span>旋转至z轴，那么根据vMF分布的形式以及随机变量函数的期望的计算：
<span class="math display">\[
\begin{align}
&amp;P_{\text{vMF}({\hat\omega_r,\kappa})}(\omega)=c(\kappa)\exp(\kappa\hat\omega_r^T\omega)\\
&amp;\mathbb{E}_{\hat \omega\sim
\text{vMF}({\hat\omega_r,\kappa})}[Y_l^m(\hat\omega)]=
c(\kappa)\int_S Y_l^m(\omega)
\exp(\kappa\hat\omega_r^T\omega)d\omega\label{expect}
\end{align}
\]</span> ​ 则将 <span class="math inline">\(\omega&#39;=R\omega\)</span>中，可以得到： <span class="math display">\[
\begin{align}
\mathbb{E}_{\hat \omega\sim
\text{vMF}({\hat\omega_r,\kappa})}[Y_l^m(\hat\omega)]&amp;=
c(\kappa)\int_S Y_l^m(R^{-1}\omega&#39;) \exp(\kappa
(R^{-1}z)^TR^{-1}\omega&#39;)dR^{-1}\omega&#39; \label{ints}\\
&amp;=c(\kappa)\int_S Y_l^m(R^{-1}\omega&#39;) \exp(\kappa
z^T\omega&#39;)dR^{-1}\omega&#39; \label{intm}\\
&amp;=c(\kappa)\int_S Y_l^m(R^{-1}\omega&#39;) \exp(\kappa
\cos\theta)d\omega&#39; \label{inte}
\end{align}
\]</span> ​ 从公式<span class="math inline">\(\eqref{ints}\)</span>到<span class="math inline">\(\eqref{intm}\)</span>很好理解，旋转向量的的正交性可以立刻抵消exp中的R。而公式<span class="math inline">\(\eqref{intm}\)</span>到<span class="math inline">\(\eqref{inte}\)</span>则稍微有点绕：</p>
<ul>
<li><span class="math inline">\(z^T\omega&#39;\)</span>恰好是 <span class="math inline">\(\omega&#39;\)</span> 的方位角（中的俯仰角<span class="math inline">\(\theta\)</span>）</li>
<li><span class="math inline">\(dR^{-1}\omega&#39;\)</span>中的 <span class="math inline">\(R^{-1}\)</span>原先需要被提出来，但由于其行列式为1（旋转矩阵嘛），不会影响最后函数输出的单个值的结果（注意，对于每一个<span class="math inline">\(m, l\)</span>而言，公式<span class="math inline">\(\eqref{ints}\)</span>的输出都是一个值），故可以省略</li>
</ul>
<p>​ 此后，根据球谐函数的性质（比如展开为Wigner D
Matrix表示以及其正交性），我们最后可以将公式<span class="math inline">\(\eqref{ints}\)</span>左边写为： <span class="math display">\[
\begin{equation}
\mathbb{E}_{\hat \omega\sim
\text{vMF}({\hat\omega_r,\kappa})}[Y_l^m(\hat\omega)]=
c(\kappa)D^{(l)}_{m0}(\hat{\omega}_r)\int_{S^2}Y_{l}^0(\hat{\omega})e^{\kappa\cos\theta}
d\hat{\omega}\label{origin}
\end{equation}
\]</span> ​ 其中：<span class="math inline">\(D^{(l)}_{m0}(\hat{\omega}_r)\)</span>以及<span class="math inline">\(Y_{l}^0(\hat{\omega})\)</span>的形式都是已知的，这里不在赘述了（确实很麻烦）。我们只将上式的积分部分进行拆解。由于积分实际上是在球面上完成的，这里实际进行了一次二重积分（球面积分），将笛卡尔坐标系转化为球面的天顶角：<span class="math inline">\((x, y, z)\rightarrow(\theta,\phi
)\)</span>，这里给出一张图：</p>
<center>
<img src="/2022/08/13/Mip-NeRF-Ref-NeRF/zenith.jpg" style="zoom:50%;">
</center>
<center>
Figure 2. Ref NeRF半球积分示意图
</center>
<p>​
图中的黑色圆圈就是“积分对象”：可以看做球体的上半球表面是由无数个圆环组成的，对应了角度为<span class="math inline">\(\theta\)</span>（确定了位置），半径为<span class="math inline">\(\sin
\theta\)</span>（确定了形状）的圆圈（可知<span class="math inline">\(\phi\)</span>的积分范围是<span class="math inline">\(-\pi\rightarrow\pi\)</span>）：故积分可以拆成（首先知道<span class="math inline">\(Y_l^0(\hat{\omega})=P_l(\cos\theta)\)</span>）:
<span class="math display">\[
\begin{equation}
\int_{S^2}Y_{l}^0(\hat{\omega})e^{\kappa\cos\theta}
d\hat{\omega}=\int_{-\pi}^{\pi}\int_{0}^{\pi}P_l(\cos\theta)e^{\kappa\cos\theta}\sin\theta
d\theta d\phi
\end{equation}
\]</span> ​ <span class="math inline">\(\theta\)</span>的范围是<span class="math inline">\([0,
\pi]\)</span>，这是因为我们只需要积分上半球。由于反射不可能发生在下半球，可知下半球<span class="math inline">\([-\pi,0]\)</span>的所有输出都是0。这样，根据论文中所说的步骤，进一步替换积分变量，展开并简化可以推出IDE公式。</p>
<p>​ 但是，选择实函数形式的球谐并不是一个很好的选择。首先，公式<span class="math inline">\(\eqref{real_sh}\)</span>已经展示了实函数形式的复杂性（主要是有分支）；此外，我们需要考虑到，角度形式的SH需要把方向向量转化为天顶角，这种额外的操作看着就很不优雅。建议使用笛卡尔坐标系形式的球谐函数。参见<a href="https://en.wikipedia.org/wiki/Spherical_harmonics#Separated_Cartesian_form">Wikipedia/Shperical
Harmonics - Separated Cartesian
form</a>，可刺激了，虚函数运算与二项式公式的结合哦。不过只要使用这种方法实现，利用Pytorch就很简单：</p>
<ul>
<li>首先Pytorch支持虚数运算。这里吐槽一下，Pytorch支持的虚数运算基于<code>torch.complex64</code>类型，一看到<code>64</code>就知道怎么回事了，运算量可能等同于float32运算（两个float32存在一块），在使用auto
mixed
precision时，complex32将可能产生一系列的问题，很多算子都没有对complex32有支持。而假设我们使用APEX库的O2等级优化，所有的float32都会变成float16，那么这里参与运算的复数就会产生一系列未定义算子的问题。（什么ComplexHalf未定义这些算子啊之类的报错）</li>
<li>SH在这就是用作encoding，所以其实只需要将结果的实部、虚部取出来作为encoding的成分就好了。可以认为，原来的positional
encoding是用了正交相位的两种基底进行表示，而SH其实也是正交的两种基底（实与虚在虚平面上是正交的）进行表示。</li>
</ul>
<hr>
<h2 id="iii.-复现细节">III. 复现细节</h2>
<h3 id="值得一提的点">3.1 值得一提的点</h3>
<p><img src="/2022/08/13/Mip-NeRF-Ref-NeRF/network.png" style="zoom:50%;"></p>
<center>
Figure 3. Ref-NeRF网络结构
</center>
<p>​ 其实，没什么好说的。根据Ref NeRF论文图，复现的内容如下：</p>
<div class="note info"><p>​ 首先修改spatial network，在spatia
network之后追加三个head。三个head的输入就是spatial network的输出：</p>
<ul>
<li><p>opacity &amp; roughness head:
由于τ（density）与ρ（roughness）都是没有输出范围限制的（但是都需要大于0，故ρ之后与τ类似，单独处理即可）。注意roughness与opacity都需要经过bias之后再通过softplus激活（软ReLU）</p></li>
<li><p>color &amp; tint head: <span class="math inline">\(c_d,s\)</span>都是[0, 1]
之间的值，故输出直接变6维。color与tint都使用sigmoid进行激活，不过bias不同。</p></li>
<li><p>normal
head：预测法向量，三维，需要进行normalize，不需要任何激活</p></li>
</ul>
</div>
<div class="note success"><p>​ 需要绕一下的部分是法向量。法向量的来源有两个：（1）spatial
network计算的density，可以对位置求导。Pytorch中，要实现对位置求导需要使得输入的位置向量可导：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fine_pos.requires_grad = <span class="literal">True</span>										    <span class="comment"># 此步必要	</span></span><br><span class="line">fine_rgbo, pred_normal = mip_net.forward(fine_pos, fine_dir)</span><br><span class="line">r_num, p_num, _ = fine_rgbo.shape</span><br><span class="line">density_grad, = torch.autograd.grad(fine_rgbo[..., -<span class="number">1</span>], fine_pos, 			  <span class="comment"># fine_pos 是可优化的</span></span><br><span class="line">       torch.ones(r_num, p_num, device = fine_rgbo.device), retain_graph = <span class="literal">True</span> <span class="comment"># retain graph使得计算图可以继续backward</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>​ 另一个来源就是spatial network之后的normal
head，预测。预测的结果在经过正则化（orientation
loss）以及预测误差（与density
grad的差别）backward之后，应当可以学出较好的结果。</p>
</div>
<p>​ 此外注意，directional network变深了。可以认为directional
network有spatial network一样的结构（包括8层256 hidden
units的MLP，并且有skip connection）。</p>
<h3 id="一些坑">3.2 一些坑</h3>
<p>​ 由于笔者复现Ref NeRF基于之前实现的<a href="https://github.com/Enigmatisms/NeRF">Enigmatisms/NeRF</a>，这个repo中实现的NeRF并非原始NeRF，而是mip
NeRF 360（部分），主要包含这样的特性：</p>
<ul>
<li>本repo实现了mip NeRF 360中的proposal network
distillation。也即：coarse-to-fine的stratified
sampling并没有使用。stratified sampling非常慢（由于coarse
network需要forward所有点，fine network也要forward），proposal
network则是用浅MLP（5层），forward点后直接输出预测的density，再利用fine
network输出的density（weight）进行监督。这样就能完成从fine
network到proposal network的蒸馏。此蒸馏的实现较为复杂（weight
bound的计算），这里不赘述。我也不想单开一篇博客讨论。</li>
<li>使用了自动混合精度（amp），可以选用apex或者torch.native_scaler</li>
</ul>
<p>​ proposal
network着实坑了我一把。复现完成（第一版）之后，跑了一下shinny
blender的ball数据集：</p>
<p><img src="/2022/08/13/Mip-NeRF-Ref-NeRF/false_ball_2.png" style="zoom: 67%;"></p>
<center>
Figure 4. 为什么那么多噪点？
</center>
<p>​
如上图第一列：很多噪点。这些噪点是什么？一开始我也不敢下结论，毕竟不知道是不是自己的ref
nerf复现有问题。于是我将深度以及normal都可视化了出来（后两列）。可见，深度图中也存在很多空洞，normal就不说了吧（事实上，normal学习一直有问题，normal本身就比较难学）。空洞产生的可能原因有两个：</p>
<ul>
<li>density学习有问题，有些位置density非常低</li>
<li>采样（不管是训练还是测试时）位置不对，采样在了一些空的位置</li>
</ul>
<p>​ 于是我开了一个新的分支，在此分支上我将proposal
network删掉了，使用原始NeRF的coarse-to-fine框架进行测试。对比图如下图所示：左边为原始proposal
network存在时，训练60轮之后的结果，而右边则为原始NeRF训练40轮之后的结果。可以看出，原始NeRF框架下的采样是（至少相对上是）没问题的。但笔者并不想放弃proposal
network（个人觉得这个方法比较优雅），故笔者将proposal
network进行了小的改动：</p>
<!-- tab 原始Proposal Network -->
<p>​ 原始prop net输入coarse points之后，输出density，此后coarse
points将会被弃用。根据density计算的weight，将指导inverse sampling，fine
network的输入只为inverse
sampling的结果（也就是说，集中在weight高的地方）。假设，prop
net计算的density有缺陷，也即weight有缺陷，在实际的表面附近weight很小，在空域中weight大，那么inverse
sampling可能无法在此条光线上采到有效的点。</p>
<!-- endtab -->
<!-- tab 修改后的Proposal Network -->
<p>​ 很简单，就是复用coarse points，将coarse
depths（采样的长度）与inverse sampling的采样长度（fine
depths）进行拼接，排序。但其实在实现中，要考虑proposal network的weight
bound计算。啊，这一步很复杂。可以这么说：</p>
<ul>
<li>proposal
network需要预测每一个采样点（fine采样点）的weight上界（weight
bound）。上界如何计算？两个fine采样点之间会存在一个采样区间，此区间将会与coarse采样的区间重合，则此fine采样区间的weight上界应该是所有与之有交集的coarse区间weight之和。</li>
<li>coarse points合并到fine
points相当于修改了fine采样区间。那么就需要计算更多区间交集。这里我不赘述方法，详见：<a href="https://github.com/Enigmatisms/NeRF/blob/635509b005a3272a0cddeac60a7aeac9432dddd1/py/nerf_base.py#L53">NeRF/coarseFineMerge</a>以及<a href="https://github.com/Enigmatisms/NeRF/blob/635509b005a3272a0cddeac60a7aeac9432dddd1/py/addtional.py#L15">NeRF/getBounds</a></li>
</ul>
<!-- endtab -->
<p>​
这样修改，也就使得每条光线上，既有均匀采样的部分（保证了coverage），又使得density大的部分可以有更多采样点。可能有人觉得，不就是增加了一些采样点吗？这样为什么能保证proposal
network的学习是正确的呢？很简单，网络不仅有更加充足的输入，fine
network提供给proposal network的监督也更加充足了（见【修改后的Proposal
Network】部分，其中我们说到“更多的区间交集”）。</p>
<p><img src="/2022/08/13/Mip-NeRF-Ref-NeRF/result_001.png" style="zoom:67%;"></p>
<center>
Figure 5. shinny blender helmet数据集，训练20轮
</center>
<table>
<colgroup>
<col style="width: 52%">
<col style="width: 47%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;">无proposal net 训练40轮（4k次）</th>
<th style="text-align: center;">有proposal net 训练60轮（6k次）</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><img src="/2022/08/13/Mip-NeRF-Ref-NeRF/no_prop_002.png"></td>
<td style="text-align: center;"><img src="/2022/08/13/Mip-NeRF-Ref-NeRF/prop_003.png"></td>
</tr>
</tbody>
</table>
<p>​
修改后的方法，只训练20轮输出后的结果就让我觉得肯定是改对了，如上图所示。接下来将展示【未完成训练】时的训练结果。由于原始Ref
NeRF使用<span class="math inline">\(2^{14}\)</span>大小的batch，需要训练250k轮。我设备能力有限，只batch大小为<span class="math inline">\(2^9\)</span>（差了32倍），也没训练到250k就先暂停了（笑死，我的3060
for
laptop，有个风扇坏了，训练的时候能飙到83度，所以我得开一台电风扇对着我电脑吹）。下面是简单的结果展示：</p>
<p><img src="/2022/08/13/Mip-NeRF-Ref-NeRF/curves.png"></p>
<center>
Figure 6. 训练不是一次完成的，保存checkpoint短点续训。收敛性并不好
</center>
<p>​
从上图看出，虽然训练应该远没有结束（这才不到7小时），PSNR曲线的上升能力属实堪忧。笔者感觉PSNR无法上升至论文中的29，个人认为可能的问题仍然是出在proposal
network上。目前正在尝试一种改进的方法。</p>
<p><img src="/2022/08/13/Mip-NeRF-Ref-NeRF/Screenshot%20from%202022-08-19%2013-31-01.png"></p>
<center>
Figure 7. 有趣的手动退火
</center>
<p>​
效果大概就是这样（如下图所示）。从左到右分别是：RGB，深度与法向量。emm，法向量大概是可视化错了。不过学的应该也有一些问题，在某些视角能看到头盔上的条纹对应的法向量与其他位置不一致。PSNR为19，还是太模糊了一点。</p>
<p><img src="/2022/08/13/Mip-NeRF-Ref-NeRF/ezgif-1-8207b1faa2.gif"></p>
<center>
Figure 8. 旋转头盔
</center>
<hr>
<h2 id="reference">Reference</h2>
<ul>
<li><p>https://en.wikipedia.org/wiki/Spherical_harmonics</p></li>
<li><p>https://en.wikipedia.org/wiki/Associated_Legendre_polynomials</p></li>
<li><p>扩展阅读: https://dellaert.github.io/NeRF22/</p></li>
</ul>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>Rust CUDA混合编程</title>
    <url>/2022/08/09/Rust-CUDA%E6%B7%B7%E5%90%88%E7%BC%96%E7%A8%8B/</url>
    <content><![CDATA[<p>​ （未完成，请勿点击）Rust FFI（foriegn function
interface）非常有吸引力，特别是当你用熟了<a href="https://github.com/nannou-org/nannou">nannou</a>库之后（啊，nannou，比OpenCV香了不知道多少倍，OpenGL-base库牛逼！）。CUDA编程也属于很有吸引力的活动（谁会讨厌优化代码，在已经比多线程CPU快n倍的基础上看着它跑得越来越快呢）。两者放在一起只能说是让人觉得万事皆空。本文记录了在以下两个项目：</p>
<ul>
<li>LSMv2：CUDA加速的激光雷达仿真器（simple 2D ray caster）</li>
<li>ShadowCaster：CUDA加速的空域计算算法（2D阴影投射算法）</li>
</ul>
<p>​
中，使用CUDA/Rust混合编程所遇到的/产生的：（1）语言方面的坑。（2）CUDA程序设计上的一些坑。（3）一些算法设计思路。</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>GPU</tag>
        <tag>CUDA</tag>
        <tag>Rust FFI</tag>
      </tags>
  </entry>
  <entry>
    <title>Mip NeRF思想注入与更多的NeRF方法</title>
    <url>/2022/05/03/Mip-NeRF%E6%80%9D%E6%83%B3%E6%B3%A8%E5%85%A5%E4%B8%8E%E6%9B%B4%E5%A4%9A%E7%9A%84NeRF%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>​ （未完成，请勿点击）。最近读了非常多关于NeRF的论文，毕竟这玩意从ECCV
2020被提出来之后就爆火了，变体层出不穷，基本上我能想到的卷法，都有人卷过了。低垂的果实总是被有能力又有准备的人先摘走，留下来的都是一些需要费大力气才能摘到的果实。论文不仅需要读，好的论文一定要复现，才能深入了解其精髓，西安交大人工智能学院的刘龙军副教授曾经在组会上说到：读论文不复现等于白读！大家都深以为然:&gt;。而其中最有复现价值（并且难度没那么高的，不像Instant
NGP，official repo代码都看不懂）的当属：</p>
<ul>
<li>ICCV 2021: <a href="https://arxiv.org/abs/2103.13415">Mip-NeRF: A
Multiscale Representation for Anti-Aliasing Neural Radiance
Fields</a></li>
<li>ECCV 2022: <a href="https://arxiv.org/abs/2111.12077">Mip-NeRF 360:
Unbounded Anti-Aliased Neural Radiance Fields</a></li>
</ul>
<p>​ 其中Mip NeRF 360中的proposal
network已经成为目前个人所实现的NeRF框架的基础。本文是复现过程中的一些心得以及对其他所读的NeRF论文的总结。</p>
<span id="more"></span>
<h2 id="section"></h2>
<p>​ Neural surface
reconstruction方法，利用多视角图片对表面进行建模。个人认为，这样的方法存在以下优点与缺点：</p>
<ul>
<li>已知NeRF对于density、法向量以及表面的建模非常垃圾（density云雾效应，表面建模非常粗糙、噪声很多，法向量非分块平滑）</li>
<li>而对于表面的建模很有可能会使得半透明物体的建模能力下降（由于表面建模一般期望表面density较为集中）</li>
</ul>
<p>​
对于个人而言，本篇论文仅作为了解（知道对应的方法），并不准备实际使用类似的思想（个人更想对所有材质都能进行建模）。</p>
<p>​
NeuS中的RGB预测与NeRF一致，主要区别在于density以及weight的计算。NeuS就是希望density可以集中在表面附近，不产生云雾或者奇异的自遮挡，利用density求得的weight也需要具有一定的性质，主要是
<strong><u>无偏性</u></strong>（unbiased）以及
<strong><u>遮挡感知性</u></strong>（occlusion-aware）。对于NeRF而言，遮挡感知性是已经具备的性质，在weight的计算过程中，“accumulated
transmittance”不断累乘（小于等于1的值），形成的weight在光线前段通过不透明物体时将显著降低，这样使得被遮挡的物体/表面不会影响渲染的结果。而NeRF的weight则不存在无偏性，由于正常情况下，density将会在表面附近存在峰值，而由于accumulated
transmittance将使得weight发生移动（通常都是向前，特别是在表面附近的density较为分散时），使用这样的density无法估计出好的表面。</p>
<p>​
作者的表面建模使用SDF进行表征（外正内负），作者使用名为S-density的函数作为表面附近density的分布。此density实际上是sigmoid函数的导数，计算较为简单：
<span class="math display">\[
\begin{align}
\phi_s(t)=\frac{se^{-sx}}{(1+e^{-sx})^2},\label{wf}\\
\Phi_s(t)=\frac{1}{1+e^{-sx}}\\
w(t)=\frac{\phi_s(f(p(t)))}{\int_{-\infin}^{+\infin}\phi_s(f(p(u)))du}\label{weight}
\end{align}
\]</span> ​
由于我们实际需要设计一种同时具备无偏性以及遮挡感知性的weight，直接使用归一化的S-density显然是没有办法满足要求的（关于表面对称，不满足遮挡感知性）。作者先从无偏性出发，寻找一个不透明度density（opacity
density），使得根据此density通过体积渲染计算的weight就是公式<span class="math inline">\(\eqref{wf}\)</span>。可能此时有人会有疑问：不是说以公式<span class="math inline">\(\eqref{wf}\)</span>确定的weight不具有遮挡感知性吗？作者在保证无偏性之后对此问题进行了讨论。首先，作者遵循NeRF的体积渲染公式：
<span class="math display">\[
\begin{equation}\label{derive1}
T(t)\rho(t)=w(t),\text{ where
}T(t)=\exp{\left(-\int_0^t\rho(u)du\right)}
\end{equation}
\]</span> ​
其中t是什么？是SDF函数值，在讨论无偏性时先讨论最简单的情况：<strong><u>平面单障碍物</u></strong>。单个平面障碍物的SDF很简单，就是<span class="math inline">\(-|\cos\theta|(t-t^*)\)</span>，其中<span class="math inline">\(t,t^*\)</span>都代表光线方向的深度值，<span class="math inline">\(\theta\)</span>为入射方向于平面法向量的夹角。则根据指数函数的性质以及平面的SDF公式，代入公式<span class="math inline">\(\eqref{weight},\eqref{derive1}\)</span>，可以得到：
<span class="math display">\[
\begin{equation}
T(t)\rho(t)=|\cos\theta|\phi_s(f(p(t)))\mathop{\longrightarrow}^{T(t)\rho(t)=-\frac{dT}{dt}(t)}T(t)=\Phi_s(f(p(t)))
\end{equation}
\]</span> ​ 也即得到accumulated
transmittance的形式就是sigmoid函数。由公式<span class="math inline">\(\eqref{derive1}\)</span>可以根据<span class="math inline">\(T(t)\)</span>，两边求对数后求导可以得到<span class="math inline">\(\rho(t)\)</span>的表达式： <span class="math display">\[
\begin{equation}\label{density}
\rho(t)=\frac{-\frac{d\Phi_s}{dt}(f(p(t)))}{\Phi_s(f(p(t)))}
\end{equation}
\]</span> ​
根据此公式，按照NeRF渲染公式可以求出对称、无偏的weight（sigmoid导数的形式）。此后，作者考虑多个平面（区分物体表面内外），如下图所示：</p>
<center>
<img src="/2022/05/03/Mip-NeRF%E6%80%9D%E6%83%B3%E6%B3%A8%E5%85%A5%E4%B8%8E%E6%9B%B4%E5%A4%9A%E7%9A%84NeRF%E6%96%B9%E6%B3%95/2022-08-25 (2).png" style="zoom:60%;">
</center>
<p>​ 根据公式<span class="math inline">\(\eqref{density}\)</span>知，由于<span class="math inline">\(d\Phi_s/dt\)</span>的值域为正<span class="math inline">\(\mathbb{R}\)</span>，而： <span class="math display">\[
\begin{equation}
\frac{d\Phi_s(f(p(t)))}{dt}=\frac{d\Phi_s(u)}{du}\frac{du}{dt},\text{
where }u=f(p(t))
\end{equation}
\]</span> ​ 只有当<span class="math inline">\(f&#39;(p(t))\)</span>为正数时，<span class="math inline">\(\rho(t)\)</span>才是正数，否则为负。负数是没有意义的，故我们将负数部分截断到0（背面“剔除”，光线穿过背面表面时，SDF是增加的，导数为正）。这样，被遮挡的部分（背面）将不会产生任何影响。此外，由于使用的公式仍然是NeRF的光线渲染公式，<span class="math inline">\(T(t)\)</span>仍然从0开始积分到当前t，故经过几个障碍物的遮挡后，靠后方的weight会越来越小，这也是遮挡感知的一种体现。根据所推导的连续公式，将其离散化（实际上就是每两个点之间进行零阶保持，用quadrature近似积分）。</p>
<p>​
虽然上述推导基于“平面物体”，但实际上对于光滑物体（一阶导连续），每个点都可以估计切平面（作为近似的法平面），也就可以利用平面物体推导的结果。则可以看出，使用NeuS的同时需要对法向量进行估计（如Ref
NeRF中的两种方法，可以使用MLP预测法向量，也可以使用density的一阶梯度作为法向量，本论文中则可以用SDF梯度作为法向量）。</p>
<p>​ 一些关于NeuS的注意事项：</p>
<ul>
<li>NeuS中的SDF函数是MLP（MLP近似了空间距离场），同时NeuS中也包含了一个层次化采样的NeRF模型（用于loss计算）。loss计算的逻辑流大概是这样：SDF
MLP将会输出空间的SDF值，</li>
</ul>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>Rust学习 II</title>
    <url>/2022/05/03/Rust%E5%AD%A6%E4%B9%A0-II/</url>
    <content><![CDATA[<h1 id="rust---ii">Rust - II</h1>
<hr>
<h2 id="i.-intro">I. Intro</h2>
<p>​
变量的lifetime之前的部分，理解起来都比较简单。而一到lifetime出场，一群妖魔鬼怪也就跟着出场了。不过其实是因为之前的两天学习中，对于变量的引用，所有权的租借理解不够到位。本文仍然是在跟着Rust官方（的非官方，它自己写的）教程学习过程中，整活扩展的一些记录。</p>
<span id="more"></span>
<hr>
<h2 id="ii.-使得stack更强">II. 使得stack更强</h2>
<h3 id="迭代器的构造">2.1 迭代器的构造</h3>
<p>​
在之前的实践中，为了查看我的stack是否正确，我使用match语法糖写了一个简单的遍历方法。但这种遍历方法不够强，它无法使得我可以直接使用for循环遍历此stack。如果要直接for循环遍历，正如C++中一样，需要重构（或者实现）iterator相关方法。这里我们介绍<code>IntoIter</code>，<code>Iter</code>与<code>IterMut</code></p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">IntoIter</span>&lt;T&gt;(List&lt;T&gt;) <span class="keyword">where</span> T: <span class="built_in">Default</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;T: <span class="built_in">Default</span>&gt; List&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">into_iter</span>(<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> IntoIter&lt;T&gt; &#123;</span><br><span class="line">        <span class="title function_ invoke__">IntoIter</span>(<span class="keyword">self</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;T: <span class="built_in">Default</span>&gt; <span class="built_in">Iterator</span> <span class="keyword">for</span> <span class="title class_">IntoIter</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">type</span> <span class="title class_">Item</span> = T;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">next</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;<span class="keyword">Self</span>::Item&gt; &#123;</span><br><span class="line">        <span class="keyword">self</span>.<span class="number">0</span>.<span class="title function_ invoke__">pop</span>()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 这里有两点需要注意：</p>
<ul>
<li>首先，iterator这玩意就像C++中的迭代器一样，与原类型是不同的。这也就是为什么我们需要重新定义一个叫做<code>IntoIter</code>的模块。实际上这告诉我们，不是<code>List&lt;T&gt;</code>本身有迭代器，而是其在执行<code>into_iter</code>函数之后，返回的迭代器可以进行迭代。那么，以上代码的三个块，分别代表了：定义需要返回的迭代器类型（<code>IntoIter</code>），给<code>List</code>实现返回迭代器的操作，实际实现迭代器的内部功能<code>next</code></li>
<li><code>self.0</code>是什么玩意？注意到，此struct只有一个域，本质上是一个tuple
struct（内部的变量没有名字），那么他们的域可以按照<code>self.k</code>来依顺序访问。此外，由于这里调用了pop，并且我们发现，返回值是<code>Option&lt;T&gt;</code>，不难发现此迭代器会逐步销毁原<code>List</code>。在执行<code>into_iter</code>操作之后，原变量（stack本体）应该丧失了所有权，转移到一个<code>IntoIter</code>变量中。我们要求原stack是mutable的（不是mutable也没有意义，全域静止管理的stack是吧），否则无法进行pop。</li>
</ul>
<p>​
怎么说呢，此实现需要非常遵守固定程式，故也没有给我整活留下太大的空间。</p>
<p>​
但是很多时候，我并不想使得原来的stack被销毁，我只想迭代一下，输出看看。则我们可以实现一个返回引用的iterator，也即我希望内部的所有逻辑都是引用：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">Iter</span>&lt;T&gt; <span class="keyword">where</span> T: <span class="built_in">Default</span> &#123;</span><br><span class="line">	this: &amp;Link&lt;T&gt;				<span class="comment">// this的type与stack.head一致，记录此this，才能在每一次next时知道下一次next应该从何处开始</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;T: <span class="built_in">Default</span>&gt; List&lt;T&gt; &#123;			<span class="comment">// 返回一个自定义的迭代器</span></span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">iter</span>(&amp; <span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="title function_ invoke__">Iter</span>(&amp; <span class="keyword">self</span>.head)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;T: <span class="built_in">Default</span>&gt; <span class="built_in">Iterator</span> <span class="keyword">for</span> <span class="title class_">Iter</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">type</span> <span class="title class_">Item</span> = &amp;T;</span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">next</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;<span class="keyword">Self</span>::Item&gt; &#123;		<span class="comment">// 注意，为什么需要&amp;mut 呢？每一次next，我们都要修改Iter的this指向（指向下一个）</span></span><br><span class="line">        <span class="keyword">self</span>.this.<span class="title function_ invoke__">as_ref</span>().<span class="title function_ invoke__">map</span>(|node|&#123;</span><br><span class="line">            <span class="keyword">self</span>.this = &amp;node.next;</span><br><span class="line">            &amp;node.elem</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
逻辑看起来很正确，对吧？看了一眼官方教程，很不一样。。。但是没关系！要有自信。结果一编译就爆炸了，无奈瞅了一眼官方教程，结果发现它也爆炸了。可以的，我们都炸在了
<strong><u>lifetime</u></strong> 这玩意上。</p>
<h2 id="impotant-lifetime">2.2 Impotant: Lifetime</h2>
<p>​
人的一生啊（lifetime），他自己就不知道。一个人的前途命运啊，当然要靠自我奋斗。啊同时还要考虑到历史的进程。我当年在上海当...（内容快涉嫌违规了）。lifetime，其实是我们很熟悉的概念，就是变量的生存周期嘛。但是不管是C、C++还是Python，都已经把生存周期管理的事给做了，我们其实很难接触到生存周期的问题（除了C++中，最好不要返回函数中临时变量的引用或指针这样的例子外）。正如官方教程所说：</p>
<blockquote>
<p>Lifetimes are unnecessary in garbage collected languages because the
garbage collector ensures that everything magically lives as long as it
needs to. Most data in Rust is <em>manually</em> managed, so that data
needs another solution. C and C++ give us a clear example what happens
if you just let people take pointers to random data on the stack:
pervasive unmanageable unsafety. This can be roughly separated into two
classes of error:</p>
<ul>
<li>Holding a pointer to something that went out of scope</li>
<li>Holding a pointer to something that got mutated away</li>
</ul>
<p>Lifetimes solve both of these problems, and 99% of the time, they do
this in a totally transparent way.</p>
</blockquote>
<p>​
抄了好大一段啊，我就不翻译了，反正看不懂的都应该反思一下自己高中大学学的英语都用来干什么了，看不良网站去了？省流：Rust可以避免引用指针失效问题，各种处理都是完全透明的。强啊，只能说。</p>
<p>​
但同时lifetime是一个相对较为复杂的概念（上午看了半小时概念，愣是没看懂）。首先我们确定一下，lifetime的应用场景。对于普通的变量而言，其实一般不需要考虑lifetime概念，倒是引用（reference）这些玩意，由于他们可能指向一个已经move、out
of
scope或者其他原因失效的变量，我们需要特别小心。也即：对于引用而言，我们希望其指向的变量活着的时间可以至少与引用变量本身一样长。别在引用还valid的时候，白发人送黑发人了。那么为什么编译器可能会有lifetime的困惑呢？这里我引用<a href="https://www.youtube.com/watch?v=juIINGuZyBc">Youtube上一个博主的例子</a></p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">str1</span> = String::<span class="title function_ invoke__">from</span>(<span class="string">&quot;The first string.&quot;</span>);</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">str2</span> = String::<span class="title function_ invoke__">from</span>(<span class="string">&quot;2nd string.&quot;</span>);</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">result</span>: &amp;<span class="type">str</span> = <span class="title function_ invoke__">longer_string</span>(&amp;str1, &amp;str2);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;Longer string is &#123;&#125;&quot;</span>, result);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">longer_string</span>(x: &amp;<span class="type">String</span>, y: &amp;<span class="type">String</span>) <span class="punctuation">-&gt;</span> &amp;<span class="type">String</span>&#123;</span><br><span class="line">    <span class="keyword">if</span> x.<span class="title function_ invoke__">len</span>() &gt; y.<span class="title function_ invoke__">len</span>() &#123;</span><br><span class="line">        x</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        y</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
这段程序看起来很正确，但实际上没办法编译。为什么？编译器认为：<code>longer_string</code>函数输入输出的lifetime是有问题的。在这个例子中，没有什么问题，但是如果main改写成：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">str1</span> = String::<span class="title function_ invoke__">from</span>(<span class="string">&quot;The first string.&quot;</span>);</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">str2</span> = String::<span class="title function_ invoke__">from</span>(<span class="string">&quot;2nd string.&quot;</span>);</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">result</span>: &amp;<span class="type">str</span> = <span class="title function_ invoke__">longer_string</span>(&amp;str1, &amp;str2);</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">println!</span>(<span class="string">&quot;Longer string is &#123;&#125;&quot;</span>, result);</span><br></pre></td></tr></table></figure>
<p>​
确实就是错的了。但是你会觉得，诶呀这不就跟js一样嘛，一个块内部的变量不能在外部访问，很正常啊做一个检查应该就知道。确实，但如果进一步改呢？</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">str2</span> = String::<span class="title function_ invoke__">from</span>(<span class="string">&quot;2nd string.&quot;</span>);</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">str1</span> = String::<span class="title function_ invoke__">from</span>(<span class="string">&quot;The first string.&quot;</span>);</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">result</span>: &amp;<span class="type">str</span> = <span class="title function_ invoke__">longer_string</span>(&amp;str1, &amp;str2);</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">println!</span>(<span class="string">&quot;Longer string is &#123;&#125;&quot;</span>, result);</span><br></pre></td></tr></table></figure>
<p>​
这里已经不仅仅是result在局部块中的问题了。可以根据<code>longer_string</code>的定义知道，返回的引用是<code>&amp; str1</code>。而即便println可以访问到变量result，result指向的也已经是一个销毁后的变量。此外，上面这个例子的流程已经非常简单了，更复杂的情况下，编译器无法判定在引用result存活时，其指向的内容是否也是存活的。这就需要我们进行限定：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">longer_string</span>&lt;<span class="symbol">&#x27;a</span>&gt;(x: &amp;<span class="symbol">&#x27;a</span> <span class="type">String</span>, y: &amp;<span class="symbol">&#x27;a</span> <span class="type">String</span>) <span class="punctuation">-&gt;</span> &amp;<span class="symbol">&#x27;a</span> <span class="type">String</span>&#123; ...</span><br></pre></td></tr></table></figure>
<p>​
这里<code>'a</code>表示限定的lifetime，主要用来限定输入输出的lifetime（输入之间其实无所谓）。lifetime实际上是generic的，我们需要用类似模板的方法，使用尖括号进行限定。<code>a</code>实际只是一个名字，我们可以随便起，但是惯例就是单个小写的字母。注意，此处虽然<code>x</code>与<code>y</code>的lifetime可能不一致，我们仍然写了两个一样的<code>'a</code>，这种情况下，编辑器将会选择更小的一个作为输出的lifetime。这样的lifetime限定，根本目的是：
<strong><u>使得输入至少可以与输出存活得一样久</u></strong>。</p>
<p>​ <strong><u>注意：</u></strong>
lifetime用在<code>type</code>，函数、结构体、枚举类等上，一般<strong><u>不需要用在函数的内部</u></strong>。个人的理解是，这应该是一个声明的“特性”，而不需要出现在实现里。我们尝试使用lifetime来修改stack的iterator：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">Iter</span>&lt;<span class="symbol">&#x27;a</span>, T&gt; <span class="keyword">where</span> T: <span class="built_in">Default</span>&#123;			<span class="comment">// 这里应该表示的是，Iter能存活多久，this指向的内容就应该存活多久（因为this引用的lifetime现在与Iter一致）</span></span><br><span class="line">    this: &amp;<span class="symbol">&#x27;a</span> Link&lt;T&gt;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">impl</span>&lt;T: <span class="built_in">Default</span>&gt; List&lt;T&gt; &#123;				 <span class="comment">// List本身不需要显式lifetime概念，故不用写</span></span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">iter</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> Iter&lt;T&gt; &#123;			<span class="comment">// 根据lifetime省略第三规则，输入有&amp;self，则输出的lifetime默认与self一致，这样iter的lifetime会与链表本身一致，内部的引用也一样</span></span><br><span class="line">        Iter&#123;this: &amp;<span class="keyword">self</span>.head&#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125; </span><br><span class="line"><span class="keyword">impl</span>&lt;<span class="symbol">&#x27;a</span>, T&gt; <span class="built_in">Iterator</span> <span class="keyword">for</span> <span class="title class_">Iter</span>&lt;<span class="symbol">&#x27;a</span>, T&gt; <span class="keyword">where</span> T: <span class="built_in">Default</span> &#123;		<span class="comment">// 由于Iter在模板定义中，有&lt;&#x27;a, T&gt;，我们在impl块中、Iter模板定义中也要写&#x27;a</span></span><br><span class="line">    <span class="keyword">type</span> <span class="title class_">Item</span> = &amp;a&#x27; T;															<span class="comment">// type 需要设置lifetime</span></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">next</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;<span class="keyword">Self</span>::Item&gt; &#123;					<span class="comment">// 这里不需要pub，写pub会报错，说是`pub` not permitted here because it&#x27;s implied。估计是因为impl块中默认pub</span></span><br><span class="line">        <span class="keyword">self</span>.this.<span class="title function_ invoke__">as_ref</span>().<span class="title function_ invoke__">map</span>(|node|&#123;</span><br><span class="line">            <span class="keyword">self</span>.this = &amp;node.next;</span><br><span class="line">            &amp;node.elem</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 这里注意，不能写成：<code>&lt;'a, T: Default&gt;</code>
否则会出现一些<code>'a</code> not bounded
这种奇怪的，我不知道如何处理的错误。关于lifetime省略（ellision）规则，可以参考官方教程<a href="https://rust-unofficial.github.io/too-many-lists/second-iter.html">An
Ok Stack:
Iter</a>，也可以看上文提到的油管博主的视频。exmmm结果我发现，通过作者实现的方法，后面还有报错？我这一版本加上lifetime
annotation就直接过编译了。整活！开始（但实际上，我和教程实现的完全不是一个东西，虽然功能上类似，说实话，我觉得作者实现有点复杂？（开始飘了））。让我非常惊讶的是...
我感觉这玩意是个立即数啊，怎么还能引用呢？</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="built_in">assert_eq!</span>(iterator.<span class="title function_ invoke__">next</span>(), <span class="title function_ invoke__">Some</span>(&amp;<span class="number">4</span>));			<span class="comment">// 写的iter测试，如果去掉&amp;符号，就会报错，说iterator.next()返回了一个Option&lt;&amp;i32&gt;，而你这是Option&lt;i32&gt;</span></span><br></pre></td></tr></table></figure>
<p>​ 这里我保存教程中几个有趣的（颜）表情（作者编译连跪三把）：</p>
<blockquote>
<p>(╯°□°)╯︵ ┻━┻ ---&gt; (ﾉಥ益ಥ）ﾉ﻿ ┻━┻ ---&gt; 😭</p>
</blockquote>
<p>​
看到最后，作者直接祭出了<code>as_deref</code>，好吧，我不能因为我的实现可以编译就不管他这一版本，我也想知道<code>as_deref</code>是干什么的。作者做的事情很简单：作者的next项保存的是node，由于node实际已经是内部Link内部的类型了（被封装了，因为Link是<code>Option&lt;Box&lt;Node&lt;T&gt;&gt;&gt;</code>），作者需要通过map将其取出：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line">next: <span class="keyword">self</span>.head.<span class="title function_ invoke__">map</span>(|node| &amp;*node)			<span class="comment">// 直接这样会导致移动的(self.head被移动)，需要as_ref</span></span><br></pre></td></tr></table></figure>
<p>​
注意，node本身（由map，也即match类方法取出）是<code>Box&lt;Node&lt;T&gt;&gt;</code>，需要从堆中取出则用*。作者用了<code>deref</code>，但是我发现只要改成：‘</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">Iter</span>&lt;<span class="symbol">&#x27;a</span>, T&gt; &#123;</span><br><span class="line">    next: <span class="type">Option</span>&lt;&amp;<span class="symbol">&#x27;a</span> <span class="type">Box</span>&lt;Node&lt;T&gt;&gt;&gt;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
并且把map中node之前的<code>&amp;*</code>去掉其实就可以了。<code>as_deref</code>，官方文档的意思写的很明确：</p>
<blockquote>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">as_deref</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;&amp;&lt;T <span class="keyword">as</span> Deref&gt;::Target&gt;</span><br></pre></td></tr></table></figure>
<p>Converts from <code>Option&lt;T&gt;</code> (or
<code>&amp;mut Option&lt;T&gt;</code>) to
<code>Option&lt;&amp;mut T::Target&gt;</code>.</p>
<p>Leaves the original <code>Option</code> in-place, creating a new one
containing a mutable reference to the inner type’s
[<code>Deref::Target</code>] type.</p>
</blockquote>
<p>​
可能刚开始有点晕，什么是<code>T::Target</code>？结合stack例子，以及这个函数的名字就可以知道，这里实际上做了一个dereference操作，从<code>Box</code>中将被Boxed的元素取出，target实际上就是<code>Node&lt;T&gt;</code>。这里，<code>as_deref</code>做了两件连续的事情：（1）给返回值增加引用，（2）dereference操作，取出box内元素。其实看<code>std::ops::Deref</code>的说明也可以知道：</p>
<blockquote>
<p>Used for immutable dereferencing operations, like
<code>*v</code>.</p>
</blockquote>
<p>​
那么，<code>self.head</code>进行<code>as_deref</code>操作的结果也就很明显了。从<code>&amp;Option&lt;Box&lt;Node&lt;T&gt;&gt;&gt;</code>先转化为<code>Option&lt;&amp;Box&lt;Node&lt;T&gt;&gt;&gt;</code>再成为<code>Option&lt;&amp;Node&lt;T&gt;&gt;</code>。我自己原来的实现，说是<code>this: Link&lt;T&gt;</code>
但由于<code>Link&lt;T&gt; = Option&lt;Box&lt;Node&lt;T&gt;&gt;&gt;</code>，故实际上我原来的实现和我自己的修改<code>next: Option&lt;&amp;'a Box&lt;Node&lt;T&gt;&gt;&gt;</code>应该是没有太大差别的。</p>
<h3 id="理解有误">2.3 理解有误？</h3>
<p>​
尝试实现<code>IterMut</code>但出现了问题，此问题我想了很久没有想明白，于是在stackoverflow上挂了一下，两小时后有两个人回复了我。其中一人的“修改”实际上与官方教程完全重合，对我的帮助不大，但他在回答中提到的东西对我很有启发。问题在这里：<a href="https://stackoverflow.com/questions/72090145/lifetime-confusion-for-iterator">Stackoverflow:
Lifetime Confusion for iterator</a>。这里我重新列一下：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">IterMut</span>&lt;<span class="symbol">&#x27;a</span>, T&gt;&#123;</span><br><span class="line">    this: &amp;<span class="symbol">&#x27;a</span> <span class="keyword">mut</span> Link&lt;T&gt;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;T&gt; List&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">iter_mut</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> IterMut&lt;T&gt; &#123;</span><br><span class="line">        IterMut &#123;</span><br><span class="line">            this: &amp;<span class="keyword">mut</span> <span class="keyword">self</span>.head</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;<span class="symbol">&#x27;a</span>, T&gt; <span class="built_in">Iterator</span> <span class="keyword">for</span> <span class="title class_">IterMut</span>&lt;<span class="symbol">&#x27;a</span>, T&gt;&#123;</span><br><span class="line">    <span class="keyword">type</span> <span class="title class_">Item</span> = &amp;<span class="symbol">&#x27;a</span> <span class="keyword">mut</span> T;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">next</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;<span class="keyword">Self</span>::Item&gt; &#123;</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>(node) = <span class="keyword">self</span>.this &#123;</span><br><span class="line">            <span class="keyword">self</span>.this = &amp;<span class="keyword">mut</span> node.next;</span><br><span class="line">            <span class="title function_ invoke__">Some</span>(&amp;<span class="keyword">mut</span> node.elem)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="literal">None</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// self.this.as_mut().map(|node|&#123;</span></span><br><span class="line">        <span class="comment">//     self.this = &amp;mut node.next;</span></span><br><span class="line">        <span class="comment">//     &amp;mut node.elem</span></span><br><span class="line">        <span class="comment">// &#125;)</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>​
使用如上方法实现一个<code>IterMut</code>，（这里为了可以更加清晰地看出发生了什么事情，将<code>map</code>替换为了match方法，原来的实现在注释中）。这里会报错：说我发返回的<code>Some(&amp;mut node.elem)</code>的声明周期实际上是<code>'1</code>（与匿名生命周期引用&amp;mut
self一致），而我在<code>impl</code>块中显式定义了一个<code>'a</code>，两者冲突了，错误是：</p>
<blockquote>
<p>returning this value requires that <code>'1</code> must outlive
<code>'a</code></p>
</blockquote>
<p>​
这里我根据歪果仁们的回答以及我自己理解，解释一下产生此问题的原因。首先，我们定义了一个<code>IterMut</code>，它的生命周期是<code>'a</code>。这个<code>IterMut</code>使用<code>iter_mut</code>函数返回，那么我们可以根据生命周期省略规律得到，<code>IterMut</code>的生命周期就是List的<code>self</code>周期。也即<code>'a</code>与<code>List</code>（stack本体）一致（或者说，<code>IterMut</code>至少与stack本体活得一样久）。接下来，由于我对Rust语言的理解有限，我无法确定以下两个想法哪一个是正确的，所以我在此分支，两个都记录下来：</p>
<p>（1）个人更加倾向于这种解释：next函数中的<code>&amp;mut self</code>可能有单独的生命周期，因为这里的self只是一个引用，不一定需要与实例化的本体有同样的生命周期（更短即可）。也即假如<code>IterMut</code>的生命周期就是<code>'a</code>，<code>&amp;mut self</code>可能有一个单独的生命周期<code>'b</code>。self.this没办法导出正确的生命周期到node中，毕竟self.this生命周期应该是<code>'a</code>
（与<code>IterMut</code>一致），而对于self的引用又是生命周期<code>'b</code>的。如果要保证传出的<code>&amp;mut node.elem</code>是有效的，<code>'b</code>显然应该长于<code>'a</code>，（因为<code>Item = &amp;'a mut T</code>'，返回值的生命周期是<code>'a</code>的）。而如果<code>'b</code>长于<code>'a</code>，会产生一个问题：我如何确定返回值何时无效呢？如果<code>'b</code>很长，在下一次调用next时，会对此<code>IterMut</code>创建一个新mutable
reference，而原来的mutable
reference（还记得吗，它的生命周期是<code>'b</code>）<strong><u>还没有销毁</u></strong>！</p>
<div class="note warning"><p>​ Rust不允许对同一个变量保留多个valid的mutable
reference，甚至以下情况也是不允许的（一个引用整体，一个引用内部域）：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">TestStruct</span> &#123;a: <span class="type">i32</span>, b: <span class="type">f32</span>&#125;</span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">t1</span> = TestStruct&#123;a: <span class="number">0</span>, b: <span class="number">1.5</span>&#125;;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">ptr1</span>: &amp;<span class="keyword">mut</span> TestStruct = &amp;<span class="keyword">mut</span> t1;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">ptr2</span>: &amp;<span class="keyword">mut</span> <span class="type">i32</span> = &amp;<span class="keyword">mut</span> t1.a;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;Elem &#123;&#125;&quot;</span>, ptr2);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;Elems &#123;&#125;, &#123;&#125;&quot;</span>, ptr1.a, ptr1.b);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 关于此问题更详细的介绍，见：<a href="https://oribenshir.github.io/afternoon_rusting/blog/mutable-reference">Multiple
Mutable Reference</a></p>
</div>
<p>​ 此外，关于这种解释，stackoverflow上的大佬也说：</p>
<blockquote>
<ul>
<li>So to use the exclusive reference there must be a guarantee that you
can't obtain the same mutable reference again. (Note that as written, if
you call <code>next()</code> twice you'll get the same mutable reference
back, which would be a problem -- that's why the lifetime of the return
value must be bound to the lifetime of <code>&amp;mut self</code> in
this particular implementation.)</li>
<li>The principal problem lies in trying to take a reference to the
whole <code>head</code>. While that reference lives, you can't hand out
mutable references to anything inside it.</li>
</ul>
</blockquote>
<p>（2）next没有单独的生命周期，其中的<code>&amp;mut self</code>生命周期也是<code>'a</code>。这也会引发类似的问题：我们已经知道<code>'a</code>是非常长的（与stack本体一致），而这里虽然<code>&amp;mut self</code>在next函数结束之后，看似已经不见了（本次<code>&amp;mut self</code>已经销毁了），但实际上并非如此，由于我们定义了<code>&amp;mut self</code>的生命周期是<code>'a</code>，它实际还是存活着的。故也会出现多mutable
reference的问题。</p>
<p>​
已经知道错了，求求Rust不要再打我了，\(T益T)/。接下来我们来细致分析一下教程的实现。在stackoverflow的回答中，参与回答的大佬说：</p>
<blockquote>
<p>The principal problem lies in trying to take a reference to the whole
<code>head</code>.</p>
</blockquote>
<p>​
原实现中，在构造<code>IterMut</code>的过程中，this传入的参数是<code>&amp;mut self.head</code>。而<code>self.head</code>的生命周期非常长（与stack本体一致）。如果像作者一样，this指向的不是一个Link结构，而是一个Node，可能可以解决问题。教程中实现是：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line">IterMut &#123;</span><br><span class="line">    this: <span class="keyword">self</span>.head.<span class="title function_ invoke__">as_deref_mut</span>()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
<code>as_deref_mut</code>可以将<code>&amp;mut Option&lt;Box&lt;Node&lt;T&gt;&gt;&gt;</code>转化为<code>Option&lt;&amp;mut Node&lt;T&gt;&gt;</code>。而<code>self.head.as_deref_mut()</code>得到的这个node，生命周期是什么呢？个人的理解是：可以很短！因为这不是stack中常驻的head（只要stack在就有），node是可以轻易invalidate的。也就是说，之所以用node写，就是因为head已经成了...
老不死的玩意。对于一个node而言，只要take它，它就之后就没了，销毁了，使得此生命周期不会影响代码的其他部分，也不会使得某个引用活太长而挤占可以用的mutable
reference资源。其他其实没有太好说的。吐槽一下，这样的next peeking...
貌似会毁掉整个stack，我不能做到修改之后还保证原来的结构？</p>
<h3 id="生命周期的其他问题">2.4 生命周期的其他问题</h3>
<p>​
lifetime深究起来很是复杂，在编写程序的过程中很容易搞糊涂。这里我想再分析一下stackoverflow上关于conflict
lifetime的另一个例子。个人觉得，这个例子理解起来较为简单，并且如果你真的理解了lifetime，分析这个例子是很轻松的。原问题：<a href="https://stackoverflow.com/questions/41270052/cannot-infer-an-appropriate-lifetime-for-autoref-due-to-conflicting-requirements">Cannot
infer an appropriate lifetime for autoref due to conflicting
requirements</a></p>
<p>​ 其中一个佬将问题进行了简化：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">FontLoader</span>(<span class="type">String</span>);</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Font</span>&lt;<span class="symbol">&#x27;a</span>&gt;(&amp;<span class="symbol">&#x27;a</span> <span class="type">str</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">FontLoader</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">load</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> Font &#123;</span><br><span class="line">        <span class="title function_ invoke__">Font</span>(&amp;<span class="keyword">self</span>.<span class="number">0</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Window</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Phi</span>&lt;<span class="symbol">&#x27;window</span>&gt; &#123;</span><br><span class="line">    window: &amp;<span class="symbol">&#x27;window</span> Window,</span><br><span class="line">    loader: FontLoader,</span><br><span class="line">    font: <span class="type">Option</span>&lt;Font&lt;<span class="symbol">&#x27;window</span>&gt;&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;<span class="symbol">&#x27;window</span>&gt; Phi&lt;<span class="symbol">&#x27;window</span>&gt; &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">do_the_thing</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">font</span> = <span class="keyword">self</span>.loader.<span class="title function_ invoke__">load</span>();</span><br><span class="line">        <span class="keyword">self</span>.font = <span class="title function_ invoke__">Some</span>(font);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
试问，为什么load函数编译时，无法正确导出lifetime？首先，看第二个<code>impl</code>块，此块限制了（定义了）<code>Phi</code>结构体的生存时间。但此处，<code>&amp;mut self</code>却仍然是一个local的lifetime（并不一定是<code>'window</code>），接下来的流程是：</p>
<ul>
<li>loader.load。loader没有标注生存周期。load之后，返回的load将会装入loader的生命周期（这里符合生存周期省略规则，故<code>&amp;self.0</code>对应的生存周期
--- loader的生存周期被装入。）</li>
<li>返回后，希望使用Option封装装入<code>self.font</code>，但是self.font的生命周期是<code>'window</code>...，那么loader的周期是<code>'window</code>吗？我们已经说了，并不见得。假如没有人操作这个变量，很可能<code>self.loader</code>直到结构体<code>Phi</code>被销毁时才随之销毁。但是...
假设它在之前就被move了呢？故这里我们将loader的类型改写为<code>&amp;'window Fontloader</code>。这样，只要loader本身存活时间够长，就不会有冲突问题。</li>
</ul>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>Rust</tag>
      </tags>
  </entry>
  <entry>
    <title>Rust学习 I</title>
    <url>/2022/05/03/Rust%E5%AD%A6%E4%B9%A0-I/</url>
    <content><![CDATA[<h1 id="rust---i">Rust - I</h1>
<hr>
<h2 id="intros">Intros</h2>
<p>​
Rust，好！可能主要由于所有权机制上的创新，学习时的感觉与学其他语言的感觉完全不同，于是没有像学JS一样，觉得无聊，也没有像觉像学haskell一样，觉得过于抽象。但是这样一种语言创新，必然会给学习带来障碍，毕竟编程思想是完全不同的。此外，可能我使用Rust的工具链不对，个人认为vscode对于Rust的支持明显不足（缺乏自动补全，没有函数快速查看以及定义跳转等等），第一天学的时候，只能实现一些强逻辑性算法（比如什么快排，归并排序等等），无法深入使用数据结构（给我一个数据结构我根本不知道里面有什么方法）。</p>
<p>​
第一天快结束时，想学习一下Rust的可视化工具Plotters，结果发现，之前从菜鸟教程了解的写法过于粗浅，基本看不懂Plotters代码，遂投身更加深入的学习。但却发现，给自己设置的小目标
---
写一个链表，按照之前了解的语法知识，我都是写不出来的。快要放弃只是接触到了一个教程以及其官方文档：</p>
<ul>
<li><a href="https://rust-unofficial.github.io/too-many-lists/index.html">Rust
unofficial - Learning Rust With Entirely Too Many Linked Lists</a></li>
<li><a href="https://doc.rust-lang.org/std/index.html">Rust-lang
docs</a></li>
</ul>
<p>​
教程详细介绍了对于链表的实现，较为通俗易懂，有些难以思考的问题，其实沉下心来想也很快能想出来。本文是跟着教程实现过程中，笔者对于遇到的一些问题的处理方法以及自己的心得。由于笔者非常不喜欢依葫芦画瓢（因为这样，感觉自己完全学不到东西），所以笔者也在自己的实现中整活（超前学习），本文也记录了整活过程中遇到的坑及处理方法。本篇为Rust学习心得的第一章。</p>
<span id="more"></span>
<hr>
<h2 id="ii.-用rust实现链表">II. 用Rust实现链表</h2>
<h3 id="null-pointer-optimization的意义">2.1 null pointer
optimization的意义？</h3>
<p>​ 假设我们有一个这样的数据结构：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">Foo</span> &#123;</span><br><span class="line">		Empty,</span><br><span class="line">    	<span class="title function_ invoke__">NotEmpty</span>(a_pointer)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
通常来说，enum类型<code>Foo</code>（可以将enum的内存功能理解为一个union）需要有足够空间以存储其表示的数据，也即在<code>Empty</code>以及<code>NotEmpty</code>两个类型之间，选择所占空间最大的那个类型对应的内存消耗作为enum类型<code>Foo</code>的大小。但是，<code>Foo</code>如何才能知道当前表示的是<code>Empty</code>还是<code>NotEmpty</code>类型？通常，需要额外的空间（比如一个字节）存储一个叫tag的域，以指示当前<code>Foo</code>的真正含义。有一种例外，例如以上这个例子：</p>
<p>（1）<code>Empty</code> 没有关联数据</p>
<p>（2）<code>NotEmpty</code>
我们认为是一个指针，对于此指针而言，数据位为0（空指针）是不允许的</p>
<p>​
也即，此例子中，<code>NotEmpty</code>中不被允许的结果（全0）恰好可以被用于表示<code>Empty</code>。则此时，我们不再需要tag域来表示<code>Foo</code>的实际意义（Foo中数据可以直接判定）。</p>
<h3 id="错误---private-type-xxx-in-public-interface">2.2 错误 -
<code>private type 'xxx' in public interface</code></h3>
<p>​ 如果我直接写如下代码：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Foo</span> &#123;elem: <span class="type">i32</span>&#125;</span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">Bar</span> &#123;</span><br><span class="line">    test_elem: Foo</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 这样是完全没有问题的。但是如以下这两种写法，都会出现问题</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Foo</span> &#123;elem: <span class="type">i32</span>&#125;</span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">Bar</span> &#123;				<span class="comment">// 第一种写法</span></span><br><span class="line">    <span class="keyword">pub</span> test_elem: Foo</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">enum</span> <span class="title class_">Bar</span> &#123;				<span class="comment">// 第二种写法</span></span><br><span class="line">    <span class="title function_ invoke__">First</span>(Foo),</span><br><span class="line">    Second</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
两种写法都会报错，编译器认为：<code>can't leak private type</code>。struct中的权限，不同于C++的结构体（默认public），struct默认private，如果显式定义了<code>pub</code>关键字才成为public的。而对于enum而言，只要enum本身是public的，其中的所有元素都是public的。但Rust不允许用户在公开的类型中，暴露私有类型，正如参与国家机密项目的科学家，即使这个科学家（的存在）并非机密，他也不能随意讨论机密的内容。</p>
<h3 id="memreplace的作用">2.3 <code>mem::replace</code>的作用</h3>
<p>​
如果我们使用链表实现stack，也即不记录链表的尾部，假设我们需要push新的值到链表中，就会涉及到修改链表的表头：我们需要新创建一个Node，此Node的head是原来链表的head（stack堆积性），假设Node的两个域：data（数据）与next（链表指向下一个元素的“指针”），有两个内容需要修改：</p>
<p>（1）head本身的值，需要修改为最新的Node，这个只需要修改head的指向</p>
<p>（2）新Node的next，由于我们需要原来的head作为next，这里涉及到移动或者复制。如果用复制：我很惊讶我瞎搞一通竟然过编译了（见下代码块），首先，定义一下stack使用的列表：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">List</span> &#123;</span><br><span class="line">    head: Link,</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">Link</span> &#123;</span><br><span class="line">    Empty,</span><br><span class="line">    <span class="title function_ invoke__">More</span>(<span class="type">Box</span>&lt;Node&gt;),</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">    elem: <span class="type">i32</span>,</span><br><span class="line">    next: Link,</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">List</span> &#123;</span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">new</span>() <span class="punctuation">-&gt;</span> <span class="keyword">Self</span> &#123;</span><br><span class="line">        List &#123; head: Link::Empty &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 那么假设我们需要写一个push，就涉及到了将head赋值给next的操作：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">impl</span> <span class="title class_">List</span> &#123;</span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">push</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, elem: <span class="type">i32</span>) &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">new_node</span> = Node &#123;</span><br><span class="line">            elem: elem,</span><br><span class="line">            next: <span class="keyword">self</span>.head,</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 但是直接这样是不允许的，因为self.head
会被move掉，move会使得当前链表的head直接被销毁，也即链表部分被摧毁了（或者说成，partially-initialized，有一部分没有初始化）。如上，在同样的位置（next处）使用clone，如注释所示，也是不允许的。编译器提示：clone是没有被实现的特性（self.head没有Clone函数），那么我们来实现一下。考虑到head是一个Link，那么我们把Link的clone函数实现了，是不是就可以了？如下所示：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">impl</span> <span class="title class_">Clone</span> <span class="keyword">for</span> <span class="title class_">Link</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">clone</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> Link &#123;</span><br><span class="line">        <span class="keyword">match</span> <span class="keyword">self</span> &#123;</span><br><span class="line">            Link::Empty =&gt; Link::Empty,</span><br><span class="line">            Link::<span class="title function_ invoke__">More</span>(next) =&gt; Link::<span class="title function_ invoke__">More</span>(next.<span class="title function_ invoke__">clone</span>()),</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
其中需要注意的点：<code>Link</code>的enum语法特性，需要判定当前<code>Link</code>的实际意义（match）。如果是<code>Empty</code>
需要返回<code>Empty</code>，请使用namespace指定
<strong><u>返回的<code>Empty</code>是<code>Link</code>中定义的。</u></strong>
如果是<code>More</code>，这里需要注意两点：</p>
<p>（1）<code>Link::More(next)</code> 此处的next是一个shared
reference，如果要用来初始化则需要解引用<code>*next</code>。但是很遗憾，这里会报错，直接<code>*next</code>是一个移动操作。会使得<code>Link</code>成为
partially-initialized的数据，这是不被允许的。</p>
<p>（2）直接使用<code>next.clone()</code>。很抱歉，这里又有问题：</p>
<blockquote>
<ul>
<li>the method <code>clone</code> exists for struct
<code>Box&lt;Node&gt;</code>, but its trait bounds were not
satisfied</li>
<li>struct Node ----------- doesn't satisfy
<code>Node: Clone</code></li>
</ul>
</blockquote>
<p>​
个人猜测，这是由于Node本身没有实现clone函数导致的，于是这里我实现clone。</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">impl</span> <span class="title class_">Clone</span> <span class="keyword">for</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">clone</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> Node &#123;</span><br><span class="line">        Node &#123;</span><br><span class="line">            elem: <span class="keyword">self</span>.elem,</span><br><span class="line">            next: <span class="keyword">self</span>.next.<span class="title function_ invoke__">clone</span>(),</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
这样竟然过编译了，并且，结果也是正确的，说明这样的方法是有效的，可以通过暂时保存一份原数据的copy。但是这样是否更慢？测试显示，这种需要clone的方法，在同样进行2000次push的情况下，比官方文档中使用<code>std::mem::replace</code>的版本，慢将近2000倍...
所以还是好好学习官方实现吧。</p>
<blockquote>
<p>Time elapsed for my push: 309.202965ms Time elapsed for swap push:
160.718µs</p>
</blockquote>
<h3 id="在循环中使用match方法">2.4 在循环中使用match方法</h3>
<p>​
学习教程的时候我们已经知道了，对于只有两个分类的enum，可以使用match的语法糖：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">ptr</span>: &amp;Link = &amp;stack.head;</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Link</span>::<span class="title function_ invoke__">More</span>(node) = ptr &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
注意，<code>Link::More(node)</code>本身是enum类型（此例子中，是<code>Link</code>）的一个常引用（shared
ref，之所以称之为常引用，是因为个人认为这个与C++中的常引用非常类似），而node则是对应的<code>Link::More</code>类型的常引用，此处也就是<code>&amp;Box&lt;Node&gt;</code>类型的。那么根据这个语法糖，可以写出一个遍历栈的方法：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">show_stack</span>(&amp;<span class="keyword">self</span>) &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">ptr</span>: &amp;Link = &amp;<span class="keyword">self</span>.head;</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">let</span> <span class="variable">Link</span>::<span class="title function_ invoke__">More</span>(node) = ptr &#123;</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;Stack: &#123;&#125;&quot;</span>, node.elem);</span><br><span class="line">        ptr = &amp;node.next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 首先，ptr需要是【可变的】常引用（相当于const type
*），才能改变其指向。我们判定，如果ptr不是<code>Link::Empty</code>，由于此时<code>ptr</code>实际对应了一个<code>&amp;Box&lt;Node&gt;</code>，我们将<code>ptr</code>对应的Node中元素取出，并使得ptr指向下一个元素（注意，是<code>node.next</code>是<code>Link</code>类型的，但我们需要的<code>ptr</code>是对<code>Link</code>的引用，故需要符号<code>&amp;</code>）</p>
<h3 id="关于泛型编程generics">2.5 关于泛型编程（generics）</h3>
<p>​ 我想直接使用模板类型T作为栈的类型。于是需要修改定义：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">List</span>&lt;T&gt; &#123;head: Link&lt;T&gt;&#125;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span>&lt;T&gt; &#123;</span><br><span class="line">    elem: T,</span><br><span class="line">    next: Link&lt;T&gt;,</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span>&lt;T&gt; &#123;</span><br><span class="line">    elem: T,</span><br><span class="line">    next: Link&lt;T&gt;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
所有相关位置都需要增加<code>&lt;T&gt;</code>以指示当前类型是模板类型。需要注意以下几个问题：</p>
<p>（1）如果要初始化模板类型，在类型声明时需要带有<code>&lt;T&gt;</code>，而构造时（等号右边）不需要，比如：<code>let new_node: Node &lt;T&gt; = Node &#123;...&#125;;</code>，如果右边带了模板，则会报错：<code>chained comparison operator</code>。类型声明同样也包括返回值。如果不声明类型，则会进行自动类型推断，绑定类型。<code>T</code>根据先后顺序进行类型绑定，例如<code>Node</code>的两个变量都是类型<code>T</code>，而初始化时，由第一个变量传入的<code>f32</code>绑定<code>T = f32</code>，而第二个变量则是<code>i32</code>，产生冲突，则会报错。</p>
<p>（2）<code>impl</code>需要有<code>&lt;T&gt;</code>，也即例如<code>impl&lt;T&gt; ... Link&lt;T&gt;</code></p>
<p>​
但是事情并没有那么简单，不是改好了所有的模板声明与定义就能通过编译了（sad）。这里存在的一个问题时，我之前实现了一版基于<code>clone</code>方法的push，那么想要正确应用<code>clone</code>，需要
<strong><u>类型支持clone方法</u></strong>。而原来使用的<code>i32</code>，由于是基本类型，在<code>Node</code>进行clone时直接按值传递，无需clone，现在由于是未知的类型<code>T</code>，由于其很可能不是基本类型，故直接
<code>elem: self.elem</code> 默认引发 move。</p>
<p>​ 想要避免move，简单的想法是我直接
<code>elem: self.elem.clone()</code>。聪明吧？不太聪明。<code>self.elem</code>作为类型<code>T</code>的变量，需要实现<code>Clone</code>方法。对于类型<code>T</code>而言，我不知道怎么实现它的<code>Clone</code>方法（只学了两天，巨菜的），那我只能限制类型<code>T</code>包含了<code>Clone</code>特性了。于是：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">List</span>&lt;T&gt; <span class="keyword">where</span> T: <span class="built_in">Clone</span> &#123;head: Link&lt;T&gt;&#125;</span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">Link</span>&lt;T&gt; <span class="keyword">where</span> T: <span class="built_in">Clone</span> &#123;</span><br><span class="line">    Empty,</span><br><span class="line">    <span class="title function_ invoke__">More</span>(<span class="type">Box</span>&lt;Node&lt;T&gt;&gt;),</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span>&lt;T&gt; <span class="keyword">where</span> T: <span class="built_in">Clone</span> &#123;</span><br><span class="line">    elem: T,</span><br><span class="line">    next: Link&lt;T&gt;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
其中，where限制了<code>T</code>需要存在的特性，这被称为<code>trait bound</code>。没有满足就会报错：<code>E0277: required by this bound in xxx</code>
。对应地，我们需要在<code>impl</code>块中，告知编译器类型<code>T</code>已经实现了某个trait，也即<code>impl&lt;T: Clone&gt;</code>。</p>
<p>​ 这样还没完！之前写的函数还是存在问题，猜猜改了什么？</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">impl</span>&lt;T: std::fmt::Display + <span class="built_in">Clone</span>&gt; List&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">show_stack</span>(&amp;<span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">ptr</span>: &amp;Link&lt;T&gt; = &amp;<span class="keyword">self</span>.head;</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">let</span> <span class="variable">Link</span>::<span class="title function_ invoke__">More</span>(node) = ptr &#123;</span><br><span class="line">            <span class="built_in">println!</span>(<span class="string">&quot;Stack: &#123;&#125;&quot;</span>, node.elem);</span><br><span class="line">            ptr = &amp;node.next;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
答案是，将<code>impl&lt;T: Clone&gt;</code>修改为<code>impl&lt;T: std::fmt::Display + Clone&gt;</code>。这是因为Rust编译器认为，类型<code>T</code>是什么啊？我怎么display它啊？你实现了Display方法没？显然我没有。那么我们是否有必要在整个stack中都添加此约束呢？比如<code>pub struct List&lt;T&gt; where T Clone + std::fmt::Display</code>？答案是，可有可无。如果不加，对于一些复杂的自定义<code>T</code>而言，不能直接调用<code>show_stack</code>方法了。也即，<code>impl</code>块在此处，只限制了对于此方法的调用。没有实现<code>std::fmt::Display</code>特性的类型，不调用这个函数就行了，其他功能并不影响。P.S.
注意多重约束的写法是加号。P.S.2，为了简洁起见，我可能会考虑删除基于clone的版本，使得复杂类型<code>T</code>不一定需要实现<code>Clone</code>特性。P.S.3，注意，在type用法中，如果type
alias是一个模板类型，则无需写特性约束（写了也会被编译器忽略并且报一个warning的）。</p>
<h3 id="关于所有权租借以及move">2.6 关于所有权，租借以及move</h3>
<p>​
是时候写pop了。pop，很显然需要考虑栈是否空。由于栈是否空由enum的状态表示，这里直接使用match即可，我使用了一下match的语法糖：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">pop</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> T &#123;</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Link</span>::<span class="title function_ invoke__">More</span>(node) = &amp;<span class="keyword">self</span>.head &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">pop_elem</span> = node.elem.<span class="title function_ invoke__">clone</span>();</span><br><span class="line">        <span class="keyword">self</span>.head = node.next;</span><br><span class="line">        <span class="keyword">return</span> pop_elem;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">panic!</span>(<span class="string">&quot;Can not pop from an empty stack.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 这里有两个需要注意的点：</p>
<p><span id="match_move"></span></p>
<p>（1）进行match操作时，如果直接写<code>let Link::More(node) = self.head</code>，会发生move（毕竟有let在这里嘛，可以理解成node是一个新创建的变量，<code>self.head</code>将变更所有权）。我们并不希望<code>self.head</code>丧失所有权（而被销毁），则可以通过一个可变引用来使用self.head。涉及到引用的地方是不可以发生move的，因为引用只是租借了变量，获得了临时的访问或修改能力，就像住房问题，共享引用（shared）只可以使用，而不能修改（比如如果选择住酒店，就不能随意装修），与之相比，可变引用就像是对房子的长租，可以进行装修。但这两种引用都不改变原房主对房屋的所有权，此时如果发生move（所有权的转让），则是在进行违法犯罪活动（没有所有权的人，要把当前房屋的所有权转移给别人）。故<code>self.head</code>之前需要增加所有权引用。</p>
<p>（2）由于增加了引用，此处的<code>node</code>也是原<code>self.head</code>实际数据的引用（&amp;Box&lt;Node&lt;T&gt;&gt;）。那么这就涉及到一个问题，<code>self.head</code>是值（value），我们希望用<code>self.head.next</code>
（实际不能这样访问，我这里只做一个示意）来重写<code>self.head</code>。但<code>node</code>是一个引用，我们在<code>self.head = node.next</code>的过程中，会将<code>node</code>的next项move给<code>self.head</code>，对引用进行的move，是不被允许的。果不其然，最后报错了。</p>
<p>​
此处依然可以使用<code>mem::replace</code>。注意<code>mem::replace</code>的性质：</p>
<blockquote>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">replace</span>&lt;T&gt;(dest: &amp;<span class="keyword">mut</span> T, src: T) <span class="punctuation">-&gt;</span> T</span><br></pre></td></tr></table></figure>
<p>Moves <code>src</code> into the referenced <code>dest</code>,
returning the previous <code>dest</code> value.</p>
</blockquote>
<p>​ replace将目的位置用src替换，并且 <strong><u>按值</u></strong>
返回dest位置的变量。正好，我们需要<code>self.head</code>按值而非按引用返回的结果。这样获得的<code>node</code>就可以进行move（因为按值传递的<code>node</code>具有所有权）。则可以简单重写第二行：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Link</span>::<span class="title function_ invoke__">More</span>(node) = mem::<span class="title function_ invoke__">replace</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>.head, Link::Empty) &#123;...</span><br></pre></td></tr></table></figure>
<p>​
这样就可以过编译了。P.S：如果需要可控的错误控制，可以返回<code>Option&lt;T&gt;</code>，当Empty时返回None，就不用不可恢复的panic宏了。</p>
<h3 id="drop特性的实现">2.7 Drop特性的实现</h3>
<p>​
由于原本的stack链表，自动析构过程不能进行尾递归优化，为了防止析构时爆栈，需要手动析构，也即实现Drop特性。直接实现如下：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">impl</span>&lt;T: <span class="built_in">Clone</span> + <span class="built_in">Default</span>&gt; <span class="built_in">Drop</span> <span class="keyword">for</span> <span class="title class_">List</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">drop</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">ptr</span> = &amp;<span class="keyword">mut</span> <span class="keyword">self</span>.head;</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">let</span> <span class="variable">Link</span>::<span class="title function_ invoke__">More</span>(node) = mem::<span class="title function_ invoke__">replace</span>(ptr, Link::Empty)&#123;</span><br><span class="line">            ptr = &amp;<span class="keyword">mut</span> node.next;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
看起来好像很有道理？首先，我将ptr指向的本节点换出（到值），同时使得原变量置为Empty，再使得ptr指向换出后的值对应的next。但这样写是有问题的，因为我这样实现，利用了一个特性：我将ptr换出到值，此值是临时变量，在结束本次循环之后，会析构，也即此node无效了，并且原变量也设成了Empty。但我对node.next进行的引用操作，阻止了我利用临时变量短生命周期的特性，ptr指向的内容将可能无效。故这样写会触发编译错误。</p>
<p>​
正确的写法仍然是，按值传递：ptr应该一直是下一个node的值，可以写成：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">impl</span>&lt;T: <span class="built_in">Clone</span> + <span class="built_in">Default</span>&gt; <span class="built_in">Drop</span> <span class="keyword">for</span> <span class="title class_">List</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">drop</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">ptr</span> = mem::<span class="title function_ invoke__">replace</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>.head, Link::Empty);</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">let</span> <span class="variable">Link</span>::<span class="title function_ invoke__">More</span>(<span class="keyword">mut</span> node) = ptr&#123;</span><br><span class="line">            ptr = mem::<span class="title function_ invoke__">replace</span>(&amp;<span class="keyword">mut</span> node.next, Link::Empty);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
这样，每一个node原有的变量都会由replace方法，将所有权转移到ptr中，原变量全部置为Empty。注意，由于是按值转移的，给原变量赋值Empty也并不会妨碍我们在replace后使用ptr取出其中的node，因为所有权以及变量真正的信息已经转移到了ptr中。其中需要注意的两点：</p>
<p>（1）node这玩意，如果不加前面的mut，是错的。因为这里我们写的是<code>let &lt;variable&gt; = ...</code>
这样的句式，我们定义了一个变量node，但是没有将其定义成可变的。对于不可变变量，不能使用可变引用，在下一行的replace处会报错。对<code>while let</code>句式中，等号前面变量，也需要理解成是一个正规的变量定义过程。那么此处，将<code>while let</code>写为标准的match形式，也有同样的操作：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">impl</span>&lt;T: <span class="built_in">Clone</span> + <span class="built_in">Default</span>&gt; <span class="built_in">Drop</span> <span class="keyword">for</span> <span class="title class_">List</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">drop</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">ptr</span> = mem::<span class="title function_ invoke__">replace</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>.head, Link::Empty);</span><br><span class="line">        <span class="keyword">loop</span> &#123;</span><br><span class="line">            <span class="keyword">match</span> ptr &#123;</span><br><span class="line">                Link::<span class="title function_ invoke__">More</span>(<span class="keyword">mut</span> node) =&gt; &#123;</span><br><span class="line">                    ptr = mem::<span class="title function_ invoke__">replace</span>(&amp;<span class="keyword">mut</span> node.next, Link::Empty);</span><br><span class="line">                &#125;,</span><br><span class="line">                Link::Empty =&gt; &#123;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
这里需要注意的是，loop与match的配合用法（在多类型enum下使用的逻辑）。则根据这个例子，我们可以认为，match的过程中可能定义新的变量，那么此变量的性质可以根据括号内的内容进行确定。</p>
<p>（2）还有另一种写法<code>while let Link::More(node) = &amp;mut ptr</code>，我们来分析一下为什么也可以过编译：这样写，node是ptr的一个可变引用。如果需要使用结构体中的某个值，自然可以可变引用自这个结构体的可变引用了。此处的引用不会叠加，<code>&amp;mut node.next</code>不会称为引用的引用（因为<code>node.next</code>不是引用，<code>node</code>才是）。故replace后，可以把<code>node,next</code>处对应的变量所有权移动到ptr中，变量的类型（ptr是<code>Link&lt;T&gt;</code>）也可以对应replace的结果。</p>
<hr>
<h2 id="iii.-stack-with-option">III. Stack with Option</h2>
<h3 id="转向option">3.1 转向Option</h3>
<p>​
不难发现，前面的<code>enum Link</code>就是一个弱化版的Option。至于为什么是弱化版的，答案很显然，Option作为一个标准库提供的模块，自然有更多方便使用的函数。其中一个就是take函数。我们可以看take函数的定义：</p>
<blockquote>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">take</span>&lt;T&gt;(dest: &amp;<span class="keyword">mut</span> T) <span class="punctuation">-&gt;</span> T </span><br></pre></td></tr></table></figure>
<p>Replaces <code>dest</code> with the default value of <code>T</code>,
returning the previous <code>dest</code> value.</p>
</blockquote>
<p>​
这里有两种形式的take，一个是<code>std::mem::take</code>（官方文档非常清晰），另一种是：实例化的Option可以调用的take函数。两者的功能是类似的，只不过<code>mem::take</code>针对所有类型。查看Option的官方文档可以知道，take返回Option自身的同时，将原变量设为None，相当于进行所有权转移的函数，用此函数可以避免move。而对于<code>mem::take</code>，官方文档给了一个简单易懂的例子：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Buffer</span>&lt;T&gt; &#123; buf: <span class="type">Vec</span>&lt;T&gt; &#125;</span><br><span class="line"><span class="keyword">impl</span>&lt;T&gt; Buffer&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">get_and_reset</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Vec</span>&lt;T&gt; &#123;</span><br><span class="line">        <span class="comment">// error: cannot move out of dereference of `&amp;mut`-pointer</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">buf</span> = <span class="keyword">self</span>.buf;</span><br><span class="line">        <span class="keyword">self</span>.buf = Vec::<span class="title function_ invoke__">new</span>();</span><br><span class="line">        buf</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
上面的error说的就是：由于函数传入的是self的可变引用，不能被move，故报错。</p>
<p>​
那么，使用take函数，可以简化原来使用<code>mem::replace</code>的位置，如drop函数：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">impl</span>&lt;T: <span class="built_in">Clone</span> + <span class="built_in">Default</span>&gt; <span class="built_in">Drop</span> <span class="keyword">for</span> <span class="title class_">List</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">drop</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">ptr</span> = <span class="keyword">self</span>.head.<span class="title function_ invoke__">take</span>();</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">let</span> <span class="variable">Some</span>(<span class="keyword">mut</span> node) = ptr&#123;</span><br><span class="line">            ptr = node.next.<span class="title function_ invoke__">take</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
只需要记住，ptr需要接受按值传递的结果，这样不会引起move问题。此外，Option还实现了两个重要的方法：<code>map</code>以及<code>unwrap</code>。</p>
<p>​
map，有那么一些类似于python中的map。python中的map可以将一个iterator中的所有元素通过某个函数进行映射。而此处的map，是将Option进行变换。官方的定义是：map可以通过传入的函数，将<code>Option&lt;T&gt;</code>转换为<code>Option&lt;U&gt;</code>：</p>
<blockquote>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">map</span>&lt;U, F&gt;(<span class="keyword">self</span>, f: F) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;U&gt;</span><br></pre></td></tr></table></figure>
<p>Maps an <code>Option&lt;T&gt;</code> to <code>Option&lt;U&gt;</code>
by applying a function to a contained value.</p>
</blockquote>
<p>​
官方文档提供了一个这样的例子。对于<code>Option&lt;String&gt;</code>类型的变量来说（也就是带有None选项的String），直接求<code>len()</code>是非常繁琐的，我们需要通过好几行match指令块或者<code>if let</code>语法糖才能得到其长度。而对于map而言，<strong><u>由于传入的函数，操作的是T，本质是一个T-&gt;U的映射函数</u></strong>，可以很轻松地获得其长度：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">result</span> = some_string.<span class="title function_ invoke__">map</span>(|s| &#123;s.<span class="title function_ invoke__">len</span>()&#125;);</span><br></pre></td></tr></table></figure>
<p>​
那么，map的变体有<code>map_or</code>以及<code>map_or_else</code>，我觉得比较有价值的是<code>map_or</code>。其实不光是map函数有<code>_or</code>以及<code>_or_else</code>实现，其他一些函数也有这样的实现，如之后要说的<code>unwrap</code>,
<code>ok</code>，<code>or</code>本身也是一个函数。<code>map_or</code>的输入则是：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">map_or</span>&lt;U, F&gt;(<span class="keyword">self</span>, default: U, f: F) <span class="punctuation">-&gt;</span> U</span><br></pre></td></tr></table></figure>
<p>​
也即需要提供一个默认值。也即当结果为None时，返回一个默认的结果。<code>map_or_else</code>则是，传入两个函数，如果当前值非None，则执行第二个函数（f），否则执行第一个函数。</p>
<p>​
而unwrap，根据其名字理解，也即解包。显然，在Option中，我们将有意义的值包在了Some中，但通常我们可能需要内部的值。使用match块同样太过复杂，我们考虑用unwrap，这个函数实际就是一个<code>Option&lt;T&gt;</code>到T的映射。同样地，其<code>_or</code>以及<code>_or_else</code>方法，都有类似的map对应函数的函数思想。值得一提的是，<code>unwrap_or_else</code>中有这么一句话：</p>
<blockquote>
<p>Returns the contained <a href="https://doc.rust-lang.org/std/option/enum.Option.html#variant.Some"><code>Some</code></a>
value or computes it from a <strong><u>closure</u></strong>.</p>
</blockquote>
<p>​
闭包？这里说的实际上是我们传递的匿名函数，写法就是<code>|Some的内部变量| &#123;有返回值的函数体&#125;</code>。此函数与C++的匿名函数很像，也可以从外部捕获变量（捕获的变量也一样无需写在<code>|·|</code>（或C++中<code>[·]</code>）中），用在函数体中进行计算。</p>
<p>​
知道<code>map</code>的工作原理之后，我们可以立刻用map进行一些程序改写。比如stack中的pop，我们希望在修改head的同时，可以返回原head对应node的值。则可以按照如下方式进行书写：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">impl</span>&lt;T: <span class="built_in">Default</span>&gt; List&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">pop</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> T &#123;</span><br><span class="line">        <span class="keyword">self</span>.head.<span class="title function_ invoke__">take</span>().<span class="title function_ invoke__">map</span>(|node &#123;</span><br><span class="line">            	<span class="keyword">self</span>.head = node.next;</span><br><span class="line">            	node.elem</span><br><span class="line">            &#125;).<span class="title function_ invoke__">unwrap</span>()</span><br><span class="line">        )</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
此处的逻辑很简单：首先take()将<code>self.head</code>置None，并且返回实际存储的Some(node)，Some(node)进入map中的函数被处理，取出其中的node（按值），重新覆盖<code>self.head</code>（node变量内部值的move），按值返回node的elem域。但注意如果没有<code>.unwrap()</code>，如上返回的Some(T)或者None，如果要返回真正的<code>T</code>类型值，则需要加上<code>unwrap</code>，但这不是很危险，当stack为empty时，也不知道会发生什么（我们删去了empty处理）。</p>
<h3 id="as_ref-as_mut-as_deref">3.2 as_ref | as_mut | as_deref</h3>
<p>​
之前我想实现一个top函数，不过此top函数是返回值的函数，而官方教程则说：我们应该实现一个返回引用的top（教程叫做peek）。开始我觉得这好像也不是什么难事吧？于是我写了一波：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">top</span>(&amp; <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> &amp;T &#123;</span><br><span class="line">    <span class="keyword">self</span>.head.<span class="title function_ invoke__">map</span>(|node|&#123;</span><br><span class="line">        &amp;node.elem</span><br><span class="line">    &#125;).<span class="title function_ invoke__">unwrap</span>()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 结果直接报错了，错误信息：</p>
<blockquote>
<p>&amp;node.elem returns a reference to data owned by the current
function</p>
<p>self.head.map(|node|{... move occurs because <code>self.head</code>
has type <code>Option&lt;Box&lt;second::Node&lt;T&gt;&gt;&gt;</code>,
which does not implement the <code>Copy</code> trait</p>
</blockquote>
<p>​
我的理解是，self.head.map由于实际是match方法的一种简化形式，那么根据match倾向于move值这个特性，self.head被隐式move了。这样会导致错误。而与原先不同，我们不能使用take()函数（take会使得原来的self.head被设为None，同样一次take的结果也不能被move到多个变量中）。教程上推荐使用<code>as_ref</code>方法，于是我在官方文档上查了一下这个函数。看到这个函数中的其中一句话，我终于透彻地理解了文档中的两句话的意义：</p>
<ul>
<li>"Consume the original" 表示原变量将被销毁（被move，所有权丧失）</li>
<li>"Preserving the original" 表示保留原变量</li>
</ul>
<p>​ 但是<code>as_ref</code>文档中所说的："Converts from
<code>&amp;Option&lt;T&gt;</code> to <code>Option&lt;&amp;T&gt;</code>."
具体表示什么意思呢？引用符号在内部外部的区别是什么？我是这么理解的，仍然以stack中的内容为例子。stack的Link，其类型是<code>Option&lt;Box&lt;Node&lt;T&gt;&gt;&gt;</code>。那么上面这句话的意思就是将<code>&amp;...</code>
转化为<code>Option&lt;&amp; Box&lt;Node&lt;T&gt;&gt;&gt;</code>。为什么要这样呢？我们先回顾一下map的性质。我们在函数的参数列表中写的是<code>&amp; self</code>，这就导致了<code>self.head.map</code>无法进行，这是因为，由于map具有类似match的属性，会导致<code>self.head</code>发生move（到新产生的变量<code>node</code>中，如果还不是很明白，请参考<a href="#match_move">本博客的这里</a>），引用内部是不允许发生move的，故报错。而<code>take</code>则将内部的Node取了出来，但是是按值取的，原来的<code>head</code>内容变成了None，并且难以恢复。故这里，我们希望以一种不破坏原来的<code>self.head</code>的方式，返回一个对<code>self.head</code>中node的引用。注意到：由于参数列表中<code>&amp;self</code>的存在，这里的<code>self.head</code>实际上
<strong>就是<code>&amp;Option&lt;Box&lt;Node&lt;T&gt;&gt;&gt;</code></strong>。</p>
<p>​
如果将其转化成<code>Option &lt;&amp;Box&lt;Node&lt;T&gt;&gt;&gt;</code>，那么map得到的结果node，就是一个引用（<code>&amp;Node&lt;T&gt;</code>），我们可以通过如下代码来确定：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">top_node</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> &amp;Node&lt;T&gt; &#123;</span><br><span class="line">        <span class="keyword">self</span>.head.<span class="title function_ invoke__">as_ref</span>().<span class="title function_ invoke__">map</span>(|node|&#123;</span><br><span class="line">            node</span><br><span class="line">        &#125;).<span class="title function_ invoke__">unwrap</span>()</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>​
注意，由于以上代码只是测试使用，我没有定义成public函数（事实上，定义成public函数会报错，Node是一个私有类型，被放在了公共区域，private
type
leak错误）。这段代码是可以过编译的（放在对应的<code>impl</code>块中）。则说明，node本身就是一个引用。故不发生move，<code>self.head</code>被成功保存下来了。太好了，我们又赢啦！那么，最后如果要返回<code>&amp;node.elem</code>，只需要在<code>self.head</code>之后，加上<code>.as_ref()</code>即可。</p>
<p>​
那么余下的两个函数，根据分析<code>as_ref</code>时的经验，理解起来应该会容易很多：</p>
<ul>
<li><code>as_mut</code>: Converts from
<code>&amp;mut Option&lt;T&gt;</code> to
<code>Option&lt;&amp;mut T&gt;</code>.
也即，当结构体成员函数使用<code>&amp;mut self</code>输入时，<code>as_mut</code>后接的<code>map</code>将可以输出node的可变引用</li>
<li><code>as_deref</code>:
我错了，我暂时不想去递归deref以及<code>Deref::Target</code>是个什么玩意。</li>
</ul>
<p>​
这里我想再按照自己的理解，解读一下官方教程的例子。官方教程想通过自定义的<code>peek_mut</code>修改栈顶数据，但是：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line">list.<span class="title function_ invoke__">peek_mut</span>().<span class="title function_ invoke__">map</span>(|&amp;<span class="keyword">mut</span> value| &#123;</span><br><span class="line">    value = <span class="number">42</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>​
这样写是显然不可以的。首先，<code>peek_mut</code>就如我们的<code>top_node_mut</code>一样，返回的是<code>&amp;mut T</code>
（官方教程则是返回<code>Option&lt;&amp;mut T&gt;</code>），在map之后，将成为<code>&amp;mut T</code>，也即，value本身就是一个mutable
reference，那么此例子中，对于一个mutable
reference，再进行引用，成了mutable reference的mutable
reference，会怎么样呢？首先，mutable reference变量value，只是说
<strong><u>其指向的内容是可变的</u></strong>，但并没有声明，value本身可以变（也即value不可以改变指向，但是能改变指向的内容），只有value本身有mut属性，才能安全地对value进行mutable
reference。这里显然没有这样的条件，并且即使挂上了这个引用，最后修改的也是value值，而不是value指向的值。</p>
<hr>
<h2 id="rust-其他todo项">Rust 其他TODO项</h2>
<ul>
<li>值得一记，回头搞清楚原理（主要是dyn关键词用法）：使用函数作为参数进行传递（callback类写法）</li>
</ul>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="title function_ invoke__">sort_test</span>(&amp; bubble_sort);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">sort_test</span>(sort_func: &amp;<span class="keyword">dyn</span> <span class="title function_ invoke__">Fn</span>(&amp;<span class="keyword">mut</span> [<span class="type">i32</span>])) &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">arr</span> = [<span class="number">7</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">7</span>, <span class="number">10</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">6</span>];</span><br><span class="line">    <span class="title function_ invoke__">sort_func</span>(&amp;<span class="keyword">mut</span> arr);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">bubble_sort</span>(arr: &amp;<span class="keyword">mut</span> [<span class="type">i32</span>]) &#123;</span><br><span class="line">	...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>Vec</code>
切片的<code>to_vec</code>函数与切片类型（切片转数组或其他数据类型时的overhead）
<ul>
<li><code>Vec</code>切片之后会变成
<code>&amp;[type]</code>？比如<code>&amp;vec[3..9]</code>
实际上是<code>&amp; [i32]</code>?</li>
</ul></li>
<li><code>cargo new --lib &lt;name&gt;</code> 的
<code>lib</code>具体起什么作用？</li>
<li><code>Box</code>
说是堆的指针？其作用类似于C中动态分配内存的结构?</li>
</ul>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>Rust</tag>
      </tags>
  </entry>
  <entry>
    <title>Cartographer编译问题整理</title>
    <url>/2022/04/11/Cartographer%E7%BC%96%E8%AF%91%E9%97%AE%E9%A2%98%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<h1 id="cartographer">Cartographer</h1>
<hr>
<p>​ 毕设工作设计到与cartographer进行定量实验比较。本人在<a href="https://github.com/Enigmatisms/cartographer_tester">Enigmatisms/cartographer_tester</a>中整理了cartographer以及ros驱动代码，添加了自动化轨迹读取等功能，两周前在Ubuntu
18.04上已经完成了测试，但在Ubuntu
20.04上一直编译不通过，调了一下午才调出来。本文记录了cartographer在不同版本的Ubuntu上（尤其是20.04）的一些典型编译问题以及解决方案。笔者现已经通过文中所说的解决方案完成了cartographer的编译。</p>
<span id="more"></span>
<hr>
<h2 id="lua-not-found">Lua Not Found</h2>
<p>​ 从Github上下载Lua，本地编译安装并且<code>sudo make install</code>
是可以使得这个错误消失。但是，我在Ubuntu 18.04用此方法安装Lua
5.3之后，编译导致ABSL库问题（与Lua有关的）。遂<code>sudo make uninstall</code>卸载，使用</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt install lua5.2</span><br></pre></td></tr></table></figure>
<p>​
通过apt安装。但是这样安装的<code>lua5.2</code>，编译时仍然说找不到（即使重启，仍然也找不到）。不过，其实我跳过了官网的<code>rosdep</code>步骤，先走完<code>rosdep</code>步骤再编译就能找到<code>lua 5.2</code>了。关于如何解决<code>rosdep update</code>速度慢的问题，见
<a href="https://blog.csdn.net/qq_45831587/article/details/120705199#comments_20681710">[这篇博客，亲测有效]</a>.
这篇博客虽然针对20.04，对于18.04，只需要修改python3为python2.7即可。</p>
<hr>
<h2 id="undefined-reference-to-absl">Undefined Reference to ABSL</h2>
<p>​ <code>absl</code>库可能产生问题:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[241/387] Linking CXX executable cartographer_pbstream</span><br><span class="line">FAILED: cartographer_pbstream </span><br><span class="line">: &amp;&amp; /usr/bin/c++  -O3 -DNDEBUG  -rdynamic CMakeFiles/cartographer_pbstream.dir/cartographer/io/pbstream_main.cc.o  -o cartographer_pbstream  libcartographer.a  /usr/local/lib/libceres.a  -lglog  -lspqr  -ltbb  -lcholmod  -lccolamd  -lcamd  -lcolamd  -lamd  -llapack  -lf77blas  -latlas  -lsuitesparseconfig  -lrt  -lcxsparse  -llapack  -lf77blas  -latlas  -lsuitesparseconfig  -lrt  -lcxsparse  -llua5.2  -lm  /usr/lib/x86_64-linux-gnu/libboost_iostreams.so.1.71.0  -lglog  /usr/lib/x86_64-linux-gnu/libgflags.so.2.2.2  -lcairo  /usr/local/lib/libprotobuf.a  /usr/local/lib/libabsl_leak_check.a  /usr/local/lib/libabsl_cord.a  /usr/local/lib/libabsl_cordz_info.a  /usr/local/lib/libabsl_cord_internal.a  /usr/local/lib/libabsl_cordz_functions.a  /usr/local/lib/libabsl_cordz_handle.a  /usr/local/lib/libabsl_hash.a  /usr/local/lib/libabsl_city.a  /usr/local/lib/libabsl_bad_variant_access.a  /usr/local/lib/libabsl_low_level_hash.a  /usr/local/lib/libabsl_raw_hash_set.a  /usr/local/lib/libabsl_bad_optional_access.a  /usr/local/lib/libabsl_hashtablez_sampler.a  /usr/local/lib/libabsl_exponential_biased.a  /usr/local/lib/libabsl_str_format_internal.a  /usr/local/lib/libabsl_synchronization.a  /usr/local/lib/libabsl_stacktrace.a  /usr/local/lib/libabsl_graphcycles_internal.a  /usr/local/lib/libabsl_symbolize.a  /usr/local/lib/libabsl_malloc_internal.a  /usr/local/lib/libabsl_debugging_internal.a  /usr/local/lib/libabsl_demangle_internal.a  /usr/local/lib/libabsl_time.a  /usr/local/lib/libabsl_strings.a  /usr/local/lib/libabsl_strings_internal.a  /usr/local/lib/libabsl_base.a  -lpthread  /usr/local/lib/libabsl_spinlock_wait.a  -lrt  /usr/local/lib/libabsl_throw_delegate.a  /usr/local/lib/libabsl_raw_logging_internal.a  /usr/local/lib/libabsl_log_severity.a  /usr/local/lib/libabsl_int128.a  /usr/local/lib/libabsl_civil_time.a  /usr/local/lib/libabsl_time_zone.a  -lpthread &amp;&amp; :</span><br><span class="line">/usr/bin/ld: libcartographer.a(histogram.cc.o): in function `cartographer::common::Histogram::ToString[abi:cxx11](int) const&#x27;:</span><br><span class="line">histogram.cc:(.text+0x43c): undefined reference to `absl::strings_internal::CatPieces[abi:cxx11](std::initializer_list&lt;std::basic_string_view&lt;char, std::char_traits&lt;char&gt; &gt; &gt;)&#x27;</span><br><span class="line">/usr/bin/ld: histogram.cc:(.text+0x95a): undefined reference to `absl::strings_internal::AppendPieces(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;*, std::initializer_list&lt;std::basic_string_view&lt;char, std::char_traits&lt;char&gt; &gt; &gt;)&#x27;</span><br><span class="line">collect2: error: ld returned 1 exit status</span><br><span class="line">[256/387] Building CXX object CMakeFiles/cartographer.mapping.internal.3d.scan_matching.fast_correlative...er_3d_test.dir/cartographer/mapping/internal/3d/scan_matching/fast_correlative_scan_matcher_3d_test.cc.o</span><br><span class="line">ninja: build stopped: subcommand failed.</span><br><span class="line">&lt;== Failed to process package &#x27;cartographer&#x27;: </span><br><span class="line">  Command &#x27;[&#x27;ninja&#x27;, &#x27;-j16&#x27;, &#x27;-l16&#x27;]&#x27; returned non-zero exit status 1.</span><br></pre></td></tr></table></figure>
<p>​ 此问题可能由<strong><u>两部分原因</u></strong>导致：</p>
<ul>
<li><p>Ubuntu
20.04上，cartographer，cartographer_ros等模块以及<code>abseil-cpp</code>模块均需要使用c++17标准编译（来源于这个Github
issue：<a href="https://github.com/google/or-tools/issues/2196">8.0
fails: undefined reference to absl::lts_2020_09_23::Status::Status
#2196</a>），原始的<code>install_abseil.sh</code>是这样的：</p>
<p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cmake -G Ninja \</span><br><span class="line">  -DCMAKE_BUILD_TYPE=Release \</span><br><span class="line">  -DCMAKE_POSITION_INDEPENDENT_CODE=ON \</span><br><span class="line">  -DCMAKE_INSTALL_PREFIX=/usr/local/stow/absl \</span><br><span class="line">  ..</span><br></pre></td></tr></table></figure></p>
<p>如果修改为：</p>
<p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cmake -G Ninja \</span><br><span class="line">  -std=c++17 \</span><br><span class="line">  -DABSL_CXX_STANDARD=17 \</span><br><span class="line">  -DCMAKE_BUILD_TYPE=Release \</span><br><span class="line">  -DCMAKE_POSITION_INDEPENDENT_CODE=ON \</span><br><span class="line">  -DCMAKE_INSTALL_PREFIX=/usr/local/stow/absl \</span><br><span class="line">  -DABSL_PROPAGATE_CXX_STD=ON \</span><br><span class="line">  ..</span><br></pre></td></tr></table></figure></p>
<p>​
增加<code>-std=c++17</code>，<code>-DABSL_CXX_STANDARD=17</code>，<code>-DABSL_PROPAGATE_CXX_STD=ON</code>
，前两个选项为了使得编译使用c++17标准，最后一个选项防止编译warning。而其他cartographer相关模块，只需要在每个模块下的<code>CMakeLists.txt</code>中的<code>project(xxx)</code>后添加</p>
<p><figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span>(CMAKE_CXX_FLAGS <span class="string">&quot;$&#123;CMAKE_CXX_FLAGS&#125; -std=c++17&quot;</span>)</span><br></pre></td></tr></table></figure></p></li>
<li><p>Google查找问题时，在<code>abseil-cpp</code>库的issue里找到了这么一个issue:
<a href="https://github.com/abseil/abseil-cpp/issues/640">undefined
reference errors (absl::strings_internal::CatPieces and
absl::ByChar::Find)</a>。其中有个人提到：</p></li>
</ul>
<blockquote>
<p>Confirmed on my end: if I add back what was removed from
<code>AbseilConfigureCopts.make</code> in commit <a href="https://github.com/abseil/abseil-cpp/commit/c6954897f7ece5011f0126db9117361dc1a6ff36"><code>c695489</code></a>
then it works.</p>
</blockquote>
<p>​ 于是我修改<code>install_abseil.sh</code>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git checkout c6954897f7ece5011f0126db9117361dc1a6ff36	# 修改到这个commit</span><br></pre></td></tr></table></figure>
<p>​
编译<code>abseil-cpp</code>，完成后删除cartographer之前的<code>build_isolated</code>以及<code>devel_isolated</code>并重新编译cartographer。则不再出现<code>absl</code>库问题。</p>
<hr>
<h2 id="pythoninterp-版本问题">PythonInterp 版本问题</h2>
<p>​ Ubuntu 20.04首次摒弃 python
2.7，包括ROS（rospy）在内全面转向python3，但是可能还是存在一些余孽？继续编译后我遇到了如下问题：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">CMake Error at /usr/share/cmake-3.16/Modules/FindPackageHandleStandardArgs.cmake:146 (message):</span><br><span class="line">  Could NOT find PythonInterp: Found unsuitable version &quot;2.7.18&quot;, but</span><br><span class="line">  required is at least &quot;3&quot; (found /usr/bin/python)</span><br><span class="line">Call Stack (most recent call first):</span><br><span class="line">  /usr/share/cmake-3.16/Modules/FindPackageHandleStandardArgs.cmake:391 (_FPHSA_FAILURE_MESSAGE)</span><br><span class="line">  /usr/share/cmake-3.16/Modules/FindPythonInterp.cmake:169 (FIND_PACKAGE_HANDLE_STANDARD_ARGS)</span><br><span class="line">  /opt/ros/noetic/share/catkin/cmake/python.cmake:4 (find_package)</span><br><span class="line">  /opt/ros/noetic/share/catkin/cmake/all.cmake:164 (include)</span><br><span class="line">  /opt/ros/noetic/share/catkin/cmake/catkinConfig.cmake:20 (include)</span><br><span class="line">  CMakeLists.txt:55 (find_package)</span><br></pre></td></tr></table></figure>
<p>​ emmm，我查了一下trace
stack中的所有cmake文件，没有什么发现，只是cmake无法找到python3，并且在<code>which python</code>时显示的是2.7.18的
python2。看来是默认python有问题，只需要使用：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo update-alternatives --install /usr/bin/python python /usr/bin/python2.7 1</span><br><span class="line">sudo update-alternatives --install /usr/bin/python python /usr/bin/python3.8 2</span><br></pre></td></tr></table></figure>
<p>​ 就可以解决问题，自此所有问题都得到了解决，cartographer顺利安装。</p>
<hr>
<h2 id="其他记录">其他记录</h2>
<ul>
<li>成功无bug适配了cartographer的cere-solver版本是2.0.0，在Ubuntu
18.04以及20.04上通用。</li>
<li>cartographer的
<code>CMakeLists.txt</code>很复杂，但是读一读还是能学到一些有趣的东西，比如：<code>cmake_parse_arguments</code></li>
</ul>
]]></content>
      <categories>
        <category>snippet</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>环境工程</tag>
      </tags>
  </entry>
  <entry>
    <title>NeRF论文复现</title>
    <url>/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="nerf">NeRF</h1>
<hr>
<p>​
最近工程浓度太高，关于【如何设计】以及【为什么】的思考显著少于【如何实现】以及【怎么解决】。为了平衡科研与工程，我复现了最近读的一篇多视角重建论文（见上一篇博客
<a href="https://enigmatisms.github.io/2022/03/13/Neural-Randiance-Field【1】/">Neural
Randiance Field【1】</a>）：</p>
<ul>
<li><a href="https://arxiv.org/pdf/2003.08934.pdf?ref=https://githubhelp.com">Mildenhall,
Ben, et al. "Nerf: Representing scenes as neural radiance fields for
view synthesis." <em>European conference on computer vision</em>.
Springer, Cham, 2020.</a></li>
</ul>
<p>​
NeRF这篇论文，读的时候觉得作者写得还是非常清晰，只要搞清楚了基本概念，流畅地读下来基本上没什么问题。但实现过程中，发现到处都是坑（坑主要来源于个人没有清晰的设计思路，不同模块间的输入输出连续性不强，导致接口经常改动，此外...
有些问题确实也挺坑的）。有别于NeRF的官方tensorflow实现，本论文复现使用Pytorch
+ CUDA，主要代码中约有50%
CUDA，50%python。本论文主要记录复现思路，以及复现过程中遇到的主要问题。复现见<a href>Github repo: Enigmatisms/NeRF</a></p>
<center>
<img src="/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/dynamic.gif" style="zoom:60%;">
</center>
<center>
Figure 1. blender synthetic dataset - drums 训练过程可视化（从epoch 1-
epoch 400）
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-困难部分">II. 困难部分</h2>
<h3 id="cuda加速的随机采样">2.1 CUDA加速的随机采样</h3>
<p>​
个人觉得，NeRF中有很多操作都可以用CUDA实现，正好我很长时间没有写过CUDA程序了，想借此机会回忆一下CUDA编程以及调试。首先我从随机采样下手。NeRF的直接随机采样主要用在coarse
network中，由于我们的（以及作者的）设备capacity不支持对100张(800×800)图片的直接采样（GPU
global
memory根本不够），而我们同时又希望在训练过程中，渐进地覆盖训练集的所有像素，故需要随机采样。</p>
<p>​
复现过程中，算法逻辑并非困难的部分。比较绕的地方在于输入输出的设计。采样需要输出什么？我只需要点以及对应的RGB信息就可以了吗？是否还需要其他的辅助信息（诸如，点属于的位姿id等等）？采样的修改，迭代了三个版本：</p>
<div class="note "><p>​ 初代版本的输出shape是：(采样光束数量，每条光束采样点数量 +
1，3)。至于为什么要+1，在每条光束的最后一个输出数据，是产生此光束的图像RGB信息。而之前的输出数据则是按由近到远的采样点。本版本实现已经输出一个shape为（采样光束数量，每条光束采样点数量）的<code>lengths</code>
tensor了，用于渲染，使得渲染时不需要再根据采样点3D坐标反算一遍每个点到相邻点的距离，<code>lengths</code>
张量已经计算好了。但本版本缺少重要的信息：光线方向信息，光线方向信息需要用在逆变换采样以及coarse
samples &amp; fine
samples的合并中。虽然也可以通过后期点差值来计算，但这毕竟也不是一种很高效的方法。此外，本版本的一个
<strong><u>重大缺陷</u></strong>
就是，<strong><u>在写采样之前我完全不知道数据集是什么样的</u></strong>。我直接写了一个根据内外参数采样的算法，但是数据集中
<strong><u>相机内参只有focal（并且以FoV的形式给出）</u></strong>，没有各轴的放大系数，内参是不完整的。故我被迫又去学了一下如何只用焦距计算相机坐标系下的点，并放弃了本版本代码。</p>
</div>
<div class="note "><p>​
第二代算法实际上已经功能完备了，输出的shape是(采样光束数量，每条光束采样点数量
+
1，9)，在每条光线的最后一个9维位置，保存了（对应相机的平移，光束的方向），9维个维度在其他数据中的意义分别是：</p>
<ul>
<li>前三维度：采样点(x, y, z)</li>
<li>中间三维度：光束方向（未归一化）</li>
<li>后三维度：RGB值（方便比较）</li>
</ul>
</div>
<div class="note success"><p>​
第二代版本最后的结果始终是错误的，并且刚开始的时候，我还没有掌握这种网络debug的精髓。最后一想，既然是多视角重建，结果有误，我干脆就一直输入一个视角下的图片，看看输出是什么。结果发现它给我输出了一个烧杯（lego训练集第一个）。开始我怀疑是获取采样点这一部分实现有误，我甚至把官方实现的<code>get_rays</code>函数抠出来，相同输入对比输出之后发现完全一致...
个人最后进行了一些代码的简化，但我并不认为是代码简化导致了训练的成功，反倒是positional
encoding的实现让人感觉很迷。摘取官方pe生成函数对比实验时，我发现官方的pe比我的维度大，前面多了三项，其余项均相等。这是因为官方把原输入给cat到positional
encoding之中了... 但你论文里没写你这么干了啊nmd，一遍说是 positional
encoding
可以使得原始输入没有低频偏移，一边cat了低频信号也不写上？总之，做了这个改动之后，网络成功了。当然，在成功之前，为了避免所有可能的错误，我把所有用CUDA实现了一遍的函数功能又用Python实现了一遍。</p>
</div>
<h3 id="cuda加速的逆变换采样">2.2 CUDA加速的逆变换采样</h3>
<p>​
如果可以彻底抛弃此结构，NeRF的训练至少可以加速25%。但是，如果没有这个结构，vanilla
NeRF这个暴力采样的网络很可能会有很大的质量损失。此结构的主要思想是：</p>
<blockquote>
<p>用两个网络，一个称之为粗网络，记作<span class="math inline">\(N_c\)</span>，另一个称之为精网络<span class="math inline">\(N_f\)</span>，粗网络对精网络有指导作用，指导精网络采样。
--- 为了好看，引用自我自己</p>
</blockquote>
<p>​ 我们以论文中的参数设置来看。粗网络对于每一条光线，都会先在near bound
以及 far
bound之间，划分64个均匀间隔的段。为了使得最终的结果不受到固定分段的影响，在每个段内采样时，不直接使用段的中点，而是在段内随机采样。这很可能类似于一种叫做【序列超分辨率重建】方法中所用的思想：</p>
<ul>
<li>拍摄一个场景，一张图片的精度有限，但假如拍照时相机在轻微抖动，抖动过程中拍摄到一系列图片，这些图片可能刚好在信息上具有互补能力。<strong><u>详见<a href="https://www.zhihu.com/question/25401250">【知乎，diao图重建】</a></u></strong></li>
</ul>
<p>​
从这个思想的角度出发，我们可以认为，随机采样的过程就可以有效将整条光线覆盖，这样，精度就不会受到分段间隔的限制。好，回到<span class="math inline">\(N_c\)</span>的64个采样段，每个段的采样点在过完<span class="math inline">\(N_c\)</span>之后，进行渲染的过程中都会根据透明度计算权重（与光线击中此点的概率有关）。此权重可以作为<span class="math inline">\(N_f\)</span>输入采样的指导。具体方法如下图所示：</p>
<center>
<img src="/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/sample.jpg" style="zoom:47%;">
</center>
<center>
Figure 2. 找不到一个我满意的作图工具，只能手画了
</center>
<p>​ 可见，<span class="math inline">\(N_c\)</span>如果可以正确学习，在障碍物周围形成较高的不透明度（opacity比较大），normalized
weight在障碍物周围形成的【障碍物CDF】就会类似于阶跃函数。那么当我在[0,
1]区间上进行均匀采样（采样不同weight的点），那么根据CDF曲线反查找到的length，都会集中在障碍物附近。CDF越类似一个阶跃函数，那么逆变换采样的点将越集中。不过注意，为了快速逆变换采样，near
bound到far bound的分段最好是有序的：</p>
<ul>
<li>在CPU上实现时，有序意味着可以二分查找，根据输入的weight，以及weight到length的映射表，便可以查找对应的length</li>
<li>在GPU上实现时，<strong><u>不可以使用二分查找</u></strong>。二分查找逻辑性强于计算性，CUDA实现将引起大量warp
divergence，损害GPU并行度。不过即使是顺序查找，实现也还算简单，并且有效率：</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">extern</span> __shared__ <span class="type">float</span> data[];         <span class="comment">/// length: output_pnum + 6 </span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> ray_id = offset + blockIdx.x, pt_id = threadIdx.x, output_pnum = blockDim.x;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> state_id = ray_id * output_pnum + pt_id;</span><br><span class="line"><span class="built_in">curand_init</span>(state_id, <span class="number">0</span>, r_offset, &amp;r_states[state_id]);</span><br><span class="line"><span class="type">const</span> <span class="type">float</span> weight = <span class="built_in">curand_uniform</span>(&amp;r_states[state_id]);</span><br><span class="line"></span><br><span class="line">data[pt_id] = weights[ray_id * coarse_bins + (pt_id % coarse_bins)];</span><br><span class="line">__syncthreads();</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> bin_id = <span class="number">0</span>, max_comp = coarse_bins - <span class="number">1</span>;         </span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; max_comp; i++) &#123;</span><br><span class="line">    bin_id += <span class="built_in">int</span>(weight &gt; data[i]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 代码如上。由于最终需要输出128个点，而<span class="math inline">\(N_c\)</span>的分段是64份，为了避免数据拷贝时的warp
divergence，在将数据加载到shared
memory时，进行padding：原本64个分段，只需要存储64个length（float），但由于在我的设计中，一个线程采样一个点，128个线程如何复制64个float？必然有线程什么都不能做，比如：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (threadIdx.x &lt; <span class="number">64</span>)</span><br><span class="line">	<span class="comment">// 线程id小于64的线程，复制数据，大于64的线程，什么事都不做</span></span><br><span class="line">__syncthreads();</span><br></pre></td></tr></table></figure>
<p>​ 此处就已经引入warp
divergence了，虽然可能并不严重。如果考虑到将shared
memory扩大到128个float，每个线程都可以复制到自己id对应的shared
memory区，就不会有warp divergence现象。此外，由于64B对于 shared
memory来说真的不是什么开销，所有线程一起执行时，多余的64次复制操作不会增加时间开销（<strong><u>怎么说呢，可能这只是我的一厢情愿</u></strong>，毕竟这个实现，<strong><u>没有绕开bank
conflict</u></strong>），最多就是增加功耗，所以这样做也无妨。</p>
<p>​
此后，我只需要遍历大小为64的有序数组。当前采样weight小于length的部分全部使得计数器+1，便利结束之后，就可以知道自己在哪一个区域。这样的实现完全没有warp
divergence，但是bank
conflict就另说了。不得不说，这么看来我的GPU编程技术还是很菜，要想设计完美的GPU程序，还是需要更丰富的经验。（所以Instant-NGP
5s NeRF训练是真的牛逼）</p>
<h3 id="获得采样点">2.3 获得采样点</h3>
<p>​
对于NeRF在采样环节得到的光线，每条光线上所有的点最后生成的RGBA值都只会参与所在光线的监督学习（也就是说，不会被投影到别的视角下），故在确定光线以及采样点之后，就不再需要图像位置、相机参数等等信息了。</p>
<p>​
首先，如何在针孔相机假设下，通过焦距以及图像位置获得相机坐标系下的光线方向？纯针孔相机模型十分简单：</p>
<center>
<img src="/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/600px-Pinhole.png" style="zoom:90%;">
</center>
<center>
Figure 3. 针孔相机模型[1]
</center>
<p>​ 归一化相机坐标系下的光线方向与像素坐标之间的关系为： <span class="math display">\[
\begin{equation}
\begin{pmatrix}
f &amp; 0 &amp; W/2\\
0 &amp; f &amp; H/2\\
0 &amp; 0 &amp; 1
\end{pmatrix}
\begin{pmatrix}
X_{\text{normed}}\\
Y_{\text{normed}}\\
1
\end{pmatrix}=
\begin{pmatrix}
u\\
v\\
1
\end{pmatrix}
\end{equation}
\]</span> ​ 那么只需要将上述公式取反，就可以轻松得到 <span class="math inline">\(X_{\text{normed}}=(u-W/2)/f\)</span> 以及 <span class="math inline">\(Y_{\text{normed}}=(v-H/2)/f\)</span>。我们通常讨论的相机模型因为有镜头，内参中的<span class="math inline">\(f\)</span>一般都不是实际焦距，而是实际焦距乘以轴放大系数。在NeRF
blender数据集中，焦距仅由FOV给出，没有其他内参系数，故知使用的相机模型是最简单的针孔模型。此外，注意COLMAP以及与之相关的数据集的光轴定义相对于标准相机坐标系而言，y以及z轴取反（体现在外参上，如果我们不做y，z轴取反的话，外参就是错误的）。故最后光线方向应该被表示为：
<span class="math display">\[
\begin{equation}
\begin{pmatrix}
(u-\frac{W}2)/f\\
(\frac{H}2-v)/f\\
-1
\end{pmatrix}
\end{equation}
\]</span> ​ 获得光线方向之后，注意不要归一化。归一化光线的方向向量
<strong><u>只在positional
encoding前进行</u></strong>。过早地归一化，会使得一个梯台形frustum，成为一个...
具有弧度的形状，如下图所示。我们认为，梯台形frustum更加符合标准相机模型。</p>
<table>
<thead>
<tr>
<th style="text-align: center;">正常梯台frustum</th>
<th style="text-align: center;">弧形frustum</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><img src="/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/flat.png"></td>
<td style="text-align: center;"><img src="/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/round.png"></td>
</tr>
</tbody>
</table>
<p>​
NeRF采样点需要在一个全局坐标系下（显然，否则都在自己的相机坐标系下，学习的内容将会有冲突）。故光线方向需要根据外参转换到世界坐标系。光线方向直接左乘外参的旋转分量即可。此后只需要根据方向，分段以及噪声抖动进行采样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sampled_coords = coords[indices]</span><br><span class="line">resolution = (far - near) / point_num</span><br><span class="line">all_lengths = torch.linspace(near, far - resolution, point_num).to(target_device)</span><br><span class="line">lengths = all_lengths + torch.rand((ray_num, point_num)).to(target_device) * resolution</span><br><span class="line"><span class="comment"># torch sum (相机坐标系光线 点乘 相机外参旋转) 等价于 （相机外参旋转矩阵 矩阵乘 光线方向），只不过这样处理直接得到行向量，比较方便</span></span><br><span class="line">ray_raw = torch.<span class="built_in">sum</span>(torch.cat([sampled_coords / focal, -torch.ones(sampled_coords.shape[<span class="number">0</span>], <span class="number">1</span>, dtype = torch.float32).to(target_device)], dim = -<span class="number">1</span>).unsqueeze(-<span class="number">2</span>) * cam_tf[:, :-<span class="number">1</span>], dim = -<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 很多none，是为了增加维度，ray_raw.shape =（光线数,6）,而lengths.shape = (光线数，采样点数)</span></span><br><span class="line">pts = cam_tf[:, -<span class="number">1</span>] + ray_raw[:, <span class="literal">None</span>, :] * lengths[:, :, <span class="literal">None</span>]</span><br></pre></td></tr></table></figure>
<h3 id="渲染">2.4 渲染</h3>
<p>​
几乎所有关于NeRF的论文，在prerequisite部分，都会写原始NeRF的光线渲染公式。NeRF的光线渲染公式是由图形学的volume
rendering积分公式得来的，但由于积分没有更简单的解析形式，只能使用累加进行近似。我并不是特别明白其中使用指数函数的原因（1984年的光线渲染原文也没有看得特别明白），但是如果将指数函数理解为任意增函数，其实渲染公式也很好理解。
<span class="math display">\[
\begin{align}
&amp;C(\pmb{r})=\sum^N_{i=1}T_i(1-\exp(-\sigma_i\delta_i))\pmb{c_i}\\
&amp;T_i=\prod_{j=1}^{i-1}\exp(-\sigma_i\delta_i)=\exp\left(\sum_{j=1}^{i-1}-\sigma_i\delta_i
\right)
\end{align}
\]</span> ​ 其中<span class="math inline">\(\delta_i={t_{i+1}-t_{i}}\)</span>，也就是相邻两个采样点之间的距离，<span class="math inline">\(\sigma_i\)</span>是计算的volume
density（不透明度因子）。那么从采样点i到采样点i+1之间的透明度，被建模为：<span class="math inline">\(1-\exp(-\sigma_i\delta_i)\)</span>，可以看出，不透明度或者两点间距离越大，最后得到的透明度越低。透明度越高，到达i+1采样点时，i+1采样点的RGB将被更多地保留。那么<span class="math inline">\(T_i\)</span>则是一个概率因子，此概率因子考虑了遮挡关系：假设光线在经过靠前的采样点时，通过了不透明度较高的区域，那么这条光线击中后面点的概率，应该降低。我们不能抛弃此概率因子而完全使用透明度。考虑这样的一个场景：</p>
<p><img src="/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/eg.png"></p>
<center>
Figure 4. 遮挡关系的考虑
</center>
<p>​
假设采样点只有这两个，两个物体的不透明度都较高。不考虑遮挡关系时，由<span class="math inline">\(1-\exp(-\sigma_i\delta_i)\)</span>计算得到的透明度是相对比较接近的，这样就会造成两个不同物体RGB值的平均，得到错误的结果。<span class="math inline">\(T_i\)</span>则可以解决这个问题。</p>
<p>​ 渲染的实现并没有什么好讲的，根据公式实现就行。</p>
<h3 id="杂项">2.5 杂项</h3>
<ul>
<li><p>粗网络使用的采样点，同样需要放入精网络中，与精网络的逆变换采样点合并。但是需要注意，渲染
<strong><u>一定要保证输入点以及深度值有序</u></strong>，根据渲染公式中的<span class="math inline">\(\delta_i=t_{i+1}-t_i\)</span>就可以知道。故合并粗网络、精网络采样点之后，需要sort。怎么说呢，PyTorch对张量sort的支持，可比modern-gpu
CUDA库的merge sort快多了...</p></li>
<li><p><code>curand_init</code>，如果需要使用，首先需要引用头文件<code>&lt;curand.h&gt;</code>
以及
<code>&lt;curand_kernel.h&gt;</code>，此外，其四个参数中，有三个比较重要：</p>
<table>
<colgroup>
<col style="width: 26%">
<col style="width: 6%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr>
<th>seed</th>
<th>subsequence</th>
<th>offset</th>
<th>randomState</th>
</tr>
</thead>
<tbody>
<tr>
<td>不同的block以及线程可以根据其id直接获得不同seed</td>
<td>没用</td>
<td><strong><u>别忘记设置</u></strong>，假设每次使用的randState都在kernel中被new出来，如果不根据函数执行的次数设置offset，每次的randomState都会是一样的</td>
<td>48位，还挺大，建议分块new，节省内存。详情见<code>deterministic_sampler.cu</code></td>
</tr>
</tbody>
</table></li>
<li><p>NeRF数据集非标准pytorch数据集，数据集加载需要自己实现。首先需要实现一个Dataset类（继承torch的相关类），其中必须要自定义<code>__getitem__</code>函数（相当于C++中的<code>[]</code>运算符重载）。有Dataset类之后，就可以使用Dataloader了，torch的dataloader有两个好处，一是可以通过多workers的方式提高加载数据集的吞吐能力，使得加载数据集的耗时被掩盖。此外，dataloader非常节约显存，不需要一次性全部加载存在显存之后索引，笔者非常推荐这种方式。</p></li>
</ul>
<hr>
<h3 id="iii.-复现结果">III. 复现结果</h3>
<p>​ 舒服啦。debug之后还算成功，唯一不爽的就是
debug耗时太长，以为是什么重要的细节实现出错，最后竟然可能败在了positional
encoding没有cat原输入上...</p>
<p>​ 关于实现的依赖项，见Github项目的<a href="https://github.com/Enigmatisms/NeRF/blob/master/README.md"><code>README.md</code></a>。其中使用到了APEX加速，O2等级优化（实测，O3等级优化使得我的loss从一开始就是NaN，非概率性NaN）。O2优化的速度已经很快了，相对于原始无混合精度加速而言，已经加速了40-50%。12.5s可以跑完100次训练。在这里，一次训练包括：粗网络采样，1024条光线+64个点/每条光线--&gt;
粗网络训练 --&gt; 粗网络渲染 --&gt; 逆变换采样 128点/每条光线 --&gt;
精网络192点/每条光线 进行训练 --&gt; 精网络渲染。速度还行，但对比起5s
NeRF... 太拉了。</p>
<p>​
我没有什么耐心，不想看到最后训练得有多好，只要有个可以的结果，就说明复现成功，对论文的理解充分：</p>
<p><img src="/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/lego_1.png"></p>
<center>
Figure 5. epoch 1训练结果（100张图像全部采样）
</center>
<p><img src="/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/lego_2.png"></p>
<center>
Figure 6.训练过程中的结果
</center>
<p><img src="/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/lego_3.png"></p>
<center>
Figure 7.约三小时训练后（1000 epochs）得到的结果（400*400px）
</center>
<p>​ Loss的变化曲线（drums）训练结果</p>
<p><img src="/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/curve.png"></p>
<center>
Figure 8. drums 1400 epochs（800*800分辨率）loss曲线
</center>
<p>​ 一些有趣（失败训练结果）的图：</p>
<table>
<colgroup>
<col style="width: 21%">
<col style="width: 39%">
<col style="width: 39%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;">好看的lego烧杯</th>
<th style="text-align: center;">lego彩虹</th>
<th style="text-align: center;">更好看的lego云</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><img src="/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/beautiful_2.png"></td>
<td style="text-align: center;"><img src="/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/beautiful_1.png" style="zoom:54%;"></td>
<td style="text-align: center;"><img src="/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/false_result.png" style="zoom: 54%;"></td>
</tr>
</tbody>
</table>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://en.wikipedia.org/wiki/Pinhole_camera_model#:~:text=The%20pinhole%20camera%20model%20describes,are%20used%20to%20focus%20light.">Wikipedia:
Pinhole Camera Model</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>Neural Radiance Field【1】</title>
    <url>/2022/03/13/Neural-Radiance-Field%E3%80%901%E3%80%91/</url>
    <content><![CDATA[<h1 id="neural-rf">Neural RF</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​ 深度学习的大环境下，视图合成（view
synthesis）必然不会缺席（毕竟没什么数学能力也能搞，是吧）。NeRF作为其中比较杰出的工作之一，文章后续也受到很多关注，包括但不限于【NeRF++，NeRF--，Point
NeRF】。本文是一篇关于NeRF及其++版本的论文理解，后续将在[Neural Radiance
Field【2】]中介绍Point NeRF以及NeRF的复现：</p>
<ul>
<li><a href="https://arxiv.org/pdf/2003.08934.pdf?ref=https://githubhelp.com">Mildenhall,
Ben, et al. "Nerf: Representing scenes as neural radiance fields for
view synthesis." <em>European conference on computer vision</em>.
Springer, Cham, 2020.</a></li>
<li><a href="https://arxiv.org/pdf/2010.07492.pdf">Zhang, Kai, et al.
"Nerf++: Analyzing and improving neural radiance fields." <em>arXiv
preprint arXiv:2010.07492</em> (2020).</a></li>
</ul>
<center>
<img src="/2022/03/13/Neural-Radiance-Field%E3%80%901%E3%80%91/bench.gif" style="zoom:100%;">
</center>
<center>
Figure 1. 拿个视频当NeRF demo是吧?（误）
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-nerf本篇">II. NeRF本篇</h2>
<h3 id="文章脉络">2.1 文章脉络</h3>
<p>​ 本文由于是神经网络radiance
field表征的开山之作，所用方法以及思想都较为简单，清晰易懂。</p>
<p>​ 本论文有三个主要贡献：</p>
<ul>
<li>第一次使用神经网络（MLP）对连续的volumetric空间进行建模，并使用可微投影模型的离散近似设计优化方法</li>
<li>设计了一种positional
encoding，可以将低频的空间位姿输入转化为高维向量，提升模型的表示能力</li>
<li>设计了一种层级化的采样算法，通过coarse-to-fine，coarse
sampler采样结果对fine sampler进行指导，使得fine
sampler可以更加聚焦于物体表面附近的采样，提升采样训练效率</li>
</ul>
<center>
<img src="/2022/03/13/Neural-Radiance-Field%E3%80%901%E3%80%91/nerf.png" style="zoom:100%;">
</center>
<center>
Figure 2. NeRF网络信息处理过程
</center>
<p>​ 网络的信息处理流程：</p>
<div class="note danger no-icon"><p>给定多张已知内外参的图像，从这些图像中，随机挑选一些光线（运用到了相机模型），在光线上进行点的采样（这里忽略coarse2fine层级化采样），那么这些采样点就会有平移旋转信息，分别被表示为（平移）<span class="math inline">\(\pmb{x}\)</span>，旋转被表示成<span class="math inline">\(\pmb{d}\)</span>（一个3D单位向量)</p>
<ul>
<li>
采样的进行：为了避免使用固定的voxel
volume（意思是说，作者不希望在进行voxel化之后，每次光线在volume中采样，打击到同一个voxel时得到的是一个固定的位置，这样网络最后的输出会直接与voxel的量化精度有关），作者均分光线为N段（采样N个点），每段内由均匀分布采样一个点
</li>
<li>
但是显然，这样会采样到大量的遮挡点或者空域点，作者认为这非常不合适。故作者使用一个coarse
sampler，一个fine sampler。coarse
sampler采样更少的点（每条线段的等分N更小），这些点先在MLP中进行evaluation，判定每条线上哪些点属于比较好的点（接近实际的表面），fine
sampler可以着重在这些区域进行采样
</li>
<li>
coarse sampler 采样得到的点也会参与优化，当然由于coarse
sampler采样的点属于指导性的点，其evaluation不能存在太大的computation
overhead，故作者同时也用了一个coarse网络，此网络也参与优化，优化可以使得此网络能更好判定采样区域的好坏，给出的权重更合理。此思想很有趣。
</li>
</ul>
</div>
<div class="note info no-icon"><p>点进行positional embed之后，输入到MLP网络中，网络输出每个点：</p>
<ul>
<li>
与位置以及方向（相机发出的光线朝向）相关的RGB值（相当于观测到的颜色）
</li>
<li>
只与位置相关的opacity：可以认为，这是网络对于此点接近有效表面点的概率表示，或者单纯认为，这是空间中某点的光导率
</li>
</ul>
</div>
<div class="note success no-icon"><p>最后颜色使用volume rendering模型进行渲染，可以得到最后的结果</p>
</div>
<h3 id="一些问题">2.2 一些问题</h3>
<p>（1）论文理解过程中最初的阻碍是：radiance
field究竟是一个什么概念？</p>
<blockquote>
<p>We represent a static scene as a continuous <strong><u>5D
function</u></strong> that outputs the radiance emitted in each
direction (θ, φ) at each point (x, y, z) in space, and a density at each
point which acts like a differential opacity controlling how much
radiance is accumulated by a ray passing through (x, y, z)</p>
</blockquote>
<p>​ 其中 (θ, φ) 应当是自变量， (x, y, z)
也是自变量。给定一个观测角度，以及一个点，输出rgb以及一个类似alpha通道的东西。个人的疑问在于，此点（x，y，z）到底是什么？与RGB之间的关系是什么？首先，上文所说的radiance，指的完全就是RGB值（光线），对于一个固定点而言，不同方向观测的颜色可能是不一样的（由于光照的区别），故RGB值不同，但只有一个RGB是无法完成视觉建模的，需要透明度。比如，对于物体正前方的一个空气点，在与观测物体相同的方向上，我确实也可以认为此点发出了与物体相同颜色的光，但在别的视角下，物体与此点在成像平面上并不重合时，空气点产生的RGB就需要被透明度加权成0，使之不影响最后的RGB输出。</p>
<p>​ 但说实在的：“a differential opacity controlling how much radiance is
accumulated by <strong><u>a ray passing through (x, y,
z)</u></strong>”，我对这句话的理解并不是特别深。在我粗浅的理解中，此句的意义是：opacity量控制的是最后渲染的结果，本点在成像时能对结果产生多大影响？渲染到2D成像平面上某一(u,
v)点的颜色，是不同3D点产生光线颜色在此处投影的加权平均。</p>
<p>​ 在后文所提到的NeRF++一文中，作者通俗地解释了NeRF训练的结果。</p>
<p>（2）训练过程中同一条光束上，不同的3D
volume点最后融合成的结果是否与之前看的某几篇multi-view depth
estimation方法相同？</p>
<p>​ 并不一样，multi-view depth estimation 人家真的使用了dense voxel
volume，但本工作中，query点仅限于光束上，并不会实际变换到某一个voxel
volume中，再进行叠加。本文训练query得到的点，并不在固定的voxel中，作者也提到，固定的voxel会使得最终的结果与voxel分辨率相关，并且作者最后得到的结果，是一个有能力映射连续空间的函数。</p>
<p>（3）从直觉上讨论，positional
embeddings为什么有助于表征高维信息？</p>
<p>​ 此处的positional embeddings不是learnable positional
embeddings，并且也不是简单暴力地从<span class="math inline">\((x, y, z,
\theta,
\phi)\)</span>通过某一个神经网络（比如一个MLP）映射到高维空间，因为简单这样做没有任何意义，毕竟之后的场景表示就是一个MLP，MLP接MLP相当于一个更大的MLP。作者在此处用了类似于Transformer的处理方法，也即用了一系列不同频率的
<span class="math inline">\(\sin\)</span>, <span class="math inline">\(\cos\)</span>
函数组合成一个高维表征。那么如何映射到一个高维向量我们已经清楚了，重点是：为什么？</p>
<p>​
第一，如果从个人直观上理解来看，之前我们讨论分类器时，经常会说：低维分不开的，某个高维空间下可能就可以分开了。低维空间下的物理临近性，在高维空间中不一定成立，也就是说，低维距离近的数据可能在高维的差异很大。两个相近的5D输入，由于深度不连续或者物体形状突变，观测到的颜色可能截然不同，那么这种输入上的空间上趋于连续平滑性质，便是低频，经过非线性映射之后，自然是可能到某一个高维空间的，在此高维空间下，两个原近似5D输入有较大差别，也就形成了高频信号（低频即平滑缓变，高频则间断跳变）。</p>
<p>​ 第二，作者提供了一篇ICML 2018论文[1]，论文中提出：</p>
<blockquote>
<p>By using tools from Fourier analysis, we highlight a learning bias of
deep networks towards low frequency functions.</p>
</blockquote>
<p>​
如果不预先将本身就是低频信息的位置与旋转变换到高维空间下，神经网络的表示能力将会受到更大的削弱（低频输入--&gt;
网络倾向于学习低频信息 --&gt; 欠拟合）。</p>
<p>（4）volume density是视角不变的，有什么道理吗？</p>
<blockquote>
<p>We encourage the representation to be multiview consistent by
restricting the network to predict the volume density σ as a function of
only the location x</p>
</blockquote>
<p>​
如果说density只与位置有关，那么作者相当于潜在地做了物体表面预测（预测哪些是实际的物体点，哪些是空气点或者是内部点），当然，也可能纯粹是表面估计+透明物体透明度估计。NeRF++中也给了一个类似的、非常简明的观点。</p>
<p>（5）以下公式中为什么有一个指数分布？是之前的一个已有模型吗？ <span class="math display">\[
\begin{equation}
C(\mathbf{r})=\int_{t_n}^{t_f}T(t)\sigma(\mathbf{r}(t))c(\mathbf{r}(t),
\mathbf{d})dt, \text{ where }
T(t)=\exp\left(-\int_{t_n}^t\sigma(\mathbf{r}(s))ds\right)
\end{equation}
\]</span> ​ 是的，这涉及到一些图形学邻域的知识。Beer' s
Law中提到的Volumetric Attenuation[2],
如果认为某个半透明材质的透明度（光导率）是恒定的，穿过其中的光线出射时的光强与在其中穿行的距离成负指数关系。此指数的存在与
<strong><u>光线穿过一个具有一定导光率（可以认为是空间中有一定density阻挡光的粒子）的介质而不与这些粒子碰撞的概率</u></strong>。由于作者是在光束上离散采样，最后作者用了一个离散求和近似了此积分，甚至最后作者还说：</p>
<blockquote>
<p>This function for calculating <span class="math inline">\(\hat{C}(r)\)</span> from the set of (<span class="math inline">\(c_i, \sigma_i\)</span>) values is trivially
differentiable and r<strong><u>educes to traditional alpha
compositing</u></strong> with alpha values <span class="math inline">\(\alpha_i=1-\exp(-\sigma_i\delta_i)\)</span>.</p>
</blockquote>
<h3 id="一些扩展想法">2.3 一些扩展想法</h3>
<ul>
<li>个人感觉这个模型是可以预训练的？通过仿真，可以生成很多视点位姿差距很小的图像，即使是简单的场景，使用这种方式是否可以创造一个“具有空间连续性”并且“具有一定2D场景还原能力”的大环境？使用仿真数据，生成小视点位姿差距图像训练，并进行监督（而非投影回到输入图像），可能可以帮助连续平滑函数的构建？</li>
<li>已知NeRF是 volumetric-based（弱volumetric），那么Point-based
NeRF的地位是否有类似于 Eulerian &lt;---&gt;
Lagrangian对偶的关系？换言之，Point-based
NeRF在NeRF问题上相较于volumetric-based
NeRF取得的成功，是否在激光SLAM领域也有指导意义？</li>
</ul>
<hr>
<h2 id="iii.-nerf">III. NeRF++</h2>
<p>​
NeRF++可以说是一篇很好的NeRF补充文，其中不光讨论了NeRF的成功原因，并且也提出解决了NeRF在无约束场景（存在大范围背景）下效果不好问题的方法。个人的建议是，如果看了NeRF一文，想要加深理解，一定要看看NeRF++。</p>
<p>​ 本文的主要贡献有两个：</p>
<ul>
<li>解释了为什么NeRF可以在有“shape-radiance
ambiguity”问题的情况下，仍然得到很好的结果</li>
<li>提出了一种新的parameterization方法，用于解决unbounded大范围背景场景问题</li>
</ul>
<h3 id="shape-radiance-ambiguity">3.1 Shape-Radiance Ambiguity</h3>
<center>
<img src="/2022/03/13/Neural-Radiance-Field%E3%80%901%E3%80%91/sra.png" style="zoom:80%;">
</center>
<center>
Figure 3. Shape-Radiance Ambiguity
问题：形状不对但是颜色对了也能恢复少部分视角下的图像
</center>
<p>​
乍一看，看不懂。这啥意思？我们首先来看NeRF的输出，NeRF对于每一个3D点，在每一个视角下，输出opacity（view-independent）以及RGB（view-dependent）。此opacity，正如作者所说：</p>
<blockquote>
<p>NeRF reconstructs an <strong><u>opacity field <em>σ</em> representing
a soft shape</u></strong>, along with a radiance field
<strong>c</strong> representing view-dependent surface texture.</p>
</blockquote>
<p>​
就是物体形状的一种soft（指模拟量，在物体真正形状附近的值是平滑过渡的）表示。那么在仅仅渲染好一个（或者少数的train
set）视角的情况下，RGB与opacity会如何被训练？本文作者举了一个这样的例子：假设我训练时仅有少数几个视角，我认为地将物体的形状（opacity）<strong><u>训练成一个球</u></strong>，而颜色，则根据重投影（渲染）的结果与原图的差别进行优化。那么可以对比一下，预期结果与这样训练的结果之间的差别：</p>
<div class="tabs" id="span-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#span-unique-name-1">正常训练</a></li><li class="tab"><a href="#span-unique-name-2">训个球</a></li></ul><div class="tab-content"><div class="tab-pane active" id="span-unique-name-1"><p>​ 最后的结果，应当是：某一3D点在某一视角下观测在成像平面上体现的颜色 =
不同点 <strong><u>部分准确的</u></strong> RGB与
<strong><u>准确的</u></strong>
opacity（对应了准确的物体形状）的加权和。</p></div><div class="tab-pane" id="span-unique-name-2"><p>​ 此结果则是：某一3D点在某一视角下观测在成像平面上体现的颜色 =
准确的RGB * 1（opacity在单位球上）。</p></div></div></div>
<p>​ 作者想表达的也就是：在不需要精确model
3D形状时，在某几个少数视角下，我也能把正确的2D图像输出。比如下面这张街头艺术，显然作者并没有在墙上真的搞一个这样的洞，但是他却能成功在这个视角下，把他想要的3D效果给画出来。</p>
<center>
<img src="/2022/03/13/Neural-Radiance-Field%E3%80%901%E3%80%91/optical-illusion-murals-street-art-1010-19.jpg" style="zoom:100%;">
</center>
<center>
Figure 4. 2D-3D视觉错觉：形状完全不对，但是能表示正确的3D意义
</center>
<p>​
这是个什么问题呢？显然，<strong><u>过拟合问题</u></strong>。少数视角下，我只需要通过硬调输出使得与输入一致，完全不用管原物体形状胡来，就能达到一个低loss，这样的结果有泛化能力吗？显然是没有的。NeRF++作者做了一个关于【球形opacity】物体的实验：</p>
<center>
<img src="/2022/03/13/Neural-Radiance-Field%E3%80%901%E3%80%91/demo.png" style="zoom:100%;">
</center>
<center>
Figure 3. 换视角后的泛化能力极差
</center>
<p>​
那么为什么NeRF避免了这个问题呢？作者认为：如果不尽可能准确表示物体的3D信息（opacity尽可能正确），那么RGB输出对应的函数将会是高频的，不平滑的函数。很显然，一个球状物体，如果要在几个不同的观测下看到的都是一张，如上图所示，挖掘机的图案，那对于每一个3D点，<strong><u>它在不同的观测角度下的颜色</u></strong>
必然是差别巨大的，小的观测角差别就能带来很大的输出变化，这个函数显然是高频的。</p>
<p>​ 而由论文[1]，我们已经知道
神经网络学习高频函数相对困难，低频函数会被优先学习。而低频对应着平滑，关于这点，作者说：</p>
<blockquote>
<p>For the correct shape, the surface light field will generally be much
smoother (in fact, constant for Lambertian materials).</p>
</blockquote>
<p>​
确实如此，正常物体，尤其是大多数人造物，颜色都是分块相等的，不同视角下由于光照问题可能有一定差别，但总体上说，应该还是具有平滑性的。此外，高频函数如果需要被神经网络所表达，将需要更多参数。毕竟对于MLP来说，有限的参数，代表了对空间有限的线性划分，而有限的层数（对应有限的activation），则对应着有限的复杂形状（非线性变换意味着网络可以表达更加形状丰富的流形）。而且，根据经验，过拟合（高频函数）都是在over-parameterization以及样本过少时发生的。</p>
<p>​ 在此基础上，作者还认为NeRF的网络结构设计也与 shape radiance
ambiguity
的消除有关。但这个理论就不如上面所说想法那么有【Ah-hah】的感觉了，在这里我就不赘述了。</p>
<h3 id="inverse-sphere-parameterization">3.2 Inverse Sphere
Parameterization</h3>
<p>​ 用一句话来总结这部分工作，就是：Inverse
depth。在双目视觉中，假如我们要直接表示深度图，通常是做不到的，尤其在室外。假设我们看到了天空，那么天空的距离是多少呢？我们debug查看一下变量，奥
NaN
啊，那没事了。对于场景中存在较多较远物体时，即使没有inf距离，也可能使得网络不得不学习【输出需要加一个大bias】这种傻特征。在双目等应用中，通常我们都取inverse
depth，距离远就0，距离再怎么近也不可能1/0。</p>
<p>​
看NeRF一文中的demo就知道，它的输入，都是一些限定大小的物体，并且这些物体还特地去除了背景。emmm，你说如果一个网络只能处理这种数据，我们会评价它：未来可期。那么本着【未来工作未来录】的想法，是我做审稿人我就给你拒了（误）。个人认为，至少背景还是要有的吧，不然看起来还真缺点实际意义。NeRF++作者认为，常规NeRF，由于训练使用的是点采样这种方法，对于大型unbounded场景来说，远距离下采样要多少个点才算够？离散的话，能很好近似渲染过程的积分吗？太稠密的话，是否会使得网络专注于背景建模，使得前景的效果变差？并且也消耗计算资源？作者发现确实会这样：</p>
<center>
<img src="/2022/03/13/Neural-Radiance-Field%E3%80%901%E3%80%91/nearfar.png" style="zoom:80%;">
</center>
<center>
Figure 5. 经典鱼和熊掌不可兼得
</center>
<p>​ 针对此问题，作者提出了这样的方法：</p>
<ul>
<li>由于多视角重建问题，一般都是针对物体的（有focus，有一个可以 被bound
的对象），那么此对象周围部分bounded区域，用一个NeRF来描述，此NeRF什么也不需要改，因为处理的区域是小范围bounded的区域。选择一个球型区域，所有的相机位置都被包括在这个球型区域内。</li>
<li>外部区域，全部用inverse sphere表示。</li>
</ul>
<center>
<img src="/2022/03/13/Neural-Radiance-Field%E3%80%901%E3%80%91/inverse.png" style="zoom:67%;">
</center>
<center>
Figure 6. 已知光线方向与r求其在inverse sphere上的投影
</center>
<p>​ 上图就能很清晰地说明inverse
sphere的工作原理。对于一个已知r，当r小于一个阈值<span class="math inline">\(r_0\)</span>时，说明此点在bounded区域内，可以直接用NeRF及其对应的采样求和近似积分来计算渲染结果。大于<span class="math inline">\(r_0\)</span>时，用inverse
sphere对应的采样方法：<u><strong>只需要在<span class="math inline">\(r&#39;=1/r\)</span>， <span class="math inline">\(r&#39;\)</span>在[0,
1]区间内随机采样即可</strong></u>。由于3D点点p在光线上（不在sphere半径方向上），一般需要根据r值以及光线方向，求其在inverse
sphere上的投影位置<span class="math inline">\((x&#39;,y&#39;,z&#39;)\)</span>，这里就不赘述方法了。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="http://proceedings.mlr.press/v97/rahaman19a/rahaman19a.pdf">Rahaman,
Nasim, et al. "On the spectral bias of neural networks."
<em>International Conference on Machine Learning</em>. PMLR, 2019.
【注：作者貌似ICML转刊PMLR了】</a></p>
<p>[2] <a href="https://graphics.cg.uni-saarland.de/courses/cg1-2019/">Philipp
Slusallek, Computer Graphics: Chapter - Volume Rendering.</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>远古SDF文档</title>
    <url>/2022/02/22/%E8%BF%9C%E5%8F%A4SDF%E6%96%87%E6%A1%A3/</url>
    <content><![CDATA[<iframe src="//www.slideshare.net/slideshow/embed_code/key/dUI2s72z0jLiEq" width="750" height="420" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%; border-radius: 2px;;" allowfullscreen>
</iframe>
]]></content>
      <categories>
        <category>snippet</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>SLAM</tag>
      </tags>
  </entry>
  <entry>
    <title>简单的ROS跨设备控制</title>
    <url>/2022/02/22/%E7%AE%80%E5%8D%95%E7%9A%84ROS%E8%B7%A8%E8%AE%BE%E5%A4%87%E6%8E%A7%E5%88%B6/</url>
    <content><![CDATA[<h1 id="rrrros">RRRROS</h1>
<hr>
<p>​
ROS常用的进程通信机制是消息传递，是基于各个node与master的XML-RPC实现，并且可能用到TCP/UDP等传输层协议，非常地网络。这样看来，ROS进行跨设备通信应该是比较简单的。本篇主要记录一个简单的ROS跨设备应用场景，并简介其中的原理。</p>
<span id="more"></span>
<hr>
<h2 id="使用ros跨设备rviz可视化">使用ROS跨设备rviz可视化</h2>
<p>​
你有一个工控设备，在一个轻量级机器人上。机器人没办法给你举着一个屏幕，方便你控制他的方式只有ssh。这时候，你打开了机器人身上的一个激光雷达，但突然记起来，自己没办法可视化机器人看到的东西，怎么办呢？当然，你大可以像我一样显得蛋疼去写一个用终端可视化点云的工具...，就像这样
<a href="https://github.com/Enigmatisms/tviz">Github:
Enigmatisms/tviz</a>：</p>
<center>
<img src="/2022/02/22/%E7%AE%80%E5%8D%95%E7%9A%84ROS%E8%B7%A8%E8%AE%BE%E5%A4%87%E6%8E%A7%E5%88%B6/tviz.gif" style="zoom:80%;">
</center>
<center>
Figure 1. 闲得蛋疼
</center>
<p>​
反正写完我也没用过，还是上正经方法吧。首先，如果要跨设备使用ROS，两个设备必须能够互相访问，比如：在同一个网段下。可能出现单向能ping通的情况（比如墙，或者无内网穿透）。互相可以ping通应该就没有问题。</p>
<p>​ 从这里开始，我设定如下的应用场景：</p>
<ul>
<li>主机A，是用于可视化的设备，运行rviz</li>
<li>从机B，是机器人（或者相应工控设备），直接连接了传感器但是不方便显示</li>
</ul>
<p>​
首先，在主机A上ssh到从机B。并且修改从机<code>/etc/hosts</code>，首先查看A，B设备的ip，设为a，b：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ifconfig</span><br><span class="line">sudo vim /etc/hosts</span><br></pre></td></tr></table></figure>
<p>​ 给主机以及从机命名（随便叫），比如我叫主机
master，从机slave，<code>/etc/hosts</code>中就填写并保存，相应地，主机的<code>/etc/hosts</code>也这么修改</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">192.168.xx.a master</span><br><span class="line">192.168.xx.b slave</span><br></pre></td></tr></table></figure>
<p>​ 修改完之后，从机需要修改ROS定义的两个环境变量：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export ROS_HOSTNAME=slave</span><br><span class="line">export ROS_MASTER_URI=http://msater:11311</span><br></pre></td></tr></table></figure>
<p>​ 注意，从机的host name还是自己的name，但是master
URI则是：<strong><u>主机ip +
端口（一般都是11311）</u></strong>。这里实际上是：ROS的master以及node都看ip进行通信，只有一个唯一的master（确实可以开多个roscore，但是消息不是共享的），master
URI就确定了master所在的网络位置。如果不export修改ROS Master
URI，一般来说:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo $ROS_MASTER_URI			# 输出都是 http://localhost:11311</span><br></pre></td></tr></table></figure>
<p>​ 修改ROS master URI就是告诉本机，master（roscore）在位于master
URI的机器上。</p>
<p>​
已经说了，按照同样的方法修改主机<code>/etc/hosts</code>，之后需要修改主机环境变量：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export ROS_HOSTNAME=master</span><br><span class="line">export ROS_MASTER_URI=http://master:11311</span><br></pre></td></tr></table></figure>
<p>​ <strong><u>注意这里，master
URI</u></strong>就是主机自己的ip。之后，主机开<code>roscore &amp;</code>（一定要在主机上开，因为这是设定嘛，master
URI都说了roscore在这里），再打开rviz，配置好。从机只需要能够输出ros消息即可，在主机上用<code>rostopic list</code>就能看到消息了。</p>
<ul>
<li>P.S：2D激光雷达数据传输完全没问题，就算是帧率高，点数多，也不会有太大延迟，但是图像消息就不一样了。<strong><u>如果需要跨设备图传</u></strong>，不要使用原始的<code>sensor_msgs/Image</code>消息，会非常慢，ppt级传输。可以使用<code>sensor_msgs/CompressedImage</code>，亲测很快。但是这取决于你想看流畅高刷还是高清无码，不过个人觉得，compressed
image消息并没有使得画面质量有太多的下降。</li>
</ul>
]]></content>
      <categories>
        <category>snippet</category>
      </categories>
      <tags>
        <tag>ROS</tag>
      </tags>
  </entry>
  <entry>
    <title>2D激光SLAM中的SDF表征</title>
    <url>/2022/02/21/2D%E6%BF%80%E5%85%89SLAM%E4%B8%AD%E7%9A%84SDF%E8%A1%A8%E5%BE%81/</url>
    <content><![CDATA[<h1 id="sdf-slam">SDF-SLAM</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​
在家配电脑环境工程时，真没有事干，就只能看看论文了。之前太naive了，了解得少，只知道2D地图表征常用栅格图以及点云，不常用的是隐式函数（implicit
function），却忘记了还有SDF这个中间表征。查找2D-SLAM文献时，蹦出了几篇SDF相关的文章，都还算中规中矩，通俗易懂（比起什么cartographer分支定界来说，简直太友好了，不过说起来，这几篇论文中除了cartographer魔改论文之外，真的谈了后端吗？）：</p>
<ul>
<li><p>Fossel, Joscha-David, Karl Tuyls, and Jürgen Sturm. "2D-SDF-SLAM:
A signed distance function based SLAM frontend for laser scanners."
<em>2015 IEEE/RSJ International Conference on Intelligent Robots and
Systems (IROS)</em>. IEEE, 2015.</p></li>
<li><p>Daun, Kevin, et al. "Large scale 2d laser slam using truncated
signed distance functions." <em>2019 IEEE International Symposium on
Safety, Security, and Rescue Robotics (SSRR)</em>. IEEE, 2019.</p></li>
<li><p>Fu, Xingyin, et al. "Improved Signed Distance Function for 2D
Real-time SLAM and Accurate Localization." <em>arXiv preprint
arXiv:2101.08018</em> (2021).</p></li>
</ul>
<p>​ P.S.
本文内容并不多。虽然这有三篇论文，其中值得大篇幅讲的不可能塞在这篇博客中，不值得大篇幅讲的都在这了。</p>
<span id="more"></span>
<hr>
<h2 id="ii.-iros-2015-2d-sdf-slam">II. IROS 2015: 2D-SDF-SLAM</h2>
<p>​ 本文貌似先于cartographer发表，是2D
SLAM中使用SDF作为地图表征的开山鼻祖。我们说，2D
SLAM主要就是两种方法：</p>
<div class="tabs" id="span-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#span-unique-name-1">Eulerian</a></li><li class="tab"><a href="#span-unique-name-2">Lagragian</a></li></ul><div class="tab-content"><div class="tab-pane active" id="span-unique-name-1"><p>​ 如果不知道我在说什么，参阅我之前的一篇英文博文<a href="https://enigmatisms.github.io/2021/11/14/A-Duality-Problem-of-Representations/">【A
Duality Problem of
Representations】</a>。这里的Eulerian方法指的就是使用一个静态的网格表征，比如基于（概率）栅格图的GMapping，Hector
SLAM，Google's
Cartographer。这种方式的好处就是：天然适合进行信息融合。</p></div><div class="tab-pane" id="span-unique-name-2"><p>​
与Eulerian类别的方法互为对偶。你显式建模空间障碍物的分布，我就用一堆同时含有轨迹以及地图信息的粒子来代表整个空间。典型的方法就是粒子滤波。很有趣的是，要说用到PF方法的SLAM，GMapping也算是一个，所以GMapping实际上是：粒子表征含有Eulerian方法的Lagrangian方法。基于点云的方法，其实可以看作是这样的方法，因为其对地图的表征是动态的粒子。</p></div></div></div>
<p>SDF相比于以上方法，有这样一些特点：</p>
<ul>
<li>相对于grid
map，其需要的内存相对小一些。SDF，特别是截断SDF，只需要表征障碍物附近即可，而grid
map很多时候都是全空间的。</li>
<li>相对于grid map，SDF最后到地图需要多一步 --- marching
square（cubes）算法。虽然多了这一步，SDF以此求得的地图也是sub-grid（pixel）的。</li>
<li>相对于点云表征，SDF由于从某种意义上类似于grid
map，其融合更加友好。</li>
</ul>
<p>​ 本文呢，主要贡献可以这么说：</p>
<ul>
<li>提出了更好的SDF更新方法（这种更新方法与我熟知的方法大相径庭，个人认为此方法应该非常快速，但是存在一个大问题）</li>
<li>把SDF引到... 2D
SLAM中来？当时来说确实可以算是radical的创新吧，但从现在的角度看来也不过如此？（嚯，垃圾hqy大放厥词）</li>
</ul>
<p>​ 本文的弊病（个人认为的）：</p>
<div class="note danger"><p>实验也太简单了。</p>
<ul>
<li><p>首先你仿真就仿真，把仿真的地图公开一下，别只公开一个啊
我们就用这个开源的Simple Two Dimensional Robot
Simulator。我知道ROS已经集成了这玩意，但是这玩意怎么看都觉得有点简陋，万一你跑个巨简单的地图说，啊我这很好啊，这有什么意义呢？</p></li>
<li><p>真实的数据集也是自己采集的，而且环境很简单。没有公开数据集...</p></li>
<li><p>我说，至少也去radish上干一干GMapping啊，怎么只对比Hector
SLAM</p></li>
</ul>
</div>
<p>​
关于这篇文章的内容，我并不想多说，其SDF更新之术，我在第三节结合SSRR的论文一起说。而其配准方式，只是一个带Huber
Loss的高斯牛顿法。等等，它好像也没有Huber核...。emmm，至于为什么我也不想深究这个配准后面的数学原理，是因为个人认为：</p>
<div class="note primary"><p>​
本质上，SDF方法的优化方法与GMapping的极大后验没有什么区别。GMapping中计算这个极大后验用了一个“似然域”，这个似然域是什么东西呢？你可以简单认为在每一个激光点处都有一个2D高斯核，叠在一起（有点像GMM）。这玩意就和SDF非常像了，只不过SDF是纯纯的距离，似然域像是个SDF的近似。那么既然方法上都没有太大区别，其实也就没有必要再理解一遍这个算法过程。况且我之前还自己设计过基于SDF的配准，只不过当时不知道我设计的东西有个术语叫SDF罢了。</p>
</div>
<hr>
<h2 id="iii.-后两篇内容">III. 后两篇内容</h2>
<h3 id="ssrr-2019">3.1 SSRR 2019</h3>
<p>​
本文是cartographer的魔改，作者自己说自己是基于cartographer，将cartographer只基于grid
map拓展为了可以基于TSDF。本文我想说的不多，由于作者其实也没有介绍太多新的ideas，主要篇幅都是关于：</p>
<ul>
<li>基于TSDF表征的表征更新：如何快速而有正确地计算TSDF（local
SLAM，也就是前端的内容）</li>
<li>基于分支定界法的后端（带有回环约束的图优化）</li>
</ul>
<p>​
说起来，TSDF的更新方法确实和我理解得非常不同。个人在2021年6月份简单研究了一下普通SDF的计算，当时写了一个具有普适性的SDF计算代码（也就是说，任意给我一段折线，我都能求出其SDF），关于我原来对SDF的想法，参见<a href>【远古SDF文档】</a>。反正大概就是这个样子：</p>
<center>
<img src="/2022/02/21/2D%E6%BF%80%E5%85%89SLAM%E4%B8%AD%E7%9A%84SDF%E8%A1%A8%E5%BE%81/sdf.png" style="zoom: 80%;">
</center>
<center>
Figure 1. SDF样式.
其中，越接近折线颜色饱和度越浅，不同的颜色代表了正负号的不同
</center>
<p>​
这样的SDF，计算当然是：对于空间每一点而言，计算其到折线段上距离的最小值（并且判定这个点在折线段的哪一边）。不考虑边的情况下，这样的想法计算量也还是挺大的，2D栅格上，每个点需要做【到不同线段的投影】，再进行一个最小值的reduce。所以个人从一开始就觉得，这种计算方法肯定比较消耗计算资源，不过这样的方法看起来是可以并行加速的（这里我想到了CUDA）。</p>
<p>​ 但论文中提出了两种截然不同的方法：</p>
<center>
<img src="/2022/02/21/2D%E6%BF%80%E5%85%89SLAM%E4%B8%AD%E7%9A%84SDF%E8%A1%A8%E5%BE%81/methods.png" style="zoom:80%;">
</center>
<center>
<span id="fig2"> Figure 2. SDF更新方法[2] </span>
</center>
<p>​
这两种方法都避开了：一个点的SDF值需要与折线段上所有的线段发生相关计算的问题。虽然，所有线段都参与计算是最正确的方法（里面没有任何的近似）。但考虑到，激光数据进入是以点为单位的，如果转换为线段：</p>
<ul>
<li>首先，转换为线段就存在不小的计算开销以及复杂度上相同的内存开销。不管是否进行抽稀（Douglas-Peuker算法）或者近似（拟合），都会至少是<span class="math inline">\(O(n)\)</span>的计算量。并且，线段还不能直接用斜截式表示（存在奇异性）。</li>
<li>此外，转换为线段过后，如果没有做下采样操作，线段数目将非常多（虽然点云已经是一个sparse表征了），通常来说都会在100段以上。假如设grid纵横为n，线段条数为<span class="math inline">\(N\)</span>，计算资源消耗的复杂度将会是<span class="math inline">\(O(n^2N)\)</span></li>
</ul>
<p>​ 作者提出的第一种方法，称为projective
ray方法，这种方法其实还是近似于grid
map的思想。我用激光器光束模型来update每一个击中点附近的SDF值，简单考虑，我就认为在每一个击中点所在激光线上，我可以把激光线上点相对于击中点的距离直接当作SDF值。由于在这里，更新的每一个点都在激光线上，所以如果<span class="math inline">\(\text{range} + \Delta
d\)</span>是某个grid的深度，那么<span class="math inline">\(\Delta
d\)</span>就是SDF值，计算就非常简单了。但这种方法的问题也很大：</p>
<div class="note warning"><ul>
<li>求出的不是真正的SDF距离，大多数情况下都不是“到最近表面的距离”，只有在激光束垂直入射表面并且附近没有其他表面时，这种方法计算的SDF才是正确的</li>
<li>在入射角度大，或者grid分辨率很低时，SDF质量非常差。在IROS 2015
SDF文中说到：</li>
</ul>
<blockquote>
<p>Cells which are both positive and negative are in conflflict as they
are updated with both positive and negative distances, which do not tend
to cancel each other.</p>
</blockquote>
<p>​ 借用IROS
2015中的图，表示一下大概就是下图这样。个人认为，这种想法简直就是在用【方法的前途】换速度。</p>
<center>
<img src="/2022/02/21/2D%E6%BF%80%E5%85%89SLAM%E4%B8%AD%E7%9A%84SDF%E8%A1%A8%E5%BE%81/proj.png" style="zoom:60%;">
</center>
<center>
<span id="fig3"> Figure 3. SDF更新方法： Projective ray的弊端[1] </span>
</center>
</div>
<p>​ 而作者提出的第二种方法，看起来更加正确。在这种方法下：</p>
<ul>
<li>首先我需要evaluate每一个激光击中点的local
normal（局部法向），这一步也不是那么好做，我在自研算法里有这个操作，需要进行初级分割，以免深度不连续位置导致法向量evaluate有误</li>
<li>根据局部法向，沿着局部法向的方向向内外扩展SDF，如<a href="#fig2">图二（b）</a>以及下图所示：</li>
</ul>
<center>
<img src="/2022/02/21/2D%E6%BF%80%E5%85%89SLAM%E4%B8%AD%E7%9A%84SDF%E8%A1%A8%E5%BE%81/norm.png" style="zoom:80%;">
</center>
<center>
<span id="fig4"> Figure 4. SDF更新方法：法向法[3] </span>
</center>
<p>​
但个人觉得这种方法还是不甚优雅，在点特别稀疏的场景下，这样计算应该是会导致<strong><u>SDF稀疏</u></strong>的。毕竟你只update法线方向周围的部分点，如果点过于稀疏（1.
角度分辨率过小或2.
入射角度太大），那在垂直法向的方向上无法得到足够的coverage，就会出问题。</p>
<p>​
这里，分支定界法我不多说，因为我并没有深入理解到其方法的精髓。在这里不得不承认，运筹学虽然学习了分支定界法，但是太流于表面，可能当时会做题（意思是现在题都做不出来了），但并没有体会到这个思想的美妙性，关于基于BB方法的后端优化，个人可能会用专门的一篇博客来讨论（有关分支定界法本身以及其在SLAM中的应用）。</p>
<h3 id="arxiv-preprint-2021">3.2 arXiv Preprint 2021</h3>
<p>​
这篇文章，可能之所以是preprint，就是因为没有太多可以投的点吧，除了SDF更新之外，我只简单提一些本文提出的好的思想：</p>
<h4 id="free-space-update">3.2.1 Free Space Update</h4>
<p>​ 是
空域的思想吗？有点这个味道，但是并不完全。作者已经想到了，可以利用与空域的冲突性，来剔除动态障碍物，只需要在地图中建立空域概念，如果一个hit观测出现在空域中（在多数帧下显示为un-occupied，本帧发现存在障碍物），那么大概率会是动态障碍物。这个思想在我们算法里也有，并且它的free
space计算方法就和我们很像：</p>
<center>
<img src="/2022/02/21/2D%E6%BF%80%E5%85%89SLAM%E4%B8%AD%E7%9A%84SDF%E8%A1%A8%E5%BE%81/free.png" style="zoom:90%;">
</center>
<center>
<span id="fig5"> Figure 5.
空域的计算方法（灰色的部分是一束激光线产生的空域）[3] </span>
</center>
<h4 id="expansion">3.2.2 Expansion</h4>
<p>​
作者也意识到纯法向SDF更新的问题（稀疏性），所以作者用了一个“迭代取点”的方法。首先，Deming
regression至少需要三个点才能生成一条直线，在入射角度过大或者距离过远的地方，一个grid内部可能找不到那么多点，作者根据hit点的邻域关系逐步expand搜索域。举个简单的例子：</p>
<ul>
<li>在某一个激光点的8-邻域内（扩展一次），只有一个点，显然两个点没办法形成regression，需要继续扩展</li>
<li>在8-邻域点对应的8-邻域内（扩展两次），找到了第三个点，那么用这三个点regress一条线并进行法向更新</li>
<li><strong><u>垂直法向</u></strong>上的更新半径，<strong><u>根据扩展的次数</u></strong>确定，越稀疏的位置，扩展次数越多，更新半径就越大。</li>
<li>这样一种方法，应该至少可以消除大部分稀疏性问题带来的影响。</li>
</ul>
<h4 id="类似view-selection">3.2.3 类似view selection</h4>
<p>​ 作者在 <strong><em>Improve Priority Strategy</em></strong>
一段中写到：</p>
<blockquote>
<p>The cells closer to the cell that gives rise to the update are put on
a higher priority.</p>
</blockquote>
<p>​
SDF的标准定义就应该是：离谁近就用到谁的距离来更新。而不管是projective
ray还是局部法向法，都不是按照“谁最近就用谁更新”的原则计算SDF的，那么就需要引入取舍标准：不同点计算的结果不同时，我取谁。作者这里并没有一刀切，而是用加权的方式融合。</p>
<h4 id="outlier-removal">3.2.4 Outlier removal</h4>
<p>​
emmm，简单来说就是，剔除深度不连续点。这，叔叔我啊，可早就写过了。</p>
<h4 id="子地图融合">3.2.5 子地图融合</h4>
<p>​
这没有什么指的说的，对于这种显式或者隐式用了grid的方法，融合就是比较简单。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://www.researchgate.net/profile/Joscha-David-Fossel/publication/308298063_2D-SDF-SLAM_A_signed_distance_function_based_SLAM_frontend_for_laser_scanners/links/58e66d1fa6fdcc6800b47916/2D-SDF-SLAM-A-signed-distance-function-based-SLAM-frontend-for-laser-scanners.pdf">Fossel,
Joscha-David, Karl Tuyls, and Jürgen Sturm. "2D-SDF-SLAM: A signed
distance function based SLAM frontend for laser scanners." <em>2015
IEEE/RSJ International Conference on Intelligent Robots and Systems
(IROS)</em>. IEEE, 2015.</a></p>
<p>[2] <a href="https://www.researchgate.net/profile/Oskar-Von-Stryk/publication/336088692_Large_Scale_2D_Laser_SLAM_using_Truncated_Signed_Distance_Functions/links/5e8ca2da92851c2f52884e06/Large-Scale-2D-Laser-SLAM-using-Truncated-Signed-Distance-Functions.pdf">Daun,
Kevin, et al. "Large scale 2d laser slam using truncated signed distance
functions." <em>2019 IEEE International Symposium on Safety, Security,
and Rescue Robotics (SSRR)</em>. IEEE, 2019.</a></p>
<p>[3] <a href="https://arxiv.org/pdf/2101.08018.pdf">Fu, Xingyin, et
al. "Improved Signed Distance Function for 2D Real-time SLAM and
Accurate Localization." <em>arXiv preprint arXiv:2101.08018</em>
(2021).</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>SLAM</tag>
        <tag>表征</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo NexT主题 更强的自定义页面</title>
    <url>/2022/02/18/Hexo-NexT%E4%B8%BB%E9%A2%98-%E6%9B%B4%E5%BC%BA%E7%9A%84%E8%87%AA%E5%AE%9A%E4%B9%89%E9%A1%B5%E9%9D%A2/</url>
    <content><![CDATA[<h2 id="hexo-next美化">Hexo NexT美化</h2>
<hr>
<p>​ Hexo
NexT主题博客默认只有一个主页面，虽然可以在config.yml中选择以哪个板块作为主页面，但假如我想有多个不同的页面都与主页一样有页面预览，还是难以直接做到的。网上确实有一篇教程：<a href="https://finisky.github.io/customizecategorybyextension/">【Hexo添加自定义分类菜单项并定制页面布局(简洁版)】</a>，我的snippet板块第一版就是用这个教程搭建的，但之后发现存在一些问题。那么应该如何解决呢？</p>
<span id="more"></span>
<hr>
<h2 id="snippet板块与主板块关系">Snippet板块与主板块关系</h2>
<p>​
Snippet板块下的所有post，其分类（category）都是"snippet"，根据上文博客提到的代码：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> realestatePosts = locals.<span class="property">posts</span>.<span class="title function_">filter</span>(<span class="keyword">function</span>(<span class="params">x</span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> x.<span class="property">categories</span>.<span class="property">data</span>[<span class="number">0</span>].<span class="property">name</span> == filteredCategory;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>​
这样可以筛选分类为"filteredCategory"的博文，只显示在Snippet板块。但是主板块上仍然无法阻止分类为"filteredCategory"的博客显示（主板块上不显示最合理），开始时我尝试修改<code>.njk</code>文件，但分页会出现错误。我在hexo-next开了个issue，点击下述图片以查看。解决方案是把<code>hexo-generator-index</code>替换为<code>hexo-generator-indexed</code>。</p>
<center>
<div style="background-color: rgb(245, 245, 245); border-radius: 18px; padding: 7px;">
<a href="https://github.com/theme-next/hexo-theme-next/issues/1691"><img alt="Qries" src="/2022/02/18/Hexo-NexT%E4%B8%BB%E9%A2%98-%E6%9B%B4%E5%BC%BA%E7%9A%84%E8%87%AA%E5%AE%9A%E4%B9%89%E9%A1%B5%E9%9D%A2/link.png" style="zoom: 60%"></a>
</div>
</center>
<hr>
<h2 id="强化">强化</h2>
<p>​ <a href="https://finisky.github.io/customizecategorybyextension/">【Hexo添加自定义分类菜单项并定制页面布局(简洁版)】</a>开了一个很好的头，通过这种方法确实可以生成一个新的板块，其中只留有特定分类的博文，但是多post一些博文会发现致命问题：</p>
<ul>
<li>博文排序是倒序的，越老的post排在越前面。阿哲，历史文件的现实意义？</li>
<li>博文置顶失效了。在<code>hexo-generator-indexed</code>中有个这样的功能：只需要在markdown的<code>front-matter</code>中填上:<code>sticky: x</code>（x是优先级，最小0最大100），就会根据优先级来排序，可以实现置顶功能，但是在博客的方法下失效了。我们看看博客中提到的方法代码：</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> pagination = <span class="built_in">require</span>(<span class="string">&#x27;hexo-pagination&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> filteredCategory = <span class="string">&#x27;snippet&#x27;</span>;</span><br><span class="line"></span><br><span class="line">hexo.<span class="property">extend</span>.<span class="property">generator</span>.<span class="title function_">register</span>(<span class="string">&#x27;custom&#x27;</span>, <span class="keyword">function</span>(<span class="params">locals</span>)&#123;</span><br><span class="line">  <span class="keyword">var</span> realestatePosts = locals.<span class="property">posts</span>.<span class="title function_">filter</span>(<span class="keyword">function</span>(<span class="params">x</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> x.<span class="property">categories</span>.<span class="property">data</span>[<span class="number">0</span>].<span class="property">name</span> == filteredCategory;</span><br><span class="line">  &#125;);</span><br><span class="line">  <span class="keyword">return</span> <span class="title function_">pagination</span>(<span class="string">&#x27;snippets&#x27;</span>, realestatePosts, &#123;</span><br><span class="line">    <span class="attr">perPage</span>: <span class="number">10</span>,</span><br><span class="line">    <span class="attr">layout</span>: [<span class="string">&#x27;index&#x27;</span>],</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>​
非常plain，就是过滤了一下标签。在这里，我按照<code>hexo-generator-indexed</code>中的代码（在hexo的node_module下可以看到），借鉴其<code>generator.js</code>修改了这个博客过滤：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> pagination = <span class="built_in">require</span>(<span class="string">&#x27;hexo-pagination&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> &#123; sort &#125; = <span class="built_in">require</span>(<span class="string">&#x27;timsort&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> filteredCategory = <span class="string">&#x27;snippet&#x27;</span>;</span><br><span class="line"></span><br><span class="line">hexo.<span class="property">extend</span>.<span class="property">generator</span>.<span class="title function_">register</span>(<span class="string">&#x27;custom&#x27;</span>, <span class="keyword">function</span>(<span class="params">locals</span>)&#123;</span><br><span class="line">  <span class="keyword">var</span> posts = locals.<span class="property">posts</span>.<span class="title function_">filter</span>(<span class="keyword">function</span>(<span class="params">x</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> x.<span class="property">categories</span>.<span class="property">data</span>[<span class="number">0</span>].<span class="property">name</span> == filteredCategory;</span><br><span class="line">  &#125;).<span class="title function_">sort</span>(<span class="string">&#x27;-date&#x27;</span>).<span class="title function_">slice</span>(<span class="number">0</span>);				<span class="comment">// 复制，而非原地操作</span></span><br><span class="line">  <span class="title function_">sort</span>(posts.<span class="property">data</span>, <span class="function">(<span class="params">a, b</span>) =&gt;</span> (b.<span class="property">sticky</span> || <span class="number">0</span>) - (a.<span class="property">sticky</span> || <span class="number">0</span>));</span><br><span class="line">  <span class="keyword">return</span> <span class="title function_">pagination</span>(<span class="string">&#x27;snippets&#x27;</span>, posts, &#123;</span><br><span class="line">    <span class="attr">perPage</span>: <span class="number">10</span>,</span><br><span class="line">    <span class="attr">layout</span>: [<span class="string">&#x27;custom&#x27;</span>],</span><br><span class="line">    <span class="attr">data</span>: &#123;</span><br><span class="line">      <span class="attr">__index</span>: <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>​
过滤之后立马调用timesort，根据日期排序，再根据posts中博客的<code>sticky</code>值排序，两处都定义了匿名函数。这样一来，博客生成的就是正确的排版。</p>
]]></content>
      <categories>
        <category>snippet</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Redmi G 2021锐龙版双系统环境工程记录</title>
    <url>/2022/02/17/Redmi-G-2021%E9%94%90%E9%BE%99%E7%89%88%E5%8F%8C%E7%B3%BB%E7%BB%9F%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<h1 id="amd-yes">AMD Yes!</h1>
<hr>
<p>新电脑 Redmi G 2021 Ryzen7 版装<strong><u>双系统</u></strong> （win11
+ ubuntu 18.04
LTS）过程中遇到了一些问题，以后如果要换设备大概率还得再来一遍，本篇权当记录。不过说实话，从本篇字数来看，应该算得上一篇正规post而不是snippet了。这确实也与snippet板块的设置理念相悖，不过可能我就是那么啰嗦吧。PS：本文与AMD
yes没有任何关系。</p>
<span id="more"></span>
<hr>
<h2 id="flann找不到">FLANN找不到</h2>
<p>​
使用<code>flann</code>库时，在<code>CMakeLists</code>中是需要<code>find_package</code>操作的，但<code>flann</code>如何找？</p>
<p>​ 首先如果我们一波：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone &lt;flann仓库地址，这里不写，随便找都能找到&gt;</span><br><span class="line">cd flann/; mkdir build; cd build/</span><br><span class="line">cmake ..; make -j</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure>
<p>​
安装<code>flann</code>库，虽然<code>flann</code>会被成功安装到<code>/usr/local/include</code>下（如果没有指定安装路径就会到这个地方），但其<code>.cmake</code>配置文件对CMake而言是不可见的，首先（1）<code>make install</code>没有自己复制<code>.cmake</code>文件，并且（2）<code>locate</code>也是没能找到<code>.cmake</code>文件（不知道为什么）</p>
<p>​ 最后的解决方案有两个:</p>
<ul>
<li>可以在<code>flann</code>库下的<code>cmake</code>文件夹下找到<code>FindFlann.cmake</code>，将其复制到<code>cmake</code>对应的配置文件夹下:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/usr/share/cmake-3.10/Modules/</span><br></pre></td></tr></table></figure>
<p>​
这个做法很魔法，并且要手动改系统文件（需要管理员权限那种），但一劳永逸。</p>
<ul>
<li>如果有ros（对，我有），那么pcl库中自带<code>flann</code>
只需要指定pcl导入<code>flann</code>即可（CMake配置）</li>
</ul>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">find_package</span>(PCL REQUIRED COMPONENTS kdtree)</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="lz4冲突">LZ4冲突</h2>
<p>​ 服气。lz4在ROS
melodic中有一份实现（lz4.h）相关，在<code>pcl</code>库中又有一份实现（存在<code>/usr/include/flann</code>下）。首先如果CMake要能找到
lz4，就需要使用<code>pkg-config</code>：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">find_package</span>(PkgConfig REQUIRED)</span><br><span class="line">pkg_check_modules(LZ4 REQUIRED liblz4)</span><br></pre></td></tr></table></figure>
<p>​
如果没有<code>pkg-config</code>，可以使用<code>apt install</code>进行安装。</p>
<p>​ 发生冲突确实可以使用<a href="https://github.com/ethz-asl/lidar_align/issues/16#">某个Github
issue</a>中提到的方案解决，但是这个方案涉及到修改<code>/usr/include</code>下的头文件，非常不优雅。个人在寒假前遇到过这个问题，当时貌似解决了，但没有记录下来，现在也回忆不起来，只能等回到学校后查看学校电脑了。</p>
<hr>
<h2 id="nvidia">Nvidia!!!</h2>
<p>​ 英伟达真折磨到我了。之前我在<a href="https://enigmatisms.github.io/2021/11/21/Nvidia-%E7%AE%80%E5%8D%95%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B/">[Nvidia
简单环境工程]</a>中提到如何安装显卡驱动，但事实证明这份教程博客非常不完全。</p>
<ul>
<li>我在实验室另一台RTX 3060上安装时遇到了无法安装CUDA
11.3的情况，可能是GPU与对应的460+
driver不适配（我忘了是不是460+了，由于CUDA 11.4对应470.95，个人猜测CUDA
11.3没到470，我也不想花时间去考证）
<ul>
<li>不能安装11.3确实有些不方便，英伟达的apex（某个auto mixed
precision库）需要CUDA与pytorch版本对上... 但我11.4 +
torch(cu113)真就不行，所以一直想卸了11.4装11.3 但都失败，表现在
<strong><u>安装11.3之后</u></strong>
电脑重启会黑屏，卡在登录界面，无论使用recovery还是直接启动都不行，并且在recovery的root权限命令行中使用<code>nvidia-smi</code>可能卡爆电脑。</li>
</ul></li>
<li>RTX 3060（for laptop computer）甚至都不能安装CUDA
11.4，表现类似也是黑屏，但是<code>nvidia-smi</code>在recovery root
console中正常
<ul>
<li>使用博客中的<code>sudo apt-get --purge remove nvidia-*</code>并不能完全删除英伟达驱动（之前都是可以的）。执行命令导致<code>0 package to add\delete\update</code>，等于没动，原因不明</li>
<li>无论怎么删，<code>nvidia-smi</code>都阴魂不散，但如果这样卸载然后安装别的版本CUDA，又不会提示说电脑中已经有一个现有的英伟达驱动而冲突了。</li>
</ul></li>
</ul>
<p>​
最后一直删不掉，其他指令都无效了，只能重装系统，一天半的工作白干。</p>
<p>​ 这里值得一提的是：</p>
<div class="note danger"><p>根本不应该用<code>sudo apt-get --purge remove</code>以及<code>sudo apt autoremove</code>这么暴力而且危险的方式来卸载显卡驱动。</p>
</div>
<p>​ 英伟达已经写好了:</p>
<ul>
<li>使用<code>nvdia-uninstall</code>命令可以直接干净卸载（之前我不知道这个）</li>
<li>使用<code>/usr/local/cuda-x</code>下的脚本<code>cuda-uninstaller.sh</code>可以方便地卸载CUDA</li>
</ul>
<p>​
这两个命令运行起来几乎没有破坏性，在经历了11.3\11.4的失败之后，11.4中我直接用上述命令卸载并重装11.6，干净又卫生。</p>
<hr>
<h2 id="opencv新坑">OpenCV新坑</h2>
<p>​
OpenCV还是我的必装库。但安装opencv对我来说已经是一件很久没做过的事情了，难免忘掉很多细节。</p>
<ul>
<li><p>首先准备好<code>opencv_contrib</code>，里面还是有很多值得安装的拓展内容的</p></li>
<li><p><strong><u>准备好opencv需要安装的一些库</u></strong>：这部分可以参考
<a href="https://gist.github.com/raulqf/f42c718a658cddc16f9df07ecc627be7">[raulqf/Install_OpenCV4_CUDA11_CUDNN8.md]</a>
这个Gist。没有这些库是过不了cmake的</p></li>
<li><p><code>libEGL.so</code>消失问题：</p></li>
</ul>
<blockquote>
<p>The imported target "QT5::Gui" references the file
"/usr/lib/x86_64-linux-gnu/libEGL.so" but this file does not exist.</p>
</blockquote>
<p>​
很奇怪的一个问题，<code>libEGL.so</code>是可以被locate到的，在ubuntu的文件property中可以看到（直接用GUI查看property），<code>libEGL.so</code>要么是<strong><u>不存在</u></strong>，要么指向了一个不存在的<code>so.x</code>文件（此文件不是真正的静态库，只是一个软链接），这里提醒一下设置软链接的方式，这么久了都忘了：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo ln -s &lt;source name&gt; &lt;target name&gt;</span><br></pre></td></tr></table></figure>
<p>​
此处我们只需要首先<code>locate libEGL.so</code>，发现有很多<code>.so.1.0</code>以及<code>.so.1.0.0</code>之类的文件，或者一些类似的，不在<code>/usr/lib/x86_64-linux-gnu/</code>下的文件，都是可以拿来使用的。创建好对应的软链接，命名为<code>libEGL.so</code>（以及<code>libGL.so</code>因为这个文件也存在相同问题）放在上述目录下即可。</p>
<ul>
<li>oracle-java 编译opencv
java版：我用不到，但是它硬要我这样干。只能下载openjdk。<code>openjdk-default</code>默认版本（当前）11.0.13，但是opencv傻乎乎地要求我安装11.0.4，并且要求我安装<code>oracle-java11-installer-local</code>
<ul>
<li>但很不幸，openjdk与oracle-java版本对不上，<code>oracle-java11-installer-local</code>不能正常安装，系统需要我把对应11.0.4
<code>oracle-java11-installer-local</code>的deb包放到<code>/var/cache/oracle-java11-installer-local</code>下</li>
<li>我照做的，无误，但是系统就是不认账，一直认为我没有这么做，叔叔我啊，真的要生气了</li>
<li>一怒之下想绕开<code>oracle-java11-installer-local</code>的安装，但是系统不允许，告诉我：</li>
</ul></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1 not fully installed or removed.</span><br><span class="line">After this operation, 0 B of additional disk space will be used.</span><br><span class="line">E: Internal Error, No file name for oracle-java11-installer-local:amd64</span><br></pre></td></tr></table></figure>
<p>​
这个问题是：装到一半由于一些问题而没装好的包，使得新的dpkg请求没办法完成。那么如何取消这样的
<strong><u> not fully installed or removed</u></strong>
的安装进程呢？</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo dpkg --force-depends --purge oracle-java11-installer-local</span><br></pre></td></tr></table></figure>
<p>​ 对于本问题的
<code>oracle-java11-installer-local</code>，这样即可。</p>
<hr>
<h2 id="rtw89-8852ae">RTW89-8852AE</h2>
<p>​
额。刚买回电脑来的第三天（开始装ubuntu），装完发现不能联网，十分恶心（显示
<strong><u>No WiFi Adapter
Found</u></strong>）。由于win11可以正常联网，网卡硬件端肯定没有问题，推测没有网卡驱动，再一查解决方案后成功解决...
不过在这里，我并不能省略 <strong><u>“一查”</u></strong>
的过程，因为有些命令我是不清楚用法的:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lspci			# 用于显示当前主机的所有PCI总线信息</span><br></pre></td></tr></table></figure>
<p>​ 执行结束后出了一大堆信息，其中有用的就只有：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">02:00.0 Network controller: Realtek Semiconductor Co., Ltd. Device 8852</span><br><span class="line">03:00.0 Ethernet controller: Realtek Semiconductor Co., Ltd. RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller (rev 15)</span><br></pre></td></tr></table></figure>
<p>​ Ethernet
controller一般都是有线网络网卡。实际上有用的就是这一条命令，但搞清楚
<strong><u>就是这一条有用</u></strong>
的过程还是很曲折的。其中还遇到这么一些指令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo lshw -class network</span><br></pre></td></tr></table></figure>
<p>​ 输出如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">*-network                 </span><br><span class="line">     description: Wireless interface</span><br><span class="line">     product: Realtek Semiconductor Co., Ltd.</span><br><span class="line">     vendor: Realtek Semiconductor Co., Ltd.</span><br><span class="line">     physical id: 0</span><br><span class="line">     bus info: pci@0000:02:00.0</span><br><span class="line">     logical name: wlp2s0</span><br><span class="line">     version: 00</span><br><span class="line">     serial: &lt;xxxxxxxxxxxxxxxxxxxx&gt;</span><br><span class="line">     width: 64 bits</span><br><span class="line">     clock: 33MHz</span><br><span class="line">     capabilities: pm msi pciexpress bus_master cap_list ethernet physical wireless</span><br><span class="line">     configuration: broadcast=yes driver=rtw89_pci driverversion=5.4.0-100-generic firmware=N/A ip=&lt;xxxxxxxxxxxxxxxxxxxx&gt; latency=0 link=yes multicast=yes wireless=IEEE 802.11</span><br><span class="line">     resources: irq:85 ioport:3000(size=256) memory:d1800000-d18fffff</span><br><span class="line">*-network</span><br><span class="line">     description: Ethernet interface</span><br><span class="line">     product: RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller</span><br><span class="line">     vendor: Realtek Semiconductor Co., Ltd.</span><br><span class="line">     physical id: 0</span><br><span class="line">     bus info: pci@0000:03:00.0</span><br><span class="line">     logical name: eno1</span><br><span class="line">     version: 15</span><br><span class="line">     serial: &lt;xxxxxxxxxxxxxxxxxxxx&gt;</span><br><span class="line">     capacity: 1Gbit/s</span><br><span class="line">     width: 64 bits</span><br><span class="line">     clock: 33MHz</span><br><span class="line">     capabilities: pm msi pciexpress msix bus_master cap_list ethernet physical tp mii 10bt 10bt-fd 100bt 100bt-fd 1000bt-fd autonegotiation</span><br><span class="line">     configuration: autonegotiation=on broadcast=yes driver=r8169 firmware=rtl8168h-2_0.0.2 02/26/15 latency=0 link=no multicast=yes port=MII</span><br><span class="line">     resources: irq:24 ioport:2000(size=256) memory:&lt;xxxxxxxxxxxxxxxxxxxx&gt; memory:&lt;xxxxxxxxxxxxxxxxxxxx&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>​
隐去了一些重要信息。在没有安装8852对应的网卡驱动前，第一项（第一个<code>*-network</code>，每一项表示一个网络控制设备）显示的是
<strong><u>unmanaged</u></strong>。此外还有一个命令（多了我也没记住）：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">iwconfig</span><br></pre></td></tr></table></figure>
<p>​ 这是什么？常用的是<code>ifconfig</code>，区别主要在于：</p>
<blockquote>
<p>iwconfig is similar to ifconfig, but is dedicated to wireless
networking interfaces.[1]</p>
</blockquote>
<p>​ 好，那么在<code>lspci</code>之后，我已经知道了Realtek
8852网络控制器这个型号，接下来就是查找网卡驱动了，此处忽略google的过程，找到了Github库：<a href="https://github.com/lwfinger/rtw89">[Github:
lwfinger/rtw89]</a>，直接编译安装就可以使用！</p>
<p>​ 但是在安装前一定要注意，Redmi G 2021 默认是打开了secure
boot的（我一开始还被蒙在鼓里），secure
boot的情况一定要按照repo中README的指示安装，否则就会不成功。我直接取消了secure
boot，直接安装成功。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://wiki.debian.org/iwconfig">Debian/iwconfig</a></p>
]]></content>
      <categories>
        <category>snippet</category>
      </categories>
      <tags>
        <tag>环境工程</tag>
      </tags>
  </entry>
  <entry>
    <title>关于卷积的一些思考</title>
    <url>/2022/02/11/%E5%85%B3%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[<iframe src="//www.slideshare.net/slideshow/embed_code/key/EeH6ZygZvj9G5m" width="750" height="420" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%; border-radius: 2px;" allowfullscreen>
</iframe>
]]></content>
      <categories>
        <category>snippet</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title>3D Reconstruction with Posed Mono-cam Images</title>
    <url>/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/</url>
    <content><![CDATA[<h1 id="re3d">Re3D</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​ 电脑还没到，我[#]。不得不说京东有些店是真的脑瘫，买RTX发AMD，AMD
yes也别这样啊。没办法工作的情况下只能看论文，继续3D重建。3D重建有些部分与我当前工作有重合之处，我也想从中获得一些启发。本文是两篇小论文以及一本书（这本书的其中一卷）的一个小理解：</p>
<ul>
<li><a href="https://arxiv.org/pdf/2003.10432.pdf?ref=https://githubhelp.com">Murez,
Zak, et al. "Atlas: End-to-end 3d scene reconstruction from posed
images." <em>European Conference on Computer Vision</em>. Springer,
Cham, 2020.</a></li>
<li><a href="https://proceedings.neurips.cc/paper/2021/file/0a87257e5308197df43230edf4ad1dae-Paper.pdf">Bozic,
Aljaz, et al. "Transformerfusion: Monocular rgb scene reconstruction
using transformers." <em>Advances in Neural Information Processing
Systems</em> 34 (2021)</a></li>
<li>书（不得不说这本...
期刊？写得真不错，CV方向的基础以及前瞻，不过是当时的前瞻了，可能也比较老）:
<a href="https://www.nowpublishers.com/CGV">Foundations and Trends® in
Computer Graphics and Vision</a></li>
</ul>
<p>​ 附注：不让我工作我就打原神。</p>
<span id="more"></span>
<hr>
<h2 id="ii.-基本概念">II. 基本概念</h2>
<p>​
以下内容很多都来自于[1]，个人觉得此文写得很不错，逻辑清晰，易读性强。</p>
<h3 id="d重建概述">2.1 3D重建概述</h3>
<h4 id="d重建的基本方法">2.1.1 3D重建的基本方法</h4>
<p>​ 笔者认为，3D重建行业发展的理想道路应该是：</p>
<ul>
<li>单目RGB-已知图像位姿的3D重建</li>
<li>双目RGB 图像位姿可以未知</li>
</ul>
<p>​
实际上，可以将第二种情况视作第一种情况的特例。第二种情况只不过是将一半的图像用于双目深度计算了。在[1]中，作者认为：</p>
<blockquote>
<p>The 3D reconstruction of shapes from
<strong><u>multiple</u></strong>, <strong><u>uncalibrated</u></strong>
images is one of the most promising 3D acquisition techniques.</p>
</blockquote>
<p>​ 但“uncalibrated
mono-cam”应该说是最困难的一种，当然如果做出来了，意义也是最大的一种（用最少的先验知识以及辅助工具获得了想要的信息，这就是优雅的、低成本的好方法）。</p>
<p>​ 关于视觉3D重建，[1]中提到了两种主要的方向：</p>
<pre class="mermaid">
graph TB
A(3D Shape Extraction)
B(Passive)
C(Active)
D(Single vantage point)
E(Single vantage point)
F(Multiple vantage points)
G(Multiple vantage points)
A--&gt;B
A--&gt;C
B--&gt;D
B--&gt;F
C--&gt;E
C--&gt;G
H(Shape from texture&lt;br&gt;Shape from occlusion&lt;br&gt;Shape from defocus&lt;br&gt;Shape from contour&lt;br&gt;Time to contact)
I(Passive stereo&lt;br&gt;SfM&lt;br&gt;Shape from sillhouttes)
J(Time of Flight&lt;br&gt;Shape from texture)
K(Structed light&lt;br&gt;Active stereo&lt;br&gt;Photometric stereo)
D--&gt;H
F--&gt;I
E--&gt;J
G--&gt;K
</pre>
<center>
Figure 1. 3D重建方法分类
</center>
<div class="tabs" id="span-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#span-unique-name-1">Active</a></li><li class="tab"><a href="#span-unique-name-2">Passive</a></li></ul><div class="tab-content"><div class="tab-pane active" id="span-unique-name-1"><p>​
可以认为，active方法是一种通过一些处理使得后续的复杂计算（比如correspondence
search）变简单的方法。比如使用光斑进行“制导”：一个长波光源发射不可见光，另一个接收器（相当于相机）接收光。假设我们认为发射的是可见光，接收器也是一台相机，那么相当于是：相机拍摄到一个亮斑，而发射器可以认为是相机的反向模型，则“发射器-接收器”可被视作是两台相机组成的双目系统，而亮斑的存在已经帮我们标注好了correspondence。</p>
<center>
<img src="/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/active.png" style="zoom:50%;">
</center>
<center>
Figure 2. Active 方法图示[1]
</center>
<p>​
当然，单点没什么卵用。我们希望可以获得整个面的correspondences关系，是否仍然可以使用active光斑法？当然也是可行的，不过由于我们在使用单点光斑时，基于的想法是“<strong><u>唯一性</u></strong>
以及
<strong><u>容易查找性</u></strong>，直接使用单点法中光斑的2D复制显然是不行的（emmm，事实上也可以，基于红外光斑阵列的深度相机也有的，但是这种方法除了保证了极线上的全局最优性，并没有实际解决correspondence
search很棘手的问题）。</p>
<p>​ [1]中作者介绍了一些对光斑进行“positional
embed”的方法。比如，我就使用 <strong>Attention is all you need</strong>
中的sinusoidal positional
encodings思想，用多组不同频率或者相位的正弦波来唯一地表征一个位置，这样方便我们进行查找。</p></div><div class="tab-pane" id="span-unique-name-2"><p>​
本方法不使用其他辅助手段，一般来说都是直接靠算法算出结果来的。比如说：passive
triangulation。通过预先计算的correspondences，解出在某一个相机坐标系下的坐标。但作者自己也说：</p>
<blockquote>
<p>Correspondence search actually is the <strong><u>hardest</u></strong>
part of stereo, and one would typically have to solve it for many
points.</p>
</blockquote>
<p>​ 这我也没啥好说的，只能说（1）确实。（2）考虑一下CVPR
2021最新工作（好吧已经不是最新了）
PointDSC？（好吧*2，作者这篇文章是2010年的）。</p>
<p>​
虽然如此，passive方法更加优雅，不依赖发射器件，只进行接收符合大多数生物的特性，并且这样的方法适用性更广，active方法对应的什么结构光、ToF一到室外场景可能就直接寄了。</p></div></div></div>
<h4 id="d重建面临的挑战">2.1.2 3D重建面临的挑战</h4>
<ul>
<li>复杂物体形状：自遮挡
(self-occlusion)，视角不全，表面细节丰富等等</li>
<li>一些奇怪的纹理：反射、透射，万花筒式（比如钻石），半透明物体</li>
<li>Scalability：既要能够重建小物体，也要能够重建大物体。（从家具到城市）</li>
<li>数据量大、处理维度高（3D表征比2D高）：自、弱、无监督</li>
<li>精度：这个不用讲，高精度鲁棒实时不仅仅是2D SLAM的追求</li>
<li>Semantic 3D与Opportunistic scanning，说的是两个对偶：
<ul>
<li>前者指重建的<strong><u>算法过程基于内容</u></strong>，假设我知道我需要重建的是一辆车，那么知道“车”的先验信息或许对我进行重建有很大帮助。那么重建过程就需要对待重建的场景有一定理解，至少是语义级别的。这其中包含了一定的
High level task 帮助 low level task的意思。</li>
<li>后者指重建的<strong><u>数据获取过程基于内容</u></strong>，假设我知道当前场景大量存在无纹理区域（对passive方法不友好），我是否可以自适应更换到active方法（比如结构光）？</li>
</ul></li>
</ul>
<h3 id="相机模型回顾">2.2 相机模型回顾</h3>
<p>​
之前其实没有仔细推过这部分的内容，现在权当补个票。首先，我们明确一下符号：</p>
<table>
<colgroup>
<col style="width: 15%">
<col style="width: 31%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 6%">
<col style="width: 21%">
</colgroup>
<thead>
<tr>
<th><span class="math inline">\(R\)</span></th>
<th><span class="math inline">\(C\)</span></th>
<th><span class="math inline">\(K\)</span></th>
<th><span class="math inline">\(p\)</span></th>
<th><span class="math inline">\(z\)</span></th>
<th><span class="math inline">\(P\)</span></th>
</tr>
</thead>
<tbody>
<tr>
<td>外参：旋转</td>
<td>世界坐标系下相机光心</td>
<td>内参矩阵</td>
<td>图像位置</td>
<td>深度</td>
<td>世界坐标系位置</td>
</tr>
</tbody>
</table>
<p>​ 则若已知相机在世界系下的旋转与平移（<span class="math inline">\(R,C\)</span>），内参矩阵已知的情况下，有如下关系：
<span class="math display">\[
\begin{equation}
zp=KR^T(P-C)
\end{equation}
\]</span> ​ 实际上<span class="math inline">\(R^T(P-C)\)</span>只不过做了一个世界系-&gt;相机系的坐标变换。此公式应当非常熟悉。</p>
<p>​
我们考虑单目已知相机位姿与参数时的情况，并且我们假设已经获得了两张图片中的correspondences（我一句话，就搞完了SLAM和correspondence
search）。那么显然，对于世界坐标系下同一点： <span class="math display">\[
\begin{align}
&amp;z_1p_1=K_1R_1^T(P-C_1)\label{first}\\
&amp;z_2p_2=K_2R_2^T(P-C_2)\label{second}
\end{align}
\]</span> ​ 则可以通过公式<span class="math inline">\(\eqref{first}\)</span>反求P： <span class="math display">\[
\begin{equation}
z_1R_1K_1^{-1}p_1+C_1=P
\end{equation}
\]</span> ​ 带入到公式<span class="math inline">\(\eqref{second}\)</span>中： <span class="math display">\[
\begin{align}
&amp;z_2p_2=K_2R_2^T(z_1R_1K_1^{-1}p_1+C_1-C_2)\rightarrow\\
&amp;z_2p_2=z_1K_2R_2^TR_1K_1^{-1}p_1+K_2R^T_2(C_1-C_2)\label{homo1}
\end{align}
\]</span> ​ 其中<span class="math inline">\(K_2R_2^TR_1K_1^{-1}:=A\)</span>被称为“Infinite
Homography”，其物理意义有两种解释：</p>
<ul>
<li>图像i中一像素<span class="math inline">\(p_i\)</span>位置确定的光线，其灭点（vanishing
point）在图像j下的投影矩阵：<span class="math inline">\(p_j=Ap_i\)</span></li>
<li>可以认为<span class="math inline">\(A\)</span>矩阵就是光线方向在两个相机之间的变换矩阵</li>
</ul>
<p>​ 我们暂且拿公式<span class="math inline">\(\eqref{homo1}\)</span>来玩一玩，看看它能推出一些什么有趣的理论。我们可以从理论上证明：</p>
<blockquote>
<p>双目匹配中，经过rectification的两张图像，correspondence
search只需要在水平方向上进行。</p>
</blockquote>
<p>​ 看起来...
好无聊的理论。不过我仍然要来试一下：首先假设双目的相机内参一致，也即<span class="math inline">\(K_1=K_2\)</span>，并且若是经过校准（外参也经过标定）的双目相机，应有：<span class="math inline">\(R_1=R_2\)</span> 以及 <span class="math inline">\(C_1\)</span>与<span class="math inline">\(C_2\)</span>在相机z轴坐标上一致（其一的光心在另一相机的xy平面上），那么由公式<span class="math inline">\(\eqref{homo1}\)</span>，可以推出： <span class="math display">\[
\begin{equation}
z_2p_2=z_1(I)p_1+K_2R_2^T(C_1-C_2)
\end{equation}
\]</span> ​ 由于相机z轴坐标以及方向均一致，故对于同一个点，<span class="math inline">\(z_1=z_2\)</span>，而<span class="math inline">\(K_2R_2^T(C_1-C_2)\)</span>只有x轴方向不为0，故可以知道：
<span class="math display">\[
\begin{equation}
p_2=p_1+\alpha v_x,\text{ in which }v_x \text{ only has x component}
\end{equation}
\]</span> ​ 这也就说明了标定后的双目只需水平进行correspondence
search。</p>
<h3 id="对极约束与基础矩阵">2.3 对极约束与基础矩阵</h3>
<p>​ 2.2中实际上我们已经得到了一个重要的矩阵<span class="math inline">\(A\)</span>，用于进行灭点的映射。当然，这部分只是重要公式<span class="math inline">\(\eqref{homo1}\)</span>的一部分，观察公式<span class="math inline">\(\eqref{homo1}\)</span>的第二部分<span class="math inline">\(K_2R_2^T(C_1-C_2)\)</span>，不难发现，这部分是将世界坐标点<span class="math inline">\(P\)</span>用<span class="math inline">\(C_1\)</span>带入到公式<span class="math inline">\(\eqref{second}\)</span>中，也即<span class="math inline">\(C_1\)</span>在相机2下的投影。我们将这个投影点<span class="math inline">\(K_2R_2^T(C_1-C_2)\)</span>称为极点（epipole）</p>
<center>
<img src="/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/epi.png" style="zoom:70%;">
</center>
<center>
Figure 3. 相机关系与对极约束[1]
</center>
<p>​ 如图，<span class="math inline">\(e_2\)</span>就是<span class="math inline">\(C_1\)</span>对应相机的极点。而另一个点<span class="math inline">\(Am_1\)</span>（灭点的映射）。而由于公式<span class="math inline">\(\eqref{homo1}\)</span>对应了一个线性映射，并且有两个点已知：</p>
<div class="note "><h5 id="一个结论">一个结论</h5>
<p>我们可以知道，投影在相机1下，并且像素位置为图上<span class="math inline">\(m_1\)</span>位置的所有3D位置点，将会投影在相机2由<span class="math inline">\(e_2\)</span>以及<span class="math inline">\(Am_1\)</span>确定的直线上。</p>
</div>
<p>我们将这条线称为<span class="math inline">\(m_1\)</span>在相机2下的极线（epipolar line）。</p>
<p>​
我们回过头来看2.2中的双目问题，由于未标定的相机（正如上图所示）是双目相机的一般化：</p>
<blockquote>
<p>Suppose we have two images, taken at the same time and from different
viewpoints. Such setting is referred to as
<strong><u>stereo</u></strong>.</p>
</blockquote>
<p>​ 在一般的两相机 (stereo) 情形下，进行correspondence
search应该是在极线上进行，而标定后的简化双目模型，其极线就是特殊的水平线。由于：</p>
<ul>
<li>极点（如<span class="math inline">\(e_2\)</span>）根据定义，由于其在<span class="math inline">\(C_2\)</span>所在的X轴上，投影不存在，可以认为在无穷远处</li>
<li>对于相机1的任意一个位置，其投影灭点投影应该是存在的，但与一个X轴上无穷远点形成连线，可以（intuitively）认为形成的极线是水平的。</li>
</ul>
<p>​ 这也反过来说明了双目问题水平搜索的正确性。</p>
<p>​
讨论完双目问题之后，再来细致地看一下“<strong><u>一个结论</u></strong>”中说的投影点必须在直线上这一结论。此时我们知道<span class="math inline">\(e_2\)</span>，<span class="math inline">\(m_2\)</span>，<span class="math inline">\(Am_1\)</span>在同一直线上。这能导出什么有用的信息？显然，三者线性相关，列向量组成的<span class="math inline">\(3\times 3\)</span>矩阵缺秩。 <span class="math display">\[
|\begin{pmatrix}
e_2 &amp; Am_1 &amp; m_2
\end{pmatrix}|=0, \text{ where |·| means determinant}
\]</span> ​ 注意上述矩阵<span class="math inline">\((e_2 \quad Am_1\quad
m_2)\)</span>每一列的第三分量都是1，并不只是简单的一个二维矩阵。显然，<span class="math inline">\(e_2\)</span>与<span class="math inline">\(Am_1\)</span>确定的平面法线垂直于<span class="math inline">\(m_2\)</span>：</p>
<center>
<img src="/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/draw.jpg" style="zoom:45%;">
</center>
<center>
Figure 4. 外积与垂直关系
</center>
<p>​
用goodnote随便涂了两笔，其中蓝色，红色以及黑色线才是真正的向量。由于外积可以写为反对称矩阵形式，也即：
<span class="math display">\[
\begin{equation}
a\times b=[(a_1\quad a_2\quad a_3)^T]\times b=[a]_\times
b=\begin{pmatrix}
0 &amp; -a_3 &amp; a_2 \\
a_3 &amp; 0 &amp; -a_1 \\
-a_2 &amp; a_1 &amp; 0
\end{pmatrix}b
\end{equation}
\]</span> ​ 则可以得到： <span class="math display">\[
\begin{equation}
|\begin{pmatrix}
e_2 &amp; Am_1 &amp; m_2
\end{pmatrix}|=0\iff m_2^T([e_2]_\times Am_1)=0\rightarrow
m_2^T([e_2]_\times A)m_1=0
\end{equation}
\]</span> ​ 我们把矩阵<span class="math inline">\([e_2]_{\times}A\)</span>称为：基础矩阵（fundamental
matrix）(<span class="math inline">\(F\)</span>)，其限定了由对极约束的两个图像点之间的关系。</p>
<hr>
<h2 id="iii.-eccv-2020-atlas">III. ECCV 2020: Atlas</h2>
<p>​ 最终重建基于TSDF (truncated-SDF)。网络主要结构：</p>
<p><img src="/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/atlas.png"></p>
<center>
Figure 5. 大力神的网络结构
</center>
<p>​ 经过流程主要是：</p>
<ul>
<li>2D特征提取，提取每张图像点的特征。</li>
<li>特征反投影，也就是由2D变为3D。这个反投影过程基于：
<ul>
<li>空间voxelize，作者称之为feature volume</li>
<li>相机模型，将一个点的特征投至与其关联光线穿过的所有voxel（如果我没理解错的话）</li>
</ul></li>
<li>增量融合：一张一张图像叠在一起，形成的feature volume
<strong><u>变换到统一世界坐标系下</u></strong> 增量叠加。</li>
<li>形成一个dense的feature volume，这点我简单说一下：</li>
</ul>
<center>
<img src="/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/sketch.png" style="zoom:40%;">
</center>
<center>
Figure 6. 相机在volume中反投影示意图1（sketchup 2015）
</center>
<p>​
由于每张图像都会形成一个volume，比如蓝色的为相机于位置1全局volume中得到的反投影，红色为相机在位置2下于全局volume中得到的反投影，为了方便观察，我将两者分开（实际上全局只存在一个灰色的volome），两者叠加：</p>
<center>
<img src="/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/sk2.png" style="zoom:50%;">
</center>
<center>
Figure 7. 相机在volume中反投影示意图2（sketchup 2015）
</center>
<p>​
其中有些部分会有叠加，并且如果：某一部分在位姿1下观测到（在蓝色frustum内），并且也在位姿2下观测到（红色frustum内），由加权running
average，特征会被保留，如果某些特征只在辆frustum的对称差集内（只有一个位姿有观测），那么加权平均将会弱化这些特征的存在性（毕竟如果在很多帧的情况下，某个位置都只被一个位姿观测到，那么大概率这个位置被遮挡了或者是一些不重要的角落）。根据加权平均（原文公式(3)(4)），观测点越少，特征越不显著（幅值越接近0）。</p>
<ul>
<li>下一步是3D encoder-decoder模型，使用了<span class="math inline">\(3\times3\times3\)</span>卷积以及<span class="math inline">\(1\times1\times
1\)</span>卷积（用于特征维度的变换），关于3D卷积的一点点分析，见此PDF：[TODO]
<ul>
<li>形状还是类似bottleneck</li>
</ul></li>
<li>作者在此处用了以下一些手段来保证训练的效果，因为这一部分直接回归TSDF（事关结果质量）：
<ul>
<li>encoder-decoder模型由于有bottleneck形状，上采样过程中每层都会输出TSDF，在不同精细度下与ground
truth进行对比监督</li>
<li>TSDF中的“Focal loss”，由于3D重建中存在大量empty
space，对训练其实没有帮助，TSDF距离大于0.99者被强制设为1，并且阻断反向的梯度流动，这样这些voxel对结果将不产生影响</li>
<li>惩罚墙中墙等现象，由于重力存在，3D重建简单场景时，竖直方向是可以整体来看的，比如对于一座简单的山（没有空洞，没有大于等于90度的峭壁），一整个voxel
volume中，对于平面上任意竖列voxel，一定是下部存在voxels（山），上部不存在（空气）。并且由于TSDF重建是用marching
cubes寻找等势面，重建的voxels只存在于表面，内部应该也不会有。故在这种简单情形下，我们可以认为，每一列就仅应该存在一个点（表示简单山表面）。</li>
<li>上面的意思就是说：如果在这座假想的简单山<strong><u>内部</u></strong>进行采样，由于内部是不存在表面重建的voxel的（空的），我们的重建不应该在对应位置增加一个
墙中点。</li>
</ul></li>
</ul>
<blockquote>
<p>However, to prevent the network from hallucinating artifacts behind
walls, outside the room, we also mark all the voxels where their entire
vertical column is equal to 1 and penalize in these areas too. The
intuition for this is that if the entire vertical column was not
observed it was probably not within the room.</p>
</blockquote>
<p>​ 不过笔者认为，关于“artifacts behind
walls”这一部分，个人的解释还有一定问题（感觉有点强行解释），而网络上也无法找到对应的资料，如有人刚好读到此处并且有自己的理解，还望不吝赐教。</p>
<p>​ 所以其中重要的部分是？个人认为是这么两部分：</p>
<ul>
<li>2D特征反投影及加权平均融合：这一步真正生成了可用的feature
volume</li>
<li>3D特征encoder-decoder：对于feature
volume的重映射，并生成多尺度信息</li>
</ul>
<p>​ 其中feature
volume生成有点意思，但个人认为可能这种正向的（2D-&gt;3D）资源消耗更大，毕竟每张图像都对应了一个feature
volume（虽然是增量的叠加）。</p>
<hr>
<h2 id="iv.-nips-2021-transformerfusion">IV. NIPS 2021:
TransformerFusion</h2>
<p>​
在上一小节末，我提到：<strong><u>正向的</u></strong>方法，其实我个人并没有看多少篇多视角3D重建的文章，也不知道是否有对应方法的分类。此文的特点就是：使用了反向的方法（3D-&gt;2D），并且使用了transformer（但个人感觉这里用transformer可能有些缺点，之后再说）。</p>
<p><img src="/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/trans.png"></p>
<center>
Figure 8. TransformerFusion主要结构
</center>
<p>​
基于DL的方法开始总是离不开特征学习，至于怎么使用，这是不同的网络架构需要考虑的事情。</p>
<p>​
此文并没有使用层级，只是分成了coarse以及fine两部分，层与层之间在处理的较后部分才存在联系。其中要说的是transformer的
<strong><u>反向法</u></strong>。关于本文使用的tricks，个人不想再多说，什么free-space
filtering（用类似于第三节说的“Focal loss”）以及refinement
network，感觉大多数工作都会有。本节只想着重讨论此文方法与ECCV
2020方法的区别，以及其transformer的使用优劣之处。</p>
<p>​
与正向法相对，反向法对于每张图像上的特征并不直接反投影到全局的feature
volume再进行求和（平均），反向法处理的视点是每一个3D
voxel。在一个全局volume中，对于一个特定的voxel <span class="math inline">\(v\)</span>，我在不同的图像中查找：</p>
<ul>
<li>此voxel在经过投影后，是否落在图像中？如果不再就跳过，如果在，将会选取本图像投影点附近的特征（根据线性插值）</li>
</ul>
<p>​ 正向法中是2D-&gt;3D信息流，使用反投影正向计算。而反向法是3D-&gt;2D的
<strong><u>查找</u></strong>
方式。从个人的感受上而言，笔者认为反向法更加优雅。</p>
<p>​
另一方面，transformer具体做了什么？对于任意一个重建voxel，不同图像拍摄得到的信息对此voxel的贡献肯定是不一样的，比如我要重建你的鼻子，那么距离近并且角度合适的图像学习的特征大概率比距离远或角度不合适图像产生的特征更加有价值。<strong><u>不同图像对某一点特征的贡献度</u></strong>
将由transformer来评定。</p>
<p>​
transformer不仅仅输出【经过attention机制评定贡献度】融合的多张图像特征，还输出softmax时的概率（也就是每张图像的贡献weight），这是为了进行
<strong><u>视角选择（view
selection）</u></strong>。看到这里，我感觉到一阵莫名的亲切，这不就是2D
SLAM里的点云融合吗？所以这也成了我认为本文存在的不足之处。</p>
<h5 id="transformer-pros-cons">Transformer Pros &amp; Cons</h5>
<div class="tabs" id="span-unique"><ul class="nav-tabs"><li class="tab active"><a href="#span-unique-1">Pros</a></li><li class="tab"><a href="#span-unique-2">Cons</a></li></ul><div class="tab-content"><div class="tab-pane active" id="span-unique-1"><p>​
Transformer确实应该用，【贡献不同】这点从直觉上就很正确，与其使用别的方法进行学习，不如直接加attention，此处也非常适合attention操作。ECCV
2020一文中，对于不同视角下的特征，并没有明显的区分性，可以说是一视同仁，如果要说3D
CNN进行了一些取舍，未免有些牵强。ECCV
2020中，如何区分significance，成了非常魔法的一部分。</p></div><div class="tab-pane" id="span-unique-2"><p>​ Transformer是<span class="math inline">\(O(n^2)\)</span>的，并且如果要深究，此处应该用Set
Transformer这样置换不变的网络（并且人家Set Transformer至少还用induced
point方法降低了复杂度）。而若要限制复杂度，就可以用
<u><strong>队列</strong></u> 的方式，我只需要保存不超过<span class="math inline">\(N\)</span>张图片，算法就不会越跑越慢了。但这其实也不太爽，对于每一个voxel，我需要维护的是一个小顶堆。由于本网络输出每张图像的weight，根据weight选择，超出堆大小就drop堆顶weight最小的图像特征。这样的话，烦人的就是管理的复杂度了，相比之下attention复杂度可能还小些？如果考虑一整个feature
volume，那么复杂度就是<span class="math inline">\(O(n^3N(C+1))\)</span>，其中n是volume大小，<span class="math inline">\(N\)</span>是堆大小，<span class="math inline">\(C\)</span>是特征维度，+1表示需要保存weight。</p></div></div></div>
<p>​
综上，transformer的attention，个人觉得是一个可保留的点，但是transformer带来的overhead个人感觉又是一个不可忽视的问题。至于怎么解决，个人粗略一想只想到
对于feature volume进行pruning（使得feature
volume不要是dense的），毕竟<strong><u>3D表面重建</u></strong>，<strong><u>表面表面</u></strong>，重建的是3D空间中的2D流形，存储复杂度在理想情况下应该是<span class="math inline">\(O(n^2)\)</span>的，那么多空区域扔一扔，都留下来的话，简直就是土匪，土匪都不如。</p>
<center>
<img src="/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/disgust.jpeg" style="zoom:80%;">
</center>
<center>
Figure 9. 反正钱肯定是挣不着啦
</center>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://www.nowpublishers.com/article/Details/CGV-007">Foundations
and Trends® in Computer Graphics and Vision - Vol 4 - Issue 4: 3D
Reconstruction from Multiple Images Part 1: Principles</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>3D重建</tag>
      </tags>
  </entry>
  <entry>
    <title>我贫瘠的数学世界【1】- SAM与优化方法</title>
    <url>/2022/01/30/%E6%88%91%E8%B4%AB%E7%98%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B8%96%E7%95%8C%E3%80%901%E3%80%91-SAM%E4%B8%8E%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h1 id="bfgsam">BFGSAM</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​
很长一段时间没有静下心来看过有很强理论性的内容了，我十分担心自己会丧失理论上的思考能力以及数学计算能力。正好之前在看某篇论文时，看到其中提到一种叫做SAM（sharpness
aware
minimization）的方法，说是效果还行，此前保存了SAM论文，但没去细读。最近寒假由于电脑故障没办法工作，很闲，便重新了解了一些数值优化方面的知识（比如拟牛顿族），并读了读SAM（虽然读完感觉？？？这怎么这么魔法）</p>
<ul>
<li><a href="https://arxiv.org/pdf/2010.01412.pdf">ICLR 2021: Foret,
Pierre, et al. "Sharpness-aware minimization for efficiently improving
generalization." <em>arXiv preprint arXiv:2010.01412</em>
(2020).</a></li>
<li><strong><u>《我这种菜鸡哪有资格觉得DL顶会论文魔法》系列</u></strong>（下图图源论文）</li>
</ul>
<p><img src="/2022/01/30/%E6%88%91%E8%B4%AB%E7%98%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B8%96%E7%95%8C%E3%80%901%E3%80%91-SAM%E4%B8%8E%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/sam.png"></p>
<span id="more"></span>
<hr>
<h2 id="ii.-条件数与quasi-newton">II. 条件数与quasi-Newton</h2>
<h3 id="条件数与稳定性">2.1 条件数与稳定性</h3>
<p>​ 条件数（condition number）：</p>
<blockquote>
<p>The <strong>condition number</strong> of a <a href="https://en.wikipedia.org/wiki/Function_(mathematics)">function</a>
measures how much the output value of the function can change for a
small change in the input argument.</p>
</blockquote>
<p>​
这个概念也就是一个衡量输入输出关系的指标：输入发生小的改变是否会使得输出发生大的改变？如果会，那么优化结果将有很大的抖动。比如在深度学习中，观察loss曲线，loss波动非常大，可能因为条件数太大，需要使得输入的变化在合理范围内减小（控制学习率）。</p>
<p>​
这里我们不对一般的优化问题进行讨论，只讨论矩阵情况。矩阵中，条件数是：
<span class="math display">\[
\begin{equation}
\kappa(A)=\frac {\sigma_{\max}(A)}{\sigma_{\min}(A)}
\end{equation}
\]</span> ​ 其中<span class="math inline">\(\sigma_{\max}\)</span>代表矩阵A的最大奇异值（如果是非奇异矩阵，就是最大特征值），<span class="math inline">\(\sigma_{\min}\)</span>是最小特征值。经常我们在奇异值分解时，取出其对角值，判定最大特征值与最小特征值之比，如果过大就进行一些保护操作，实际上就是在保护大条件数时的解情况。</p>
<p>​ 条件数确定了一个问题的前后向稳定性：</p>
<blockquote>
<p>算法的“前向误差”是结果与真解之间的差别，即<span class="math inline">\(\Delta y=y^{*}-y\)</span>。“后向误差”是满足<span class="math inline">\(f(x+\Delta x)=y^{*}\)</span>的最小<span class="math inline">\(\Delta
x\)</span>，也就是说后向误差说明算法的所解决的问题。前向误差和后向误差通过条件数发生关系：前向误差的幅度最多是条件数乘以后向误差的幅度。[2]</p>
</blockquote>
<h3 id="preconditioning">2.2 Preconditioning</h3>
<p>​
假设我们已经知道，某个问题的条件数很大（ill-conditioned），但我们又不得不解这个问题，应该怎么办？使用preconditioner（怎么翻译，不知道，日语翻译是“前処理行列”，好吧人家都是中文）</p>
<blockquote>
<p>In mathematics, <strong><u>preconditioning</u></strong> is the
application of a transformation, called the
<strong><u>preconditioner</u></strong>, that conditions a given problem
into a form that is more suitable for numerical solving methods.[3]</p>
</blockquote>
<p>​ 此处简单翻译一下英文维基（因为没有中文，而英文讲得挺清楚的）：</p>
<ul>
<li>首先假设我们有一个病态线性问题：</li>
</ul>
<p><span class="math display">\[
\begin{equation}
Ax=b
\end{equation}
\]</span></p>
<ul>
<li>可以用一个 <strong><u>preconditioner矩阵</u></strong> <span class="math inline">\(P\)</span> 使得<span class="math inline">\(P^{-1}A\)</span>使得条件数小于A：</li>
</ul>
<p><span class="math display">\[
\begin{equation}
AP^{-1}(Px)=b
\end{equation}
\]</span></p>
<ul>
<li>我们认为：<span class="math inline">\(AP^{-1}\)</span>是一个新的矩阵<span class="math inline">\(Q\)</span>，也就得到：<span class="math inline">\(Qy=b\)</span>这个问题，首先解这个问题得到<span class="math inline">\(y\)</span>后再根据<span class="math inline">\(Px=y\)</span>解出<span class="math inline">\(x\)</span></li>
</ul>
<p>​
很巧妙的方法。进一步了解这种方法的应用以及其work的机制，参见reference。</p>
<h3 id="quasi-newton法简介">2.3 Quasi-Newton法简介</h3>
<p>​
拟牛顿（quasi-Newton）法，顾名思义就是牛顿法的近似。牛顿法需要用到二阶导，在更加一般的情况下---海森（Hessian）阵。但并不是所有函数都容易求二阶导，要么是因为其解析表达式太复杂，要么是因为维度太高，二阶导的时空开销都是至少<span class="math inline">\(O(n^2)\)</span>的。此时我们可以使用一些方法来近似海森矩阵，用近似的海森矩阵计算更新方向。在此我将简介一些更为熟知的拟牛顿迭代方法（的好处）：BFGS（族），DFP，SR1。</p>
<p>​
BFGS（四个人名字貌似）是一种很好用的拟牛顿迭代算法，相比于DFP以及SR1，这个算法可能有一定优势（要不然为什么Google
ceres
solver里的线搜索只提供LBFGS以及BFGS？难不成因为写起来简单？），并且其存在一种对内存以及算力更加友好的实现（Limited-BFGS），这个更友好的实现可以摆脱普通BFGS的<span class="math inline">\(O(n^2)\)</span>时间复杂度，使得时间复杂度变为<span class="math inline">\(O(mn)\)</span>，一般来说m都小于n。</p>
<div class="tabs" id="span-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#span-unique-name-1">BFGS</a></li><li class="tab"><a href="#span-unique-name-2">DFP</a></li><li class="tab"><a href="#span-unique-name-3">SR1</a></li></ul><div class="tab-content"><div class="tab-pane active" id="span-unique-name-1"><ol type="1">
<li>维持对称正定性。(2) 一种奇妙的自我矫正能力。(3)
对于大型稀疏问题非常有效</li>
</ol>
<blockquote>
<p>BFGS is the most effective quasi-Newton correction... Also, BFGS has
self-correcting properties: if <span class="math inline">\(H_k\)</span>
incorrectly approximates the curvature of the objective function and
this estimate slows down the iteration, then the (inverse) Hessian
approximation will tend to correct itself in the next few steps. [4]</p>
</blockquote></div><div class="tab-pane" id="span-unique-name-2"><ol type="1">
<li>第一个提出的quasi-Newton方法，是BFGS
update的对偶。（2）在解决二次问题时，迭代产生共轭方向（与共轭梯度法重合）。(3)
对于大型问题，效率非常低。</li>
</ol>
<blockquote>
<p>This formula, like BFGS, is a rank 2 formula update and it has nice
properties as well, however it is not as fast. It is less effective than
BFGS at self-correcting of the Hessians. Likewise, DFP could fail for
general nonlinear problems, it can stop at a saddle point, it is
sensitive to inaccurate line searches and it’s Hessian updates are
sensitive to round-off errors and other inaccuracies. [4]</p>
</blockquote></div><div class="tab-pane" id="span-unique-name-3"><p>​ SR1如其名（Symmetric Rank-1），DFP与BFGS都是秩-2算法。</p>
<blockquote>
<ul>
<li>The matrices generated are very good approximations to the (inverse)
Hessian matrices, often better than BFGS.</li>
<li>The drawback of the method is that sometimes <span class="math inline">\((s_k − H_ky_k)^Ty_k\approx0\)</span> and there may
not be a symmetric rank one formula that satisfies the secant condition.
Hence instabilities and breakdown may occur.</li>
</ul>
</blockquote></div></div></div>
<p>​
秩-1算法（SR-1）得到的海森矩阵可能比秩-2算法的海森矩阵更好，但是它无法保证更新矩阵的正定性，线搜索将是非精确线搜索[5]（来自台湾一个叫做，国立中正大学的课件，这大学名字感觉一看就知道在纪念谁）。</p>
<h4 id="bfgs法推导">2.4 BFGS法推导</h4>
<p>​
中文维基的话呢，就是简单告诉你：算法就是这样，至于推导，自己推去吧。英文维基则没有过程。推导并不难（别在开始时抄错公式就行，我因为抄错公式而花了一个半小时用各种方法推而没有结果，果然努力是不值钱的，方向错了一点用都没有）。</p>
<p>​ 首先，拟牛顿法都基于这一个假设：更新方向<span class="math inline">\(\pmb{p}_k\)</span>与海森近似阵<span class="math inline">\(B_k\)</span>，梯度的关系正如牛顿法中海森梯度与更新方向的关系如下，当然，我们也可以将这里视为对梯度的preconditioning：
<span class="math display">\[
\begin{equation}
B_k\pmb{p}_k=-\nabla f(x_k)
\end{equation}
\]</span> ​ 由于<span class="math inline">\(\pmb{p}_k\)</span>只是一个方向，可将其写为<span class="math inline">\(\pmb{p}_k=\alpha(x_{k+1}-x_k)\)</span>。注意拟牛顿条件：
<span class="math display">\[
\begin{align}\label{quasi}
&amp;f(x_k+\Delta x)\approx f(x_k)+\nabla f(x_k)\Delta x + \frac
12\Delta x^TB\Delta x\rightarrow\\
&amp;\text{Approx linearity: }\nabla f(x_k+\Delta x) \approx \nabla
f(x_k)+ B\Delta x\rightarrow\\
&amp;B_{k+1}(x_{k+1}-x_k)=\nabla f(x_{k+1})-\nabla{f(x_k)}\\
&amp;\text{let: } y_k=\nabla f(x_{k+1})-\nabla{f(x_k)},
s_k=x_{k+1}-x_k\\
&amp;\text{thus, }B_{k+1}s_k=y_k\label{update}
\end{align}
\]</span> ​ 则更新<span class="math inline">\(B_k\)</span>（或者称为correction），<strong><u>必须要使得<span class="math inline">\(B_{k+1}\)</span>满足公式<span class="math inline">\(\eqref{update}\)</span></u></strong>。在BFGS中，为了满足对称且正定（positive
definiteness），人为使得更新公式如下： <span class="math display">\[
\begin{equation}\label{new}
B_{k+1}=B_k+\alpha u_ku_k^T+\beta v_kv_k^T
\end{equation}
\]</span> ​ 注意其中<span class="math inline">\(u,v\)</span>均是列向量。只要公式<span class="math inline">\(\eqref{new}\)</span>满足更新公式<span class="math inline">\(\eqref{update}\)</span>即可。注意公式<span class="math inline">\(\eqref{new}\)</span>后有两个更新项，只有一个时将是秩1算法。在这里，我们就地取材，使得<span class="math inline">\(u_k=y_k,v_k=B_ks_k\)</span>。求<span class="math inline">\(\alpha,\beta\)</span>。</p>
<p>​ 则带入公式<span class="math inline">\(\eqref{update}\)</span>，整理后可以得到： <span class="math display">\[
\begin{align}
&amp;(B_k+\alpha u_ku_k^T+\beta v_kv_k^T)s_k=y_k\rightarrow\\
&amp;(\alpha u_ku_k^T+\beta v_kv_k^T)s_k=y_k-B_ks_k\rightarrow\\
&amp;(\alpha u_k^Ts_k)u_k+(\beta v_k^Ts_k)v_k=y_k-B_ks_k\rightarrow\\
&amp;\text{for: }u_k=y_k,v_k=B_ks_k\\
&amp;\text{let: }\alpha u_k^Ts_k=1,\beta v_k^Ts_k=-1\\
&amp;\alpha=\frac
1{y_k^Ts_k},\beta=-\frac{1}{s^T_kB_k^Ts_k}=-\frac{1}{s^T_kB_ks_k}
\end{align}
\]</span> ​ 则可以得到更新公式。</p>
<hr>
<h2 id="iii.sam">III.SAM</h2>
<p>​
这篇论文我也不是很想细讲，不知道是因为我没有深入理解还是这篇论文本身就有那么一点魔法，个人感觉此文最后得出的算法貌似很trivial。SAM（sharpness
aware
minimization）是一种新的误差函数，此误差函数可以提升网络的泛化能力（<strong><u>使得最优值附近较为平滑</u></strong>）。</p>
<p>​ 一般的提升泛化能力方法可以分为这么几种：</p>
<ul>
<li><p>限制活动参数数量：weight
decay（限制部分参数的存在）、Dropout（参数随机存在）以及比较新的stochastic
depth（随机扔层，多用在attention结构中）</p></li>
<li><p>loss方面：比如分类问题中的label smoothing loss，使得one-hot变成了
0.9或者0.8
hot，label不再是硬的，或者说是从分类问题转化为回归问题，从“数字信号学习”变为“模拟信号学习”。</p></li>
<li><p>数据处理方面：数据增强（传统），Random
Erase，mixup/cutmix（现代数据增强）。</p></li>
</ul>
<p>​ 在loss方面，如果说label
smooth算是杰出的一个泛化能力增强尝试的话，个人觉得这还是不够的。毕竟这就不优雅。本来人家猫就是猫，我能很明确告诉你这就是猫，100%概率，但label
smooth偏要说这是90%的置信度，强行软化。</p>
<p>​
SAM则着重于优化网络学习结果计算的loss形状。假设我们把loss值函数看作是：
<span class="math display">\[
\begin{equation}
l=L(x;\theta)
\end{equation}
\]</span> ​ 其中x是输入数据，<span class="math inline">\(\theta\)</span>是网络参数。我们大可以将上式看作是关于<span class="math inline">\(\theta\)</span>的函数（可以认为输入给定），那么我们希望对于任意给定输入，loss都能保持一定的平滑性，正如我们希望
<strong><u>超平面是存在平滑性的</u></strong>，以免发生过拟合。那么如何保证此“平滑性”？</p>
<p>​ <del>首先，我们知道，根据某个xx理论 显然 不难得到 易于证明
QED</del>。首先，作者将问题写成了这样（这里我跳过了作者抛出的一个theorem），假设我们现在已经有了一个参数<span class="math inline">\(w\)</span>（这是个向量但我不想打<code>\pmb&#123;&#125;</code>，为了方便），我们需要找一个有更强泛化能力的参数<span class="math inline">\(w^*\)</span>，那么<span class="math inline">\(w\)</span>局部最大loss可以写为： <span class="math display">\[
\begin{align}
&amp;[\mathop{\max}_{|\epsilon|_2\leq\rho}L_s(w+\epsilon)-L_s(w)]+L_s(w)+\lambda\Vert
w\Vert^2\label{div}\\
&amp; L_s^{SAM}:=\mathop{\max}_{|\epsilon|_2\leq\rho}L_s(w+\epsilon)
\end{align}
\]</span> ​ 其中<span class="math inline">\(\rho\)</span>是个超参数。作者将局部最大loss拆分为<span class="math inline">\(\eqref{div}\)</span>就是为了说明：方括号里的项实际上包含了局部变化率信息（越大说明sharpness越高），剩余部分就是plain
loss with regularizer。</p>
<p>​ 作者进一步认为： <span class="math display">\[
\begin{align}
\epsilon^*(w)=\mathop{\arg\max\;}_{|\epsilon|_2\leq\rho}L_s(w+\epsilon)\mathop{\approx}^{Taylor}\mathop{\arg\max\;}_{|\epsilon|_2\leq\rho}L_s(w)+\epsilon^T\nabla_wL_s(w)=\mathop{\arg\max\;}_{|\epsilon|_2\leq\rho}\epsilon^T(w)\nabla_wL_s(w)
\end{align}
\]</span></p>
<p>​ 感觉如果直接求解<span class="math inline">\(\arg\max\epsilon^T(w)\nabla_wL_s(w)\)</span>
只是求解在对应参数点<span class="math inline">\(w\)</span>，与<span class="math inline">\(L_s\)</span>梯度内积最大的参数偏移值。这么看来，貌似<span class="math inline">\(\epsilon\)</span>的方向与<span class="math inline">\(\nabla L_s(w)\)</span>一致，范数取最大值（<span class="math inline">\(\rho\)</span>）即可？作者最后确实也是这么解的：
<span class="math display">\[
\begin{equation}\label{max}
\epsilon^*(w)=\rho\text{
sign}(\nabla_wL_s(w))|\nabla_wL_s(w)|^{q-1}/\left(\Vert\nabla_wL_s(w)
\Vert^q_q\right)^{1/p}
\end{equation}
\]</span> ​ 作者说p=q=2是最优参数。但... 为什么要用 sgn函数？这里...
作者写复杂了。<span class="math inline">\(|...|\)</span>是 element-wise
absolute操作，sgn + |...|
相当于是先取每个元素的值，归一化后再将原来的方向加上。</p>
<p>​ 由于公式<span class="math inline">\(\eqref{max}\)</span>求出了最终的<span class="math inline">\(\epsilon\)</span>，那么我们的<span class="math inline">\(L_s^{SAM}(w)\)</span>梯度可以求出如下，由于<span class="math inline">\(L_s^{SAM}(w)\approx L_s(w+\epsilon^*(w))\)</span>:
<span class="math display">\[
\begin{align}
&amp;\nabla_wL_s^{SAM}(w)\approx
\nabla_wL_s(w+\epsilon^*(w))=\frac{d(w+\epsilon^*(w))}{dw}\nabla_w{L_s(w)}|_{w=w+\epsilon^*(w)}\rightarrow\\
=&amp;\nabla_w{L_s(w)}|_{w=w+\epsilon^*(w)}+\left[\frac{d(\epsilon^*(w))}{dw}\nabla_w{L_s(w)}|_{w=w+\epsilon^*(w)}\right]
\end{align}
\]</span> ​ 最后，作者甚至将上式方括号内的项省略掉，直接一步： <span class="math display">\[
\begin{equation}
\nabla_wL_s^{SAM}(w)\approx \nabla_w{L_s(w)}|_{w=w+\epsilon^*(w)}
\end{equation}
\]</span> ​
个人感觉很暴力。因为假设这样，假设在SGD背景下进行迭代，每一次将直接取负梯度方向优化，而SAM则是首先计算本参数所在位置的梯度，之后设置一临时向量，其值是梯度归一化结果乘以ρ，计算实际更新方向时，当前参数加临时向量位置evaluate得到梯度后当作方向。而ρ是个魔法参数，也不自适应，甚至我都不知道ρ是否鲁棒，是否会出现ρ“条件数大”的情况。作者相当于在此处：</p>
<div class="note warning"><p>​
每次不在参数位置获得梯度，而在参数附近的一个魔法位置获得梯度。作者的理论也很魔法，核心部分竟然是一个一阶泰勒展开的极值（内积最大值结果），作者将其说成是
<strong><u>dual norm
problem</u></strong>，好家伙，一下成了泛函分析问题了，逼格++。</p>
</div>
<p>​
虽然本文引用量100+，但个人始终感觉<strong><u>不太对劲</u></strong>（很魔法），有机会将尝试一下本算法。不过按道理来说，如果这个方法很成功，就像AdamW
&gt;
Adam这样，SAM一定会被Pytorch进行官方实现的，引用量比肩ResNet、transformer也说不定，<strong><u>可惜并没有</u></strong>。</p>
<p>​
个人水平实在有限，没办法读出本文的深意，也没办法从中获得启发，如果有读者对此文产生兴趣并有自己的深入理解，笔者愿意深入探讨。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://en.wikipedia.org/wiki/Condition_number">Wikipedia:
Condition number</a></p>
<p>[2] <a href="https://en.wikipedia.org/wiki/Numerical_stability">Wikipedia:
Numerical stability</a></p>
<p>[3] <a href="https://en.wikipedia.org/wiki/Preconditioner">Wikipedia:
Preconditioner</a></p>
<p>[4] <a href="http://people.math.sfu.ca/~elushi/project_833.pdf">Yang
D., Enkeleida L., Qingguo L., Investigation of quasi-Newton methods for
unconstrained optimization</a></p>
<p>[5] <a href="https://www.cs.ccu.edu.tw/~wtchu/courses/2012s_OPT/Lectures/Chapter%2011%20Quasi-Newton%20Methods.pdf">Chapter
11 Quasi-Newton Methods</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>优化理论</tag>
      </tags>
  </entry>
  <entry>
    <title>Instant Neural Graphics Primitives</title>
    <url>/2022/01/23/Instant-Neural-Graphics-Primitives/</url>
    <content><![CDATA[<h1 id="instant-ngp">Instant NGP</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​ 保研前是想搞3D重建来着，大概是无缘吧（xD）。最近老被安利 【5s
NeRF训练】，听起来很强的样子，速度提升了好几个数量级，遂观摩了一下：</p>
<ul>
<li><a href="https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.pdf"><strong>Instant
Neural Graphics Primitives with a Multiresolution Hash Encoding</strong>
Thomas Müller, Alex Evans, Christoph Schied, Alexander Keller
arXiv:2201.05989 [cs.CV], Jan 2022</a></li>
</ul>
<p>​ 文章很有趣，对我现有工作有一定的启发价值，当然结果也很nice：</p>
<center>
<img src="/2022/01/23/Instant-Neural-Graphics-Primitives/robot5.gif" style="zoom:125%;">
</center>
<center>
Figure 1. Hoho. Da. Nice.
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-简单分析">II. 简单分析</h2>
<h3 id="本文在解决什么问题">2.1 本文在解决什么问题</h3>
<p>​ 本领域我了解很少，在搞2D
SLAM时了解过一些SLAM对地图的建模方式。其中有一个方式叫做隐式函数（implicit
functions），旨在用一个参数化的函数来表示一个曲面。而当下神经网络应用火爆，这种参数化的表面表征当然可以使用深度学习的方式来学习。比如如下两篇论文所说的：</p>
<blockquote>
<p>Neural SDFs are typically encoded using large, fixed-size MLPs which
are expensive to render.[1]</p>
</blockquote>
<blockquote>
<p>Our algorithm represents a scene using a fully-connected
(non-convolutional) deep network, whose input is a single continuous 5D
coordinate (spatial location (x, y, z) and viewing direction (θ, φ)) and
whose output is the volume density and view dependent emitted radiance
at that spatial location.[2]</p>
</blockquote>
<p>​
最容易理解的例子应该就是SDF（有向距离场），之前也做过有向距离场表示的点云融合。有向距离场的0集（0-水平集）代表了真实曲面，而有向距离场就是给定一个d维输入（d维空间中的一点），输出正负值（在d-1维流形的“内部”还是“外部”）。那么这个d-1维流形（高维曲面）可以使用神经网络来表示，毕竟神经网络是万能的函数逼近器。如上引用所说，可以使用一个MLP（多层感知机）来“拟合”这个SDF。</p>
<p><img src="/2022/01/23/Instant-Neural-Graphics-Primitives/mlp.png"></p>
<center>
Figure 2. SDF的神经网络表征[1]
</center>
<p>​
但在3D重建领域，训练这个神经网络表征可能非常困难，首先是因为数据的维度比较高，此外是输入量较大。举个例子：NeRF（Neural
Radiance
Field）需要一个物体的多角度输入图像，两张不同图象上对应的不同像素，可能就是两条不同的光线，需要通过已知的相机位姿
+
由内参确定的光线方向求解交点以求解真实的3D点，这一步计算量已经很大了（但按照个人的理解，这一步应该是与神经网络无关的），下一步又需要把真实的3D点与不同角度下的2D点联系起来，训练【5D输入：相机中心位置
+
本图像某一像素点对应的光线两轴角度（没有roll所以是两轴）】-&gt;【5D输出：density（相当于alpha通道）+
view-dependent
RGB】的这样一个网络。如果直接把点值输入，希望在某一个小范围上直接端到端，那可能需要很深的MLP层数才能学到足够好的神经网络近似表征，这样的MLP，一是<strong><u>大</u></strong>，二是
<strong><u>fixed-size and task
dependent</u></strong>，既不好训练又没有普适性。</p>
<p>​ 而作者在related
work中举了一个例子：attention机制中为位置信息引入的positional
embeddings可以使得网络很好地使用（甚至学出）位置信息。把我们的低维信息embed到某个高维空间，使得我们需要训练的MLP输入不再是原始的或者简单处理的数据，而是一个个高维空间中具有良好性质（比如
<strong><u>可插值，n阶连续等等</u></strong>）的encoding，对缩减MLP大小非常有好处。反观attention机制中的一些learnable
positional
embeddings，他们的实现也不过就是（以torch为例）<code>nn.Parameter</code>，并没有说让输入过一些新的层，以一种不额外延长forward
pass长度的方式增加了参数数量。</p>
<p>​
不过实际上，用参数embeddings表示的情况有人已经做过了。举个例子，假设我有一个voxel
map，大小为<span class="math inline">\(L\times W\times H\)</span>，voxel
map中每一个点我都会有一个高维encoding。但作者也说，这存在三个很大的问题：</p>
<div class="note danger"><p>Memory footprint. 如果只用这样的方式设计，内存开销将会是<span class="math inline">\(O(n^3)\)</span>，这还是非常大的，很容易炸显存。</p>
</div>
<div class="note "><p>Trade-off并不值得。如果使用过量的embeddings，很可能出现：整个feature
embeddings
参数块只更新一小部分参数：比如如果是2D地图上的query，在双线性插值的情况下需要取周围四个feature
vectors，更新四个feature
vectors，但MLP的反向传播还是会改动整个MLP的所有参数，花大力气就优化了小部分encodings，可能不值。</p>
</div>
<div class="note warning"><p>稀疏化也不好做。首先，稀疏化是必要的。拿另一个领域（SLAM）中的一个例子来说：占用栅格图，对于没有物体的地方我真的有必要存吗？显然我只需要存障碍物栅格即可。但稀疏化可能很困难，比如用hash方法，可能哈希冲突啊，怎么解决？链表？存到别的位置的冲突处理？这非常不利于GPU并行加速。</p>
</div>
<h3 id="multiresolution-grid">2.2 Multiresolution Grid</h3>
<p>​
个人感觉视角合成或3D重建与双目匹配、光流类似问题还是有很大区别的，而在后两者中，一种常用的处理办法就是特征金字塔（feature
pyramid），其一般目的很简单：在特征金字塔趋于顶端位置（多次下采样后），可以进行粗匹配，粗匹配可以给向下不断扩大的精细特征图提供初值，使之更容易收敛到正确的位置（初值估计）。而视角合成与3D重建中，应该没有这种说法。个人倾向于这样认为：</p>
<ul>
<li>考虑一个一般一维信号，此信号可以进行频谱分解，存在不同频率成分</li>
<li>如果我们把低分辨率（coarse部分）当作低频部分，此部分可以大致刻画局部趋势</li>
<li>把高分辨率部分（fine）当作高频部分，此部分可以刻画局部细节</li>
<li>就比如一座山峰，其整体趋势由低频决定，而山峰上的各种崎岖地形由高频
部分决定</li>
</ul>
<p>​ 也即，multi-resolution
grids是为了兼顾不同方面（低分辨率局部趋势）（高分辨率局部细节）而设置的结构。而作者在此处的设计是这样的：</p>
<p><img src="/2022/01/23/Instant-Neural-Graphics-Primitives/struct.png"></p>
<center>
Figure 3. 整体结构
</center>
<p>​
作者并没有使用稠密的grid结构，稠密的特征grid开销太大了（所以RAFT搞的full
correlation
volume到底在干什么），作者在不同的分辨率层级上射击了双射或满射（应该是满射吧），也即
<span class="math inline">\(f:R^2\rightarrow R\)</span>：</p>
<ul>
<li>在低分辨率层级上，由于grid数量本来就较少，那么每个grid足够分配到一个特征向量</li>
<li>在高分辨率层级上，grid数量多，为了不<span class="math inline">\(O(N^2)\)</span>复杂度增加特征向量，将根据分辨率线性增加特征向量数目，此时可能引发
<u><strong>哈希冲突</strong></u>。</li>
</ul>
<p>​
而暴力划分grid，重建精度将会收到grid分辨率影响，作者直接使用临近点线性插值的方式获得更加“精细”的特征，可插值性在本问题中非常有意义，如果在同一个grid（四个角点对应相同的特征向量index）中两个不同点特征向量在网络输出上并没有平滑性，那么将会使学习到的函数（比如SDF或者radiance
field）<strong><u>不连续</u></strong>，0阶不连续代表着表面连接特性的跳变，在与深度视觉相关的邻域中，0阶不连续是可以容忍的（毕竟存在不同位置的物体以及遮挡），而在单个物体表面重建或视角合成中将导致结果有问题。至于为什么此结构具有可插值性，我将在后文分析。</p>
<p>​ 最后不同分辨率的特征将被concat在一起。用concat的理由：</p>
<blockquote>
<p>First, it allows for independent, fully <strong><u>parallel</u>
processing</strong> of each resolution. Second, a reduction of the
dimensionality of the encoded result <strong>y</strong> from <em>LF</em>
to <em>F</em> may be <strong><u>too small</u></strong> to encode useful
information. (要知道F才2)</p>
</blockquote>
<h3 id="哈希冲突">2.3 哈希冲突</h3>
<p>​
作者说自己并不显式处理哈希冲突，因为哈希冲突的解决涉及到较为复杂的逻辑（并且判断是显著增了）。我们知道，在一个wrap中存在逻辑分支，将会引起wrap
divergence，对于if/else同等计算量需求的操作，将损失至少50%的计算速度。但不解决哈希冲突将导致
<strong><u>两个不相的grid（甚至可能物理距离就很远）</u></strong>映射到同一个特征向量上（hash出来的index是一致的），理论上来说，这将对反向传播过程产生影响（一个特征向量同时在多个不相关的位置贡献loss）。而实际情况中没有影响主要有这么三个原因：</p>
<div class="note "><p>​ Multi-resolution
结构。我们已经提到，（1）低分辨率决定了局部趋势（2）低分辨率足够双射。这样一来，低分辨率决定的局部趋势就可以保证正确性。此外，所有可能产生哈希冲突的分辨率层级同时产生哈希冲突是“statistically
very unlikely to occur
simultaneously”，那么我们就应该看高分辨率下哈希冲突时具体的学习过程。</p>
</div>
<div class="note "><p>​
【这部分我感觉作者有点强行解释】：梯度加权平均。作者认为，即使两个不关联点A，B拥有同一个特征向量，A，B最终贡献给loss的大小也几乎不可能相同。比如A接近物体表面，B在empty
space中，那么最后loss很可能会更倾向于给A更大的权重，造成：同样一个特征向量产生的两份不同梯度，A的梯度方向占主导地位。最后网络也会自行向与A相关的方向优化。</p>
</div>
<p>​
但若考虑到产生多次哈希冲突的情况，个人觉得很有可能产生哈希冲突的这些点各自可能的权重
<strong><u>也随机散布在空间中</u></strong>，那最后合成出来的梯度实际上是个四不像梯度...
还是有可能产生奇怪输出的，只不过“statistically very unlikely to
occur”罢了。于其说是：“implicit hash collision
resolution”，不如说是：我发现不解决哈希冲突本来就基本不可能有啥问题。我个人对这种处理方法的看法是：“mostly
elegant, statistically unlikely to be inelegant”。</p>
<h3 id="可插值性与平滑性">2.4 可插值性与平滑性</h3>
<p>​
笔者已经在上文解释过了，可插值性是<strong><u>非常重要</u></strong>的。但本设计为什么会存在这种可插值性？有如下几个疑问：</p>
<ul>
<li>此设计是天然具有可插值性（就像CNN的平移不变性以及transformer的置换不变性）还是需要靠其他人为步骤的设计使其具有可插值性？</li>
<li>如果是后者，这种奇妙功能是如何实现的？</li>
<li>如果不仅仅需要连续，还需要可导的平滑表面，应该怎么做？</li>
</ul>
<p>​ 作者说：</p>
<blockquote>
<p>Interpolating the queried hash table entries ensures that the
encoding enc(x; θ), and by the chain rule its composition with the
neural network m(enc(x; θ); Φ), are continuous.</p>
</blockquote>
<p>​ 也就是说，multi-resolution hash table
本身是没有可插值性的，正是因为我的插值操作使得网络具有了可插值性【Counter-intuitive】。为什么会这样呢？</p>
<p>​
对于低分辨率层级来说，可能很多输入点都落于一个grid（或者voxel）内部，这时这些点将会共用grid（或者voxel）的角点index，也就是插值所使用的特征向量索引。由于可以认为，输入点在空间上临近，输出结果也要求需要在空间上临近。举一个这样的例子，假设我需要根据2D图像恢复3D模型，那么2D输入点临近对于一个原本连续的形体，应该就是连续的（对于原本就是不连续的形体则另说）。那么，网络根据A,B,C几个点插值后的特征的相似性，结合输出结果在监督下的ground
truth相似性，就能推出此局部是否应该具有可插值性：</p>
<ul>
<li>临近输入导致临近以及相似输出 ---
说明是可插值的，<strong><u>映射函数连续</u></strong></li>
<li>临近输入导致结果差别大或者不相似 ---
说明局部不可插值（可能分属不同物体或者是一个物体的几个分立子原件），允许映射函数不连续</li>
</ul>
<p><img src="/2022/01/23/Instant-Neural-Graphics-Primitives/bunny.png"></p>
<center>
Figure 4. 可插值性图示（图源 Stanford bunny）
</center>
<p>​ 学习连续性还是较为简单的，只需要设置相应的监督【相似/近输入】--&gt;
【相似/近输出】。而对于高阶平滑，比如SDF就要求一阶（导）连续（代表着可导）作者说有如下两种方法：</p>
<div class="tabs" id="span-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#span-unique-name-1">二次或三次插值</a></li><li class="tab"><a href="#span-unique-name-2">插值近似函数</a></li></ul><div class="tab-content"><div class="tab-pane active" id="span-unique-name-1"><p>双二次以及双三次插值可以使得导数不再是呈块状的，而是连续的。但是需要的lookup成本变高了，就拿双三次插值来说，双三次插值需要一次采样16个点的特征向量，而双线性只需要四个点，放在3维空间中开销更加难以接受。</p></div><div class="tab-pane" id="span-unique-name-2"><p><span class="math display">\[
\begin{align}
&amp;S(x)=x^2(3-2x)\\
&amp;S&#39;(x)=6x(1-x)
\end{align}
\]</span> ​
作者推荐这样的插值公式，在双（三）线性情况下只采样4（8）个点，又可以：</p>
<blockquote>
<p>The derivative of the smoothstep vanishes at 0 and at 1, causing the
discontinuity in the derivatives of the encoding to vanish by the chain
rule.</p>
</blockquote>
<p>​
意思是：导数在0，1（也就是插值边界处）为0，根据链式求导的导数相乘，使得边界点的导数为0。也即不会因为线性插值这样在边界出现导数不连续的情况。感觉有点妙。</p></div></div></div>
<hr>
<h2 id="iii.-其他后续">III. 其他后续</h2>
<p>​
笔者近几天回到家没有可用设备来训练，想试试demo但没有办法。笔者之后可能写一篇本文官方实现的源码分析，暂定应该是《CUDA踩坑实录【4】》的内容。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://arxiv.org/pdf/2003.08934.pdf">Mildenhall, Ben,
et al. "Nerf: Representing scenes as neural radiance fields for view
synthesis." <em>European conference on computer vision</em>. Springer,
Cham, 2020</a></p>
<p>[2] <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Takikawa_Neural_Geometric_Level_of_Detail_Real-Time_Rendering_With_Implicit_3D_CVPR_2021_paper.pdf">Takikawa,
Towaki, et al. "Neural geometric level of detail: Real-time rendering
with implicit 3D shapes." <em>Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition</em>. 2021.</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>3D重建</tag>
      </tags>
  </entry>
  <entry>
    <title>Depth Completion论文三篇</title>
    <url>/2022/01/23/Depth-Completion%E8%AE%BA%E6%96%87%E4%B8%89%E7%AF%87/</url>
    <content><![CDATA[<h1 id="depth-completion">Depth Completion</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​
深度补全中存在多模态数据融合的问题：单目RGB图像直接进行深度估计比较困难（直接深度估计，个人感觉只能凭借常识和先验知识），而如果同时存在稀疏激光点云（散步在稠密的图像上），可以通过“传播的思想”将一些位置的深度传播出去。在返乡的高铁上没事干（事实上由于河南大雪以及湖北大雨，高铁变成了低铁，时间+2h），看了五篇论文，本文简要分析了其中三篇关于
guided深度补全的文章：</p>
<ul>
<li>ICCV 2019: <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Xu_Depth_Completion_From_Sparse_LiDAR_Data_With_Depth-Normal_Constraints_ICCV_2019_paper.pdf">Xu,
Yan, et al. "Depth completion from sparse lidar data with depth-normal
constraints." <em>Proceedings of the IEEE/CVF International Conference
on Computer Vision</em>. 2019.</a></li>
<li>ICRA 2020 (可能写得不行 才6引): <a href="https://arxiv.org/abs/2103.00783">Hu, Mu, et al. "Towards Precise
and Efficient Image Guided Depth Completion." <em>arXiv e-prints</em>
(2021): arXiv-2103.</a></li>
<li>AAAI 2020: <a href="https://ojs.aaai.org/index.php/AAAI/article/view/6635">Cheng,
Xinjing, et al. "Cspn++: Learning context and resource aware
convolutional spatial propagation networks for depth completion."
<em>Proceedings of the AAAI Conference on Artificial Intelligence</em>.
Vol. 34. No. 07. 2020.</a></li>
</ul>
<p>​
本文可能写得<strong><u>很烂</u></strong>，笔者在看这三篇论文以及写博客时，由于返乡安排太紧，只睡了3.25小时。</p>
<span id="more"></span>
<h3 id="需要解决的问题">1.1 需要解决的问题</h3>
<p>​ 这里我就直接摘抄CSPN++中对于深度补全预期效果的阐述：</p>
<blockquote>
<p>CSPN claims three important properties should be considered for the
depth completion task, 1) <strong><u>depth preservation</u></strong>,
where the depth value at sparse points should be maintained, 2)
<strong><u>structure alignment</u></strong>, where the detailed
structures, such as edges and object boundaries in estimated depth map,
should be aligned with the given image, and 3) <strong><u>transition
smoothness</u></strong>, where the depth transition between sparse
points and their neighborhoods should be smooth. [1]</p>
</blockquote>
<p>​ 但实际上，阅读ICCV 2019文章之后，个人觉得可能还差了这两点：</p>
<ul>
<li>符合3D约束，2D深度图能满足一些3D假设</li>
<li>正确的平滑假设：edge preserving的平滑假设（类似双边滤波的思想）</li>
</ul>
<hr>
<h2 id="ii.-sparse-lidar-guidance-iccv-2019">II. Sparse LiDAR Guidance
(ICCV-2019)</h2>
<p><img src="/2022/01/23/Depth-Completion%E8%AE%BA%E6%96%87%E4%B8%89%E7%AF%87/iccv2019.png"></p>
<center>
Figure 1. 网络处理架构
</center>
<p>​
个人认为本工作虽然比ICRA-2020这篇早了一年，但是质量更高。本论文看问题的角度非常独特：</p>
<div class="note primary"><ul>
<li>一般论文：直接在2D空间，硬凿loss，或者像ICRA-2020的PENet，包含一些不明所以的3D信息</li>
<li>本论文：直接在3D空间下建模 深度与法向量的关系，放弃piece-wise depth
constant假设，转向piece-wise plain假设（观测由一块块平面构成）</li>
</ul>
</div>
<p>​ 个人认为，piece-wise depth
constant是不优雅的，首先，这个假设的直接结果就是：边缘的模糊与平滑（相当于加了一个平均核），在2D
CV邻域，成像结果可以是piece-wise
constant的，光学成像结果不仅与深度有关，与反射率、材质、介质等等均有关系，十分复杂。但对于深度而言，此假设太过简单粗暴，而作者提到的
“plain-origin distance piece wise
constant”则是基于：大量人工场景都是由碎片化的平面构成
这一特点，比较符合实际。举个例子，我们观测两堵墙，两堵墙都不是完全垂直于我们视线的。使用Piece-wise
constant假设将会使得深度过渡更加平滑，对于多平面深度不连续情况而言，误差较大（会平均一些不该平均的位置），而“plain-origin
distance piece-wise
constant”则可以准确描述两堵墙（甚至是更多的平面）。</p>
<p>​ 本论文的一般处理步骤：</p>
<div class="note "><h4 id="特征提取网络prediction-stage">特征提取网络（prediction
stage）</h4>
<div class="note danger no-icon">
<p>
​UNet-ResNet34 backbone
提取特征，生成：<strong><u>coarse深度图</u></strong>，<strong><u>Guidance
Feature</u></strong>（相当于context信息），<strong><u>法向量估计</u></strong>，<strong><u>置信度</u></strong>。
</p>
</div>
<div class="note warning no-icon">
<p>
​根据粗深度 + 法向量，变换到每个点所在平面到原点（也即相机中心）的距离
</p>
</div>
</div>
<div class="note "><h4 id="recurrent-refinement-stage">Recurrent Refinement Stage</h4>
<p>​ 使用Diffusion
model（类似置信传播，但并未直接使用MRF或者CRF相关公式），可以认为是一种规则的图卷积？迭代多次，diffusion根据两个像素位置对应的guidance
feature相似度判定diffusion coefficient。最后的结果从plain-origin
distance变换为原始的深度。</p>
<p>​ 当然，如果涉及到存在sparse LiDAR深度点的像素位置，特征提取网络输出的
confidence 将会把原深度以及预测深度加权求和。</p>
</div>
<p>​ 这里只简单推一推Plain-origin distance：已知点到平面的距离公式是
<span class="math display">\[
\begin{equation}\label{dist}
N(\pmb{X})\cdot \pmb{X} -P=0
\end{equation}
\]</span> ​ 其中<span class="math inline">\(N(\pmb{X})\)</span>是三维点<span class="math inline">\(X\)</span>所在表面的切平面（tangent
space）的法向量，通常来说，给定足够多的点，可以使用PCA或者求解协方差矩阵最小特征值对应特征向量（实际上还是类似PCA）的方法求解。<span class="math inline">\(\pmb{X}\)</span>是平面上一点到相机中心的相机坐标系3D
vector。公式<span class="math inline">\(\eqref{dist}\)</span>表达的意义很清晰，<span class="math inline">\(N(\pmb{X})\cdot\pmb{X}\)</span>是 <span class="math inline">\(\pmb{X}\)</span>
在平面法向量上的投影距离，也就是原点到平面的距离。</p>
<p>​ 而有深度值 + 相机内参 + 像素位置，可以根据<span class="math inline">\(zK\pmb{x}=\pmb{X}\)</span>求的<span class="math inline">\(\pmb{X}\)</span>。那么正逆变换： <span class="math display">\[
\begin{align}
&amp;P(\pmb{x})=D(\pmb{x})N(\pmb{x})K\pmb{x}\\
&amp;D(\pmb{x})=\frac{P(\pmb{x})}{N(\pmb{x})K\pmb{x}}
\end{align}
\]</span> ​ 总的来说，这篇文章很好理解，写得很清晰。</p>
<hr>
<h2 id="iii.-penet-icra-2020">III. PENet (ICRA-2020)</h2>
<p>​
PENet个人感觉创新点很有限，这个网络给人一种十分魔法的感觉，比如Color-dominant和Depth-dominant是如何进行处理的，为什么可以做到不同模态数据的dominant。</p>
<img src="/2022/01/23/Depth-Completion%E8%AE%BA%E6%96%87%E4%B8%89%E7%AF%87/icra2020.png">
<center>
Figure 2. 看到网络结构后我就觉得 坏了 应该很魔法
</center>
<h3 id="dilated-accelerated-cspn">3.1 Dilated &amp; Accelerated
CSPN++</h3>
<p>​
作者唯一花了大篇幅介绍的，有实质内容的部分就是这一部分。其中有个很奇怪的地方（可能是我不懂Spatial
Propagation Network），其中的公式（3）： <span class="math display">\[
\begin{equation}\label{map}
D_{i}^{t+1}=W_{ii}D_i^0+\Sigma_{j\in N(i)}W_{ji}D_j^t
\end{equation}
\]</span> ​
对于这种迭代式的结构，个人感觉有点类似RNN（RAFT里就有RNN的某个经典结构：GRU）。但这和卷积的区别在哪？看起来很像卷积：对于图像某个位置的输出第t+1层卷积的输出，是上一层此位置周围邻域内所有输入线性组合的非线性映射（考虑激活函数）。关于这个translated
propagation，照我个人理解，其意思大致是这样：仍以论文中<span class="math inline">\(3\times3\)</span>邻域为例：</p>
<p>​ 在一般情况下，对于一个【特征图】进行计算的<span class="math inline">\(3\times3\)</span>矩阵实际上应该是一个张量，此张量可以是<span class="math inline">\(3\times3\times
C\)</span>大小的。换句话说，这里有9个特征向量，被组织成了二维grid结构。那么如果需要输出是一个向量，那针对每一个向量的映射就应该是大小为<span class="math inline">\(C\times C\)</span>的矩阵。故公式<span class="math inline">\(\eqref{map}\)</span>中定义的<span class="math inline">\(W\)</span>实际上应该是<u><strong>很多矩阵</strong></u>。</p>
<p>​
这里与卷积不同的是：卷积层的每一个kernel都会考虑感受野内的每一个输入（除非这个卷积学习得很奇怪，就只有一个点值非0）。比如此处的<span class="math inline">\(3\times3\times
C\)</span>的输入。假设我们使用一个<code>Conv2d(C, N, k = 3)</code>进行计算（输出一个大小为<span class="math inline">\(1\times1\times
N\)</span>的向量），输出的第k个通道（此处也即<span class="math inline">\(\text{output}_{[0,0,k]}\)</span>）是： <span class="math display">\[
\begin{equation}
N_k=\sum_{t=0}^C\left\{\sum_{i=0}^2\sum_{j=0}^2A_t(i,
j)C_t(i,j)\right\}+\text{bias},\text{ where }A\text{ is input and
}C\text{ is kernel}
\end{equation}
\]</span> ​ 卷积实际上是将图像以通道划分的，处理信息的视角是
通道。而此处的Spatial Propagation，是以每个像素的特征向量为视角： <span class="math display">\[
\begin{equation}
V_o=\sum_{i=0}^2\sum_{j=0}^2W_{ij}A(i,j),\text{ where
}W_{ij}\in\R^{C\times C}
\end{equation}
\]</span> ​
我们可以认为这就是一个<strong><u>向量的线性组合</u></strong>过程。综上所述，通俗地来说：</p>
<ul>
<li>卷积是以通道为视角的，卷积核都是每个通道进行计算的</li>
<li>Spatial
propagation（至少在这篇论文里）是特征向量（某一点的所有通道值）为视角的，可以视作向量的线性组合。</li>
</ul>
<p>​
但需要注意的是，以上只是个人认为的【卷积】与【SP】的区别，论文中实际以【深度图】（单通道，而不是上文所说的特征图）进行计算，故每个<span class="math inline">\(W_{ij}\)</span>实际是一个具体的值。由于第t+1次迭代的输出（x,
y）是第t次迭代输入（x, y）邻域值的组合。而由于不同像素<span class="math inline">\((x_1,
y_1)\)</span>相对于其邻域某个点（比如相对距离(-1, -1)的像素）与<span class="math inline">\((x_2,
y_2)\)</span>相对于相同的相对位置点，affinity值是不一样的，<strong><u>权重并不是共享</u></strong>的，故简单卷积是无法计算的。</p>
<p><img src="/2022/01/23/Depth-Completion%E8%AE%BA%E6%96%87%E4%B8%89%E7%AF%87/onehot.png"></p>
<center>
Figure 3. One-hot convolution --- affinity map shifting
</center>
<p>​
事实上，按照SP的思想，每个像素相对于邻域内某个相对位置点将得到一affinity值，那么对于某一个相对位置点，将得到一个大小为<span class="math inline">\((H, W)\)</span>的单通道affinity
map，就比如：，图像中所有像素相对于<span class="math inline">\(3\times
3\)</span>邻域内(-1, -1)位置将形成一个单通道affinity map，那么<span class="math inline">\(3\times
3\)</span>邻域将形成9个相对于不同位置的单通道affinity
map。而且这些affinity map就像是relative positional
embeddings一样，需要与正确相对位置的值运算，举例说明：</p>
<ul>
<li>考虑图像上（1, 1）点对应的像素，并考虑一个<span class="math inline">\(3\times 3\)</span>邻域</li>
<li>(1, 1)点对应像素在迭代生成输出时首先应将自身值与【相对位置(0,
0)的affinity map通道】上的【(1, 1)位置值（代表了(1,
1)点相对于与自身相对距离为(0,
0)点的affinity）】进行相乘，作为base值</li>
<li>后(1, 1)点计算其领域点信息：
<ul>
<li>(0, 0)点相对于【（-1, -1）affinity map通道上的(1,
1)位置】值相乘，叠加到base值上</li>
<li>(0, 1)点相对于【（-1, 0）affinity map通道上的(1,
1)位置】值相乘，叠加到base值上..., etc.</li>
</ul></li>
<li>从Figure 2中也看出相应的意思：<span class="math inline">\(A^x\)</span>是不同方向（x为方向，也即相对位置）对应的affinity
map，在经过one-hot convolution之后，组成一个乘法kernel。</li>
</ul>
<p>​
显然我们是不希望使用for循环的（对于CUDA加速不友好）。作者的方法实际上就是使用one-hot
convolution实现了tensor的roll操作，并且此roll不是循环的（设0），因为有些像素就是没有某个特定位置的值（比如右下角点没有(1,
1)相对位置点）。直接roll可能需要借助额外的masking操作，故作者就使用固定的one-hot卷积核，卷积affinity
map的每一个通道（每个通道的one-hot
卷积核不一样，因为所表示的相对位置不一样），卷积的结果可以直接用于【乘法
+ 叠加】操作。</p>
<h2 id="iv.-cspn-aaai-2020">IV. CSPN++ (AAAI-2020)</h2>
<p><img src="/2022/01/23/Depth-Completion%E8%AE%BA%E6%96%87%E4%B8%89%E7%AF%87/aaai2020.png"></p>
<center>
Figure 4. 看成了CSDN...
</center>
<p>​ 本论文可以称为是：终极自适应
工作。CSPN++在两方面进行了自适应考虑：</p>
<ul>
<li>Context-aware：对于图像内容本身的处理进行自适应，用以提升精度</li>
<li>Resouce-aware：对于计算资源的自适应，比如自适应选择
<strong><u>卷积核大小（或propagation域大小）</u></strong> 以及
<strong><u>迭代次数（per-pixel）</u></strong></li>
</ul>
<p>​
两方面的awareness存在权衡关系：计算资源富足时在计算精度以及结果质量上必然更好，反之亦然。其中，个人觉得Context-aware没有特别多可以说的，作者也就是从两个不同的角度进行信息综合：</p>
<ul>
<li>每一个像素使用不同大小的kernel得到的结果综合</li>
<li>每一个像素迭代不同阶段时的信息综合</li>
</ul>
<p>​ CSPN block迭代公式本身是： <span class="math display">\[
\begin{equation}
H^+_x(t+1)=\kappa(x) H_x(0) + \sum_{y\in N(x)}\kappa(y)H_y(t),\text{
where }N(x) \text{ is the neighbor of }x
\end{equation}
\]</span> ​ 其中的neighbor表示去心邻域，以上操作记为<span class="math inline">\(H_{CSPN}(x,t)\)</span></p>
<p>​ 综合 迭代平均 以及 核平均，更新公式应该是（我们令<span class="math inline">\(H_x(t
)\)</span>为迭代第t次时，像素位置x的深度值hidden state）： <span class="math display">\[
\begin{align}
&amp; H^+_x(t+1)=\lambda_x(k, t+1)H_{CSPN}(x,t)+H^+_x(t)\\
&amp; H^+_x(t)=\sum_{i=0}^k\alpha_x(k)H^+_x(t,i), \text{ where }H_x^+(t,
i) \text{ also indicates kernel size}
\end{align}
\]</span> ​ 其中<span class="math inline">\(\lambda_x(k,  t)\)</span>（迭代综合系数）以及<span class="math inline">\(\alpha_x(k)\)</span>
（kernel综合系数）都是网络的输出，注意这些系数均带有下标，说明是与像素有关的
per-pixel prediction coefficient。</p>
<p>​ 本论文有意思的点在于，论文通过Context-aware
propagation过程定义的公式，导出了computational
cost的简单表达式，computational
cost在此处的作用相当于惩罚项。由于Context aware的过程是：multi-branch
prediction，最后根据预测的<span class="math inline">\(\alpha\)</span>
以及 <span class="math inline">\(\lambda\)</span>系数整合多branch的预测结果。此处，<span class="math inline">\(\alpha\)</span>以及<span class="math inline">\(\lambda\)</span>是先于CSPN
block实际迭代过程给出的（由一个修改的ResNet-34网络给出）。在Resource-aware计算过程中，作者将
“weighted average”变为了“max
pool”：根据预测系数，每个像素位置选择“最大”branch进行计算： <span class="math display">\[
\begin{equation}
k_x^*=\mathop{\arg\max \alpha_x(k)}_k,t^*_x=\mathop{\arg
\max\lambda(k_x^*,t)}_t
\end{equation}
\]</span> ​
这样可以省去多路计算的计算开销，但显然这样牺牲了结果质量。</p>
<p>​ 另一方面，作者在论文中对computational cost进行了建模： <span class="math display">\[
\begin{align}
&amp; E(c_x|\{\alpha_x, \lambda_x\})=\frac  1{hw}\sum_x E(c_x|\alpha_x,
\lambda_x)\label{normx}\\
&amp;E(c_x|\alpha_x, \lambda_{x})=\frac 1
{Nk_{\max}}\sum_{k}\sum_t\alpha_x(k)\lambda_x(k,t)k^2t\label{norma}
\end{align}
\]</span> ​ <span class="math inline">\(\eqref{normx}\)</span>相当于是所有像素位置求平均（期望），<span class="math inline">\(\eqref{norma}\)</span>则是某一个确定的像素位置进行的期望计算：因为一个像素位置进行传播的复杂度显然是<span class="math inline">\(O(k_{\max}^2N)\)</span>，其中<span class="math inline">\(k_{\max}\)</span>是最大核大小，<span class="math inline">\(N\)</span>是迭代次数，而如果将<span class="math inline">\(\alpha\)</span>以及<span class="math inline">\(\lambda\)</span>分别看作核取大小 <span class="math inline">\(k\)</span> 以及 迭代次数为 <span class="math inline">\(t\)</span> 时的概率（个人认为这是可以的，在“max
pool”下选取的就是最大“概率”branch进行计算），cost的期望便可以以上述两个公式进行计算。</p>
<p>​
事实上作者也将此惩罚项向有约束优化中拓展了，但最后的形式还是惩罚项（因为这个优化问题non-convex，拉格朗日对偶没啥大用处）。惩罚项的坏处就是，约束是软约束，超出约束范围是可能的。</p>
<p>​
不过综上所述，个人觉得CSPN++这篇论文相对还是比较有意思的（尤其是Resource-aware部分），有一定启发性，相比ICRA
2020的PENet，个人觉得这篇文章写的更不那么魔法。</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>深度补全</tag>
      </tags>
  </entry>
  <entry>
    <title>Swin Transformer 复现</title>
    <url>/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="swin-transformer">Swin Transformer</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​ Swin Transformer获ICCV best
paper之后，就总有很多人提起它。个人在前段时间复现了一个与ViT相关的工作（Compact
Convolution
Transformer），感觉实现太简单（训练难），遂想尝试一些更加复杂的工作。同时我当然也想看看best
paper到底是什么水平。此论文写得很清晰，实验做得非常漂亮，思想也很有趣，不过可以说是一篇typical神经网络文章：<strong><u>一个公式都没有</u></strong>（attention公式以及复杂度计算公式不算）。个人虽然惊叹于其SOTA表现，但由于存在不可解释的魔法，也始终觉得很膈应。本文是我在复现过程中的整理的一些思路和我觉得本论文中疑难之处及其理解。复现见：<a href="https://github.com/Enigmatisms/Maevit/tree/master/swin">Github/Maevit(这实际是ViT的复现repo)</a></p>
<p>​ 论文原文：<a href="https://arxiv.org/abs/2103.14030">Liu, Ze, et al.
"Swin transformer: Hierarchical vision transformer using shifted
windows." <em>arXiv preprint arXiv:2103.14030</em> (2021).</a></p>
<p><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/intro.png"></p>
<center>
Figure 1. 艺术之国：还有一个XJTU的（MSRA nb）[1]
</center>
<span id="more"></span>
<h2 id="ii.-some-points">II. Some Points</h2>
<h3 id="复杂度">2.1 复杂度</h3>
<p>​ 复杂度计算（二次部分）：图像大小为<span class="math inline">\(h\times
w\)</span>，那么由分块大小为M，可以得到<span class="math inline">\(h\times
w/M^2\)</span>个patch，每个pacth的大小是<span class="math inline">\(M^2\)</span>。而对于一个patch，相当于是用一个小ViT，对<span class="math inline">\(M^2\)</span> patch token进行 “global”
attention，复杂度<span class="math inline">\(O({(M^2)}^2)=O(M^4)\)</span>故总复杂度：<span class="math inline">\(O(M^2hw)\)</span>，对于通道数为2C的embedding而言，就如论文所说的：<span class="math inline">\(O(2M^2hwC)\)</span></p>
<p>​ 这么说Set transformer中的induced point
机制，可能也可以应用到这里来？</p>
<h3 id="masked-attention">2.2 Masked Attention</h3>
<p>​ Masking
很好理解，由于原图是物理上连续的，经过了一次循环移动操作之后，循环移动的分界面是物理上不连续的区域，故在进行注意力机制处理时不能包括分界面两边的区域。比如：</p>
<center>
<img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/shift.png" style="zoom:100%;">
</center>
<center>
Figure 2. 循环移动示意图
</center>
<p>​
右边是循环移动前的图，左边是循环移动后的图。我们希望，能够分块进行attention。个人的理解大概是这样的，其实这个很简单：我使用官方实现做了一个小实验之后，大概明白了其包含的思想（但是这个矩阵操作我可能做不来，有点妙，我顶多自己在这循环）：</p>
<p>​ 这个小实验的设置大概是这样的：图像大小为 4 * 4，window大小为 2 *
2，偏移为1 * 1，得到的四个mask长这样(其中，黄色为0，紫色为-100）：</p>
<p><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/mask.png"></p>
<center>
Figure 3. attention mask
</center>
<p>​
なんで？可以看下面这个可视化：我们将16个块编号，并进行循环移动，循环移动后的图和原图：</p>
<p><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/new.png" style="zoom:50%;"></p>
<center>
Figure 4. 循环移动illustration
</center>
<p>​ 注意力操作将把一个window内的元素flatten，比如第一个window内的 ((6,
7), (10, 11)) -&gt; (6, 7, 10,
11)。flatten操作是行优先的。故对于第一个window而言，由于内部的所有元素都是原图中的元素，可以直接进行attention操作，故attention
mask值全为0。</p>
<ul>
<li>第二个window：((8, 5), (12, 9)) -&gt; (8, 5, 12, 9)。由于(8, 5) 以及
(12, 9)两两不能做attention操作，故mask应该就是figure
2中的第二个图。比如图中4 * 4矩阵的(0,
1)位置是-100，代表了块8与块5之间的attention
logit值应该加一个很大的负偏置，也就是消去了两个块之间的关联。</li>
<li>此后的两个window都能很快以这个思想推出。</li>
</ul>
<p>​ 代码中则是这么实现的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">H, W = input_resolution</span><br><span class="line">img_mask = torch.zeros((<span class="number">1</span>, H, W, <span class="number">1</span>))  <span class="comment"># 1 H W 1</span></span><br><span class="line">h_slices = (<span class="built_in">slice</span>(<span class="number">0</span>, -self.window_size),</span><br><span class="line">            <span class="built_in">slice</span>(-self.window_size, -self.shift_size),</span><br><span class="line">            <span class="built_in">slice</span>(-self.shift_size, <span class="literal">None</span>))</span><br><span class="line">w_slices = (<span class="built_in">slice</span>(<span class="number">0</span>, -self.window_size),</span><br><span class="line">            <span class="built_in">slice</span>(-self.window_size, -self.shift_size),</span><br><span class="line">            <span class="built_in">slice</span>(-self.shift_size, <span class="literal">None</span>))</span><br><span class="line">cnt = <span class="number">0</span></span><br><span class="line"><span class="comment"># 分块赋值操作 经过分块赋值之后，一个window内可以进行attention操作的块为同一个id</span></span><br><span class="line"><span class="keyword">for</span> h <span class="keyword">in</span> h_slices:			</span><br><span class="line">    <span class="comment"># 比如cnt = 0，根据h_slices与w_slices的第一个元素，赋值给[0:-win_size, 0:-win_size] 这样是没有问题的</span></span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> w_slices:							 </span><br><span class="line">        img_mask[:, h, w, :] = cnt</span><br><span class="line">        cnt += <span class="number">1</span></span><br><span class="line">mask_windows = window_partition(img_mask, self.window_size)  <span class="comment"># nW, window_size, window_size, 1 --&gt; 分window操作</span></span><br><span class="line">mask_windows = mask_windows.view(-<span class="number">1</span>, self.window_size * self.window_size)	<span class="comment"># flatten操作：（所有batch的所有window，window内所有块）</span></span><br><span class="line"><span class="comment"># 此处魔法：unsqueeze(1) 导致 mw 为 (B, 1, N), unsqueeze(2) 导致 mw 为 (B, N, 1)</span></span><br><span class="line"><span class="comment"># 相当于计算时，一个按行repeat（前者） 一个按列repeat（后者），相当于自己减自己的转置 就可以得到：相同id的位置是0，不同的是一个非0值</span></span><br><span class="line">attn_mask = mask_windows.unsqueeze(<span class="number">1</span>) - mask_windows.unsqueeze(<span class="number">2</span>)		   </span><br><span class="line"><span class="comment"># 所有非零值变为-100</span></span><br><span class="line">attn_mask = attn_mask.masked_fill(attn_mask != <span class="number">0</span>, <span class="built_in">float</span>(-<span class="number">100.0</span>)).masked_fill(attn_mask == <span class="number">0</span>, <span class="built_in">float</span>(<span class="number">0.0</span>))</span><br></pre></td></tr></table></figure>
<h2 id="iii.-relative-position-bias">III. Relative Position Bias</h2>
<h3 id="positional-embeddings">3.1 Positional Embeddings</h3>
<p>​ 实际上，我对position embeddings（特别是non-learnable
PE）到底是如何工作的还并不是特别清楚。position embeddings 如何表示位置
是否有直观的理解？</p>
<blockquote>
<p>Moreover, positional embeddings are trainable as opposed to encodings
that are fixed.</p>
</blockquote>
<p>​ 意思大概是这样的，一个简单的positional
embeddings（只在初始时加入的那种）可以被如下公式表示： <span class="math display">\[
\begin{equation}\label{pos}
\epsilon_{ij}=\frac{\text{lin}_q(x_i)(\text{lin}_k(x_j))^T+\text{lin}_q(x_i)(\text{lin}_k(p_{j}))^T}{\sqrt
d_k}
\end{equation}
\]</span> ​
个人认为更加合理的表示应该是（如果对于初始就加到embedding上的position
embeddings来说）： <span class="math display">\[
\begin{equation}
\epsilon_{ij}=\frac{\text{lin}_q(x_i + p_i)(\text{lin}_k(x_j +
p_j))^T}{\sqrt d_k}
\end{equation}
\]</span> ​ 在某篇博客中的表述是这样的：对于公式<span class="math inline">\(\eqref{pos}\)</span>中的<span class="math inline">\(\text{lin}_k(p_{j})\)</span> 我们将其改为<span class="math inline">\(p_{ij}\)</span>，此处<span class="math inline">\(p_{ij}\)</span>是整个positional embeddings的(i,
j)元素，表示了处于位置i的query相对于处于j位置的key的位置关系，可以理解成是与位置有关系的相关性。比如，在CV应用中，常见的inductive
bias就是：临近关联性，即使经过分块，相邻的块与块（或者位置相近的）之间也是有关联性的。一般的positional
embeddings，临近的两个位置，positional
embeddings的某个metrics（比如差值、点乘）可能比较小（大）。</p>
<p>​
本节的重点是讨论相对位置嵌入，因为绝对位置嵌入之前已经实现过了（就很简单），特别是learnable
positional
embeddings，就没有什么好讨论的。我们已经说了，相对位置嵌入是为了解决绝对位置嵌入无法编码任意多的位置的缺点。这里我讨论一下music
transformer中的relative positional embeddings（计算比较简单）： <span class="math display">\[
\begin{equation}
\text{Attn}_{rel}=\text{softmax}(\frac{QK^T+S_{rel}}{\sqrt{d_k}})V,\text{
where }S_{rel}=QR^T
\end{equation}
\]</span> ​ 我感觉上面的公式怪怪的，因为：</p>
<ul>
<li><span class="math inline">\(Q\)</span>（query）不仅与映射<span class="math inline">\(W_q\)</span>有关，与数据本身也是有关系的，不同的图像<span class="math inline">\(Q\)</span>差别很大，那么一个<span class="math inline">\(R\)</span>怎么能很好捕获到不同query向量之间的关联性？举一个具体的例子：</li>
</ul>
<p><span class="math display">\[
\begin{equation}
A=\begin{pmatrix}
1 &amp; 2 &amp; 3 &amp; 4 \\
5 &amp; 6 &amp; 7 &amp; 8 \\
9 &amp; 10 &amp; 11 &amp; 12 \\
13 &amp; 14 &amp; 15 &amp; 16 \\
\end{pmatrix}\xrightarrow{\text{flatten}}(1,...,16)
\end{equation}
\]</span></p>
<p>​
上例子中（CV二维），元素1在位置上应与（2，5）有着最紧密的关系，那么应该<span class="math inline">\(QR^T\)</span>计算的结果在(0,1)(1,0)位置都较大（softmax之后也会较大），但是<span class="math inline">\(QR^T\)</span>的计算中，对任何<span class="math inline">\(Q\)</span>而言<span class="math inline">\(R\)</span>是相同的，不同的矩阵<span class="math inline">\(A\)</span>，元素1与元素2、5均应该有此关系，那么在<span class="math inline">\(Q\)</span>改变的情况下，什么机制保证了<span class="math inline">\(QR^T\)</span>的稳定性呢？这已经是人类难以理解的魔法了，例如：相邻两patch，由于位置临近可能确实存在一定关系，对于不同的数据都有这样的共性，<span class="math inline">\(R\)</span>也只能去学可以泛化的共性了。</p>
<h3 id="rpe的实现">3.2 RPE的实现</h3>
<h4 id="music-transformer">3.2.1 Music Transformer</h4>
<p>​ 不同的relative positional embeddings实现有一些差别。最早期的relative
positional embeddings 有这样的问题：空间复杂度是<span class="math inline">\(O(L^2D)\)</span>。因为：</p>
<p>​ 求解relative positional
embeddings带来的距离logit，需要得到query与PE之间的点乘。考虑一个head的情况，Q的形状应该是：<span class="math inline">\((L,D_h)\)</span>，其中L是序列长度，<span class="math inline">\(D_h\)</span>是对应head的embedding
dimension。我们希望知道，query的每个向量（embedding）与不同距离位置的相关程度，比如，<span class="math inline">\(Q\)</span>的第i行（序列中第i个token的embedding），需要计算其与各个位置的分数，那么就需要：
<span class="math display">\[
\begin{equation}
\text{logit}(q_i)=q_iE_r^T,\text{ where
}E_r=(\text{PE}_0,...,\text{PE}_{L-1}) ,\text{PE.shape}=(1,D_h)
\end{equation}
\]</span> ​</p>
<p>​ 而直接计算<span class="math inline">\(QE_r^T\)</span>的结果并不是我们想要的：它算出来的矩阵和我们需要的矩阵分别是这样的,其中<span class="math inline">\(v_{i,j}\)</span>表示的是第 i 个query向量和
与其距离为j的位置的logit bias。 <span class="math display">\[
\begin{equation}
A=\begin{pmatrix}
v_{0,0} &amp; v_{0,1} &amp; ... &amp; v_{0, L-1}\\
v_{1,0} &amp; v_{1,1} &amp; ... &amp; v_{1, L-1}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
v_{L-1,0} &amp; v_{L-1,1} &amp; ... &amp; v_{L-1, L-1}\\
\end{pmatrix},B=\begin{pmatrix}
v_{0,0} &amp; v_{0,1} &amp; ... &amp; v_{0, L-1}\\
v_{1,1} &amp; v_{1,0} &amp; ... &amp; v_{1, L-2}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
v_{L-1,L-1} &amp; v_{L-1,L-2} &amp; ... &amp; v_{L-1, 0}\\
\end{pmatrix}
\end{equation}
\]</span> ​ 以A的最后一个行的首尾两个元素为例。<span class="math inline">\(v_{L-1,0}\)</span>表示的是最后一个embedding与自身的位置偏移logit偏置，而最后一个元素<span class="math inline">\(v_{L-1,L-1}\)</span>表示的则是：最后一个embedding与相距L-1距离位置的logit偏置。而我们反过来看最后一行的self
attention，最后一行的self
attention的结果logit中，最后一个元素表示的才是自己与自身的attention值。</p>
<p>​ 也就是说，直接计算<span class="math inline">\(QE_r^T\)</span>是不行的，这样计算会导致self
attention 与 positional
attention求出的logit在逻辑意义上的错位。B才是我们需要的：从对角线元素的下标就能看出。</p>
<p>​
那么如果要进行直接的矩阵运算，一个简单的想法就是：我可以直接计算一个中间矩阵R，R包含了（旋转过的）<span class="math inline">\(E_r\)</span>，这样，对于每一个query向量，其计算都应该是正确的，再直接矩阵相乘（<u><strong>毕竟能直接矩阵运算的，CPU上可以SIMD，GPU上并行度好</strong></u>）。那么可以将<span class="math inline">\(Q\)</span>与<span class="math inline">\(E_r\)</span>处理成这样： <span class="math display">\[
\begin{equation}
Q.\text{shape}=(L,1,D_h),R.\text{shape}=(L,L,D_h),S_{rel}=QR^T
\end{equation}
\]</span> ​ 其中，R第一维度下每一个元素都是一个<span class="math inline">\(E_r\)</span>。这种实现简单直观，但是，内存开销很大，长序列不友好。既然相对位置嵌入是为了解决长序列建模问题，那么自然其时间复杂度以及空间复杂度不能因为序列长度增长而变得难以接受。于是，music
transformer的作者提出了一种空间复杂度为<span class="math inline">\(O(LD)\)</span>的方法。</p>
<p>​ 很显然，直接计算<span class="math inline">\(QE_r^T\)</span>已经包含了所有需要<span class="math inline">\(S_{rel}\)</span>的信息，只不过对应关系错了（位置有误）。如何通过<span class="math inline">\(QE_r^T\)</span>的结果计算<span class="math inline">\(S_{rel}\)</span>？</p>
<p>​ 作者用了一个巧妙的矩阵操作：pad + reshape：图示一下：</p>
<p><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/rel.png" style="zoom: 67%;"></p>
<center>
Figure 5. skewing操作图示
</center>
<p>​ 作者在文章中说到：</p>
<blockquote>
<p>Pad a dummy column vector of length L before the leftmost column.</p>
</blockquote>
<p>​
这样再reshape之后，导致了一个问题，原有的有效元素丢失，引入的矩阵中出现了一些dummy
elements。并且感觉出现了：第i行元素被挤到第j行的情况。举个例子，正常情况下，一个长度为5的序列，<span class="math inline">\(S_{rel}\)</span>的index 2行应该是（循环右移2）：
<span class="math display">\[
\begin{equation}
(1,2,3,4,5)\rightarrow(4,5,1,2,3)
\end{equation}
\]</span> ​
所以个人感觉padding是有点问题的，应该直接进行一些变换：线性变换是不可能的（不存在一个矩阵R，可以将第一行旋转0，第二行旋转1，第三行旋转2,...，因为如果存在这样的矩阵，则对于矩阵A，A只有第一列全是1，其他全是0，这样显然没有逆的矩阵，R成了它的逆）。个人觉得，一个简单的实现应该是：计算一个循环移动过的索引矩阵，比如我知道本次需要计算的seq
length为N，那么我首先计算一个大小为<span class="math inline">\(N *
N\)</span>的索引矩阵，根据此索引矩阵取<span class="math inline">\(QE_r^T\)</span>元素，但这样又引入了一个<span class="math inline">\(O(N^2)\)</span>复杂度的存储开销（比<span class="math inline">\(O(N^2D)\)</span>小了很多，16位一般就够用，相当于几张大型双通道图像）。</p>
<div class="note info"><p>可能这是优雅的实现，毕竟我发现swin也是这么求的。music
transformer在干啥？是我没看懂还是本身就是错的？不应该错了啊。</p>
</div>
<h4 id="感觉正确的实现">3.2.2 感觉正确的实现</h4>
<p>​ 所以，我带着怀疑态度看了一下music transformer以及swin
transformer的实现。music transformer还真是这样写的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> self.relative_pos:</span><br><span class="line">    <span class="comment">#apply same position embeddings across the batch</span></span><br><span class="line">    <span class="comment">#Is it possible to apply positional self-attention over</span></span><br><span class="line">    <span class="comment">#only half of all relative distances?</span></span><br><span class="line">    Er  = self.Er[:, embedding_start:, :].unsqueeze(<span class="number">0</span>)</span><br><span class="line">    QEr = torch.matmul(queries, Er.transpose(-<span class="number">1</span>,-<span class="number">2</span>))</span><br><span class="line">    QEr = self._mask_positions(QEr)</span><br><span class="line">    <span class="comment">#Get relative position attention scores</span></span><br><span class="line">    <span class="comment">#combine batch with head dimension</span></span><br><span class="line">    SRel = self._skew(QEr).contiguous().view(b*h, t, t)</span><br></pre></td></tr></table></figure>
<p>​
其中的skew毫无保留地实现了论文的思想，个人感觉非常诡异。个人觉得原因可能是：它是music
transformer，只保留一个方向的attention，故可能有所不同？</p>
<p>​ 个人思考后出来的实现与这篇博客：<a href="https://theaisummer.com/positional-embeddings/">AI Summer:How
Positional Embeddings work in Self-Attention (code in
Pytorch)</a>给出的实现方法很相似。但在swin
transformer中，我还是忽略了一个很重要的问题：普通的序列一般是一维的，所以展开之后的相对距离实际上是一维度量：
<span class="math display">\[
\begin{equation}\label{rm}
\begin{pmatrix}
0 &amp; 1 &amp; 2 &amp; ... &amp; L-1\\
-1 &amp; 0 &amp; 1 &amp; ... &amp; L-2\\
-2 &amp; -1 &amp; 0 &amp; ... &amp; L-3\\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
-L+1 &amp; -L+2 &amp; -L+3 &amp; ... &amp; 0\\
\end{pmatrix}
\end{equation}
\]</span> ​ 而对于二维图像中的embeddings，注意两点：</p>
<ul>
<li>相对位置编码以及绝对位置编码解决的是同一个问题，所以实际上是可以相互转化的</li>
<li>正负方向有别，x+1以及x-1是不一样的，但是x，y方向也是不一样的</li>
</ul>
<p>​ 我们以 window size = 2 的情况来说明swin transformer中的“相对位置
<strong><u>bias</u></strong>（至于为什么要
<strong><u>加粗</u></strong>以及“双引号”，之后会说到）”的实现：对于以下A，B，C，D四个位置的像素每个位置相对于其他不同位置像素的二维距离分别是（注意有方向）
<span class="math display">\[
\begin{align}
&amp;\text{image}=\begin{pmatrix}
A &amp; B\\
C &amp; D
\end{pmatrix}\\
&amp;A:\begin{pmatrix}
(0,0) &amp; (0,1)\\
(1,0)  &amp; (1, 1)
\end{pmatrix}\\
&amp;B:\begin{pmatrix}
(0,-1) &amp; (0,0)\\
(1,-1)  &amp; (1, 0)
\end{pmatrix}\\
&amp;C:\begin{pmatrix}
(-1,0) &amp; (-1,1)\\
(0,0)  &amp; (0, 1)
\end{pmatrix}\\
&amp;D:\begin{pmatrix}
(-1,-1) &amp; (-1,0)\\
(0,-1)  &amp; (0, 0)
\end{pmatrix}\\
\end{align}
\]</span> ​ 随便说明一个元素的意义，以D的第一行第二列元素(-1,
0)为例：这里说明的是：<span class="math inline">\(D\)</span>与<span class="math inline">\(B\)</span>的相对位置差别：B相对于D是行-1，列不变，故为(-1,
0)。那么将每个元素战平可以得到： <span class="math display">\[
\begin{equation}\label{flat}
\begin{pmatrix}
(0,0) &amp; (0,1) &amp; (1,0)  &amp; (1, 1)     \\
(0,-1) &amp; (0,0) &amp; (1,-1)  &amp; (1, 0)   \\
(-1,0) &amp; (-1,1) &amp; (0,0)  &amp; (0, 1)   \\
(-1,-1) &amp; (-1,0) &amp; (0,-1)  &amp; (0, 0) \\
\end{pmatrix}\\
\end{equation}
\]</span> ​ 我在公式<span class="math inline">\(\eqref{rm}\)</span>下面的无序列表中说到：x、y方向是等价的，故实际上公式<span class="math inline">\(\eqref{flat}\)</span>中不同的相对坐标值可以简化：比如我们从左下角开始标记id，相同的相对坐标值id相同，可以将公式<span class="math inline">\(\eqref{flat}\)</span>标记为（标记不唯一）： <span class="math display">\[
\begin{equation}\label{id}
\begin{pmatrix}
4 &amp; 5 &amp; 7  &amp; 8  \\
2 &amp; 4 &amp; 6  &amp; 7  \\
1 &amp; 3 &amp; 4  &amp; 5  \\
0 &amp; 1 &amp; 2  &amp; 4 \\
\end{pmatrix}\\,
\begin{pmatrix}
3 &amp; 4 &amp; 5  &amp; 6  \\
2 &amp; 3 &amp; 4  &amp; 5  \\
1 &amp; 2 &amp; 3  &amp; 4  \\
0 &amp; 1 &amp; 3  &amp; 4 \\
\end{pmatrix}\\
\end{equation}
\]</span> ​ 我们可以：</p>
<ul>
<li>在一个表中预存不同id对应的bias</li>
<li>将这个表变成learnable的，每次索引就好了，让网络自己学值</li>
</ul>
<p>​ 公式<span class="math inline">\(\eqref{id}\)</span>看起来真的很像绝对位置编码的样子，事实上这里就体现了绝对位置编码和相对位置编码的共同性以及相互转化。就像相对位姿一样，只要与一个global项（绝对量）结合，相对就会转化成绝对，反之亦然。</p>
<p>​ 值得一提的是：对于window
size为L的window来说，因为每个像素点在不同方向上最多有<span class="math inline">\(2L-1\)</span>个不同位置，那么(x,
y)的相对位置组合也就有<span class="math inline">\((2L-1)^2\)</span>种情况。比如，公式<span class="math inline">\(\eqref{id}\)</span>对应L=2的情况，就有9种不同的位置，L=3时为49种...
等等，都是可以验证的。理解了这个，indexing机制就只剩一个问题了：怎么实现。这个...
也不能完全说是问题吧。</p>
<div class="note warning"><p>​
我在某天午夜思考实现方法，想了一小时没有头绪，遂睡觉。第二天早上醒来在床上花了三分钟想到了实现方法，这告诉我们睡眠非常重要。实现思想非常简单，所有其他位置的index，都可以复用(0,
0)位置的index，并在(0, 0)位置的index表元素中加上相同的偏置就可以了。</p>
</div>
<p>​ 关于2D relative positional bias，还有一个问题就是：positional
bias的shape应该如何？</p>
<blockquote>
<p>当然是<span class="math inline">\((\text{head num},
2L-1,2L-1)\)</span></p>
</blockquote>
<p>​ 但是为什么是这样呢？</p>
<p>​ 首先，relative positional bias之所以与embedding
dimension一点关系都没有，是因为人家叫
<strong><u>bias</u></strong>，学的内容并不是一个什么向量，它就是一个在计算softmax时加入的偏置，是一维的，并且每个head是不一样的。</p>
<p>​ 其次，为什么是一个大小为<span class="math inline">\(2L-1\)</span>的方阵呢？因为两个方向都有<span class="math inline">\(2L-1\)</span>种不同的位置。</p>
<hr>
<h2 id="iv.-复现结果">IV. 复现结果</h2>
<p>​ swin
transformer针对的是大型数据集（ImageNet），显然，这是我电脑没办法带动的（实验室的单3060也没办法跑）。所以我找了一些"compact
ImageNet"，最后选定的是imagenette2-320（与timm
docs使用同一个数据集）。数据集中图像的高固定为320。数据集共有十个分类，每个分类大约1000张图片（很小了）。</p>
<table>
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;"><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/1.JPEG"></th>
<th style="text-align: center;"><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/2.JPEG"></th>
<th style="text-align: center;"><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/3.JPEG"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">收音机</td>
<td style="text-align: center;">卡车</td>
<td style="text-align: center;">鱼</td>
</tr>
</tbody>
</table>
<center>
Figure 6. 一些分类图片（相比之下CIFAR-10就是高糊）
</center>
<p>​ 不得不说，224 * 224的图像确实非常吃显存。batch
size为50时显存占用是10GB，再高就炸我显卡了，故最后batch
size取了一个保险的40（约8GB占用）。复现结果如下：</p>
<p>​
首先得说明的是，我使用的参数基本与CCT一致，并没有调过，也不想费事去调，只是想理解一下本文的思想。文中使用的现代CV训练方法，比如cutmix等等这些操作，我一概没有使用，scheduler曾经使用过timm实现的余弦退火，但是最大最小学习率设置不合适，导致训练结果直接崩了（从70%调到10%），笔者也并不想花时间调。最终的结果大概是（存在过拟合，同样笔者也懒得调优了）：</p>
<ul>
<li>训练集83.5% 测试集78% (imagenette2-320)</li>
<li>除了第一次使用160 epochs之外，其余均是250
epochs，学习率固定分别固定(1e-5, 5e-6以及4e-6)</li>
</ul>
<p><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/trainacc.png"></p>
<center>
Figure 7. train set accuracy
</center>
<p><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/testacc.png"></p>
<center>
Figure 8. test set accuracy
</center>
<p><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/trainloss.png"></p>
<center>
Figure 9. train set loss
</center>
<p><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/testloss.png"></p>
<center>
Figure 10. test set loss
</center>
<hr>
<h2 id="v.-一些torch函数">V. 一些torch函数</h2>
<h5 id="torch.triu">torch.triu</h5>
<blockquote>
<p>triu(input, diagonal=0, *, out=None) -&gt; Tensor Returns the upper
triangular part of a matrix (2-D tensor) or batch of matrices</p>
</blockquote>
<p>​
也即可以通过这个函数获得某个矩阵的上三角部分。对应的下三角是<code>torch.tril</code>。其中的diagonal参数指示了：相对于真正的对角线的偏移量，默认为0，也即对角线下方的所有元素设为0。如果是正数，比如1，将会使得0元素分界线向右上方偏移（1），反之往左下方。不是很常用。</p>
<h5 id="torch.masked_fill">torch.masked_fill</h5>
<p>​ 本实现中使用了此函数：在attention
mask中，将所有为负数的区域变为-100（使得logit很小）。传入的第一个参数相当于条件张量（一般会转化成true
false的bool张量），第二个参数是需要fill的值。</p>
<h5 id="torch.gather">torch.gather</h5>
<p>​ 本实现中，relative positional
bias一开始的实现使用过。gather实际上在没有view改变形状的情况下，直接根据提供的index，在原始矩阵中进行索引，得到的值组成一个新的矩阵：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rpe = torch.gather(s, -<span class="number">1</span>, self.relp_indices.repeat(batch_size, win_num, self.head_num, <span class="number">1</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>​ 上公式可以直接在最后一维度选择（第二个参数，dim =
-1），直接根据索引(self.relp_indices)，从一个（最后两个维度）shape为(2L
- 1, 2L-1)的矩阵中直接取出一个大小为(L, L)的矩阵。</p>
<h5 id="torch.register_buffer">torch.register_buffer</h5>
<p>​ torch有两个常用的 与 "register"
有关的函数：<code>register_buffer</code>以及<code>register_parameter</code></p>
<ul>
<li>register_buffer会将对应的张量加入到model.state_dict中，但是它不会参与反向传播计算。这给我们保存模型中一些无关参数（或者常数）提供了便利，这样加入model.state_dict中的参数可以直接被torch.save保存</li>
</ul>
<h5 id="torch.view-torch.reshape-torch.contiguous">torch.view /
torch.reshape / torch.contiguous</h5>
<blockquote>
<p>help(torch.reshape): Contiguous inputs and inputs with compatible
strides can be reshaped without copying, but you should not depend on
the copying vs. viewing behavior.</p>
</blockquote>
<p>​
view只能针对contiguous的数据进行操作，是在底层数据内存组织基础上，返回一种以不同于底层数据内存组织方式的视角（view，或认为是步长）来查看数据的tensor。比如：底层是矩阵<span class="math inline">\(A_{2\times2}\)</span>，transpose之后是<span class="math inline">\(B_{2\times2}\)</span> <span class="math display">\[
\begin{equation}
A=\begin{pmatrix}
1 &amp; 2\\
3 &amp; 4
\end{pmatrix},
B=\begin{pmatrix}
1 &amp; 3\\
2 &amp; 4
\end{pmatrix}
\end{equation}
\]</span> ​
A在内存中实际上是按照行优先进行一维存储的：实际上保存的数据是(1, 2, 3,
4)并且按照stride = (2,
1)进行访问。而B作为A的transpose，实际上没有修改内存组织（transpose后的数据与A共用内存（<strong><u>如果不小心可能会导致不想要的修改</u></strong>）），但是是以stride
= (1, 2) 访问数据。这里的stride = (i, j)可以认为是：</p>
<ul>
<li>行方向上的索引增加1，在物理地址的寻址中需要移动i个位置</li>
<li>列方向上索引增加1，物理地址寻址需要移动j个位置</li>
</ul>
<p>​ 故由于B是(1, 2)，那么B[0, 1] = (B基地址 + 1 * 2偏移).value = 3。B[1,
0] = (B基地址 + 1 * 1偏移).value = 2。</p>
<p>​
上示例中，A是contiguous的，但B并不是，因为其访问数据的方式在内存中不是线性连续的。故B这样的矩阵，<strong><u>不能直接view</u></strong></p>
<ul>
<li>直接view操作不改变内存组织方式，view前后数据共享内存</li>
<li>reshape相当于是
X.contiguous().view。如果一个矩阵不是contiguous的，contiguous操作将会开辟新的内存空间并复制原来的tensor，以新的view进行数据存储</li>
<li>值得一提的是，<code>permute</code>, <code>narrow</code>,
<code>expand</code>,
<code>transpose</code>操作之后，均会使得contiguous不成立。但是<code>view</code>操作过后，虽然stride可能发生改变，但其并不影响contiguous性。</li>
</ul>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://github.com/microsoft/Swin-Transformer">Github:
microsoft/Swin-Transformer</a></p>
<p>[2] <a href="https://arxiv.org/abs/1809.04281">Huang, Cheng-Zhi Anna,
et al. "Music transformer." <em>arXiv preprint arXiv:1809.04281</em>
(2018).</a></p>
<p>[3] <a href="https://theaisummer.com/positional-embeddings/">AI
Summer:How Positional Embeddings work in Self-Attention (code in
Pytorch)</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>前端小学习</title>
    <url>/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="front-end">Front-End</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​
某天我回过头来看自己大一写的游戏，越玩越觉得制作尽量细节拉满（确实，不过估计是因为我大一非常闲，可以整天泡在写游戏里）。虽然如此，我还是觉得Pygame不适合做这个游戏，并且我觉得大一时的代码设计思想还不成熟，非常乱，想重构这个游戏。思来想去，用Unity（写了个弹珠打砖块游戏）觉得不爽，并且C#语言风格与C++类似，不想重复，遂想用一些（感觉上）完全不一样的语言去做这件事，最后确定用前端写网页游戏。前端说有趣，也还挺有趣的（毕竟我之前一直想当建筑设计师，搞设计的热情还是有的），但总感觉少了点深度思考（可能因为我接触的太简单）。为了在实践中学习前端，我将之前用Pygame实现的用户登录界面用JS升级了一下（只是功能升级，并没有更好看，见<a href="https://github.com/Enigmatisms/JSen">Github:Enigmatisms/JSen</a>），本文记录在做这个小小项目过程中遇到的一些问题。</p>
<table>
<colgroup>
<col style="width: 55%">
<col style="width: 44%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;"><img src="/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/5.png" style="zoom: 40%;"></th>
<th style="text-align: center;"><img src="/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/home.png"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Ethians Alpha 1.0 主菜单</td>
<td style="text-align: center;">一个（个人认为的）人性化的登录/注册网页</td>
</tr>
</tbody>
</table>
<center>
Figure 1. 目标 与 现阶段 发展不平衡之间的矛盾
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-html碎片知识">II. HTML碎片知识</h2>
<p><img src="/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/joke.png"></p>
<center>
Figure 2. href="html是编程语言!!!.com"
</center>
<p>​
众所周知，HTML是编程语言（误）。作为一种标记语言，当然要去记其中的标记以及js中如何调用这些元素。这里只举一些简单的例子：</p>
<h3 id="控件元素">2.1 控件元素</h3>
<p>​ html5中有一些很有趣的"控件"，比如<code>button</code>
（按键），<code>input</code>
文本输入框，<code>file</code>文件上传框等等。这些元素有共性，也有特殊的用法。比如button和input都可以
<code>focus</code> 以及 <code>blur</code>：</p>
<ul>
<li>focus：聚焦。对于input来说，focus函数会使得文本输入框像是被选中了一样（如果网页中存在focus之后的text输入框，那么键盘输入会直接出现在这个输入框中）。button的focus...
可能就是单纯的定位吧（使得网页翻页到button所在位置）。举个例子：可以写一个这样的功能，使得用户输入用户名后按<code>enter</code>键可以直接跳转到密码输入框上
---&gt; 密码输入框.focus()</li>
<li>blur：focus的反义。举个例子：用户填写信息之后希望放弃本次填写，第一次<code>ESC</code>使得输入框不再被选中，第二次直接返回上一级。</li>
</ul>
<p>​
对应的，有一些事件驱动的函数，比如<code>onkeyup</code>（用户按键抬起时的行为），<code>onclick</code>（点击时的行为），<code>onblur</code>（用户取消选中时的行为）。当然这很多都是和JS相关的。</p>
<p>​ 不同之处比如：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">value</span>=<span class="string">&quot;&quot;</span> <span class="attr">placeholder</span>=<span class="string">&quot;Username&quot;</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;password&quot;</span> <span class="attr">value</span>=<span class="string">&quot;&quot;</span> <span class="attr">placeholder</span>=<span class="string">&quot;Password&quot;</span>/&gt;</span></span><br></pre></td></tr></table></figure>
<p>​
text可以指定自己的类型，指定为password可以自动回显成:black_circle:，好，很有精神。</p>
<h3 id="name-class-id">2.2 name / class / id</h3>
<p>​
怎么说呢，只能简单区分一下，因为我还没有遇到这三个的坑（触及本质的那种）。</p>
<ul>
<li>name：重名是完全可以的，一个html中可以有多个name属性为同一个值的元素。可以在js中使用：<code>getElementsByName</code>，注意element用了复数形式，返回的是一个NodeList（可以下标索引）。name方便了同种类型元素的类似操作。比如我写的那个
<strong><u>自动评教脚本</u></strong>。</li>
<li>id:
这玩意貌似是每个html文件唯一的，毕竟js方法是：<code>getElementById</code>：唯一表示了一个元素的存在（特化元素的好方法）。</li>
<li>class:
为什么要用class呢？感觉name处理了重复性，id处理了唯一性，class好像没事干。同一class可以有不同的name，同一name也可以有不同的class，class属性目前我在css中遇到过，css不方便定义一个name的样式，但是可以定义一个id的样式，而如果需要多元素统一样式，可以使用class。</li>
</ul>
<h3 id="span-div">2.3 span &amp; div</h3>
<div class="tabs" id="span-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#span-unique-name-1">span</a></li><li class="tab"><a href="#span-unique-name-2">div</a></li></ul><div class="tab-content"><div class="tab-pane active" id="span-unique-name-1"><p>​
&lt;span&gt;是内联元素，内部可以填充文本。内联元素的好处就是：我不换行显示。这样可以创建一些有name/id/class的文本而不换行（注意&lt;p&gt;也是换行的块级元素）。我把它用在了用户名或密码输入不符合要求时的提示信息显示上：</p>
<p><img src="/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/log5.png"></p>
<center>
Figure 3. span的应用（红色字体只会在输入不符要求时出现）
</center></div><div class="tab-pane" id="span-unique-name-2"><p>​
&lt;div&gt;元素是一个容器，非常常用，常见于网页的组织（相同功能的放一起，可以认为就是花括号了）。它是块级元素（这意味着它通常都是另起一行，并且结束后会换行的），所以不引入一些魔法（比如CSS组织）可能没办法让其不换行显示（可能只是我不知道而已）:</p>
<p><img src="/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/div.png"></p>
<center>
Figure 3. 很多div
</center></div></div></div>
<h2 id="iii.-css碎片知识">III. CSS碎片知识</h2>
<p>​
我从来没有系统学过CSS（或者是HMTL，都是要用的时候学一点算一点）。虽然如此，我觉得其中有些内容还是有必要搞清楚的，毕竟也不能只会而不知道为什么。</p>
<center>
<img src="/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/css.jpg" style="zoom:80%;">
</center>
<center>
Figure 4. Game of Front-end Thrones
</center>
<h3 id="定位">3.1 定位</h3>
<p>​
css每个元素可以指定<code>position</code>，我接触过的只有其中三个（准确来说是四个，第四个<code>static</code>没有显式用过）：</p>
<ul>
<li><code>relative</code>：relative会保持正常的文档flow，比如写如下的代码：</li>
</ul>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">span</span><span class="selector-class">.relative</span> &#123;</span><br><span class="line">  <span class="attribute">position</span>: relative;</span><br><span class="line">  <span class="attribute">left</span>: <span class="number">0px</span>;</span><br><span class="line">  <span class="attribute">border</span>: <span class="number">3px</span> solid blue;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-tag">span</span><span class="selector-class">.test</span> &#123;</span><br><span class="line">  <span class="attribute">position</span>: relative;</span><br><span class="line">  <span class="attribute">left</span>: <span class="number">0px</span>;</span><br><span class="line">  <span class="attribute">border</span>: <span class="number">3px</span> solid blue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 根据以上的CSS代码在body中放置两个同级的span：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;relative&quot;</span>&gt;</span>This div element has position: relative;<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;test&quot;</span>&gt;</span>This div element has position: relative;<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>​ 结果是这样的：</p>
<p><img src="/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/rel.png"></p>
<center>
Figure 5. 双relative
</center>
<p>​ 说明文档flow（元素的先后位置关系）没有被破坏。</p>
<ul>
<li><code>absolute</code>则是绝对定位：它会将元素从文档flow中取出，比如将上面<code>span.text</code>的position属性改为<code>absolute</code>会得到这样的结果：</li>
</ul>
<p><img src="/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/abs.png"></p>
<p>​
本来<code>span.test</code>这个inline元素应该跟随在<code>span.relative</code>的后面，但是由于<code>test</code>从flow中单独提取出来了，它相对于其最邻近的relative父级元素（本例子中就是&lt;body&gt;）定位。</p>
<p>​ 注意，如果需要使用absolute定位，其定位方式是相对于
<strong><u>最邻近的relative 父级元素</u></strong>。</p>
<h3 id="显示">3.2 显示</h3>
<p>​ <code>display</code>可以有这样四种常用的选项：<code>none</code>,
<code>inline-block</code>，<code>inline</code>, <code>block</code></p>
<ul>
<li><code>none</code>：元素不被渲染，不占空间。不像<code>visibility: hidden</code>一样，<code>hidden</code>的元素虽然看不见，但是也占位置</li>
<li><code>inline-block</code>:
<ul>
<li>与<code>inline</code>不同之处在于：它可以设置行内元素的width
height以及margin（相当于一个不添加换行符的小block）</li>
<li>与<code>block</code>不同之处在于：已经说了，它不会换行显示</li>
</ul></li>
</ul>
<h3 id="子元素选择">3.3 子元素选择</h3>
<p>​
这里只简单记录使用到的一些语法（我其实也并没有仔细去学的打算，前端学习工作的优先级很低）</p>
<ul>
<li><code>#</code> 可以直接指定id，比如<code>#first</code>
将会指定<code>id = first</code>元素的样式</li>
<li><code>.</code>是class
selector，可以不指定元素：比如下代码块第一行，也可以指定元素：比如第二行</li>
</ul>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.classname</span> &#123;...&#125;		<span class="comment">/* 表示所有 class = &quot;classname&quot;的元素*/</span></span><br><span class="line"><span class="selector-tag">span</span><span class="selector-class">.classname</span> &#123;...&#125;		<span class="comment">/* 表示 span的class = &quot;classname&quot;的元素*/</span></span><br></pre></td></tr></table></figure>
<p>​ 有些有趣的例子可以看这篇文章说的: <a href="https://css-tricks.com/multiple-class-id-selectors/">Difference
between "#header .class" &amp; "#header.class"</a></p>
<h2 id="iv.-js碎片知识">IV. JS碎片知识</h2>
<h3 id="浏览器端js与服务器端js">4.1 浏览器端js与服务器端js</h3>
<p>​
本人还并没有开始Node.js的学习，只是了解了以下浏览器端JS的写法。开始时我还不知道这两者有什么区别，直到遇上了这么一个问题：</p>
<blockquote>
<ul>
<li>Log 5.0希望可以从本地加载用户数据，以便sign in时可以比对用户。</li>
<li>Sign up时可以写出到本地文件</li>
</ul>
</blockquote>
<p>​
查了好久，都没有发现有什么接口可以帮我读出或者写入到本地文件的。最后面向Google，有人说：浏览器上运行的JS出于安全性考虑，是不允许写入和读取本地数据的，如果需要实现文件操作，最好使用一个服务器host的文件。实际上这就不是很前端了。</p>
<p>​ 而Node.js
本质上是后端语言（只不过可以使用JS这个前端语言编辑），Node.js常用于服务器端，它没有：</p>
<ul>
<li>BOM（Browser Object
Model）：对浏览器进行访问和操作的模型。也就是说，<code>window</code>这个没有了</li>
<li>DOM （Document Object Model）：
<code>document</code>以及其下属元素也没有了</li>
</ul>
<p>​ 原来本人上手用浏览器端js，但想做一些后端的事情。</p>
<div class="note danger"><p>学习语言这样的东西时，我延续了Python/C++的学习方式：上手就是自行设计项目并通过实践来学习。这种学习方式有的时候可能并不好，特别是在其前驱知识不牢固的情况下。不看理论、教程、文档可能只能让我们明白
<strong><u>如何解决问题</u></strong> 而不是
<strong><u>如何分析问题并设计方法</u></strong>。</p>
</div>
<h3 id="本地服务器小坑">4.2 本地服务器小坑</h3>
<p>​
我们已知浏览器出于安全考虑，不能随便加载本地文件这一事实。加载本地文件不一定要是进行数据的读入或者写出，比如最基本的
<strong><u>跨模块调（引）用</u></strong>
都属于一种加载本地文件的行为。比如我有两个文件：<code>a.js</code>
以及<code>b.js</code>，其中：</p>
<ul>
<li><code>a.js</code>相当于一个utility模块，定义了很多有趣的常用函数</li>
<li><code>b.js</code>相当于一个客户模块，需要使用<code>a.js</code>的函数</li>
<li><code>c.html</code>调用了<code>b.js</code>模块（作为网页的行为）</li>
</ul>
<p>​ 那么这涉及到import与export。但是由于基于本地文件的import,
export是不允许的（本质是加载本地文件），如果直接在本地使用文件打开，会报如下的错误：</p>
<p><img src="/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/error.png"></p>
<center>
Figure x. CORS错误 无法加载特定的本地文件
</center>
<p>​
但是如果我使用服务器，将<code>c.html</code>定义的网站挂在上面，再使用服务器对应的url访问网页时并不会有文件访问限制。这实际上涉及到两个协议以及一个policy：</p>
<div class="note info"><p>​ 双击html文件可以直接打开为网页，此处使用的是file
protocol，打开网页时浏览器url显示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">file:///&lt;path to your file&gt;</span><br></pre></td></tr></table></figure>
</div>
<div class="note success"><p>​
使用服务器也可以加载网页，此时使用http(s)协议，按照个人的理解，一次http请求访问大概是这样的流程：</p>
<ul>
<li>域名解析：用户输入url，url经过DNS服务转为IP返回给用户</li>
<li>三次握手：由于http（是应用层的）在传输层上使用TCP/IP协议，故需要握手建立连接</li>
<li>网站服务器通过http协议回传html、css、javascript等文件到本地</li>
<li>本地浏览器解析html等文件，渲染网页</li>
</ul>
</div>
<p>​
虽然乍一看，两种方式并没有本质上的区别，都是通过某种方式获得网页文件，在本地进行渲染，那么对于文件访问这种事情，本来不应该有区别的。但本地访问却受到如上图所说的
CORS policy限制：</p>
<blockquote>
<p><strong><u>C</u></strong>ross-<strong><u>O</u></strong>rigin
<strong><u>R</u></strong>esource <strong><u>S</u></strong>haring (CORS)
is an HTTP-header based mechanism that allows a server to indicate any
origins (domain, scheme, or port) other than its own from which a
browser should permit loading resources.[1]</p>
</blockquote>
<p>​ 与之相对的一个概念叫做：Same-origin policy，关于same origin
policy，这篇文章讲得很清楚: <a href="https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy">MDN
Web Docs: Same Origin Policy</a>.
这个policy的大概意思是说，【协议（比如同http或者同https）】【端口】【host】三者必须相同。而本地打开的文件，并没有host，也没办法做到host相同。并且有人这么说：</p>
<blockquote>
<p>Chrome doesn't believe that there's any common relationship between
any two local files.[2]</p>
</blockquote>
<p>​
除了在浏览器中直接disable此安全设置，否则没办法直接绕开（事实上，我觉得绕开也非常不优雅）。假如不绕开，那就只有一个选择了，使用服务器host我们的网页。于是我写了一个http
server：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Use to create local host</span></span><br><span class="line"><span class="keyword">import</span> http.server</span><br><span class="line"><span class="keyword">import</span> socketserver</span><br><span class="line">PORT = <span class="number">8080</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NoCacheHTTPRequestHandler</span>(</span><br><span class="line">    http.server.SimpleHTTPRequestHandler</span><br><span class="line">):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">send_response_only</span>(<span class="params">self, code, message=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().send_response_only(code, message)</span><br><span class="line">        self.send_header(<span class="string">&#x27;Cache-Control&#x27;</span>, <span class="string">&#x27;no-store, must-revalidate&#x27;</span>)</span><br><span class="line">        self.send_header(<span class="string">&#x27;Expires&#x27;</span>, <span class="string">&#x27;0&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    NoCacheHTTPRequestHandler.extensions_map.update(&#123;<span class="string">&quot;.js&quot;</span>: <span class="string">&quot;application/javascript&quot;</span>,&#125;)</span><br><span class="line">    httpd = socketserver.TCPServer((<span class="string">&quot;&quot;</span>, PORT), NoCacheHTTPRequestHandler)</span><br><span class="line">    httpd.timeout = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            httpd.handle_request()</span><br><span class="line">        <span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">            httpd.server_close()</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>​
实际上代码并不是我写的，代码是我从两个Stackoverflow回答中整理出来的（非常抱歉，这两个回答我也不记得来源了，太久远了）。其中第一个回答只是python3的http
request
server（stackoverflow上有人回答了用python2设置的本地http服务器，下面就有个哥们把他代码改成python3了）。然而我发现初版代码有个很大的问题：这tm打开服务器就关不掉了，我记得当时作者调用了个这玩意：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">httpd.serve_forever()</span><br></pre></td></tr></table></figure>
<p>​
<code>Ctrl + C</code>根本关不掉，而平台又是windows，没办法<code>Ctrl + Z</code>再<code>kill %1</code>，非常烦。于是我google（如何才能让http
server不阻塞呢？（因为我发现server每次<code>Ctrl + C</code>没有反应是因为阻塞在一个奇怪的循环里）），最后找到别人写的<code>NoCacheHTTPRequestHandler</code>，再设置一下timeout就可以很方便关闭了。</p>
<p>​
为什么要关闭呢？这里有个我没明白原理的坑：每次我不关闭server，或者没有完全关闭（可能只是挂起了），在修改js代码后刷新网页或者重新访问是不会更新行为的。我怀疑是它端口一直开着，使用的是cache过的网页，故js代码更新并不会引起网页行为的更新。</p>
<h3 id="export-import">4.3 export &amp; import</h3>
<p>​
我一开始以为export以及import的使用就会像我每天早上起床一样简单（确实很简单），但实际上export与import只在解决完http服务器问题之后才开始用（本地file协议根本是不允许的，两个js文件origin都是null，没办法互相访问，除非在html中使用丑陋的全局变量）。</p>
<p>​ 但是export与import我遇到了default 以及non-default (name imports)
问题。</p>
<p>​ 首先，import export必须要在
<code>module</code>中使用。module与一般的js文件不同，在引入html时，需要定义（<strong><u>type=</u></strong>）：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;module&quot;</span> <span class="attr">src</span>=<span class="string">&quot;xxx.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>​
比如在我的练手小项目里：<code>common.js</code>定义了一些多个js文件可以共用的函数，其中一个js文件如<code>signin_modules.js</code>调用了<code>common.js</code>中的一些函数或类，html文件直接加载的是<code>signin_modules.js</code>，那么<code>signin_modules.js</code>就必须是一个module。我开始觉得很疑惑，为什么<code>signin_modules.js</code>是module？不应该是<code>common.js</code>是一个
<strong><u>模块</u></strong>
才对么？实际上，<code>signin_modules.js</code>（使用import的js）是top
level
module，其他的被引用文件都是底层module。import处定义了module，被引用的文件会自动变为lower
level modules。如果不加<code>type=module</code>将会报错：</p>
<blockquote>
<p>SyntaxError: import declarations may only appear at top level of a
module.</p>
</blockquote>
<p>​ 其次，是named以及default的区别。</p>
<div class="tabs" id="onetab-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#onetab-unique-name-1">named import/export</a></li><li class="tab"><a href="#onetab-unique-name-2">default import/export</a></li></ul><div class="tab-content"><div class="tab-pane active" id="onetab-unique-name-1"><p>​ named
import因为带有变量（或者自定义类型）名，故可以同时调入/调出多个元素。但要记住，named一定需要使用花括号包住！</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123;bar, fool&#125; <span class="keyword">from</span> <span class="string">&quot;module name&quot;</span></span><br></pre></td></tr></table></figure>
<p>​ 不管是引入一个还是多个，都需要使用花括号包住。</p></div><div class="tab-pane" id="onetab-unique-name-2"><p>​ default import/export
的好处就是不需要提供名字，但这也导致了每个module只能有一个default
import/export。default情况下不要使用花括号。当然，也可以把default写出来：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> some_value;			<span class="comment">// default可有可无，但花括号一定无</span></span><br></pre></td></tr></table></figure></div></div></div>
<p>​
搞错了default/named的结果（并且还不知道这个机制），就是会找不到模块中的错误（之前搞错了一直以为模块中定义有问题）。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS">MDN Web
Docs: Cross-Origin Resource Sharing (CORS)</a></p>
<p>[2] <a href="https://coderedirect.com/questions/104753/origin-null-is-not-allowed-by-access-control-allow-origin-in-chrome-why">Code
Redirect: "Origin null is not allowed by Access-Control-Allow-Origin" in
Chrome. Why?</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>JavaScript</tag>
        <tag>前端开发</tag>
      </tags>
  </entry>
  <entry>
    <title>Vision Transformers</title>
    <url>/2021/11/28/Vision-Transformers/</url>
    <content><![CDATA[<h1 id="vit">ViT</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​ 去年的一个工作<a href="#refs">[1]</a>，Vision
Transformer的成功带动了变形金刚在视觉邻域的应用。CNN-based的backbone可能就快败在NAS以及ViT衍生模型手下了。为了回顾transformer以及加深理解，我复现了这篇论文<a href="#refs">[2]</a>（其中的ViT-Lite以及CCT）。这个工作是对ViT进行轻型化，并且作者也提出了使用卷积加入inductive
bias的方法。论文提出的网络复现起来很简单，毕竟不是什么大型网络以及复杂架构，但是要复现其结果感觉还是挺吃经验的。复现见：<a href="https://github.com/Enigmatisms/Maevit">[Github🔗:Enigmatisms/Maevit]</a></p>
<table>
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;"><img src="/2021/11/28/Vision-Transformers/train.png"></th>
<th style="text-align: center;"><img src="/2021/11/28/Vision-Transformers/test.png"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">最终（无mixup）训练集准确率（约99.8%）</td>
<td style="text-align: center;">最终（无mixup）测试集准确率（约94.5%）</td>
</tr>
</tbody>
</table>
<center>
Figure 1. CIFAR-10实验，官方实现显示的最终acc约为94.7%
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-a-few-points">II. A Few Points</h2>
<h3 id="inductive-bias">2.1 Inductive Bias</h3>
<p>​ 按照Wikipedia的定义，归纳偏置其实就是
为了处理没有见过的数据而在学习器上做的假设。</p>
<blockquote>
<p>The <strong>inductive bias</strong> (also known as <strong>learning
bias</strong>) of a learning algorithm is the set of assumptions that
the learner uses to predict outputs of given inputs that it has not
encountered.</p>
</blockquote>
<p>​
维基以奥卡姆剃刀原理作为了其中一个例子。事实上，奥卡姆剃刀原理这种归纳偏置实际上是
权重正则化的底层思想：模型不应该过于复杂。</p>
<blockquote>
<p>A classical example of an inductive bias is <a href="https://en.wikipedia.org/wiki/Occam&#39;s_razor">Occam's
razor</a>, assuming that the simplest consistent hypothesis about the
target function is actually the best. Here <em>consistent</em> means
that the hypothesis of the learner yields correct outputs for all of the
examples that have been given to the algorithm.</p>
</blockquote>
<p>​ ViT论文中提到：</p>
<blockquote>
<p>We note that Vision Transformer has much less image-specific
inductive bias than CNNs. In CNNs, locality, two-dimensional
neighborhood structure, and translation equivariance are baked into each
layer throughout the whole model.</p>
</blockquote>
<p>​ 此处所说的inductive
bias实际上是卷积神经网络的特性。由于卷积核每次操作都是针对某个位置领域的像素（或特征）进行运算，卷积操作也就包含了一个这样的假设：一个像素（特征）的信息一般与其周围的像素（特征）存在一定的关联性（当然，如果你非要对每个图像位置，取出其周围的像素，过MLP，然后说MLP也有这样的inductive
bias，那我也没办法）。</p>
<p>​ 相比之下，Transformer看什么都具有全局眼光。Transformer
这种从NLP过来的结构，本来用于处理语句token的embeddings，语言这种东西就会存在长距离的关联关系，如果要使用卷积（比如一维卷积），可能层数得非常深才能使感受野足够大。于是，卷积层的领域信息综合这种inductive
bias在transformers中是找不到的。所以说，ViT-Lite的作者希望自己能把更多传统CNN模型的inductive
bias融合到ViT模型中（毕竟patch化以及插值是唯二利用率空间邻域信息的操作）实际上做的工作非常浅层：</p>
<ul>
<li>我在输入Transformer前，让生成embeddings的网络具有卷积层不就行了吗？看起来像小打小闹。</li>
</ul>
<h3 id="两篇论文的思想">2.2 两篇论文的思想</h3>
<p>​
论文思想其实并没有什么好说的，就是Transformer模型在视觉中的应用：</p>
<div class="note danger no-icon"><p>ViT将图像进行了分块操作（patch），每个patch进行tokenize，形成了一串embeddings序列。而CVT以及CCT实际上是将tokenize的分块操作变成了卷积操作，以此引入inductive
bias，CCT做得更加彻底，使得positional
embeddings不是很必要（但是从我自己的复现实验上看，结论好像有点不同？）</p>
</div>
<div class="note warning no-icon"><p>Embeddings 过多个transformer layer（自注意力 + Feed
forward）。当然，在embeddings输入之前，可以加positional
embeddings信息。</p>
</div>
<div class="note info no-icon"><p>ViT遵循BERT的模式，输出class token进行分类。而CVT CCT使用 sequential
pooling（实际上。。。就是一种注意力pooling机制，使得不定长的sequence可以输出一个单个的embeddings进行分类），相当于是隐式使用class
token了。</p>
</div>
<div class="note success no-icon"><p>一层线性层完成分类。（ViT
imagenet预训练时使用的MLP稍微深一丢丢）。</p>
</div>
<p>​ 值得一提的是，原论文名字叫做：An Image is Worth 16X16
Words....。可以从中看出其“patchify”过程，实际上是固定patch个数的。这使得ViT不适用于不同的数据集：</p>
<ul>
<li>CIFAR10大小只有32 *
32，那么一个patch只有四个像素，能有多少信息？不会要我上采样吧</li>
<li>MNIST更不用说了</li>
<li>ImageNet？真是谁有钱谁work啊，不是人人都能训的动image
net这种贵物的。我们将这种人称之为：卡怪。ViT是一个大模型，参数很多（ViT-base效果不太可，ViT-胡歌效果才SOTA，但是胡歌（huge）版参数已经超ResNet-1001了，我没理解错的话，ResNet-1001是个千层面网络）。</li>
<li>CCT就相对轻型很多了，而且可以适用于小数据集。我自己做实验使用的就是CIFAR-10。</li>
</ul>
<hr>
<h2 id="iii.-训练tricks">III. 训练tricks</h2>
<h3 id="写在前面">3.1 写在前面</h3>
<p>​
我自己本身很反感调参。在我看来，<strong><u>人工智能训练师</u></strong>就是初中毕业就能干的活，但不管怎么样，打不过的时候，该加入还是要加入，至少了解使自己恶心的事物到底恶心在哪，才有机会去改变吧。由于之前一直被设备以及这种恶心感限制，一直没怎么了解训练tricks，这次花了一点时间稍微涉及了一点点。</p>
<blockquote>
<p>人工智能训练师和驯兽师没有区别，训练的客体都是能力未知的对象，训练主体都不需要特别高的智力。乐观地说，人类还是有机会理解自己的创造的，但调参怪没有这个机会。悲观地说，你猜世界上有多少炼丹师是调参怪？</p>
</blockquote>
<h3 id="adamw">3.2 AdamW</h3>
<p>​
之前在自建网络解决一个二分类问题时，遇到了很严重的过拟合。当时Google到的其中一种方案是：使用weight-decay，在优化器里直接设置即可。Weight
decay 实际上就是 L2正则化（in SGD），很简单： <span class="math display">\[
\begin{align}
&amp;L_{\text{final}}=L+L_{\text{L2 Reg}}=L+\alpha\sum_{i=1}^nw_i^2\\
&amp;\frac {d L_{\text{final}}}{dw_i}=\text{grad}+2\alpha w_i\\
&amp;w_{t+1,i}=w_{t,i}-\text{lr}\times (\text{grad}+2\alpha w_i)
\end{align}
\]</span> ​
也就是说，每一次更新，权重都会根据上一次的权重进行一定的衰减。</p>
<p>​ 至少，weight decay = L2 regularization在
SGD中成立。在一些复杂的优化器，又有momentum又有平均的的（比如Adam），weight
decay实际上和L2 regularization是不一样的。</p>
<p><img src="/2021/11/28/Vision-Transformers/Adamw.png"></p>
<center>
Figure 2. AdamW以及Adam的对比<a href="#refs">[4]</a>
</center>
<blockquote>
<p>We note that common implementations of adaptive gradient algorithms,
such as Adam, <strong><u>limit the potential benefit</u></strong> of
weight decay regularization, because the weights do not decay
multiplicatively (as would be expected for standard weight decay) but by
an <strong><u>additive constant factor</u></strong>. <a href="#refs">[4]</a></p>
</blockquote>
<p>​
这个优化器在之前的某个二分类任务中我已经用过了。关于AdamW的更多信息，可以查看<a href="#refs">[5]</a></p>
<h3 id="cosineannealingwarmrestarts">3.3
CosineAnnealingWarmRestarts</h3>
<p>​
Torch自带的cosineLR好像并不是我想要的样子，因为lr_scheduler.CosineAnnealingWarmRestarts出来的是这样的结果（下图绿色）：</p>
<p><img src="/2021/11/28/Vision-Transformers/LEC.png"></p>
<center>
Figure 3. CosineAnnealingWarmRestarts以及我自定义的学习率
</center>
<p>​
绿色的曲线其学习率是一直在回跳到最大初始学习率，这好吗？我没有在API里找到任何关于学习率变小的设置。并且，这个学习率设置还有个这样的问题：如果设置T_mult（也就是让restart频率越来越低，cosine周期越来越长的一个因子），很难控制其在一定epochs后，学习率降到最低（一般来说，最好降到最低才是最好的）。</p>
<p>​
所以我用LambdaLR设计了一个余弦学习率曲线，波动是为了其有一定的退火能力，而我同时希望：</p>
<ul>
<li>学习率不断减小</li>
<li>波动频率不断减小，并且在指定的epoch减到最小</li>
</ul>
<p>​
我将这个学习率称为（xxx-Decay-Cosine-Annealing-Warm-Restart），xxx可以是线性，也可以是指数。思想很简单，学习率曲线被两条曲线夹住（不是渐近线，渐近线很难求，但是可以按照渐近线理解）。一条确定学习率最大值（可以是线性衰减或者指数衰减），另一条确定学习率下界（指数衰减），可以根据初值、终值以及epochs计算所有参数。详情见：(<a href="https://github.com/Enigmatisms/Maevit/blob/master/py/LECosineAnnealing.py">LECosineAnnealing.py</a>)</p>
<p>​ Timm (Pytorch Image
Models)是个好东西，里面提供了可以衰减的CosineAnnealingWarmRestarts:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> timm.scheduler <span class="keyword">import</span> CosineLRScheduler</span><br><span class="line">lec_sch_func = CosineLRScheduler(opt, t_initial = epochs // <span class="number">2</span>, t_mul = <span class="number">1</span>, lr_min = min_max_ratio, decay_rate = <span class="number">0.1</span>, warmup_lr_init = min_max_ratio, warmup_t = <span class="number">10</span>, cycle_limit = <span class="number">2</span>, t_in_epochs = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>​ 学习率曲线是这样的：</p>
<p><img src="/2021/11/28/Vision-Transformers/lr.png"></p>
<center>
Figure 4. CosineAnnealingWarmRestarts in timm
</center>
<p>​
Restart不是瞬间的，而是线性增大的（只不过很快速）。其中涉及到这么一些概念：</p>
<ul>
<li>warmup-epoch：热身阶段。一般用于train-from-the-scratch（从头训练），开始的学习率小，是因为初始化模型时，参数随机，梯度也基本上是随机的。如果学习率太大，梯度乱飞，可能导致NaN。小学习率使得梯度稳定，开始时向正确方向移动。</li>
<li>cooldown-epoch：冷静期。学习率减小到最小时（一般是周期性学习率scheduler结束），需要冷静一下，度过一段贤者时间，以小学习率训练一段时间。</li>
</ul>
<h3 id="labelsmoothingce">3.4 LabelSmoothingCE</h3>
<p>​
分类问题，标签是硬的。而神经网络输出，是模拟量，用模拟过程拟合离散过程存在一定难度（参考：正弦波无限叠加生成方波的吉布斯效应）。有可能在网络设计得不好时，分类很难是正确的。这个时候我们可以把硬的变成软的：</p>
<ul>
<li>Label本身转化成置信度（之前在二分类任务中用过）</li>
<li>在计算loss时进行label平滑。平滑嘛，那其目的离不开：防止过拟合，本质就是正则化手段，涨点tricks了</li>
<li>Timm已经实现了这个loss，可以直接使用</li>
</ul>
<h3 id="加速">3.5 加速</h3>
<p>​
开始时我太笨？了？5个batch就很着急地eval一次，实际上没有必要，一次eval需要花费5-6s（CIFAR-10），那么batch
size（开始时用的是64）情况下782个batch共需要eval
150多次，每个epoch训练的时间增加了10分多钟，太傻了。很显然这并不是我要说的加速。</p>
<p>​ 加速有这么几种方法：</p>
<ol type="1">
<li>混合精度：我们已经知道（在我的CUDA第二篇学习博客中），双精度
非常拉，单精度还行，要是使用float16就更快了。pytorch提供一种混合精度的方式：AMP（Automatic
Mixed Precision），自动确定哪些浮点可以简化。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># From [6]</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># Creates once at the beginning of training</span></span><br><span class="line">scaler = torch.cuda.amp.GradScaler()</span><br><span class="line"><span class="keyword">for</span> data, label <span class="keyword">in</span> data_iter:</span><br><span class="line">   optimizer.zero_grad()</span><br><span class="line">   <span class="comment"># Casts operations to mixed precision</span></span><br><span class="line">   <span class="keyword">with</span> torch.cuda.amp.autocast():</span><br><span class="line">      loss = model(data)</span><br><span class="line">   <span class="comment"># Scales the loss, and calls backward()</span></span><br><span class="line">   <span class="comment"># to create scaled gradients</span></span><br><span class="line">   scaler.scale(loss).backward()</span><br><span class="line">   <span class="comment"># Unscales gradients and calls</span></span><br><span class="line">   <span class="comment"># or skips optimizer.step()</span></span><br><span class="line">   scaler.step(optimizer)</span><br><span class="line">   <span class="comment"># Updates the scale for next iteration</span></span><br><span class="line">   scaler.update()</span><br></pre></td></tr></table></figure>
<ul>
<li>当然，timm实现了更好的接口（NativeScaler），就不需要调用什么scale(loss).backward(),
step之类的了：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">amp_scaler(loss, opt, clip_grad=<span class="literal">None</span>, parameters = model_parameters(model), create_graph = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>cuDNN</li>
</ol>
<p>​
之前一直不知道这个能怎么用，反正CSDN只顾授人以鱼嘛，告诉你装吧，也不告诉你装来干啥，粪坑实锤了（越用越觉得粪坑，实力坑菜逼）。cuDNN能加速一些运算，DL中，典型的卷积运算是会被加速的，cuDNN自动benchmark卷积，找到最好的卷积实现给你用。只需：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.backends.cudnn.benchmark = <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>工人阶级的力量</li>
</ol>
<p>​
数据集加载（Dataloader），使用多个workers。这里遇到了一些这样的问题：</p>
<ul>
<li>dataloader实际上在搞多进程，多进程默认是开子进程的（fork），但是：</li>
</ul>
<blockquote>
<p>The CUDA runtime does not support the <code>fork</code> start method;
either the <code>spawn</code> or <code>forkserver</code> start method
are required to use CUDA in subprocesses. ---- <a href="https://pytorch.org/docs/stable/notes/multiprocessing.html">Pytorch
Document</a></p>
</blockquote>
<p>​
如果在主进程中初始化了torch.cuda程序（先于dataloader有除了model.cuda()的别的cuda操作【？为什么model可以调cuda，难道因为它是进程间共享的？】），就会报错，说不能在fork的subprocess中初始化CUDA。解决方法确实就是，用spawn方法生成新的进程：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.multiprocessing.set_start_method(<span class="string">&#x27;spawn&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>​ spawn和fork的区别：<a href="https://stackoverflow.com/questions/64095876/multiprocessing-fork-vs-spawn">stackoverflow.com:
multiprocessing fork() vs
spawn()</a>。这里不多讲，spawn方式生成进程貌似炸了我的显存（<strong><u>原因可能有两点：</u></strong>1.
spawn本身特性，会大量复制资源，每个新启动的python3解释进程都占用部分资源
2.
在CUDA误初始化，如果是这样的话，误初始化问题解决应该不会炸显存了）。炸显存的问题，<a href="https://blog.csdn.net/YNNAD1997/article/details/113829532">这位CSDN老哥</a>也碰到了，但他貌似没有解决。</p>
<p>​
开始时我一直没能用成fork，都使用spawn（启动很慢，而且还炸显存）。我发现官方实现可以使用fork方式，这让我感到很奇怪，查错最后发现是：RandomErase（Dataloader数据增强的transform）默认使用了CUDA，设置device为cpu就可以解决问题了。</p>
<h3 id="mixup">3.6 Mixup</h3>
<p>​ 我超。我不知道这个工作：<a href="https://arxiv.org/abs/1710.09412">[mixup: Beyond Empirical Risk
Minimization]</a>。这个工作貌似是一种终极数据增强方法。</p>
<p>​
我超。这篇论文我看了30s之后就已经感觉有点6了，mixup就是将两个训练样本叠在一起，label可以不一样，叠加是加权的，最后形成加权的label，让网络去学。作者认为：</p>
<ul>
<li>虽然普通的数据增强确实使得训练数据增多了，但是数据增强并不是在数据的真实分布附近采样，而是加了一些随机噪声，只是增强了抗干扰能力</li>
<li>简单地说，考虑一个多峰分布，mixup可以在峰与峰之间的某个位置采样，使得label和样本在另一种意义上被平滑了。Mixup的作者说到，mixup可被理解为是：</li>
</ul>
<blockquote>
<p>A form of <strong><u>data augmentation</u></strong> that encourages
the model f to behave <strong><u>linearly in-between training
examples</u></strong></p>
</blockquote>
<hr>
<h2 id="iv.-复现结果">IV. 复现结果</h2>
<p>​
我怀疑我复现结果不如官方实现的原因是我并没有使用mixup策略，我使用的是传统的数据增强。我今晚（2021-12-05）尝试了一下mixup，但貌似（可能是没有用好，也可能是才训练了100个epoch，出不了结果）很拉，mixup参数与官方实现一致，就是没有直接调用timm库生成PrefetchLoader（因为没有时间去看文档）。无mixup训练的最佳结果是：训练集acc接近1，测试集acc
94.5%，过拟合还是有点严重：</p>
<p><img src="/2021/11/28/Vision-Transformers/first.png"></p>
<center>
Figure 5. 刚开始训练（MultiStepLR，并且实现有点问题）
</center>
<p><img src="/2021/11/28/Vision-Transformers/cosine.png"></p>
<center>
Figure 6. CosineAnnealingWarmRestarts
</center>
<p><img src="/2021/11/28/Vision-Transformers/lec_lr.png"></p>
<center>
Figure 7. 自定义学习率
</center>
<table>
<colgroup>
<col style="width: 50%">
<col style="width: 49%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;"><img src="/2021/11/28/Vision-Transformers/train.png"></th>
<th style="text-align: center;"><img src="/2021/11/28/Vision-Transformers/test.png"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">最终（无mixup版本）训练集准确率</td>
<td style="text-align: center;">最终（无mixup版本）测试集准确率</td>
</tr>
</tbody>
</table>
<h3 id="更新">12.8 更新</h3>
<p>​
我尝试了一下Mixup（想要脱离timm库用mixup还是有点麻烦的，比如timm中的mixup把输入转换成了numpy。。。为的就是用里面的贝塞尔分布？所以不得不写一个可以把tensor转换成对应numpy格式的函数）。用mixup会使训练时的效果明显变差，但是一取消mixup，效果就很好：</p>
<p><img src="/2021/11/28/Vision-Transformers/Screenshot%20from%202021-12-07%2019-40-38.png"></p>
<center>
Figure 8. 带mixup，最后约94%
</center>
<hr>
<h2 id="reference">Reference</h2>
<p><span id="refs"></span></p>
<p>[1] <a href="https://arxiv.org/pdf/2010.11929.pdf">Dosovitskiy A,
Beyer L, Kolesnikov A, et al. An image is worth 16x16 words:
Transformers for image recognition at scale[J]. arXiv preprint
arXiv:2010.11929, 2020.</a></p>
<p>[2] <a href="https://arxiv.org/pdf/2104.05704.pdf">Hassani A, Walton
S, Shah N, et al. Escaping the big data paradigm with compact
transformers[J]. arXiv preprint arXiv:2104.05704, 2021.</a></p>
<p>[3] <a href="https://arxiv.org/abs/1706.03762">Vaswani A, Shazeer N,
Parmar N, et al. Attention is all you need[C]//Advances in neural
information processing systems. 2017: 5998-6008.</a></p>
<p>[4] <a href="https://openreview.net/pdf?id=rk6qdGgCZ">Fixing Weight
Decay Regularization In Adam</a></p>
<p>[5] <a href="https://www.fast.ai/2018/07/02/adam-weight-decay/">AdamW
and Super-convergence is now the fastest way to train neural
nets</a></p>
<p>[6] <a href="https://efficientdl.com/faster-deep-learning-in-pytorch-a-guide/#4-use-automatic-mixed-precision-amp-">Faster
Deep Learning Training with PyTorch – a 2021 Guide</a></p>
<p></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>Nvidia 简单环境工程</title>
    <url>/2021/11/21/Nvidia-%E7%AE%80%E5%8D%95%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="ampere-pytorch">Ampere Pytorch</h1>
<hr>
<h2 id="i.-introduction">I. Introduction</h2>
<p>​ 近日训练神经网络花了五六十块钱，在<a href="http://www.ai-galaxy.cn/">智星云</a>平台上。这个云平台总的来说还是很便宜的，RTX
3090大概4元/h，之前训练胶囊网络的时候还狠吹了这个平台一波。但我最近感觉，该平台貌似有点坑：</p>
<ul>
<li>RTX 2080Ti的训练速度比我的MX 150（比GTX 960更差一点的卡）更慢，RTX
3090没有3090的样子</li>
<li>环境非常迷惑：比如其1080 Ti的环境，CUDA10.0 + Torch
1.4.0，直接没办法跑</li>
</ul>
<p>​
于是乎我在办公室一个同事的电脑上装了整个深度学习环境。很不幸（又幸运）的是，他的显卡是RTX
3060，对应架构为安培（Ampere
sm_86），不兼容低版本torch，使用不了CUDA加速。考虑到我之前有装显卡驱动搞爆系统的经历，我决定记录一下本次环境工程的过程。</p>
<center>
<img src="/2021/11/21/Nvidia-%E7%AE%80%E5%8D%95%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B/3060.png" style="zoom:67%;">
</center>
<center>
Figure 1. 看起来很便宜 黄仁勋Yes
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-过程">II. 过程</h2>
<h3 id="查看环境">2.1 查看环境</h3>
<p>​ 第一步当然是需要查看硬件参数：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure>
<p>​ 其中右上角会出现CUDA版本：</p>
<center>
<img src="/2021/11/21/Nvidia-%E7%AE%80%E5%8D%95%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B/smi.png">
</center>
<center>
Figure 2. nvidia-smi版本号
</center>
<p>​ 但这只是该驱动（426.00）可以支持的
<strong><u>最高版本CUDA</u></strong>。需要查看自己的CUDA版本则需要使用：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nvcc --version</span><br></pre></td></tr></table></figure>
<p>​
然后我发现，该同学的驱动是475.05.xx（忘了），但是CUDA版本却是9.1。虽说英伟达驱动向下兼容，但是9.1听起来像是上个世纪的东西（雾）。直接升级CUDA即可。</p>
<h3 id="乱搞驱动">2.2 乱搞驱动</h3>
<p>​ 我选择的是CUDA
11.4，其安装程序可以附带安装驱动，也就是说，没有驱动也没有什么问题。Ubuntu
18.04端我选择的是脚本文件安装(.run
文件)，因为这个可以受控。但是安装时遇到了一些问题：</p>
<blockquote>
<p>Existing package manager found...
(然后建议你在继续安装前remove这个existing package manager of the
driver).</p>
</blockquote>
<p>​ <a href="https://askubuntu.com/questions/1211919/error-installing-cuda-toolkit-existing-package-manager-installation-of-the-driv">Ask
Ubuntu</a>上有对应的解决方案，说是<code>--toolkit --silent --override</code>等等flag上去就行了。但个人尝试无效，按照回答直接执行之后，没有报错，但是同样也没安装好CUDA。直接运行脚本，暗装脚本会列举将会被安装的内容，第一次安装时我直接取消了除了Toolkit之外的其他选项，最后貌似也没装上去。</p>
<p>​
<strong><u>我怒了，开始暴力了起来（安全的暴力）</u></strong>。我啪地一下站起来了，很快啊，输入了以下脚本：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">下面这一句为了看看这个电脑上都装了哪些CUDA相关库</span></span><br><span class="line">dpkg -l | grep &quot;cuda&quot;</span><br><span class="line"><span class="meta"># </span><span class="language-bash">删除CUDA相关包以及其配置文件</span></span><br><span class="line">sudo apt-get remove cuda*</span><br><span class="line">sudo apt-get purge cuda*</span><br><span class="line"><span class="meta"># </span><span class="language-bash">不要随便用autoremove！除非你知道你在干什么或者你对autoremove的包进行仔细的检查</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">CSDN上就有autoremove，评论区已经有崩溃老哥说自己autoremove了一些重要包不得不重装系统了</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">显卡驱动，删除</span></span><br><span class="line">sudo apt-get remove nvidia*</span><br><span class="line">sudo apt-get purge nvidia*</span><br></pre></td></tr></table></figure>
<p>​ 执行结束之后，reboot。</p>
<h3 id="安装驱动">2.3 安装驱动</h3>
<p>​ 执行了上面这些命令之后我重启了电脑，果然，图形界面打不开了
，因为显卡驱动已经没了。看到这里并且执行到这里的xdm可以准备重装系统了（误）。在电脑启动界面，GRUB有选择系统的画面，选择Ubuntu
Recovery项，进入recovery模式进行驱动安装。recovery不需要显卡驱动也可以启动图形界面。</p>
<p>​
进入recovery模式之后，既然我们已经知道，系统里没有显卡驱动了（nvidia-smi报错了），那就可以肆无忌惮地装驱动了。直接运行驱动安装脚本，安装项可以全部勾选。安装完毕之后，安装程序将会提示我们进行环境变量设定，此时只需要修改<code>.bashrc</code>文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export PATH=$PATH:...</span><br><span class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:...</span><br></pre></td></tr></table></figure>
<p>​
检查<code>nvidia-smi</code>以及<code>nvcc</code>两个指令是否可以正确执行。按以上步骤（先删除，再重装）的方式，应该是没有问题的。重启即可，重启之后安装一些扩展库（可选）比如cuDNN以及NCCL，这两个库的安装要领只有一个：上英伟达官网对照清楚自己的驱动、CUDA版本对应哪个版本的cuDNN或者NCCL，版本对了就没问题，反正都是<code>.deb</code>包，一个<code>sudo dpkg -i</code>安装就结束了。</p>
<h3 id="安装pytorch">2.4 安装Pytorch</h3>
<p>​
Pytorch即使在最新的驱动以及CUDA（11.4）安装好之后，仍然不厌其烦地告诉你：<code>sm_86</code>
is not a supported architecture for Pytorch, among [... up to sm_70]
blahblahblah。在这里我遇到了两个坑：</p>
<h4 id="多重pytorch">2.4.1 多重Pytorch</h4>
<p>​
我惊奇地发现，pip管理包的时候，同一个库允许多个版本存在。对于这种行为，我不是很能理解，毕竟按我的理解，大多数用户的Python版本是固定的，没有跨版本的需求（用Docker或者Conda管一管不好么）。但我在执行<code>pip3 list</code>
之后，发现电脑上有：<code>1.7.1\1.8.0\1.10.0</code>
三个版本的torch，每次安装前的删除实际上都没有删除干净。</p>
<h4 id="cuda-wheel">2.4.2 CUDA Wheel</h4>
<p>​ 本地安装 CUDA 11.4 并不意味着我们可以直接使用 CUDA11.4
支持。我们知道（你知道吗），Python虽然作为一种动态语言，运行时解释，它也是支持使用编译好的库的（只要编译成
<code>.so</code> 或者 <code>.dll</code> 动态库就行），pip3
不只是安装源码，它也会安装一些动态库，<strong><u>这些动态库的编译方式</u></strong>决定了
pip3 安装的库本身的一些性质。比如我们在 <a href="https://enigmatisms.github.io/2021/09/23/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%901%E3%80%91/">CUDA
踩坑实录 【1】</a> 中已经实践过，CUDA程序作为CUDA Extension被 pytorch /
python 调用，被调用的程序是由 nvcc 编译的，nvcc的一些 flag
则决定了代码受到什么样的 architecture 支持，比如我们可以显式定义
<code>-arch=sm_86</code> 就能使得 <code>sm_86</code>
架构得到支持。也就是说，我们在安装的过程中需要选择CUDA
Wheels，也就是手动写一个（+xxx）：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip3 install torch==1.10.0+cu113</span><br></pre></td></tr></table></figure>
<p>​ 上面的 <code>+cu113</code> 就表示，我们选择CUDA 11.3
wheels，应该就是说，本库的编译是有 CUDA 11.3
完成的。虽然本地是11.4，但并没有什么影响，对于 RTX 3060 这种
<code>sm_86</code> capability 的设备，只要 CUDA 11 + 就可以了。</p>
<p>​ 另一种方法，可以直接使用本地 CUDA
完成库安装：从官网上下载source（Pytorch底层就是在调用C++代码嘛），本地用
nvcc 对 source 进行手动编译，但这确实有一点麻烦。</p>
<h3 id="验证">2.5 验证</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cuda.is_available()</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tmp = torch.zeros(<span class="number">1</span>).cuda()</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>
<p>​ 只要没有任何warning或者error，就是成功。</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>环境工程</tag>
      </tags>
  </entry>
  <entry>
    <title>A Duality Problem of Representations</title>
    <url>/2021/11/14/A-Duality-Problem-of-Representations/</url>
    <content><![CDATA[<h1 id="duality">Duality</h1>
<hr>
<h2 id="i.-introduction">I. Introduction</h2>
<p>In a slide talking about 3D geometry and deep learning, I found
something interesting: one question, of which I can not get rid. This is
a duality question about representations:</p>
<center>
<img src="/2021/11/14/A-Duality-Problem-of-Representations/dual.png" style="zoom:60%;">
</center>
<center>
Figure 1. Duality problem formulation
</center>
<p>These problems lingered in my head:</p>
<ul>
<li>Why and how we can regard probability distribution and particle
filters as dual counterparts to each other?</li>
<li>Same question for occupancy map and point clouds, as they seem to
be, according to the figure above, the representations under different
specifications?</li>
</ul>
<p>So I took some time to sink in this problem. This post is therefore
the summarization of my thoughts.</p>
<span id="more"></span>
<hr>
<h2 id="ii.-about-two-specifications">II. About two specifications</h2>
<p>​ Eulerian and Lagrangian specifications are just two perspective of
perceiving the world. Wikipedia illustrate these two specs with a good
example (though it is talking about flow field):</p>
<blockquote>
<p>The <strong><u>Lagrangian</u></strong> specification of the flow
field is a way of looking at fluid motion where the observer follows an
individual fluid parcel as it moves through space and time. Plotting the
position of an individual parcel through time gives the pathline of the
parcel. This can be visualized as sitting in a boat and drifting down a
river.</p>
</blockquote>
<blockquote>
<p>The <strong><u>Eulerian</u></strong> specification of the flow field
is a way of looking at fluid motion that focuses on specific locations
in the space through which the fluid flows as time passes. This can be
visualized by sitting on the bank of a river and watching the water pass
the fixed location.</p>
</blockquote>
<hr>
<h2 id="iii.-thoughts">III. Thoughts</h2>
<p>You will find that this description is kind of similar to the famous
"<strong><u>Wave–particle duality</u></strong>" . Somehow, the brilliant
physicians device the idea of probability and "uncertainty",
representing any given location of the physical world with the
probabilities of different kinds of particles being present (since we
know that in physics, electrons are actually a "probability cloud"
around the nucleus), which resembles to occupancy grid representation.
However, another intuitive representation of the world is that: The
world composes of myriads of small individual particles. Now this is
kind of like the point clouds, yet in the real world, the "point clouds"
are much denser and complex.</p>
<p>This would mean that, (by my understanding):</p>
<ul>
<li>Eulerian specification tends to directly model the space (no matter
what space this is), for each location within the interested space, we
model the attributes (e.g. temporal or probabilistic) of it.</li>
<li>Lagrangian specification uses individual attention, or to say, the
nonparametric, sampling-like approach to represent the interested
space.</li>
</ul>
<p>Therefore, the duality between probability distribution and particle
filters are quite straight forward:</p>
<div class="note info"><p>Probability distribution comes in many forms. There are basically two
types: parametric and nonparametric. By "probability distribution"
mentioned above, I mean the <strong><u>parametric
approach</u></strong>.</p>
</div>
<p>The salient feature of parameterized approaches is: They are commonly
defined on a fixed space, in this "fixed space", we can calculate the
pdf of this distribution. However, nonparametric approaches are
"sample-based", for example: KDE (kernel density estimation) and
particle filters. For the former one, given location and parameters, the
probabilistic attributes are fixed, yet for the latter one, the given
location might just be "void" in terms of samples, therefore the
information of the given location is subject to all the particles and
every individual matters! The focus is different, one is on the fixed
location in the space, and the other is on each individual. This is just
the characteristic of <strong><u>parameterized distribution</u></strong>
and <strong><u>particle filter method</u></strong>.</p>
<p>Say, if we have all the correct poses and transformations between the
frames (point clouds), we now have two choices of map representation:
Grid map (or voxel map) vs. point-clouds (and its variants like the
representation I've been working on). For each grid (voxel) in the map,
the focus given is "Eulerian", since we focus on the specific location.
As for point clouds, it (yes I am not going to use plural) can be seen
as the "particle filters" of walls and obstacles, which is sample-based
and "Lagrangian".</p>
<hr>
<h2 id="iv.-can-we-dig-deeper">IV. Can we dig deeper?</h2>
<p>Now we know that, point cloud (and its variants) representations are
the dual counterpart of occupancy map, yes but... what is the point? How
this is going to help us? Let's talk about the merge of
observations!</p>
<div class="note warning"><p>Formulation: the example of <u><strong>merge</strong></u> is that, if
we observe a wall in one frame and in the successive frames we observed
the same wall. Since we have the correct transformation, how we going to
use the multi-view observation to get a more accurate wall?</p>
</div>
<p>For Eulerian method like occupancy grid, merge process is naturally
incremental! Because Eulerian methods explicitly models each location,
given the correct point cloud registration result, the update of
occupancy grid is easy (using LiDAR model and the idea of "beam hitting
the obstacles").</p>
<p>Unfortunately, merge for Lagrangian approaches is difficult to tackle
with. The main goal is to build a incremental merge algorithm.
Intuitively, merge for nonparametric approaches usually requires "total
rebuild". For instance, consider every observed wall a particle filter.
Every new observation might add new information to each particle filter,
therefore for the final state a particle filter represents, we might
need to calculate the updated stated from the scratch with no previous
computation reuse (that what I currently believe). To my current belief,
the incremental merge can only be implemented at a coarse-grained
level.</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="http://3ddl.cs.princeton.edu/2016/slides/su.pdf">Hao Su
(Stanford University): 3D Deep Learning on Geometric Forms, pdf</a></p>
<p>[2] <a href="https://en.wikipedia.org/wiki/Lagrangian_and_Eulerian_specification_of_the_flow_field">Wikipedia:
Lagrangian and Eulerian specification of the flow field</a></p>
]]></content>
      <categories>
        <category>Philosophy</category>
      </categories>
      <tags>
        <tag>English</tag>
        <tag>Methodology</tag>
      </tags>
  </entry>
  <entry>
    <title>Distance Metrics on Point Clouds</title>
    <url>/2021/11/14/Distance-Metrics-on-Point-Clouds/</url>
    <content><![CDATA[<h1 id="distance-metrics">Distance Metrics</h1>
<hr>
<h2 id="i.-introduction">I. Introduction</h2>
<p>​
近期的研究有探究一个好的尺度的需求：判断配准是否完成。针对这个问题，我脑子里想的第一件事就是：判定两个点云在某个尺度上是否相近。带着这个目的，我结合之前看过的文献，在解决这个问题的方案中补充了一些新的内容。本文主要包括一下几个内容：</p>
<ul>
<li>三种传统点云尺度的简介（Hausdorff，Chamfer，Earth Mover's）</li>
<li>一种基于深度学习的距离尺度（ECCV 2020）<a href="https://link.springer.com/content/pdf/10.1007/978-3-030-58621-8_32.pdf">DPDist:
Comparing Point Clouds Using Deep Point Cloud Distance</a></li>
</ul>
<blockquote>
<p>低维的最邻近点并不意味着结果能很好地适用于任务，高维的最邻近才是最终的追求。就像你和你异地的（男）女朋友，你们地理上不是最邻近，但是在某个高维空间中，确实是最邻近的，这就是为什么我们需要变换尺度与维度看问题。---
哲♂学家 千越 · 让 · 德 · 叠buff · 何</p>
</blockquote>
<span id="more"></span>
<hr>
<h2 id="ii.-点云距离尺度">II. 点云距离尺度</h2>
<h3 id="引">2.1 引</h3>
<p>​
在某些任务中，我们希望得到两个点云之间的一种接近程度的描述。比如在配准任务中，两个点云中相似的点或特征越接近，那么意味着配准结果越好。但由于点云表征不同于Grid、体素或者深度图等表征方式，点云是无结构，无顺序的。一些简单的比较方式不再适用，比如说：我有两个体素化的点云，这两个点云的接近我可以使用两个体素相减（体素内部含有占用概率），最后对这个结果张量求范数即可。这就是论文中说的：</p>
<blockquote>
<p>They are not a function on a grid, point clouds cannot be compared
using a common metric (such as Euclidean metric)</p>
</blockquote>
<p>​
一般来说点云的距离尺度有三个非常著名的距离：Hausdorff距离，Chamfer距离，Earth
Mover's距离（EMD，或者叫Wasserstein距离，又或者叫Kantorovich-Rubinstein距离）。</p>
<table>
<colgroup>
<col style="width: 33%">
<col style="width: 32%">
<col style="width: 33%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;"><img src="/2021/11/14/Distance-Metrics-on-Point-Clouds/haus.png"></th>
<th style="text-align: center;"><img src="/2021/11/14/Distance-Metrics-on-Point-Clouds/cd.png"></th>
<th style="text-align: center;"><img src="/2021/11/14/Distance-Metrics-on-Point-Clouds/haus.png"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Hausdorff</td>
<td style="text-align: center;">Chamfer</td>
<td style="text-align: center;">Earth Mover's</td>
</tr>
</tbody>
</table>
<center>
Figure 1. 三种常用的Distance metrics图示[1]
</center>
<h3 id="hausdorff">2.2 Hausdorff</h3>
<p>​
Hausdorff距离是一种：worst-case的距离描述，它描述了两个点云之间的一个距离上界。通俗地说，Hausdorff距离（单边）是这样定义的，假设我们有两个点集A，B：</p>
<ul>
<li>A中任意一个点p，都能在B中找到其最邻近点q。那么A中每个点有一个最小距离：<span class="math inline">\(d_i=\mathop{\min}_{q_j}\Vert
p_i-q_j\Vert\)</span></li>
<li>取A中每个点最小距离的最大值（也就是最邻近距离的最大值）</li>
</ul>
<p>​ 完整的Hausdorff应该是：</p>
<ul>
<li>最后反过来，B中也有同样的一个最邻近距离的最大值。求A-&gt;B,B-&gt;A这两个距离中的大者。正式定义应该是：</li>
</ul>
<p><span class="math display">\[
\begin{equation}\label{haus}
d_{haus}=\max \left\{ D(A,B),D(B,A)\right\},\text{ where
}D(X,Y)=\mathop{\max}_{p_i} \mathop{\min}_{q_j}\Vert p_i -
q_j\Vert,p_i\in X,q_j\in Y
\end{equation}
\]</span></p>
<p>​
这个公式的问题还是很大的，此距离很容易受到外点（outliers）的影响。在文献中已经提到了此距离的修改版，简单来说就是截断Hausdorff距离，超过一定阈值的<span class="math inline">\(\mathop{\min}_{q_j}\Vert p_i -
q_j\Vert\)</span>不会被记录。但不管怎么样，这个距离都是一个最坏距离的衡量。</p>
<h3 id="chamfer">2.3 Chamfer</h3>
<p>​
Chamfer距离是一种平均意义上的距离，其意义很好理解：平均的最近点距离，定义如下：
<span class="math display">\[
\begin{equation}\label{chamfer}
d_{chamfer}=\text{normalize}(\sum_{q_j\in B}\mathop{\min}_{p_i}\Vert
p_i-q_j\Vert + \sum_{p_i\in A}\mathop{\min}_{q_j}\Vert p_i-q_j\Vert)
\end{equation}
\]</span> ​
这个距离倒是没什么好说的，它是一个平均意义上的距离，实现起来比较方便，但是对基于特征的方法并不友好（高维最邻近点计算很恶心）。很常用，因为Chamfer
distance相对于EMD存在一个优点：它并不要求建立双射，也就不要求两个点集的大小一致，可以有一对多联系。在骷髅融合者这篇博客中，我分析了一下作者提出的Composite
Chamfer
Loss，作者通过修改反向距离，建立了一个非对称的，针对不同稠密程度点云的Chamfer
loss。</p>
<h3 id="earth-movers">2.4 Earth Movers'</h3>
<p>​ 这是最理想的距离尺度，其基本定义为： <span class="math display">\[
\begin{equation}\label{emd}
d_{EMD}(A, B)=\mathop{\min}_{\phi: A\rightarrow B}\sum_{p_i\in A}\Vert
p_i - \phi(p_i)\Vert
\end{equation}
\]</span> ​ 其中<span class="math inline">\(\phi\)</span>是点集A到B的一个双射。由于是双射，上式是一个双向对称的距离。在2.3中已经说了，双射就要求集合大小一致，通常情况下，这并不容易满足，特别是在SLAM背景下，部分观测（见3.3）导致一般用不了这个距离。但在一般意义下，这个距离是最优的：</p>
<p><img src="/2021/11/14/Distance-Metrics-on-Point-Clouds/emd-cd.png"></p>
<center>
Figure 2. EMD与CD的比较，这张图的结果是很显然的[1]
</center>
<p>​ 接下来到了科普思考时间。为什么这个距离叫做Earth
Mover's（我称之为，搬砖者距离）？ 维基百科上这么说</p>
<blockquote>
<p>In statistics, the earth mover's distance (EMD) is a measure of the
distance between two probability distributions over a region D.
Informally, if the distributions are interpreted as two different ways
of piling up a certain amount of earth (dirt) over the region D, the EMD
is the minimum cost of turning one pile into the other; where the cost
is assumed to be the amount of dirt moved times the distance by which it
is moved.[2]</p>
</blockquote>
<p>​
嗯，intuitively，确实是这样的。所以称这个距离为搬砖者距离也没有问题。</p>
<hr>
<h2 id="iii.-dpdist">III. DPDist</h2>
<h3 id="基本思想">3.1 基本思想</h3>
<p>​ Deep Point Cloud
Distance，则是一种新的距离尺度，相当于是一种基于深度学习输出的误差函数定义（本身DPDist也就可以当做误差函数）。其最主要的思想就是：</p>
<div class="note primary"><p>我们不应该直接去比较两个点云，这是非常不优雅的。点云的比较，点云之间的距离，说白了应当是：其中一个点云的每一个点，到另一个生成点云<strong><u>原本的真实世界障碍物表面</u></strong>的距离。不应当是直接的：点-点距离，应当是：点-面距离。</p>
</div>
<p>​
这个想法确实是自然的，点云表征具有稀疏性，除非两个点云在物理世界的采样点完全一致，否则点-点距离再如何好都只是一个近似罢了。</p>
<center>
<img src="/2021/11/14/Distance-Metrics-on-Point-Clouds/dpdist.png">
</center>
<center>
Figure 3. 论文中有关DPDist与CD（Chamfer distance）的比较
</center>
<p>​
但新的问题同时会出现：真实世界的表面，我们是无法获得的，只能从点云中估计出来。表面估计可以是全局的，也可以是局部的。但一般来说，全局的非常难做：我们要从一个2D点云中，估计一整个连续函数用来表征点云的采样表面，这可能还稍微容易一些，但是3D，emmm，文中说某个网络想做这个事，用了亿点点参数，也没做好。</p>
<p>​
局部表面估计首先简单，参数量可以小，并且，局部近似度能更高（就比如，局部线性化，局部范围越小，近似度可以越高）。那这就产生了两个问题：</p>
<ul>
<li>我怎么能确定，点云A上的给定点p，应该使用点云B的哪一块计算局部表面来估计距离？</li>
<li>局部表面如何估计，计算如何进行？</li>
</ul>
<h3 id="作者的魔法解决之路">3.2 作者的魔法解决之路</h3>
<p>​
首先，我们需要点云的全局特征。说是全局，不如说是很多局部特征的组合，分块儿的局部特征，合成一个全局特征。作者使用3DmFV（没细看过这篇论文），大概思路就是：</p>
<p>​
首先将空间划分为一个个的Grid（可以是一个粗粒度的划分），假设空间中存在<span class="math inline">\(K\times K\times
K\)</span>个grid。由于原点云已经生成了一个N成分的混合高斯模型（GMM）（也就是一个多高斯分布加权的分布），
在不同的Grid中，都可以求到一个Fisher
Vector（也就是综合了Grid局部信息的一个GMM梯度）。由于Grid划分是固定的，固定就意味着训练方便。</p>
<div class="note danger no-icon"><p><span class="math inline">\(K\times K\times
K\)</span>每个格提取GMM的特征，得到一个四维张量：<span class="math inline">\(K\times K\times K\times
F\)</span>。这是整个点云的全局特征，它是一种固定的，有结构的特征。假设这个特征是点云A的，我们将之记为：<span class="math inline">\(L^{S_A}\)</span></p>
</div>
<div class="note warning no-icon"><p>对于每个点云B中的query点（要求点-面距离的点），总是在A中寻找里query点(<span class="math inline">\(b_i\)</span>)最近的grid，在最近Grid周围扩散n步，形成一个<span class="math inline">\(k\times k \times
k\)</span>大小的子grid，k当然是奇数，因为最近点是中心，向外扩散n步则<span class="math inline">\(k=2n+1\)</span>。</p>
</div>
<div class="note info no-icon"><p>这<span class="math inline">\(k\times k \times k\times
F\)</span>大小的张量（subgrid的特征）将被concat到<span class="math inline">\(b_i\)</span>的点云坐标上（好魔法啊，又开始concat了）。最后过一个三层全连接层，得到距离。</p>
</div>
<div class="note success no-icon"><p>由于存在对称性，A-&gt;B以及B-&gt;A的DPDist都需要计算，最后按照点数平均，得到最终的距离。</p>
</div>
<p><img src="/2021/11/14/Distance-Metrics-on-Point-Clouds/struct.png"></p>
<center>
Figure 4. DPDist的网络结构
</center>
<h3 id="个人觉得存在的问题">3.3 个人觉得存在的问题</h3>
<p>（1）部分观测。整个网络还是限定了：每个点都能有个属于自己的表面。这在一些object点云数据集上是成立的，但是在SLAM系统中很难成立。由于使用最近grid，那些两个观测点观测的对称差集中的点，会被错误地assign到一个不属于自己的表面上，这在计算中会导致问题（不准）。所以让我感到迷惑的是，作者将DPDist用在了PCRNet中（PCRNet是一个。。。emmm很魔法的网络），作为点云配准的距离尺度，替换了原来的EMD。看了它的实验就知道：人家搁这搞一张椅子的配准：</p>
<blockquote>
<p>Using the ”Chair” category and following [20], we randomly generate
5070 different transformations for training and other 5070
transformations for testing.</p>
</blockquote>
<p>​
这种物体级数据集当然不会遇到部分观测问题。事实上，部分观测问题也限制了EMD（毕竟EMD希望能建立一个点集之间的双射），部分观测导致双射无法建立。并且在SLAM问题下，对同一个物体进行不同分辨率下的观测，也直接限制了EMD的使用。</p>
<p>（2）3DmFV？虽然，论文中说3DmFV特征描述比PointNet描述更好，但是3DmFV却引入了“体素化”这种东西（虽然可以是一个很粗粒度的）。但这是否会带来accuracy-memory
tradeoff？高斯表征与混合高斯模型的描述能力以及是否有正确的物理含义也是没有说清楚的。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="http://3ddl.cs.princeton.edu/2016/slides/su.pdf">Hao Su
(Stanford University): 3D Deep Learning on Geometric Forms, pdf</a></p>
<p>[2] <a href="https://en.wikipedia.org/wiki/Earth_mover%27s_distance">Wikipedia:
Earth Mover's Distance</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>PointCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>概率图模型</title>
    <url>/2021/11/10/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="crf-mrf">CRF &amp; MRF</h1>
<hr>
<h2 id="i.-introduction">I. Introduction</h2>
<p>​ 本文是早期被挂在<a href="https://github.com/Enigmatisms/Algorithms-Plus">Github🔗:
Enigmatisms/Algorithm
Plus</a>上的一篇学习总结。写这篇学习笔记的时候博客还没有诞生，也刚刚熟练掌握Typora。本文相当于是考古post，虽然古老，但我发现当年的我学习热情也还是挺高的，这篇笔记可以说是写得不错的一个概率图模型入门文章了（开始自夸，尽管UGM部分没写完）。</p>
<p>​ 可能我最近还是要重新学一下概率图模型:</p>
<blockquote>
<p>一个概率图模型，上面的所有结点构成了所有随机变量的联合分布。需要表达的就是联合分布。--早期HQY的理解</p>
</blockquote>
<p>​
之前应该只是清楚了其中的一些概念，但是并没有产生深入的理解，比如MRF与置信传播的原理以及具体的应用方式等等（虽然已经是很老的传统方法了）。方法老归老，思想本质有启发意义就是好的。</p>
<span id="more"></span>
<hr>
<h2 id="ii.-dgm">II. DGM</h2>
<h3 id="dgm-中三种典型结构的理解">2.1 DGM 中三种典型结构的理解</h3>
<p>​ DGM(Directed Graph Model)。又叫贝叶斯网络。</p>
<pre class="mermaid">
graph LR

A[A Intelligence]--&gt;B[B GPA]
A--&gt;C[C Innovative prop.]

</pre>
<h4 id="结构一-tail-to-tail-单父多子">2.1.1 结构一 Tail to Tail
(单父，多子)</h4>
<ul>
<li>当观测到A，B与C之间独立（不存在关系，<strong><u>没有可以有信息推断</u></strong>）</li>
<li>没有观测到A，B，C之前可以有隐含的关系，不独立</li>
</ul>
<p>举个例子：</p>
<ul>
<li>A智力，B成绩，C创新力。当不知道A时，我们可以隐含地推定，当一个人成绩高，说明他创新能力高的概率很大（概率推断），反之亦然</li>
<li>而如果GPA，创新力只受到智力一个因素的影响时，已知A，那么GPA和创新力就毫无关系了。因为这两个因素B,C已经确定了，再进行概率推断已经没有意义了（信息量为0）.<strong><u>如果这个例子不好理解，那么还有一个例子：</u></strong></li>
<li>A
今天下雨，B明天下雨，C今天地面湿。其中，A（下雨）有80%可能导致积水（C），20%可能导致不积水（<span class="math inline">\(\overline
C\)</span>），50%下雨（B）。那么A未知时，地面湿时（假设C发生），可以反推A是否发生，再反推B是否发生，反过来也一样。</li>
<li>但是如果A发生了，那么C与B只与A当前事实有关，<strong><u>已经不会受到来自B或者C的推断影响了！（影响消除）</u></strong>。</li>
<li>A的观测会导致B,C的相互独立（信息的互不影响性）</li>
</ul>
<h4 id="结构二-head-to-tail-典型的因果关系">2.1.2 结构二 Head to Tail
（典型的因果关系）</h4>
<pre class="mermaid">
graph LR

A[A Diffculty]--&gt;B[B Grade]
B--&gt;C[C Recommendation]

</pre>
<p>B为关键结点。当：</p>
<ul>
<li>B没有被观测，A和C是可以有推断关系（信息关联性）的，不独立</li>
<li>B被观测：A与C独立，A已经不影响C的发生了</li>
</ul>
<p><strong><u>可以用马尔可夫链的想法来理解！</u></strong>历史事件的无后效性！当
当前不确定时，<strong>由于历史状态可以确定当前状态</strong>，那么相当于历史可以影响未来（下一状态）。而当前状态已知的话，历史信息已经不起作用力，下一状态完全由当前状态决定。</p>
<p>例子：</p>
<ul>
<li>不知道成绩的情况下，如果考试的难度大，那么每个人在考好的情况下获得推荐的概率都大。</li>
<li>但是知道了成绩的话，收益就和风险没关系了。你考得好就能获得推荐，考不好就不行。</li>
</ul>
<h4 id="结构三-head-to-head-汇点">2.1.3 结构三 Head to Head
（汇点）</h4>
<pre class="mermaid">
graph LR

A[A Difficulty]--&gt;C[C Grade]
B[B Intelligence]--&gt;C

</pre>
<p>C为关键节点。当：</p>
<ul>
<li>C没有被观测：那么A和B互相不影响（因为缺少信息判断A与B的相互影响性），结果未知，原因互相产生的影响不可知。<strong><u>条件独立</u></strong></li>
<li>C被观测到：A与B存在联系的结果，可以A-&gt;B推断或者反之。</li>
</ul>
<p>例子：</p>
<ul>
<li>考试成绩不清楚的时候，每个人的智力 /
考试难度两者之间如果也未知，知道其中一个也推不出另一个来。</li>
<li>但是如果已知成绩，比如：成绩普遍很好。那么由B，比如某个人的智力不行，但是成绩好，可以推定A（难度低），反之，如果成绩普遍很差，由B（高智力），可以推知A（难度高）。</li>
</ul>
<p><strong><u>以上这三种有向图结构，可以方便进行条件独立判定以及信息关联性的快速区分，判定两个随机变量之间是否存在关联时可以应用。</u></strong>联系例子即可。</p>
<ul>
<li>每个节点：都是一个随机变量，一般未知，需要从信息中推断</li>
<li>每个有向弧：都是条件概率。A发生时，C存在概率发生，则A-&gt;C有弧。</li>
</ul>
<h3 id="条件独立与马尔可夫链">2.2 条件独立与马尔可夫链</h3>
<p>条件独立： <span class="math display">\[
\begin{equation}
P(X,Y|Z)=P(X|Z)P(Y|Z)
\end{equation}
\]</span> ​
在Z发生的情况下，X，Y同时发生的概率为分别概率的积。可以写成另一种形式：
<span class="math display">\[
\begin{equation}
P(X|Y,Z)=\frac{P(X,Y,Z)}{P(Y,Z)}=\frac{P(X,Y|Z)P(Z)}{P(Y|Z)P(Z)}=\frac{P(X,Y|Z)}{P(Y|Z)}=P(X|Z)
\end{equation}
\]</span> ​
这最能直接说明条件独立的意义：给定条件Y,Z，若X,Y条件独立，Y条件不影响X事件，可以直接从条件中删除。而CRF中的有向边表征了条件概率，对应地，结点间关系（以上三种模式）表征了条件独立性。</p>
<p>​ 如果两个结点之间的中间结点已经完全确定，已经没有
<strong><u>不通过中间已经观测结点</u></strong>
的直连路径或者间接路径了，此时两个结点条件独立。而条件独立可以用于理解Markov链：
<span class="math display">\[
\begin{equation}
P(x_t)=P(x_1)P(x_2|x_1)P(x_3|x_1,x_2)...P(x_t|x_1,x_2,...x_{t-1})
\end{equation}
\]</span> ​
这个是普通的链式法则。而由于一阶马尔可夫假设：历史不影响未来，过去的状态与未来条件独立。那么可以简化链式法则为：
<span class="math display">\[
\begin{equation}
P(x_t)=P(x_1)P(x_2|x_1)P(x_3|x_2)...P(x_t|x_{t-1})=P(x_1)\prod_{i=1}^tP(x_{i}|x_{i-1})
\end{equation}
\]</span> ​ 这可以大大简化运算以及储存难度。</p>
<h3 id="使用例子理解dgm-马尔可夫毯">2.3 使用例子理解DGM /
马尔可夫毯</h3>
<p>朴素贝叶斯就是个很典型的DGM例子。朴素（naive）就naive在：</p>
<blockquote>
<p>基于特征条件独立假设的分类器。</p>
</blockquote>
<p>​ 特征条件独立这个假设很强了，一般做不到。但是在DGM中可以表示为：</p>
<pre class="mermaid">
graph TB

A[Label]--&gt;B[Feature 1]
A--&gt;C[Feature 2]
A--&gt;D[Feature 3]
A--&gt;E[...]

</pre>
<p>​ 给定Label后，所有的Features毫无关联（Tail to Tail 结构）。</p>
<h4 id="马尔可夫毯">2.3.1 马尔可夫毯</h4>
<p>​ 马尔可夫毯说的是这样一个集合：集合<span class="math inline">\(\Pi(t)\)</span>表征了，当我们对集合<span class="math inline">\(\Pi(t)\)</span>内的所有随机变量进行观测，那么会导致结点t与剩下的结点之间完全条件独立（<strong>啊，被孤立了，相当于<span class="math inline">\(\Pi(t)\)</span></strong>把t墙了）。例子：</p>
<pre class="mermaid">
graph LR

A(1)--&gt;B(2)
A--&gt;C(3)
B--&gt;D(5)
C--&gt;D
B--&gt;E(4)
C--&gt;F(6)
E--&gt;G(7)
D--&gt;F
D--&gt;G
F--&gt;G

</pre>
<p>​ 那么对于结点5，其马尔可夫毯为？</p>
<ul>
<li>首先2，3给定之后，由于2，3为5的父结点，2，3的观测导致5与1的独立</li>
<li>此后是5与4的独立：有赖于2的给定。</li>
<li><strong><u>观测本身会导致被观测变量与其父节点或者子结点独立！</u></strong>不确定性消除。故5建立6，7的观测，6，7要给定。</li>
<li>但是给定了7，在5，7，4形成了一个Head to Head
结构。会导致5和4的不独立，那么需要给定4以消除不确定性的方式终结。</li>
<li>最后的毯子是：<span class="math inline">\({\{2,3,4,6,7\}}\)</span></li>
</ul>
<h4 id="dgm到底能干什么">2.3.2 DGM到底能干什么</h4>
<p>​
多个变量错综复杂的因果关系，相互有影响。一个变量的改变可能导致整个网络（说到网络就会形成一个高维结构了，之所以是高维，指的是这个图可能不是平面图，不一定表达的就是二维关系）内部的变量发生连锁变化。那么为了解决有条件独立
/ 条件概率联系起来的多个网络变量，需要使用这个方法。</p>
<h4 id="有向图的概率表示">2.3.3 有向图的概率表示</h4>
<p>由条件概率的定义，联合概率可以由边缘 /
条件表示。在有向图中，由于有向图对条件概率进行建模（每一条边就是一个条件概率关系），那么使用有向图如何表示概率？举个例子：</p>
<pre class="mermaid">
graph LR

A((X1))--&gt;B((X2))
B--&gt;C((X3))
B--&gt;D((X4))
C--&gt;E((X5))
D--&gt;E

</pre>
<p>​ 如果需要使用有向图关系表示<span class="math inline">\(\{x_1,x_2,x_3,x_4,x_5\}\)</span>的联合概率分布，如何写出这个表达式？（给定顶层结点，也就是起源结点<span class="math inline">\(x_1\)</span>的初始分布<span class="math inline">\(P(x_1)\)</span>），则表达式为： <span class="math display">\[
\begin{equation}
P(x_1,x_2,x_3,x_4,x_5)=P(x_1)P(x_2|x_1)\rightarrow?
\end{equation}
\]</span> ​ 之后，<span class="math inline">\(x_3\)</span> <span class="math inline">\(x_4\)</span>是乘法关系还是加法关系？首先可以肯定，接下来的概率表达式是<span class="math inline">\(P(x_4|x_2)\)</span>与<span class="math inline">\(P(x_3|x_2)\)</span>（由于<span class="math inline">\(x_2\)</span>的存在，导致<span class="math inline">\(x_1\)</span>，<span class="math inline">\(\{x_3,x_4\}\)</span>条件独立），个人认为，此处<span class="math inline">\(x_5\)</span>的产生是<span class="math inline">\(\{x_3,x_4\}\)</span>共同作用的结果。比如说，考试：<span class="math inline">\(\{x_3,x_4\}\)</span>分别表示难度以及学生智力，<span class="math inline">\(x_5\)</span>为分数。产生分数必须要有前两个因素，故此处虽然是两个通路，但是仍然是乘法原则起作用（与事件）（<strong><u>可能隐含表达了，DGM中子结点需要所有父结点成立而产生</u></strong>）
<span class="math display">\[
\begin{equation}
P(x_1,x_2,x_3,x_4,x_5)=P(x_1)P(x_2|x_1)P(x_3|x_2)P(x_4|x_2)P(x5|x_3,x_4)
\end{equation}
\]</span> ​ 一个更加复杂的例子：</p>
<pre class="mermaid">
graph LR

A((X1))
B((X2))
C((X3))
D((X4))
E((X5))
F((X6))
G((X7))
A--&gt;D
A--&gt;E
B--&gt;D
C--&gt;D
C--&gt;E
D--&gt;F
D--&gt;G
E--&gt;G

</pre>
<p>​ 可以立即得到联合分布：（不仔细推了） <span class="math display">\[
\begin{equation}
P(x_1,...x_7)=P(x_1)P(x_2)P(x_3)P(x_4|x_1,x_2,x_3)P(x_5|x_1,x_3)P(x_6|x_4)P(x_7|x_4,x_5)
\end{equation}
\]</span></p>
<p>​ 这样的联合概率求解规律是可以推广的。</p>
<hr>
<h2 id="iii.-无向图模型ugm">III. 无向图模型（UGM）</h2>
<h3 id="基本概念">3.1 基本概念</h3>
<p>​ 区别于有向图模型（DGM），无向图模型不是对因果关系进行建模。</p>
<p>​
无向图和有向图的区别是什么？有向图表征了因果关系，并且连接有方向性，导致了处理图像这样的问题时，<strong><u>不方便进行建模</u></strong>。</p>
<pre class="mermaid">
graph LR

1--&gt;4
2--&gt;5
3--&gt;6
1--&gt;2
2--&gt;3

4--&gt;5

5--&gt;6

4--&gt;7
5--&gt;8
6--&gt;9
7--&gt;8
8--&gt;9

</pre>
<p>​
可以看出，在对有向图进行建模时，如果要进行条件独立分析（比如我们要单独分析5与其他的结点的条件独立性）。需要寻找马尔可夫毯，那么在有向图中，除了<span class="math inline">\(\{2,4,6,8\}\)</span>之外，实际上还有别的结点，而<span class="math inline">\(\{2,4,6,8\}\)</span>是1阶邻域，在图像处理中比较常见求一阶邻域与中心点间的关系。而此处，要加入<span class="math inline">\(\{3,7\}\)</span>结点（Head to
Head，由于给定了8，5与7不再条件独立，需要给定7，3的话同理）。那么显然我们加入了奇怪的点，导致分析存在一些问题，并且与有向图网络的生成方向还存在关系。</p>
<p>​
而使用无向图的话，由于结点之间是平等的，在无向图中的马尔可夫毯直接就是<span class="math inline">\(\{2,4,6,8\}\)</span>。</p>
<p>​ 无向图中，存在三种独立性：</p>
<ol type="1">
<li>全局独立性（全局马尔可夫性）</li>
</ol>
<pre class="mermaid">
graph LR

A((1))---B((2))
B---D((4))
A---C((3))
C---D
E((5))---A
D---F((6))

</pre>
<p>​ 当我们删除结点<span class="math inline">\(\{2,3\}\)</span>时，可知集合<span class="math inline">\(\{1,5\}\)</span>以及<span class="math inline">\(\{4,6\}\)</span>之间完全没有联系了。删除两个结点之间的连通性结点，产生两个连通支，则这两个连通支
<strong>独立</strong>。</p>
<ol start="2" type="1">
<li>局部独立性（局部马尔可夫性）</li>
</ol>
<pre class="mermaid">
graph TB

a((1))
b((2))
c((3))
d((4))
e((5))
f((6))
g((7))
a---b
a---c
a---d
a---e
c---f
e---g
b---f
d---g

</pre>
<p>​
可知，当我们把2，3，4，5删去之后，1结点与所有其他结点完全没有联系了。<strong><u>1被孤立了，因为其马尔可夫毯已经被删除了。</u></strong>那么，1与其他结点条件独立。写为表达式可以如下：</p>
<p>​ 设<span class="math inline">\(V_k\)</span>为我们探索的结点，<span class="math inline">\(V_M\)</span>为<span class="math inline">\(V_k\)</span>的马尔可夫毯的节点集合，而<span class="math inline">\(V_S\)</span>为<span class="math inline">\(V_i\in
\{V\}/\{V_M\cup V_k\}\)</span>，则可知： <span class="math display">\[
\begin{equation}
V_k\perp V_S|V_M
\end{equation}
\]</span> ​
即给定马尔可夫毯，则对应结点和除其本身以及马尔可夫毯结点之外的所有结点条件独立。</p>
<ol start="3" type="1">
<li>成对独立性（成对马尔可夫性）</li>
</ol>
<p>​
u，v为两个没有直连边的结点。去掉u，v之外的其他点，<strong><u>u，v条件独立。</u></strong></p>
<h3 id="团块clique的概念">3.2 团块（Clique）的概念</h3>
<p>​
如果一个结点集合内，任意两个结点之间存在连边，那么称这是一个团（Clique）。</p>
<p>​
最大团：在一个团C外部任意找一个结点，加入此团后都会破坏团的性质（此结点与至少一个结点之间不存在连边）。也即外部已经不能再加入结点使团变大了。</p>
<p>​
无向图模型中一般会涉及到大量结点，那么要表示这些结点的联合概率就十分麻烦。可以使用最大团来进行描述，将
<strong><u>无向图中的联合概率分布表示为极大团的势函数（Potential
Function）</u></strong>的积。也即： <span class="math display">\[
\begin{equation}
P(x)=\frac{1}{Z}\prod_{i=1}^n\psi_i(x_i)
\end{equation}
\]</span> ​ 上式中，<span class="math inline">\(\psi_i(x)\)</span>表示极大团<span class="math inline">\(x_i\)</span>的势函数，而Z则是归一化因子，为了使<span class="math inline">\(P(x)\)</span>满足概率的归一化性质。归一化因子又叫做：配分函数（Partition
Function），但是如何进行计算呢？举个例子（例子来自CSDN，但是感觉讲的不太清楚，我自己理解一下：）</p>
<div class="note info"><p>2021.11.15补充：当时还会看粪坑CSDN呢。PS：参考的文献都没有记录。</p>
</div>
<pre class="mermaid">
graph TB

A((x1))
B((x2))
C((x3))
D((x4))
E((x5))
A---B
A---C
B---C
C---D
C---E

</pre>
<p>​ 可知，图中存在三个极大团：<span class="math inline">\(\{x_1, x_2,
x_3\}\)</span>，<span class="math inline">\(\{x_3,x_5\}\)</span>，<span class="math inline">\(\{x_3, x_4\}\)</span>
(注意一个结点可以存在于多个极大团中！)。那么整个联合概率分布可以写为：
<span class="math display">\[
\begin{equation}
P(x_1, x_2, x_3,x_4,x_5)=\frac
1Z\psi_1(x_1,x_2,x_3)\psi_2(x_3,x_5)\psi_3(x_3,x_4)
\end{equation}
\]</span> ​
那么Z应如何计算？需要对每个结点进行遍历。下式为每个结点所在极大团的势函数：
<span class="math display">\[
\begin{align}
    &amp; x_1:\psi_1(x_1,x_2,x_3)\\
    &amp; x_2:\psi_1(x_1,x_2,x_3)\\
    &amp; x_3:\psi_1(x_1,x_2,x_3)\psi_2(x_3,x_5)\psi_3(x_3,x_4)\\
    &amp; x_4:\psi_3(x_3,x_4)\\
    &amp; x_5:\psi_2(x_3,x_5)
\end{align}
\]</span> ​
对每个结点进行求和归一化。为什么要这么做？为什么是对每一个结点结点所在团的势函数？而不是求每一个结点对应的某一个其他函数进行累加求和？</p>
<div class="note danger"><p>2021.11.15
补充：诶？我最后在这里写了一个开放性思考题？应该是原来我没想清楚，但是最后也没去想。</p>
</div>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title>位姿变换与六轴仿真</title>
    <url>/2021/10/31/%E4%BD%8D%E5%A7%BF%E5%8F%98%E6%8D%A2%E4%B8%8E%E5%85%AD%E8%BD%B4%E4%BB%BF%E7%9C%9F/</url>
    <content><![CDATA[<h1 id="axis6">Axis6</h1>
<hr>
<p>​
稚晖君牛逼。看了他的六轴机器人之后，我感觉自己没学过自动化。为了证明自己是自动化专业的学生，我尝试学习以及手推了一下正逆运动学公式，手写了一个六轴机器人的控制、仿真（rviz以及Gazebo:
for those who doesn't know how to pronounce:
<code>ɡəˈziːboʊ</code>，重音在前），代码放在了<a href="https://github.com/Enigmatisms/Axis6">[Github🔗:Enigmatisms/Axis6]</a>。本文包含如下内容：</p>
<ul>
<li>位姿变换/正逆运动学的一些基本知识</li>
<li>Gazebo的配置使用</li>
<li>仿真效果视频（<del>高清无码</del>）</li>
</ul>
<p>​ 这里放两张图：</p>
<table>
<colgroup>
<col style="width: 63%">
<col style="width: 36%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;"><img src="/2021/10/31/%E4%BD%8D%E5%A7%BF%E5%8F%98%E6%8D%A2%E4%B8%8E%E5%85%AD%E8%BD%B4%E4%BB%BF%E7%9C%9F/rviz.png" style="zoom:85%;"></th>
<th style="text-align: center;"><img src="/2021/10/31/%E4%BD%8D%E5%A7%BF%E5%8F%98%E6%8D%A2%E4%B8%8E%E5%85%AD%E8%BD%B4%E4%BB%BF%E7%9C%9F/gazebo.png"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">rviz仿真结果</td>
<td style="text-align: center;">Gazebo仿真结果</td>
</tr>
</tbody>
</table>
<center>
Figure 1. 仿真效果图
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-前置知识">II. 前置知识</h2>
<h3 id="位姿变换左右乘">2.1 位姿变换左右乘</h3>
<p>​ 这个问题个人之前一直没有搞清楚，也没有静下心来推过。</p>
<p>​ 给定空间中一个点p以及一个位姿变换<span class="math inline">\(T=[R\quad
t]\)</span>（非齐次），点p经过位姿变换的结果应该是： <span class="math display">\[
\begin{equation}\label{basic}
p&#39;=Rp+t
\end{equation}
\]</span> ​
那么现在有这样一个问题，如果我想对点p进行多次变换？或者是进行一次<strong><u>两个位姿变换合成</u></strong>对应的变换？应该怎么做？假设我们有两个位姿变换：<span class="math inline">\(T_1 = [R_1\quad t_1]\)</span>以及<span class="math inline">\(T_2 = [R_2\quad t_2]\)</span>，乍一看应该这么做：
<span class="math display">\[
\begin{equation}\label{composite}
p&#39;=R_2(R_1p+t_1)+t_2=R_2R_1p+R_2t_1+t_2
\end{equation}
\]</span> ​
上面这个公式，思想非常直白。不是要多次变换吗？不是要合成吗？那就直接先变换一次，再对结果变换一次就行了。但是<strong><u>实际上，对于位姿变换合成问题而言，这是错的结果</u></strong>。首先，我在这里给出结论：
<span class="math display">\[
\begin{align}
&amp;p&#39;=R_1(R_2p+t_2)+t_1=R_1R_2p+(R_1t_2+t_1)\tag{合成变换}\\
&amp;p&#39;=R_2(R_1p+t_1)+t_2=R_1R_2p+R_2t_1+t_2\tag{变换的复合}
\end{align}
\]</span> <div class="note danger"><center>
合成变换，与变换的复合是两回事。
</center>
</div></p>
<p>​
很多时候，我们接触的都会是合成变换。举一个例子：点云配准。假设点云A到点云B的位姿变换为T（点云A对应的激光器坐标系
需要经过变换T才能变换到点云B对应的激光器坐标系位置），已经存在一个粗糙的初始位姿变换：<span class="math inline">\(T_0\)</span>，这个变换可以是里程计或者一些算法给出的，需要
<strong><u>精配准</u></strong>
来修正这个位姿变换，使之更符合实际观测，那么假设这个精配准模块求出，点云在位姿<span class="math inline">\(T_0\)</span>下，还需要进行的变换<span class="math inline">\(\Delta T\)</span>，最后合成<span class="math inline">\(T_0\)</span>与<span class="math inline">\(\Delta
T\)</span>得到最终的变换。 ​
合成变换与变换复合的本质区别是：<strong>讨论的坐标系不同</strong>。变换的复合具有非常简单的思想，正如函数的复合，对输出进行一次新的变换。<strong><u>两次变换都是在同一个坐标系下讨论的</u></strong>，可以认为：</p>
<div class="note info"><p>参与变换复合的两个变换，是两个互不相关的，在同一个坐标系下讨论的绝对位姿变换，之间没有相对性。</p>
</div>
<p>​ 而合成变换，则具有相对性。仍然以上面的点云配准为例子，<span class="math inline">\(\Delta T\)</span>变换是在<span class="math inline">\(T_0\)</span>变换的基础上进行的，是在<span class="math inline">\(T_0\)</span>对应的坐标系下的一个变换，而<span class="math inline">\(T_0\)</span>是相对于另一个坐标系（比如全局坐标系或者子地图坐标系而言）。也就是说：</p>
<div class="note info"><p>参与合成变换的两个变换，具有关联关系，其中的一个变换是基于另一个变换确定的坐标系来讨论的。</p>
</div>
<p>​ 既然如此，那么在两种情况下的【合成的】变换分别是什么？ <span class="math display">\[
\begin{align}
&amp;T=T_1T_2\tag{合成变换}\\
&amp;T=T_2T_1\tag{变换的复合}
\end{align}
\]</span> ​ 只简单说一下合成变换为什么是右乘：显然，因为<span class="math inline">\(T_2\)</span>是在<span class="math inline">\(T_1\)</span>变换后的坐标系下的一个相对变换，其中的平移量相当于直接被<span class="math inline">\(T_1\)</span>预先变换了一次（平移就相当于是一个点）。整个式子可以看成是：<span class="math inline">\(T_2\)</span>变换被<span class="math inline">\(T_1\)</span>预先变换了一次，由于是<span class="math inline">\(T_1\)</span>来变换（动词）<span class="math inline">\(T_2\)</span>，则显然<span class="math inline">\(T_1\)</span>应该放在左边。</p>
<p>​ 所以要回答左右乘问题，其中一个角度应该是：</p>
<ul>
<li>左乘对应了绝对变换，右乘对应了追加变换，是在前一变换对应坐标系下讨论的。</li>
</ul>
<h3 id="左右乘讨论的衍生">2.2 左右乘讨论的衍生</h3>
<p>​ 为了方便理解，我画了一个图：</p>
<p><img src="/2021/10/31/%E4%BD%8D%E5%A7%BF%E5%8F%98%E6%8D%A2%E4%B8%8E%E5%85%AD%E8%BD%B4%E4%BB%BF%E7%9C%9F/transform.png"></p>
<center>
Figure 2. 位姿变换示意图
</center>
<p>​
坐标系1经过位姿变换T变换到坐标系2，那么对于两个系中定义的一些点，其坐标变换公式是什么？假设点p在坐标系i下的坐标是<span class="math inline">\(p_i\)</span>：（为了方便起见，这两个坐标都是齐次坐标）
<span class="math display">\[
\begin{align}
&amp;p_1=Tp_2\label{p1}\\
&amp;p_2=T^{-1}p_1\label{p2}
\end{align}
\]</span> ​
从坐标系1变到坐标系2是变换T，而坐标系1点变换到坐标系2就是<span class="math inline">\(T^{-1}\)</span>。这也可以用左右乘推出的公式来讨论：假设两个坐标系都是相对于一个绝对的坐标系，两个坐标系相对绝对坐标系的变换分别为<span class="math inline">\(T_1,
T_2\)</span>，那么对于点p，两个坐标系对应的坐标转换到绝对坐标系下应该是相等的，因为描述的都是绝对坐标系下的点<span class="math inline">\(p^{*}\)</span> <span class="math display">\[
\begin{equation}
T_1T_{1-p}p^*=T_2T_{2-p}p^*
\end{equation}
\]</span> ​ 因为<span class="math inline">\(T_{1-p}p^*=p_1\)</span>且<span class="math inline">\(T_{2-p}p^*=p_2\)</span>，而上式是由右乘（相对变换）得到的，可以推出公式<span class="math inline">\(\eqref{p1}\)</span>，<span class="math inline">\(\eqref{p2}\)</span>来。</p>
<h3 id="正逆运动学">2.3 正逆运动学</h3>
<p>​
关于D-H坐标与正逆运动学，这个人的博客讲得很清楚（非常推荐，他的博客写得不错，上一个我觉得写得不错的博客是苏剑林的）：</p>
<div class="note success"><center>
<a href="http://gaoyichao.com/Xiaotu/?book=math_physics_for_robotics&title=inverse_kinematics">无处不在的小土</a>
</center>
</div>
<p>​
关于正逆运动学的原理以及D-H坐标表示，我就不赘述了，上面链接的博客已经有了。我实现的六轴机器人，正逆运动学的思想是从以上博客以及Wikipedia中学来的，使用的是一个类似PUMA
560的简单带球腕六轴机器人，但是所有的关节中，link
twist都与常见模型相反，所以运动学不得不自己推。</p>
<p>​ 在此我只简述一下正逆运动学的思想：</p>
<div class="tabs" id="class"><ul class="nav-tabs"><li class="tab active"><a href="#class-1">正运动学</a></li><li class="tab"><a href="#class-2">逆运动学</a></li></ul><div class="tab-content"><div class="tab-pane active" id="class-1"><p>实际上就是，给定各个关节的位姿，求解机器人手臂末端的位姿。这是个很容易的任务，就是疯狂地进行位姿变换合成。由于使用D-H坐标描述，使得描述机器人的参数最简，并且也描述了两个关节确定的坐标系之间的相对变换，所以可以轻易地使用位姿变换合成：
<span class="math display">\[
\begin{equation}
T_6^0=T_1^0T_2^1T_3^2T_4^3T_5^4T_6^5
\end{equation}
\]</span>
每个关节相对于下一个关节的位姿变换，在正运动学篇已经进行了详细的讨论，在简单的问题中，也不过就是使用link
length, link offset, link twist, link angle计算变换矩阵。</p></div><div class="tab-pane" id="class-2"><p>可以把这个问题看作是解方程：已知期望的末端位置，需要求解出每个关节的位姿（比如角度，平移）。复杂问题下，是需要引入优化的方式来求解的（可能没有简单的闭式解），而在一些简单的情形下，可以进行
<strong><u>解耦</u></strong>，也就是找到前后不相关联的位姿变换，分解问题为子问题，子问题下就有可能求解出闭式解。带有球腕的问题就是一个典型的简化情形。</p></div></div></div>
<p>​ 我所使用的六轴机器人模型，参数定义如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// link offset / link length / link twist / link angle</span></span><br><span class="line"><span class="type">const</span> std::vector&lt;LinkInfo&gt; init_links = &#123;</span><br><span class="line">    <span class="built_in">LinkInfo</span>(<span class="number">0.5</span>, <span class="number">0</span>, M_PI_2,  <span class="number">0.134140</span>), </span><br><span class="line">    <span class="built_in">LinkInfo</span>(<span class="number">0.1</span>, <span class="number">0.8</span>, <span class="number">0</span>, <span class="number">0.012189</span>), </span><br><span class="line">    <span class="built_in">LinkInfo</span>(<span class="number">0.1</span>, <span class="number">0</span>, M_PI_2, <span class="number">-0.036790</span>), </span><br><span class="line">    <span class="built_in">LinkInfo</span>(<span class="number">0.8</span>, <span class="number">0</span>, M_PI_2, <span class="number">1.596749</span>), </span><br><span class="line">    <span class="built_in">LinkInfo</span>(<span class="number">0</span>, <span class="number">0</span>, M_PI_2, <span class="number">-0.222030</span>),</span><br><span class="line">    <span class="built_in">LinkInfo</span>(<span class="number">0.4</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1.459867</span>)  </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>​ 小土的博客中，使用的是<span class="math inline">\(-\pi /
2\)</span>的link twist，而我这里使用的是<span class="math inline">\(\pi/2\)</span>。开始我的底部三个关节的求解，完全按照<span class="math inline">\(-\pi/2\)</span>去推的，这当然会有问题，之后手推了一下<span class="math inline">\(\pi/2\)</span>的情况。</p>
<p>​
顶部三个关节如何求解，小土的博客并没有说，但是思想大致还是一样的：将末端点变换到第四个关节对应的坐标系下，使用投影法求解。</p>
<h3 id="多解问题可行域">2.4 多解问题&amp;可行域</h3>
<p>​ 以底部的三个关节以及对应机械臂为例：</p>
<p><img src="/2021/10/31/%E4%BD%8D%E5%A7%BF%E5%8F%98%E6%8D%A2%E4%B8%8E%E5%85%AD%E8%BD%B4%E4%BB%BF%E7%9C%9F/two.png"></p>
<center>
Figure 3. 位姿变换示意图
</center>
<p>​
黑色和蓝色分别表示了两种不同解下的机械臂情形。对于同一个球腕位置（也就是右上角的交汇点），可能有两个解，两个解都是需要求出来的，不同的关节会形成解组。比如<span class="math inline">\(\theta_1\)</span>以及<span class="math inline">\(\theta_2\)</span>分别对应joint 2的两个相差<span class="math inline">\(\pi\)</span>的解角度。选取谁？需要根据“能耗最小原则”：哪个解与上一时刻对应的角度最接近，说明运动到对应的状态所需能量损耗最小，机器人应该更倾向于选取这个解。多解问题存在于球腕与底部角度上。</p>
<p>​
给定末端姿态以及末端的位置，机械臂各个关节也不一定有解，比如：超出长度范围，或是没办法同时满足姿态和位置等等，这些都可能会使得求解结果成NaN，只需要限制在解为NaN时放弃本次控制。</p>
<hr>
<h2 id="iii.-gazebo仿真">III. Gazebo仿真</h2>
<p>​
我想尝试一下除了rviz之外的可视化方法，rviz版本也已经在Axis6这个库里实现了，这个版本的可视化核心就在tf的使用，也没什么困难的，可视化时碰到的大多数问题实际上都是坐标系或者变换求解错误的问题。除了rviz之外，我能想到也就只有寥寥几个可视化工具：OpenGL以及其封装的Pangolin，Gazebo。由于我从来没有用过Gazebo，故想尝试一下这个新东西。</p>
<p>​ 构建Gazebo机械臂主要有以下三步：</p>
<ul>
<li>编写urdf（或者xacro）描述机器人，以及相应的gazebo文件（.sdf或者.gazebo以及.world）</li>
<li>构建机器人控制器（transmission），使用gazebo_ros以及gazebo_ros_control进行控制</li>
<li>调参。这一步都能放进来确实是我没想到的。</li>
</ul>
<h3 id="描述机器人">3.1 描述机器人</h3>
<p>​ ROS wiki上对于描述机器人以及模型的文件是这么说的：</p>
<blockquote>
<p>Xacro (XML Macros) Xacro is an XML macro language. With xacro, you
can construct shorter and more readable XML files by using macros that
expand to larger XML expressions.[1]</p>
</blockquote>
<blockquote>
<p>Xacro is just a scripting mechanism that allows more modularity and
code re-use when defining a URDF model. When using it, what is actually
uploaded to the parameter servers (per default as the
"robot_description" parameter) actually is a URDF, as that gets
generated from the xacro file in the launch file (by expanding the xacro
macros used).[2]</p>
</blockquote>
<p>​
这里主要给出四个部分的例子，主要看注释：以下两个部分来自于<code>src/axis6/urdf/axis6.xacro</code></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!--        此处定义的是机械臂          --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">name</span>=<span class="string">&quot;world&quot;</span>/&gt;</span></span><br><span class="line"><span class="comment">&lt;!--上面这个link（机械臂）是一个固定的轴，每个urdf都需要带，相当于世界坐标系--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--定义一个机械臂，这里是六轴机器人的底座--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">name</span>=<span class="string">&quot;base&quot;</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--collision属性没有写上来，其定义方式与visual类似，定义的是碰撞箱--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">visual</span>&gt;</span> <span class="comment">&lt;!--视觉效果，定义的是我们能观察到的样子--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">origin</span> <span class="attr">xyz</span>=<span class="string">&quot;0 0 0.75&quot;</span> <span class="attr">rpy</span>=<span class="string">&quot;0 0 0&quot;</span>/&gt;</span> <span class="comment">&lt;!--rpy对应轴是xyz--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">geometry</span>&gt;</span> <span class="comment">&lt;!--定义基础模型：一个长方体，width depth height是xyz--&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">box</span> <span class="attr">size</span>=<span class="string">&quot;0.4 0.4 1.5&quot;</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">geometry</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">material</span> <span class="attr">name</span>=<span class="string">&quot;grey&quot;</span>/&gt;</span> <span class="comment">&lt;!--调用material.xacro中定义的颜色--&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">visual</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inertial</span>&gt;</span>	<span class="comment">&lt;!--惯性力学信息--&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--可以认为，此处定义了一个等效几何体，位置与姿态都给出了，并且给了多轴方向上的质量分布--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">origin</span> <span class="attr">xyz</span>=<span class="string">&quot;0 0 0.75&quot;</span> <span class="attr">rpy</span>=<span class="string">&quot;0 0 0&quot;</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">mass</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;mass&#125;&quot;</span>/&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--一种遵循shell类似语法的变量调用--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">inertia</span></span></span><br><span class="line"><span class="tag">      <span class="attr">ixx</span>=<span class="string">&quot;1.0041666666666669&quot;</span> <span class="attr">ixy</span>=<span class="string">&quot;0.0&quot;</span> <span class="attr">ixz</span>=<span class="string">&quot;0.0&quot;</span></span></span><br><span class="line"><span class="tag">      <span class="attr">iyy</span>=<span class="string">&quot;1.0041666666666669&quot;</span> <span class="attr">iyz</span>=<span class="string">&quot;0.0&quot;</span></span></span><br><span class="line"><span class="tag">      <span class="attr">izz</span>=<span class="string">&quot;0.13333333333333336&quot;</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">inertial</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">link</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!--此处定义的是关节信息，关节是连接机械臂（以及两个不同坐标系）的结构--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">joint</span> <span class="attr">name</span>=<span class="string">&quot;joint0&quot;</span> <span class="attr">type</span>=<span class="string">&quot;continuous&quot;</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--joint是机器人机械臂位姿变换的基础，可以认为joint定义的是child link的坐标系--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">parent</span> <span class="attr">link</span>=<span class="string">&quot;world&quot;</span>/&gt;</span>		<span class="comment">&lt;!--父系，或者上一个机械臂--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">child</span> <span class="attr">link</span>=<span class="string">&quot;link1&quot;</span>/&gt;</span>		<span class="comment">&lt;!--子系，连接的下一个机械臂--&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--关节相对于上一个坐标系，其原点平移偏置以及z轴的相对旋转--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">origin</span> <span class="attr">xyz</span>=<span class="string">&quot;0 0 1.5&quot;</span> <span class="attr">rpy</span>=<span class="string">&quot;0 0 0&quot;</span>/&gt;</span>  	</span><br><span class="line">    <span class="comment">&lt;!--使用child link的哪一个轴或者哪一个方向作为关节转轴--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">axis</span> <span class="attr">xyz</span>=<span class="string">&quot;0 0 1&quot;</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--电机的力矩以及速度限制（不超过以下两个设置值，这两个参数在【3.3调参】中很重要）--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">limit</span> <span class="attr">effort</span>=<span class="string">&quot;50&quot;</span> <span class="attr">velocity</span>=<span class="string">&quot;50&quot;</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">joint</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>​ 以下部分来自于<code>src/axis6/urdf/axis6.sdf</code>:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- URDF需要转为gazebo能理解的sdf类型 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">gazebo</span> <span class="attr">reference</span>=<span class="string">&quot;link1&quot;</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--设置重力为0，注意此处有Gazebo的bug[3]--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">gravity</span>&gt;</span>0<span class="tag">&lt;/<span class="name">gravity</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--关闭内部碰撞检测，也有bug[3]--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">self_collide</span>&gt;</span>0<span class="tag">&lt;/<span class="name">self_collide</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--两个摩擦系数--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mu1</span>&gt;</span>0.0<span class="tag">&lt;/<span class="name">mu1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mu2</span>&gt;</span>0.0<span class="tag">&lt;/<span class="name">mu2</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--还有kp,kd两个参数，用于定义模型的硬度，之前好像是这样的</span></span><br><span class="line"><span class="comment">	假如kp与kd很接近，那么模型会变软，可能陷到地里，kp&gt;&gt;kd时很硬。</span></span><br><span class="line"><span class="comment">	不过我也没有深究过--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">material</span>&gt;</span>Gazebo/Black<span class="tag">&lt;/<span class="name">material</span>&gt;</span> <span class="comment">&lt;!--颜色--&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">gazebo</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>​ 定义机械臂的重力为0经常出现bug，一会儿说你有
<code>multiple conflicting &lt;gravity&gt; tag</code>
然后给你强制设为<code>&lt;gravity&gt;true&lt;/gravity&gt;</code>，又存在这个bug[3]，导致gravity以及self_collide两个标签都不能被正确设置。</p>
<p>​ 以下部分来自于<code>src/axis6/world/axis6.world</code>:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">world</span> <span class="attr">name</span>=<span class="string">&quot;default&quot;</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--引入外部的模型（如果找不到，有些可能会在加载时在网上下载）--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">include</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">uri</span>&gt;</span>model://ground_plane<span class="tag">&lt;/<span class="name">uri</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">include</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!--...省略部分--&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Global light source --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">include</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">uri</span>&gt;</span>model://sun<span class="tag">&lt;/<span class="name">uri</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">include</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--最后的我的消重力方式：直接让世界没有重力，嗯，很暴力--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">gravity</span>&gt;</span>0 0 0<span class="tag">&lt;/<span class="name">gravity</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">world</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="传输控制">3.2 传输控制</h3>
<p>​
定义好这些文件后，写一个launch文件，如果编写正确，就能在Gazebo中生成出定义的机器人。但此时机器人是死的，没办法控制。使用gazebo_ros以及相关模块进行控制，这几个包都是需要自己下的，建议直接：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install ros-version-gazebo-ros*</span><br></pre></td></tr></table></figure>
<p>​ transmission定义的实际上是一个个电机：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">transmission</span> <span class="attr">name</span>=<span class="string">&quot;tran5&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">type</span>&gt;</span>transmission_interface/SimpleTransmission<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--定义在关节5上的电机--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">joint</span> <span class="attr">name</span>=<span class="string">&quot;joint5&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">hardwareInterface</span>&gt;</span>hardware_interface/EffortJointInterface</span><br><span class="line">      <span class="tag">&lt;/<span class="name">hardwareInterface</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">joint</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--电机--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">actuator</span> <span class="attr">name</span>=<span class="string">&quot;motor5&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">hardwareInterface</span>&gt;</span>hardware_interface/EffortJointInterface</span><br><span class="line">      <span class="tag">&lt;/<span class="name">hardwareInterface</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">mechanicalReduction</span>&gt;</span>1<span class="tag">&lt;/<span class="name">mechanicalReduction</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">actuator</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">transmission</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>​
需要配置一个相应的电机config文件(<code>src/axis6/config/axis6_control.yaml</code>)：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">axis6:</span></span><br><span class="line">  <span class="comment"># Publish all joint states -----------------------------------</span></span><br><span class="line">  <span class="attr">joint_state_controller:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">joint_state_controller/JointStateController</span></span><br><span class="line">    <span class="attr">publish_rate:</span> <span class="number">50</span>  </span><br><span class="line">  </span><br><span class="line">  <span class="comment"># Position Controllers ---------------------------------------</span></span><br><span class="line">  <span class="attr">joint0_position_controller:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">effort_controllers/JointPositionController</span></span><br><span class="line">    <span class="attr">joint:</span> <span class="string">joint0</span></span><br><span class="line">    <span class="attr">pid:</span> &#123;<span class="attr">p:</span> <span class="number">15.0</span>, <span class="attr">i:</span> <span class="number">0.001</span>, <span class="attr">d:</span> <span class="number">1.2</span>&#125;</span><br><span class="line"><span class="comment"># ...</span></span><br></pre></td></tr></table></figure>
<p>​
2-5行是不可少的，此项配置了整个关节状态发布器。剩余的就一个个配置，配置其类型（位置控制电机，速度控制电机）以及pid参数（<strong>很难调</strong>）。</p>
<p>​ 在加入这些信息之后，再生成Gazebo仿真，使用rostopic
list命令可以看到一些新的topic（实际上是gazebo模型subscribe的，但因为没有配置ros端，暂时无publisher），可以直接使用如下命令进行简单测试：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rostopic pub &lt;topic_name：比如/axis6/joint1_state_controllers/command&gt; &lt;topic_type:一般是std_msgs::Float64&gt; &quot;data: &lt;控制量，比如:1.0&gt;&quot; </span><br></pre></td></tr></table></figure>
<p>​
剩下的事情就是写一个控制节点，发布对应消息就能进行控制了，这里就不赘述了。</p>
<h3 id="调参">3.3 调参</h3>
<p>​
仿真，顾名思义，一定要真。即使我把摩擦关了，碰撞检测关了，重力关了，控制也并没有想象的那么简单。问题主要是：</p>
<ul>
<li>机械臂的质量以及质量分布设计得不合理（比如末端很重）</li>
<li>PID参数 + 电机limit（见xacro文件按）设置的不合理。</li>
</ul>
<p>​ 导致以下三个问题（折磨了我一下午）：</p>
<ul>
<li>电机驱动力不够 + pid参数过小时，又慢又超调</li>
<li>电机驱动力充足 + pid参数较大时，机械臂抖动严重（末端尤为严重）</li>
<li>电机驱动力充足 +
pid参数过大时，可能会炸开。。。机械臂直接飞了，这也太真实了</li>
</ul>
<p>​ 解决方案当然就是一个个电机调：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">joint0_position_controller:</span></span><br><span class="line">	<span class="attr">pid:</span> &#123;<span class="attr">p:</span> <span class="number">15.0</span>, <span class="attr">i:</span> <span class="number">0.001</span>, <span class="attr">d:</span> <span class="number">1.2</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="attr">joint1_position_controller:</span></span><br><span class="line">	<span class="attr">pid:</span> &#123;<span class="attr">p:</span> <span class="number">10.0</span>, <span class="attr">i:</span> <span class="number">0.001</span>, <span class="attr">d:</span> <span class="number">0.8</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="attr">joint2_position_controller:</span></span><br><span class="line">	<span class="attr">pid:</span> &#123;<span class="attr">p:</span> <span class="number">5.0</span>, <span class="attr">i:</span> <span class="number">0.001</span>, <span class="attr">d:</span> <span class="number">0.1</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="attr">joint3_position_controller:</span></span><br><span class="line">	<span class="attr">pid:</span> &#123;<span class="attr">p:</span> <span class="number">1.5</span>, <span class="attr">i:</span> <span class="number">0.001</span>, <span class="attr">d:</span> <span class="number">0.04</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="attr">joint4_position_controller:</span></span><br><span class="line">	<span class="attr">pid:</span> &#123;<span class="attr">p:</span> <span class="number">1.1</span>, <span class="attr">i:</span> <span class="number">0.001</span>, <span class="attr">d:</span> <span class="number">0.08</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="attr">joint5_position_controller:</span></span><br><span class="line">	<span class="attr">pid:</span> &#123;<span class="attr">p:</span> <span class="number">0.25</span>, <span class="attr">i:</span> <span class="number">0.0001</span>, <span class="attr">d:</span> <span class="number">0.0002</span>&#125;</span><br></pre></td></tr></table></figure>
<p>​
从最底部的关节开始（它应有的驱动能力最大，因为负载最大），关节号越高，其后的机械臂越少（载荷越小），那么显然，limit中的effort以及velocity应该越小，PID参数越小，机械臂也尽可能在末端变轻。</p>
<hr>
<h2 id="iv.-效果展示">IV. 效果展示</h2>
<p>​
最后的效果也就是：末端可以三轴方向平移，以及绕某一轴旋转。我复用了之前写的键盘控制函数（在LiDARSim2D库内）（多按键触发），故运动是可以合成的：</p>
<p>​ rviz：使用tf以及visualization_msg::Marker进行可视化：</p>
<video src="rviz.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<center>
Video 1. rviz仿真结果
</center>
<p>​ Gazebo：花了好几个穿模的长方体（随便画的，没必要搞机械设计了）:</p>
<video src="gazebo.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<center>
Video 2. Gazebo仿真结果
</center>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="http://wiki.ros.org/xacro">ROS wiki: xacro</a></p>
<p>[2] <a href="https://answers.ros.org/question/202162/urdf-or-xacro/">URDF or
Xacro?</a></p>
<p>[3] <a href="https://github.com/ignitionrobotics/sdformat/issues/71">Incorrect
URDF to SDF conversion of gravity and self_collide tags #71</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>运动学</tag>
        <tag>Gazebo</tag>
      </tags>
  </entry>
  <entry>
    <title>骷髅融合者-CVPR2021</title>
    <url>/2021/10/24/%E9%AA%B7%E9%AB%85%E8%9E%8D%E5%90%88%E8%80%85-CVPR2021/</url>
    <content><![CDATA[<h1 id="骷髅融合者">骷髅融合者</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​
想看看CVPR2021上都有关于点云配准或者点云处理都有什么样的文章，网上搜刮了几篇，骷髅融合者就是其中一篇。这篇论文的作者貌似是上海交大的本科生，嗯
本科CVPR一作，卢策吾老师团队，可以说是很nb了。本论文提出的思想，个人认为比较简单（可能是因为比较复杂的部分被PointNet++掩盖了，文中也没有使用时下最为流行的【变形金刚】）。并且看完Introduction之后，我就觉得这个思想好像在哪里见过：嗷，原来是我的灯条检测中含有这个方法的弱弱化版。</p>
<p>​
本短篇博客只做该论文的一个简单分析，并不附带复现（如果要带复现的话，一是需要时间，二是需要了解PointNet++）。论文的地址是：<a href="https://arxiv.org/abs/2103.10814">arXiv: Skeleton Merger: an
Unsupervised Aligned Keypoint Detector</a></p>
<p><img src="/2021/10/24/%E9%AA%B7%E9%AB%85%E8%9E%8D%E5%90%88%E8%80%85-CVPR2021/Screenshot%20from%202021-10-24%2001-40-07-16350111328661.png"></p>
<center>
Figure 1. Skeleton Merger 论文效果
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-论文思想">II. 论文思想</h2>
<h3 id="思想概述">2.1 思想概述</h3>
<p><img src="/2021/10/24/%E9%AA%B7%E9%AB%85%E8%9E%8D%E5%90%88%E8%80%85-CVPR2021/Screenshot%20from%202021-10-23%2023-45-48-16350111328672.png"></p>
<center>
Figure 2. Skeleton Merger 论文思想框架
</center>
<p>​
作者使用了一种“重构误差”的思想，使用一个更简单的表征，来重构一个点云，使得原始点云与生成的点云在某个metric下最为相似。而我在RM时做的工作：无监督优化算法的灯条检测，也是类似：</p>
<ul>
<li>找两个key
points（灯条的端点），使用灯条的端点根据hand-crafted重构方法，重构出灯条，使得生成的灯条与原始灯条图像的L2差距最小。（所以可以说，我大二下学期写的这个算法是本论文的弱弱化）</li>
</ul>
<p>​ 本文的思想大概可以被总结如下：</p>
<div class="note danger no-icon"><p>使用PointNet++，生成一个加权矩阵，加权后可以生成k个key
points，同时，PointNet++也会输出一些全局信息。生成的key
points自然形成一个完全图。</p>
</div>
<div class="note warning no-icon"><p>使用PointNet++输出的全局信息，过3层MLP，生成【activation
strength】，此后我们会知道，这实际就是skeleton完全图中，每条边存在的概率。</p>
</div>
<div class="note info no-icon"><p>完全图上，每条边都可以产生一个sub-cloud（均匀采样得到，点数与长度成正比）。之后通过一个网络（decoder），学习每一个点的offset（相对于骨架的移动），使得生成的点云可以表征更加复杂的形状。</p>
</div>
<div class="note success no-icon"><p>使用Composite Chamfer Distance（CCD，一种改进的Chamfer
Distance方法）作为loss函数，使得原始点云与生成点云的CCD最小【<a href="#unsup">无监督模型的生成式loss</a>】。</p>
</div>
<p>​ 本文不涉及任何网络结构以及网络设计，只是分析一下：</p>
<ul>
<li>其方法有哪些亮点</li>
<li>个人认为其方法可能存在哪些不足</li>
</ul>
<h3 id="亮点">2.2 亮点</h3>
<p>​ 本人认为，此论文突出的两个亮点就是：</p>
<ul>
<li>skeleton重构误差</li>
<li>CCD误差函数的设计</li>
</ul>
<p>​ 首先，通过skeleton重建点云，来辅助判定key
points的选取效果，可以使得其达到无监督的目的。在MoCo论文分析中，实际上已经说过，无监督的loss也就主要是那么两种（据我目前所知的“主要”）：</p>
<ul>
<li>对比loss（以MoCo为代表的），主动生成匹配与不匹配的样本，最大化不同类别特征之间的差别</li>
<li>生成式loss（autoencoder思想），主要思想是：学出来的特征能够经过某种方式重构输入，特征学得越好，从直觉上来说，重构效果越好。</li>
</ul>
<p>​
第二种方法的显著问题就是：一般会有比较大的计算开销（特别是重构图像时，长采样、反卷积结构等等）。个人感觉，本文是一种生成式的loss，但是由于：（1）key
points（对应的边）具有稀疏性（2）均匀采样密度可控性，计算开销可能不会太难以接受。</p>
<p>​ 本文直接对key
points形成的完全图进行重构，生成一个个的sub-cloud，但是由于有些边采样出的点，实际是不存在的，应该在其存在性上就予以抹杀（而非在offset学习阶段，强行将其拉回到某个位置），故作者引入了activation
strength，每条边都将有一个对应的activation
strength，相当于是边权，边权小的边对应的生成点在reconstruction过程中可能被丢弃，并且在loss计算过程中，也可能不会参与。</p>
<p>​ 此外就是CCD误差函数的设计。CCD是Chamfer distance的一个扩展，Chamfer
distance可以简单地将其理解成：最邻近点距离。在一个n维metric
space中给定两个集合A，B，（比如）A中的某个点<span class="math inline">\(p_i\)</span>到B中的最近点的距离，就是Chamfer
distance。</p>
<p>​ 在本问题中，集合A、B分别是生成点云与原始点云。但是需要注意，Chamfer
distance是单向的，那么需不需要构建成双向对称的loss函数呢？答案是否定的，本问题本身就不是一个对称的问题。作者做了一个分类：</p>
<div class="tabs" id="class"><ul class="nav-tabs"><li class="tab active"><a href="#class-1">正向loss</a></li><li class="tab"><a href="#class-2">反向loss</a></li></ul><div class="tab-content"><div class="tab-pane active" id="class-1"><p>对每一个生成点云中的点<span class="math inline">\(p_i\)</span>，计算<span class="math inline">\(p_i\)</span>在原始点云中的最近点<span class="math inline">\(q_i\)</span>，并且计算对应的Chamfer
distance，使之最小化，这是在提升生成点云的fidelity（准确性），也就是说：生成点云的“大致形状”应该与原始点云类似。</p></div><div class="tab-pane" id="class-2"><p>对每一个原始点云中的点<span class="math inline">\(q_j\)</span>，计算<span class="math inline">\(q_j\)</span>在生成点云中的最近点<span class="math inline">\(p_j\)</span>。这就是不对称性的体现：即便生成点云每个点在原始点云上都有很好的对应点，<strong><u>由于生成点云可能具有稀疏性</u></strong>，反过来，原始点云的某些点可能没有办法在生成点云上找到很好的对应点。数学上来说，这就是：单射和满射。正向loss如果很小，只能保证生成点云的<strong><u>fidelity</u></strong>问题，能建立一个很好的
生成点云<span class="math inline">\(\rightarrow\)</span>原始点云的单射，但是反过来，如果原始点云的每个点也能在生成点云上有很好的对应，那么可能可以建立一个原始点云<span class="math inline">\(\rightarrow\)</span>生成点云的单射，使得
<strong><u>coverage</u></strong>问题得到解决。</p></div></div></div>
<p>​ 正向fidelity loss很简单，就是这样： <span class="math display">\[
\begin{equation}\label{fid}
L_f=\sum_k a_k\sum_i\Vert p_i-q_i\Vert^2,q_i=\mathop{\arg\min}_{q}\Vert
p_i-q_i\Vert
\end{equation}
\]</span> ​ 而反向coverage
loss就没有那么简单了。首先，加入反向loss也如上式一样，定义成对称的，那么最终结果将会是：我直接让所有<span class="math inline">\(a_i\)</span>训练成0得了，没有点存在，就没有loss！显然这是很有问题的。</p>
<p>​ 一方面，我们希望<span class="math inline">\(a_i\)</span> (activation
strength)可以起到作用，另一方面我们又希望避免上述问题，我们也希望不会因为公式<span class="math inline">\(\eqref{fid}\)</span>内部的<span class="math inline">\(a_i\)</span>存在，使得<span class="math inline">\(a_i\)</span>倾向于变小。作者提出了两个策略：</p>
<ul>
<li>为了体现“coverage”，作者将会【一配多】，也就是说，不再寻找距离最小的一个点，而是：查到点<span class="math inline">\(q_i\)</span>后，删除<span class="math inline">\(q_i\)</span>来源的那条边（以及所有点），并且累加本边对应的activation
strength到一个本地的（初始化为0的累加器）变量w上。如果w小于1，那就继续在剩余点中查找最小距离点，重复上述操作，直到w&gt;1或者没有客用边。</li>
<li>假设已经没有可用边了，而w&lt;1，则进行惩罚（<strong><u>说明我们让<span class="math inline">\(a_i\)</span>学得太小了</u></strong>），在loss上增加<span class="math inline">\(\gamma (1-w)\)</span>，论文中<span class="math inline">\(\gamma\)</span>选取20.0，比较大。</li>
</ul>
<p>​ 上述操作可以保证：<span class="math inline">\(a_i\)</span>不会因为优化CCD而变得很小。</p>
<h3 id="个人觉得存在的问题">2.3 个人觉得存在的问题</h3>
<h4 id="稀疏性问题">2.3.1 稀疏性问题</h4>
<p>​
作者如何重建其生成点云的呢？首先：根据图结构，每条边进行均匀采样。每条线段上有若干个点。此后使用一个网络进行offset学习。这样会存在一定问题：重建的点云可能就是很稀疏，导致CCD
coverage
loss计算总是比较大。比如：一个圆柱型的物体，在同一高度上，绕轴不同角度可能存在很多个点，但对于本论文的方法，一个高度上就一个点，那么对于圆柱型物体，只能使用螺旋式的offset，这会使得某些位置上比较稀疏。</p>
<p>​
要解决这个问题，可能可以在初始时同一个位置采样很多个点，之后使得这些点，在过本点，垂直图结构边的平面上扩散开来。<strong><u>我认为这样的话，学习的参数可以减少（每个点只需要学习一个参数而不是三个），也可以解决稀疏问题。</u></strong></p>
<h4 id="最邻近搜索">2.3.2 最邻近搜索</h4>
<p>​
这只说下我的担忧：最邻近搜索快速吗？当然，可以使用一些加速的数据结构，比如8叉树，KD树等等，但是能有多快呢？不好说，我没有做过实验，但是这也就是非完全的生成式loss遇到的问题，loss构建时的稀疏性问题。所以个人认为，此处可以将最邻近loss换为别的loss。</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>点云</tag>
      </tags>
  </entry>
  <entry>
    <title>特龙智慧-GMapping</title>
    <url>/2021/10/22/%E7%89%B9%E9%BE%99%E6%99%BA%E6%85%A7-GMapping/</url>
    <content><![CDATA[<h1 id="特龙智慧">特龙智慧</h1>
<hr>
<p>​
我在大二上学期购买了《概率机器人》一书，当时还没有学概率论，所以我看不懂（但是我大受震撼）。大二下的暑假曾经学了一段时间，但是没有深入，到第五章就结束了。直到现在，大四了，项目有这方面的需求了，才重新开始看特龙(Sebstian
Thrun)这本口碑很好的书。尽管这本书是2006年出版的，其中的很多思想在现在的我看来，都还很有指导意义。非常后悔，自己没能在之前花精力啃下这本SLAM以及移动机器人著作。</p>
<p>​
GMapping（以及相关的粒子滤波SLAM方法）或多或少都有他的参与，最近也刚好读了相关的论文，并且仔细研读了其代码（OpenSLAM上的💩山，literally），故我把这些笔记整理成了一篇文章：</p>
<ul>
<li>本文作者并没有特龙，但是估计是相关团队的文章：<a href="https://ieeexplore.ieee.org/abstract/document/4084563/">Improved
Techniques for Grid Mapping with Rao-Blackwellized Particle
Filters</a></li>
<li>上面这篇论文可以说是：<a href="https://ieeexplore.ieee.org/abstract/document/1250629/">IROS2003:An
Efficient FastSLAM Algorithm for Generating Maps of Large-Scale Cyclic
Environments from Raw Laser Range
Measurements</a>的升级版（这篇论文的建议分布是“学”出来的）。</li>
</ul>
<p><img src="/2021/10/22/%E7%89%B9%E9%BE%99%E6%99%BA%E6%85%A7-GMapping/Screenshot%202021-10-22%20194809.png"></p>
<center>
Figure 1.
这人有一个以自己名字命名的实验室，还曾拒绝过出任Google副总裁...
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-gmapping-论文分析">II. GMapping 论文分析</h2>
<h3 id="大致思想">2.1 大致思想</h3>
<p>​
gmapping是一篇基于粒子滤波的配准工作，其主要创新点只有一点：就是得到了一个改进的粒子滤波建议分布（improved
proposal
distribution），这篇文章既没有涉及到回环检测、后端优化，也没有深入分析前端的配准算法。其主要贡献就是：改进粒子滤波在某些传感器上的表现。</p>
<p>​
我们考虑激光雷达，一般来说，激光雷达的测距精度很高，在配准算法具有很好的表现情况下时，可以认为配准也有比较好，配准结果噪声较小。因为粒子滤波的主要思想是：</p>
<div class="note info"><ul>
<li>我先建模一个易于获取的建议分布（proposal）</li>
<li>再建模一个【近似的】建议分布与目标分布之间的差别w（权重）（根据贝叶斯理论，一般是乘性的因子）</li>
</ul>
</div>
<p>​
可见，如果目标分布（贝叶斯后验）很好获得，那么我们可以直接将目标分布当作建议分布，并且使得这差别权重都相等，为1。但是一般来说，需要粒子滤波解决的问题都不会有简单的目标后验，故建模一个好的建议分布是非常必要的：</p>
<div class="note primary"><ul>
<li>一个好的建议分布可以使得【近似的】差别权重对于其近似性的要求降低</li>
<li>好的建议分布可以提高采样的质量</li>
</ul>
</div>
<p>​
传统意义上，建议分布一般会使用odometry的运动模型分布，比如沿着运动方向的与垂直运动方向两个方向为主轴的高斯分布。在粒子的更新阶段（也即从建议分布采样阶段），我们根据控制<span class="math inline">\(u_t\)</span>，确定<span class="math inline">\(x_t^{(i)}=u_t
*x_{t-1}^{(i)}\)</span>，并且根据<span class="math inline">\(u_t\)</span>，确定一个带噪声的<span class="math inline">\(x_t^{(i)}\)</span>，人工加噪相当于是从运动模型分布中采样了。但是，gmapping这篇论文说：odometry较之于LiDAR配准来说，一般都大了一些，如果我们可以在建议分布中也用上观测的值，说不定可以得到更加符合目标分布的建议分布。</p>
<blockquote>
<p>When using the odometry model as the proposal distribution in such a
case, the importance weights of the individual samples can differ
signifificantly from each other since only a fraction of the drawn
samples cover the regions of state space that have a high likelihood
under the observation model</p>
</blockquote>
<p>​
举一个例子：假设我们有一条长走廊，长走廊较为理想。那么对于配准来说，长走廊情况下的配准协方差沿着走廊方向的分量更大，但是垂直走廊方向很小，而另一方面，odometry在两个方向上可能都有较大的协方差。如果我们使用odometry的协方差，在更新采样环节可能会采到次优的位置，但如果此时结合配准误差、里程计协方差，可以将：</p>
<ul>
<li>垂直长走廊方向的协方差降下来，沿着长走廊方向的协方差则可以由odometry主导。</li>
</ul>
<p>​ 从这样的分布中采样，可以得到更好的结果。</p>
<p>​
此外，还有另一个问题。为什么你在实现PF时，使用完全随机的采样策略效果并不好？这篇论文中的一个解释我觉得非常有道理：</p>
<blockquote>
<p>However, if the observation likelihood is
<strong><u>peaked</u></strong> the number of pose samples <span class="math inline">\(x_j\)</span> that has to be sampled from the
motion model is high, since a dense sampling is needed for sufficiently
capturing the <strong><u>typically small areas of high
likelihood</u></strong>. This results in a similar problem than using
the motion model as the proposal: a high number of samples is needed to
s<strong><u>ufficiently cover the meaningful region of the
distribution</u></strong>.</p>
</blockquote>
<p>​
之前也没有想得太深，只是觉得角度上的采样不足，于是增大了角度采样。现在想想，整个后验分布确实就是一个具有突出峰值的分布，在实验过程中也发现了这一点（实验是<a href="https://enigmatisms.github.io/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/">上一篇博客</a>中的粒子滤波，更新过程中发现，收敛时的粒子分布的确呈尖峰形状）。</p>
<h3 id="如何结合观测">2.2 如何结合观测</h3>
<p>​ PF更新公式如下： <span class="math display">\[
\begin{equation}
w_t=w_{t-1}\frac{
\eta p(z_t|x_{1:t}, z_{1:t-1})p(x_t|x_{t-1},u_{t-1})
}{
\pi(x_t|x_{1:t-1},z_{1:t},u_{1:t-1})
}
\end{equation}
\]</span> ​ 朴素情况下，建议分布就是运动状态转移分布：<span class="math inline">\(p(x_t|x_{t-1},u_{t-1})\)</span>，我们将其替换：考虑到配准信息也可以使用，那么gmapping使用了一个这样的策略：</p>
<ul>
<li>首先我根据scan-matcher确定一个ROM（region of
meaning，有意义的区域），也即是配准认为可能的分布位置</li>
<li>在这个有意义的区域内进行<strong><u>多次采样</u></strong>。多次采样的结果，使用scan-matcher得到<span class="math inline">\(p(x_t|x_{1:t},z_{1:t-1})\)</span>（似然），而由于控制已知（均值已知），参数一般也已知，那么分布就已知，则在选取的点可以计算<span class="math inline">\(p(x_t^{(j)}|x_{t-1},u_{t-1})\)</span></li>
<li>我们需要计算的improved proposal是：<span class="math inline">\(p(x_t|m^{(i)}_{t-1},x_{t-1},z_t,u_{t-1})\)</span>。这个的物理意义是：在第i个粒子对应的map
<span class="math inline">\(m^{(i)}_{t-1}\)</span>下，由<span class="math inline">\(x_{t-1}\)</span>由控制量<span class="math inline">\(u_{t-1}\)</span>转移，观测到<span class="math inline">\(z_t\)</span>的条件下，在<span class="math inline">\(x_t\)</span>位置的概率。看起来这个非常像后验，但是其计算是近似的。</li>
</ul>
<p>​
但是实际上，在RBPF中，更新公式有所不同。因为RBPF是专门针对SLAM设计的一种粒子滤波，在滤波过程中，各种概率分布需要包含地图信息。针对RBPF的权重更新公式如下：
<span class="math display">\[
\begin{equation}\label{rbpf}
w_t=w_{t-1}\frac{
\eta p(z_t|x_{t}, m_{t-1})p(x_t|x_{t-1},u_{t-1})
}{
p(x_t|x_{t-1},z_t,u_{t-1},m_{t-1})
}
\end{equation}
\]</span> ​ 上式的分母可以使用贝叶斯理论展开： <span class="math display">\[
\begin{align}
&amp;p(x_t|x_{t-1},z_t,u_{t-1},m_{t-1})=\frac{p(z_t|x_t,x_{t-1},u_{t-1},m_{t-1})p(x_t,x_{t-1},u_{t-1},m_{t-1})}
{p(z_t,x_{t-1},u_{t-1},m_{t-1})}\\
&amp;p(x_t,x_{t-1},u_{t-1},m_{t-1})=p(x_t|u_{t-1},m_{t-1},x_{t-1})p(u_{t-1},m_{t-1},x_{t-1})=p(u_{t-1},m_{t-1},x_{t-1})p(x_t|x_{t-1},u_{t-1})\tag{条件独立性-1}\\
&amp;p(z_t|x_t,x_{t-1},u_{t-1},m_{t-1})=p(z_t|x_{t},m_{t-1})\tag{条件独立性-2}
\end{align}
\]</span> ​ 故，分母可以展开成为： <span class="math display">\[
\begin{equation}
\frac{p(z_t|x_t,m_{t-1})p(x_t|x_{t-1},u_{t-1})}
{p(z_t|x_{t-1},u_{t-1},m_{t-1})}
\end{equation}
\]</span> ​ 带入公式<span class="math inline">\(\eqref{rbpf}\)</span>中可以得到<span class="math inline">\(w_t=w_{t-1}p(z_t|x_{t-1},u_{t-1},m_{t-1})\)</span>。则进一步可以写为（别看公式很长，其实完全就是贝叶斯，“很好”推的！）：
<span class="math display">\[
\begin{align}
&amp;p(z_t|x_{t-1},u_{t-1},m_{t-1})=\int
p(z_t,x&#39;|x_{t-1},m_{t-1},u_{t-1})dx&#39;=\\
&amp;\int \frac
{p(x&#39;,z_t,x_{t-1},m_{t-1},u_{t-1})}{p(x&#39;|x_{t-1},m_{t-1},u_{t-1})p(x_{t-1},u_{t-1},m_{t-1})}p(x&#39;|x_{t-1},m_{t-1},u_{t-1})dx&#39;=\\
&amp;\int
p(z_t|m_{t-1},x&#39;,x_{t-1},u_{t-1})p(x&#39;|x_{t-1},m_{t-1},u_{t-1})dx&#39;\stackrel{\text{独立性}}{\longrightarrow}\\
&amp;\int p(z_t|x&#39;,m_{t-1})p(x&#39;|x_{t-1},u_{t-1})dx&#39;\propto\\
&amp;\sum_{j=1}^Kp(z_t|m_{t-1}^{(i)},x_j)p(x_j|x_{t-1}^{(i)},u_{t-1})\label{approx}
\end{align}
\]</span> ​ 公式<span class="math inline">\(\eqref{approx}\)</span>将最后的转换完成了，这个公式使得我们不必计算复杂的条件概率，而可以使用：机器人运动学模型分布与观测模型分布的加权组合，更新每一个粒子（<strong><u>运用好独立性假设以及边缘化，可以推出很多有意思的公式</u></strong>）。</p>
<p>​ 论文中的更新迭代策略是这样的：</p>
<ul>
<li>根据里程计信息，作为初值，进行配准，得到带有观测信息的<span class="math inline">\(u_{t-1}^*\)</span></li>
<li><span class="math inline">\(x_{t-1}+u_{t-1}^*\)</span>周围（一个球内）采样，每个采样点<span class="math inline">\(x_s\)</span>都可以根据里程计的高斯分布以及配准的似然域计算点权（<span class="math inline">\(p(z|x)p(x|x&#39;,u)\)</span>），注意，所有点的点权之和，就是更新公式的<span class="math inline">\(p(z_t|x_{t-1},u_{t-1},m_{t-1})\)</span>。</li>
<li>根据采样的点可以计算高斯分布，最后得到的粒子从这个高斯分布中采样。</li>
</ul>
<div class="note danger"><p>​
非常奇怪的是，<strong><u>网上所有GMapping的实现</u></strong>，都没有实现多点采样生成高斯分布再进行重新采样的步骤。</p>
</div>
<hr>
<h2 id="iii.-gmapping-代码流程">III. GMapping 代码流程</h2>
<h3 id="processscan">3.1 processScan</h3>
<p>​ processScan是核心函数：</p>
<h5 id="运动模型">3.1.1 运动模型</h5>
<p>​
首先从运动模型中采样（<code>drawFromMotion</code>函数，此函数的原理在《概率机器人上》）</p>
<h5 id="计算移动距离">3.1.2 计算移动距离</h5>
<p>​ 计算移动距离：<code>m_linearDistance</code>,
<code>m_angularDistance</code></p>
<ul>
<li>保证平移距离不过大，过大则认为位置发生了突变</li>
<li>当移动距离过大，或是长时间没有更新，那么就需要进行一次配准</li>
</ul>
<h5 id="scanmatch">3.1.3 scanMatch</h5>
<p>​
scanMatch首先根据plainReading（也就是点云原始数据）进行配准，配准使用搜索算法，在<code>optimize</code>函数中。注意代码里有bug：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (bestScore&gt;=currentScore)</span><br></pre></td></tr></table></figure>
<p>​ 六个方向移动，直到达到最大分数或者迭代次数，每次减小步长</p>
<p>​ score的计算,在之后的函数中说.
配准函数针对了每一个粒子,每个粒子都进行了一次优化</p>
<p>​ <code>likelihoodAndAScore</code>函数
进行似然计算：大概做了这样的事情：</p>
<ul>
<li>skip是跳过处理的一种实现，指的是：激光线太多，信息冗余，可以跳过一个激光线计算似然域</li>
<li>首先把激光器的位姿投影到世界坐标系下，此后对于每一条需要处理的激光线，也转到世界坐标系下，并且确定一个位于空域的点位置（激光线截短一截）</li>
<li>在一个领域内，查找最适合的障碍物点（因为激光测距会存在噪声），障碍物点需要满足：该点占用概率大于阈值，对应空域点占用概率小于阈值</li>
<li>求均值，并求激光点世界坐标位置与该均值的距离（越小说明越应该是这个障碍点）</li>
<li>求似然。这样求出的似然域是较为平滑的，故在scanMatch的optimize中，计算score也是用了类似的平滑函数</li>
</ul>
<p>​
<code>computeActiveArea</code>：是一个更新地图操作，因为地图是基于占用栅格的，未知区域也是需要表征的，限制范围可以节约内存资源。computeActiveArea更新了地图大小（每个粒子）：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//this allocates the unallocated cells in the active area of the map</span></span><br><span class="line"><span class="comment">//cout &lt;&lt; &quot;activeArea::size() &quot; &lt;&lt; activeArea.size() &lt;&lt; endl;</span></span><br><span class="line">map.<span class="built_in">storage</span>().<span class="built_in">setActiveArea</span>(activeArea, <span class="literal">true</span>);</span><br></pre></td></tr></table></figure>
<p>​
在此前，先根据scanMatch计算的位姿，计算了占用栅格（每条激光线经过的每个点），将占用栅格加入到map中，等待对地图进行更新。</p>
<h3 id="updatetreeweights">3.2 updateTreeWeights</h3>
<p>​ updateTreeWeights只做了三件事：</p>
<ul>
<li>归一化权重</li>
<li>轨迹树重置</li>
<li>权重沿着树传播</li>
</ul>
<p>​
轨迹树会不会做的是这样一件事情呢？初始时粒子都在同一位置，在迭代过程中，也可能出现两个粒子位姿一致的情况吗？会有一个parent对应了很多child的情况吗，轨迹树的child会怎么来？</p>
<p>​
propagateWeights就是一层一层将叶子节点的weight向上传播（因为在scanMatch中会重新衡量叶子节点的weight，而上层weight（相当于之前的位姿）是逐层累加的）。</p>
<p>​
但是resample计算使用的是当前叶子节点的权重，与上层的权重无关。那么这样逐层累加的weight，其作用是什么？<code>weightSum</code>在另一个类中被使用了。看代码时没有注意继承关系，以为只有<code>GridSlamProcessor</code>是主要模块，最后发现openslam版本中，还有一个类叫做：<code>GridSlamProcessorThread</code>，内部实现了一些父类没有实现的回调函数，在这个类中定义的<code>onScanmatchUpdate</code>函数中，用到了weightSum：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(part-&gt;weightSum&gt;bestWeight)&#123;</span><br><span class="line">    bestIdx=idx;</span><br><span class="line">    bestWeight=part-&gt;weightSum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
算法选择权重综合最大的一个粒子（故与历史信息相关了），取该粒子对应的map作为当前地图，根据最大权重的粒子更新地图，并且选择最优粒子的位姿当作自身当前位姿。</p>
<p>​
不过根据算法的逻辑，每次计算了底层叶子节点的weight之后，上层需要根据底层来的值修改权重累加，但是非叶子节点的weightSum并没有用（weightSum本身就没有被用过多少次），只有叶子节点（当前最新的particles）对应的weightSum才有价值，故propagateWeights以及相应函数其实是没有作用的。</p>
<h3 id="重采样">3.3 重采样</h3>
<p>​
resmapleIndexes函数：这里的重采样策略使用的也是《概率机器人》上的低方差重采样。故可能出现：两个粒子重复的情况。返回的是被采样到的粒子的下标。在这个函数的内部，由于使用的策略是低方差采样，下标是有顺序的，故采样的结果也是有顺序的。
​而<code>new TNode</code>在整个项目中出现在：</p>
<ul>
<li><code>gridslamprocessor_tree.cpp</code>
的<code>integrateScanSequence</code>中，没有实际调用</li>
<li><code>gridslamprocessor_tree.cpp</code> 的
<code>getTrajectory</code>中，在GSP构造时使用，所以对代码逻辑的影响应该不大</li>
<li><code>gridslamprocessor.hxx</code>
的<code>resample</code>函数中用到过，此处的使用对代码逻辑有实际的影响</li>
</ul>
<p>​ 建立以及更新权重轨迹树的流程与作用：</p>
<ul>
<li>根据权重进行低方差采样，结果被保存在<code>m_indexes</code>之中，注意<code>m_indexes</code>是顺序化的，比如：原来有8个粒子，id从0-7，重采样之后成为：1
1 1 4 4 4 7
7，那么在轨迹树中，0，2，3，5，6均会被删除（假设没有其他关联，整条与这几个节点有关的树枝均会被切除）</li>
<li>轨迹树实际上就是重采样树，0 1 2 3 4 5 6 7
这8个节点，按照上面的重采样例子会生成如下图所示的树：</li>
</ul>
<pre class="mermaid">
graph TD

A(root)
A1(0)
A2(1)
A3(2)
A4(3)
A5(4)
A6(5)
A7(6)
A8(7)
B(1-1)
C(1-2)
D(1-3)
E(4-1)
F(4-2)
G(4-3)
H(7-1)
I(7-2)
A---A1
A---A2
A---A3
A---A4
A---A5
A---A6
A---A7
A---A8
A2---B
A2---C
A2---D
A5---E
A5---F
A5---G
A8---H
A8---I

</pre>
<center>
Figure 2. GMapping权重树结构示例
</center>
<p>​ 重采样得到点就相当于子节点，重采样前的节点是父节点。</p>
<ul>
<li>删除所有重采样后没有结果的点，比如假设上述例子又发生了一次重采样，(7-1)(7-2)权重过小，那么(7-1)(7-2)(7)都会被删除</li>
<li>对重采样后的新particles，根据当前的点云信息，更新地图（activeArea重新计算），但是权重会被重置为0。那么这个为0的权重，将会在scanMatch函数中被修改（计算完likelihood之后，权重会被设置为likelihood），并且在weightSum中也累加一份。</li>
</ul>
<hr>
<h2 id="iv.-流程总结">IV. 流程总结</h2>
<p>​
我已经发现了：openslam的代码又臭又长，还不能编译，令人根本不知道processScan这个函数究竟在什么情况下被使用，貌似因为下载的是最原始的版本。</p>
<div class="note danger no-icon"><p>​
addScan函数（貌似是ROS封装），在转换scan信息之后，调用processScan函数。此函数首先从motion
model中采样，此后判定是否需要进行配准。</p>
</div>
<div class="note warning no-icon"><p>​
如果需要配准，通常情况下是超时或者超出距离阈值，则需要调用scanMatch函数，此函数内部使用被称之为【爬山法】的搜索方法进行匹配，得到修正后的位姿（<strong><u>但是貌似没有实现GMapping中的生成高斯分布</u></strong>）。</p>
</div>
<div class="note info no-icon"><p>​
此后需要计算似然，使用似然域法，在领域内搜点获得一个平滑似然。计算得到的似然作为新的权重，并且将此权重累加到weightSum上去。</p>
</div>
<div class="note success no-icon"><p>​
计算地图更新，也就是重新计算activeArea，需要向栅格图原始数据（PointAccumulator）的容器中增加新的栅格（或者对原有栅格进行访问）。</p>
</div>
<div class="note primary no-icon"><p>​
重采样步骤，重采样的过程中，会对轨迹树进行重建。方法在上文已经阐述过了，注意propagateWeights是没有太大意义的操作，我直接忽略了。</p>
</div>
<hr>
<h2 id="v.-效果">V. 效果</h2>
<p>​ 2007啊！他们太强了。不过也不能说完美，有如下几个问题：</p>
<ul>
<li>5cm grid 精度可以适应大多数的需求，所以2D
SLAM方向做的人越来越少了（基本满足需求了），而我尝试使用更高精度grid的时候（比如2.5cm），配准将发生错误（我猜是grid太小了，导致了激光器模型的稀疏性问题）</li>
<li>同时，grid变小将会占用过多的内存（1cm大小的格子跑Intel数据集貌似可以跑到10GB内存占用，真的无法想象当年他们那个条件怎么做实验的）</li>
<li>丢帧将会导致非常严重的问题，当点云频率很高的时候，丢帧将直接导致配飞（很奇怪，里程计不是用上了吗？）</li>
<li><strong><u>貌似没有实现2007年论文的improved
proposal思想</u></strong>。</li>
</ul>
<p>​
以下测试的地图均为5cm大小grid，intel数据包由于点云帧率低，我的i5上可以开8倍速播放包，而我自己做的仿真数据集只能2倍速（否则丢帧直接死掉），粒子个数均为15个，其他参数都是默认参数。</p>
<p><img src="/2021/10/22/%E7%89%B9%E9%BE%99%E6%99%BA%E6%85%A7-GMapping/Screenshot%20from%202021-10-22%2017-55-33.png"></p>
<center>
Figure 3. Intel 实验室数据集
</center>
<p><img src="/2021/10/22/%E7%89%B9%E9%BE%99%E6%99%BA%E6%85%A7-GMapping/Screenshot%20from%202021-10-22%2017-57-36.png"></p>
<center>
Figure 4. hqy仿真数据集【1】
</center>
<p><img src="/2021/10/22/%E7%89%B9%E9%BE%99%E6%99%BA%E6%85%A7-GMapping/Screenshot%20from%202021-10-22%2017-59-28.png"></p>
<center>
Figure 5. hqy仿真数据集【2】
</center>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>SLAM</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title>CUDA踩坑实录【2】</title>
    <url>/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/</url>
    <content><![CDATA[<h1 id="cuda-ii">CUDA II</h1>
<hr>
<h2 id="i.-introduction">I. Introduction</h2>
<p>​
CUDA十分有趣。因为我基本就是做算法和软件的，所以对于计算机体系结构，硬件设计等等了解得不多。尽管个人这方面知识有限，我仍然觉得这方面知识十分必要。Profiler能帮助我们在数据驱动的形式下优化代码，但并不会有助于我一开始就写出高质量、符合相应设备特性的代码。而深入了解CUDA对理解计算机内部一些底层的实现非常有帮助，比如说：内存访问，存储结构，流水线设计，带宽利用...
等等。</p>
<p>​
为了进一步精进CUDA技术，我又设计了一个新的项目：粒子滤波加速。本来是想给之前的<a href="https://enigmatisms.github.io/2021/08/07/Particle-Filter-Simulation/">【Particle
Filter
Simulation】</a>这篇博文中使用的Volume2D算法进行加速，但做着做着就发现该算法不适合加速，遂推倒重来，重构的过程中学习了很多新的知识。整个项目作为
<strong><u>激光雷达仿真器LiDARSim2D</u></strong>的一个补充模块，现在更新在了<a href="https://github.com/Enigmatisms/LiDARSim2D">[仿真器repo：LiDARSim2D]</a>下。</p>
<p><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/pic1.png"></p>
<center>
Figure 1. 粒子广场
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-pf-gpu管线">II. PF-GPU管线</h2>
<h3 id="之前的算法">2.1 之前的算法</h3>
<p>​ 之前的粒子滤波基于Volume2D算法，主要问题有两个：</p>
<div class="tabs" id="algos"><ul class="nav-tabs"><li class="tab active"><a href="#algos-1">速度慢</a></li><li class="tab"><a href="#algos-2">二维定位</a></li></ul><div class="tab-content"><div class="tab-pane active" id="algos-1"><p>不是说Volume2D算法慢，Volume2D算法虽然是性能瓶颈，但是单次也能只花0.2ms就算出结果来。而问题是，粒子滤波需要计算成千上万次，0.2ms在2000粒子的情况下，经过8线程加速，也就大概6fps的样子，远远达不到实时性要求。</p></div><div class="tab-pane" id="algos-2"><p>前一版算法，只对2D（x,y）进行了定位，这存在两个问题：</p>
<ul>
<li>旋转这个维度，虽然相对平移来说只有一维，但是其对结果的影响一般来说都更大。（旋转导致视角变化，视角变化导致观测可以发生巨大改变）。此外，不做角度维度的滤波使得这个粒子滤波直接失去了当2D建图中的一个附加算法模块的可能。</li>
<li>为了保证采样充分，三个维度比两个维度需要更多的采样点（比如之前如果是1600=40*40，那么直觉上来说，三维应该需要40*40*40=64000），这就引回到第一个“计算慢”的问题上了（20000点，0.6fps）。</li>
</ul></div></div></div>
<p>​
两个问题都是无法接受的！！！！不过！<strong><u>解决这两个问题的关键，是解决速度问题</u></strong>。速度上去了，那么可以接受更多点的采样，也就能解决维度问题。于是我开始思考如何加速Volume2D计算，Volume2D见<a href="https://enigmatisms.github.io/2021/08/02/Volume2D-Shader-Pro/">[我的博文]</a>。其中最有并行加速希望的地方在这：</p>
<details class="note warning"><summary><p>长代码段</p>
</summary>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">ParticleFilter::edgeIntersect</span><span class="params">(<span class="type">const</span> Edge&amp; eg, <span class="type">const</span> Eigen::Vector2d&amp; obs, std::vector&lt;<span class="type">double</span>&gt;&amp; range)</span> </span>&#123;</span><br><span class="line">    <span class="type">double</span> angle_start = eg.<span class="built_in">front</span>().<span class="built_in">z</span>(), angle_end = eg.<span class="built_in">back</span>().<span class="built_in">z</span>();</span><br><span class="line">    <span class="type">int</span> id_start = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(<span class="built_in">ceil</span>((angle_start + M_PI) / angle_incre)), </span><br><span class="line">        id_end = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(<span class="built_in">floor</span>((angle_end + M_PI) / angle_incre));</span><br><span class="line">    <span class="keyword">if</span> (id_start == id_end + <span class="number">1</span>) <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">if</span> (id_start &gt; id_end) &#123;            <span class="comment">// 奇异角度</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = id_start; i &lt; ray_num; i++) &#123;</span><br><span class="line">            <span class="type">double</span> angle = angle_incre * <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(i) - M_PI;</span><br><span class="line">            <span class="function">Eigen::Vector3d <span class="title">vec</span><span class="params">(cos(angle), sin(angle), angle)</span></span>;</span><br><span class="line">            Eigen::Vector2d intersect = eg.<span class="built_in">getRayIntersect</span>(vec, obs);</span><br><span class="line">            range[i] = intersect.<span class="built_in">norm</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt;= id_end; i++) &#123;</span><br><span class="line">            <span class="type">double</span> angle = angle_incre * <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(i) - M_PI;</span><br><span class="line">            <span class="function">Eigen::Vector3d <span class="title">vec</span><span class="params">(cos(angle), sin(angle), angle)</span></span>;</span><br><span class="line">            Eigen::Vector2d intersect = eg.<span class="built_in">getRayIntersect</span>(vec, obs);</span><br><span class="line">            range[i] = intersect.<span class="built_in">norm</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = id_start; i &lt;= id_end; i++) &#123;</span><br><span class="line">            <span class="type">double</span> angle = angle_incre * <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(i) - M_PI;</span><br><span class="line">            <span class="function">Eigen::Vector3d <span class="title">vec</span><span class="params">(cos(angle), sin(angle), angle)</span></span>;</span><br><span class="line">            Eigen::Vector2d intersect = eg.<span class="built_in">getRayIntersect</span>(vec, obs);</span><br><span class="line">            range[i] = intersect.<span class="built_in">norm</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</details>
<p>​
但是实际缺很难做，一是因为此处求交点是针对一段折线，需要先旋转数组二分查找。此外，Edge这个数据结构也不方便使用（变长Eigen::Vector2d的deque），还逼得我了解了一下thrust的libcu++
vector。遂放弃加速。</p>
<h3 id="渲染管线">2.2 渲染管线</h3>
<p>​
突然有一天上午，我觉得自己之前很蠢：之前的粒子滤波是写着玩的，要不然求range
image的方法也不会是这样（当时因为受Volume2D的启发，想要复用一下这个算法）。事实证明，这个算法不适合求深度图。想到这个，我直接开始思考用激光雷达模型</p>
<blockquote>
<p>我称之为：正向法，也即求激光雷达发射光线生成深度图的模型。</p>
</blockquote>
<p>​
深度图获取，在我看来就是一条GPU渲染管线（渲染经常做这个事情啊），而且我觉得本问题用GPU实现实在太适合了，原因有二：</p>
<ul>
<li>每个粒子根据此时的位姿求深度图，进而求重采样权重，是完全相互独立的。</li>
<li>每个粒子内部，渲染深度图使用Z
buffer方法，应该是有很不错的并行度的。</li>
</ul>
<p>​ 于是我直接设计了一个Z buffer方法：</p>
<center>
<img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/zbuf.png" style="zoom:50%;">
</center>
<center>
Figure 2. Z buffer 方法说明
</center>
<p>​ Z buffer 很好理解，它与Volume2D的异同是：</p>
<div class="tabs" id="princ"><ul class="nav-tabs"><li class="tab active"><a href="#princ-1">体积光算法</a></li><li class="tab"><a href="#princ-2">Z Buffer</a></li></ul><div class="tab-content"><div class="tab-pane active" id="princ-1"><p>计算哪些地图边界能被实际观测到（计算遮挡关系，求出没被遮挡的所有边），使用未被遮挡的边计算激光交点以及对应深度。</p></div><div class="tab-pane" id="princ-2"><p>不管遮挡关系，激光与所有可能边相交，取离自己最近的那个值（最小值）。也就是说，Z
buffer直接计算所有可能的相交，求最小值。</p></div></div></div>
<hr>
<h2 id="iii.-算法设计">III. 算法设计</h2>
<h3 id="第一代">3.1 第一代</h3>
<blockquote>
<p>数据关联越不紧密的，并行的粒度应该越粗。--- 我的理解</p>
</blockquote>
<p>​
这么说的原因是：数据关联紧密的，可能可以使用共享内存。比如本问题中，不同粒子之间，经过背面剔除(back
culling)之后的边都不一致，并且观测点也不一致，不适合放在同一个block内部，故一个粒子应该是一个block。而block内部细粒度的并行，应该针对【一个确定粒子下（观测点确定）】的所有地图边（地图两个相连角点确定的线段）（见下图说明：）</p>
<center>
<img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/para.png" style="zoom:50%;">
</center>
<center>
Figure 3. 并行说明
</center>
<p>​ 不同的观测点位于不同block，同一观测点下的不同线段（比如observing
point
1下的地图线段），线段之间是thread并行的（不同颜色线段产生的深度信息是并行计算的）。使用线段而不是Edge作为处理单元以及这样设置并行带来几个好处：</p>
<ul>
<li>线段是定长的数据（4个float就可以表示）</li>
<li>不同block可以在常量内存中共用同一个地图（初始线段）</li>
<li>同一个block内处理不同线段的thread，可以将back
culling的结果输出到一个共享的flag数组上，并且计算的深度值也可以使用共享内存保存，加速内存读写。</li>
</ul>
<p>​ 于是初代算法的流程大概是这样：</p>
<ul>
<li>观测点数为girdDim.x（也即block数）（10000+），线段数量为blockDim.x（也即线程数）（通常小于400）.</li>
</ul>
<p><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/flow.png"></p>
<center>
Figure 4. 算法流程
</center>
<p>​
由于第一代算法几乎就是整个算法的思想主体（之后的都是优化迭代，没有大改），重点说一下。</p>
<h4 id="背面剔除">3.1.1 背面剔除</h4>
<p>​
背面剔除需要flags：输入的是原始地图，原始地图中有些线段是不需要的（背面），在背面剔除函数中每个线程计算自己对应的线段是否是正面，保存在flag中。以下代码块是动态内存分配，平均每个block使用1-2KB的共享内存（很节约）。由于CUDA动态共享内存
<strong><u>只有这一种方法分配</u></strong>，所以跨类型或者多数组是不可能直接写的，需要强转指针（我哥建议我使用reinterpret_cast来完成指针转换，但是我发现这样也没问题）。注意由于分配的是int数组，故在kernel
launch时，指定的数组字节数需要为4的整数倍（bool只占1字节，所以可能需要padding）。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">extern</span> __shared__ <span class="type">int</span> range[];          <span class="comment">//...一个数据类型分为了两个不同意义以及类型的块</span></span><br><span class="line"><span class="type">bool</span>* flags = (<span class="type">bool</span>*)(&amp;range[range_num]);</span><br></pre></td></tr></table></figure>
<h4 id="单线段z-buffer">3.1.2 单线段Z buffer*</h4>
<p>​
假设本thread的id对应的线段需要被处理（事实上如果不需要被处理，会直接return，这确实会引起warp
divergence，但是overhead可以忽略），那么就需要计算这个线段产生的局部深度图。</p>
<p>​
其中的难点在于控制逻辑：<strong><u>-PI~PI</u></strong>是atan2的角度输出范围，角度奇异性（由于是逆时针，一般情况下起始点角度小于终止点，但是跨<span class="math inline">\(\pm\pi\)</span>界限（x负半轴）时会出现奇异）会影响数组下标
/ 角度id等等的计算，这里不多讲，有兴趣直接看代码吧。</p>
<p>​ 此外重要的一点就是：Z
buffer保存的始终是某个角度上深度的最小值，但是如何计算最小？需要我们把所有线段深度算出来然后求最小？<strong><u>显然不是，这样太慢了，而且需要线程间数据交流（共享内存）</u></strong>。我们考虑增量式的方法：</p>
<div class="note primary"><p>​
计算值每次和深度值数组range（共享内存）对应id进行比较，保留更小的值。但是这会涉及到一个问题：<strong><u>线程访问冲突</u></strong>。</p>
</div>
<div class="note success"><p>​
使用原子操作！原子地进行比较并且替换为更小值就行。但是很可惜：<strong><u>CUDA不支持float原子比较</u></strong>。</p>
</div>
<p>​ 那么怎么办呢？stackoverflow上有人给了方法：</p>
<div class="note info"><p>​
把Float直接按位解释为int，对此int进行一些计算，转化为一个可以保序的（ordered）int，对int进行原子比较可以使用atomicMin。</p>
</div>
<p>​ 关于Ordered int转换，见这篇别人写的博客<a href="http://stereopsis.com/radix.html">[Float radix sort]</a>,
以及stackoverflow上的<a href="https://stackoverflow.com/questions/17399119/how-do-i-use-atomicmax-on-floating-point-values-in-cuda">[一个回答]</a>（最高赞的是错的，Informate.it写的是对的）。原子操作十分香，而且感觉很优雅。</p>
<h4 id="相似度权重">3.1.3 相似度权重</h4>
<p>​
所有线程计算结束之后（相当于本粒子对应观测点的深度图算完了），一个block内计算参考深度图与本观测点深度图的L1误差<span class="math inline">\(L_e\)</span>，<span class="math inline">\(1/(L_e+1)\)</span>是本观测点的权重。</p>
<h3 id="之后的优化">3.2 之后的优化</h3>
<p>​ 第一代算法存在一些速度缺陷：</p>
<ul>
<li>使用double，进行计算：CUDA对double并不是特别友好，一些double函数比如atan2就更不用说了。int也是滥用了，有些数字使用short即可，完全不必用int。</li>
<li>Z
buffer中的线段求交点函数<code>__device__ __forceinline__ float getRange(...)</code>内部过多Eigen或者自定义数据结构的重复索引操作，并且有些计算没有复用。这个函数是整个单线段Z
buffer的瓶颈。</li>
<li>使用Eigen，库虽然方便，但是速度慢了</li>
<li><strong><u>（重要）：</u></strong>并行度低，没有使用流水线(stream)，单kernel，GPU占用巨大。</li>
</ul>
<p>​
第一个问题优化之后，使得我的算法从与CPU差不多的速度升到的CPU的五倍（相比于8线程），第二三个问题修正使得我的速度上升为CPU速度的16倍（相比于8线程），而profile以及流水线优化使得我的算法先后达到了32x，45x加速！所以我重点说一下stream
concurrency。</p>
<h3 id="stream-concurrency">3.3 Stream Concurrency</h3>
<p>​
stream，翻译是“流”，我将其理解成为流水线。实际上是GPU的一个操作“队列”：</p>
<p><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/nvvp.png"></p>
<center>
Figure 5. stream示意图[1]
</center>
<p>stream有这样的特性：</p>
<ul>
<li>如果一个kernel或者是cuda操作（比如Memcpy）在同一个stream下被launch，那么是按照issue-order（发射的顺序）执行（与之相对的是乱序发射）。</li>
<li>如果分配到不同的stream下，那么可以乱序执行，并且根据GPU资源利用情况，可能有overlap。</li>
</ul>
<p>​
那么显然，overlap多大，说明GPU越不容易空闲，很可能可以有几个kernel函数的并行执行，相当于流水线操作，上一个kernel还没执行完，下一个kernel已经开始了。如果不指定stream，使用default
stream，那么profile得到的图会是一个完全阶梯状的，阶梯之间一般没有并行（issue-order限制），一开始我就是单stream执行的，<strong><u>并且是一个超大的kernel（需要处理上万个block）</u></strong>。</p>
<p>​ 当我意识到这一点之后，我将kernel拆分了，反复调用particle
filter这个核函数，不过每次只处理不到100个block。开始时跑的效果并不好，<strong><u>直到我使用了CUDA
Profiler</u></strong>，将运行状态绘制出来之后发现，诶？完全阶梯状的kernel调用，并且profiler也告诉我：“<strong><u>kernel
overlap too small:
0%</u></strong>”，也就是说，block几乎是顺序计算的，这样的效率太低！</p>
<p>​ 查阅了很多资料[1][2][3]，最后确定使用stream：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">cudaStream_t streams[<span class="number">8</span>];</span><br><span class="line">streams[<span class="number">0</span>] = cudaStreamDefault;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; <span class="number">8</span>; i++)</span><br><span class="line">    <span class="built_in">cudaStreamCreateWithFlags</span>(&amp;streams[i],cudaStreamNonBlocking);</span><br><span class="line"><span class="comment">// cudaProfilerStart();</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; cascade_num; i++) &#123;</span><br><span class="line">    particleFilter &lt;&lt;&lt; <span class="number">16</span>, seg_num, shared_to_allocate, streams[i % <span class="number">8</span>]&gt;&gt;&gt; (...);</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">CUDA_CHECK_RETURN</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line"><span class="comment">// cudaProfilerStop();</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; <span class="number">8</span>; i++)</span><br><span class="line">    <span class="built_in">cudaStreamDestroy</span>(streams[i]);</span><br></pre></td></tr></table></figure>
<p>​
创建了不同的stream（cudaStreamNonBlocking），循环地把不同的kernel（处理particles的不同offset位置）发射到不同的stream上，实现更加紧凑的并行。cudaStreamDefault
在CUDA7之后不会有之前的隐式同步问题（默认stream会导致操作串行化），所以可以使用。</p>
<p>​
当然，流水线最后的级数，block的大小都是profile试着调整过来的。32x加速的版本，使用的grid有点过小（4个粒子，8个streams）：</p>
<ul>
<li>4个粒子的kernel会迅速执行完，但是kernel时间并没有长到可以充分利用流水线调度空余时间。</li>
<li>最后使用16个粒子的kernel，速度提到了45x（profile之后突然想到的）</li>
</ul>
<h3 id="一些其他的加速尝试">3.4 一些其他的加速尝试</h3>
<p>​ 以下是证明在本问题中无效的加速尝试：</p>
<ul>
<li>动态并行（dynamic
parallelism，这也是在上一篇CUDA博客中折磨我的东西）。<strong><u>这个完全没用！</u></strong>反倒是增大了每个kernel的线程资源消耗（一个block就只有最多1024线程），导致算法变得更慢。很显然嘛，一个block大概200-300个线程，那么每个线程还得再launch一个子kernel（多线程），显然资源会不够。</li>
<li>内存吞吐流水操作：CUDA希望我做这个事情：内存的移动是小块小块的，不要一起完成，否则没有太大的流水线加速效果。但实际情况是：即使是个几百MB的global
memory复制，也非常迅速地完成了（貌似没到1ms）</li>
</ul>
<p><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/cuda.png"></p>
<center>
Figure 6. CUDA stream化的优势
</center>
<ul>
<li>更加激进的位宽优化（能换short就short了），剩余的一些优化用处不大。</li>
<li>等等等等：尝试了很多方法，不一一列举了。</li>
</ul>
<h3 id="采样点不足">3.5 采样点不足</h3>
<p>​
旋转对算法结果的影响能力比平移大。试想一下自己平移一些之后看到的世界与旋转一点看到的世界的差异就知道了。开始时，角度的采样明显是欠缺的：</p>
<ul>
<li>三个轴上都使用均匀分布随机数。因为开始时我希望保证三个维度下的采样应该一致，但这种做法并不好，因为我
<strong><u>并不能保证</u></strong>，在每一个平移位置，旋转的采样都足够了。</li>
</ul>
<p>​
之后我使用了如下的策略：12800个点，先在平移上均匀采样1280个点，每个平移位置：360度等间隔采样（10个点，36度一个），那么一个平移位置对应了10个点，再对这10个点加少量位置噪声。这种策略，<strong><u>可以保证每个平移位置的角度采样都是充分的</u></strong>，就不会因为角度采样过于随机导致视角缺失。</p>
<h3 id="一些坑">3.6 一些坑</h3>
<ul>
<li>Eigen/CUDA不兼容的坑：在同学的RTX 2070设备上测试时，他的驱动是CUDA
10.2，Eigen 3.3.4，我的驱动CUDA
10.1，Eigen相同，我可以编译，他报错：找不到<code>Eigen 找不到&lt;math_functions.hpp&gt;</code>：把Eigen升级到3.4.0
（直接上Gitlab爬下它的源码进行include），正确选择arch代数（RTX
2070至少应该选arch=sm_70? 我的MX150是sm_61）就可以通过编译。</li>
<li>std::atomic库与CUDA不兼容：我想把之前写的键盘操作用在CUDA可视化中，但是编译不过，CUDA中的std::atomic部分类型的copy
constructor是deleted
functions，没有实际意义。最后没有解决，放弃了，直接使用OpenCV。</li>
<li>nvcc要加一些flags才能避免Eigen的一些傻逼warning：<code>--expt-relaxed-constexpr -Xcudafe --diag_suppress=esa_on_defaulted_function_ignored</code>，CMake添加这个：<code>add_compile_options(-Wno-deprecated-declarations)</code></li>
<li>__constant__ memory访问的问题：定义__constant__
变量，是不能用extern的，并且constant内存是已经存在的，只需要声明用多少(不能malloc)，只要能看到这个变量的定义，那么这个变量对能看到它的函数都是全局的。<strong><u>在不同文件中使用同一个constant
memory变量，需要：</u></strong>打开CUDA的separate
compilation选项（目的是生成一个relocatable的代码），separate
compilation在之前的动态并行中说过。</li>
<li>一些结构体定义的函数如果需要在GPU上用，要声明为__host__ __device__
（双重属性），这样的话，CPU / GPU上会各有一份实现。</li>
<li>带cuda开头的cuda runtime API一般都是host
only，不要使用在kernel中。</li>
<li>使用nvvp进行可视化profiling，需要安装java8，配置jre-1.8（针对Ubuntu18.04），环境错了是打不开profile工具的。并且profile的时候需要有root权限。</li>
<li>粒子的运动：每个粒子应该朝自己的方向前进后退左移右移，而不是与控制点保持一样的方向。方向一致的运动结果是有问题的。</li>
</ul>
<hr>
<h2 id="iv.-实验结果">IV. 实验结果</h2>
<h3 id="粒子滤波效果一览">4.1 粒子滤波效果一览</h3>
<p>​ 6fps慢速播放效果：</p>
<video src="cv_output1.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<center>
Video 1. 慢速播放效果
</center>
<video src="cv_output2.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<center>
Video 2. 常速播放效果（特意找了一个较长时间没有收敛的情况）
</center>
<h3 id="profile结果">4.2 Profile结果</h3>
<p>​
小block的kernel方便进行kernel之间的并发，而大block的kernel就可以明显看出执行偏顺序化了。</p>
<p><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/Screenshot%20from%202021-10-16%2014-24-07.png"></p>
<center>
Figure 7. 8 streams 小block kernel
</center>
<p><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/Screenshot%20from%202021-10-16%2014-26-17.png"></p>
<center>
Figure 8. 8 streams 大block kernel
</center>
<p>​
极端情况是单stream大block，由于资源占用过多，kernel之间完全是串行执行了。</p>
<p><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/Screenshot%20from%202021-10-16%2014-28-26.png"></p>
<center>
Figure 9. 单 stream 大block kernel
</center>
<h3 id="速度说明">4.3 速度说明</h3>
<p>​
已经测试的速度（12800粒子，$$115度激光，角分辨率0.5度，共330个激光点的情况）：</p>
<ul>
<li>GeForce MX150: 约为42fps</li>
<li>GeForce RTX 2070: 约为116.5fps</li>
</ul>
<h3 id="四张图">4.4 四张图</h3>
<p>​
红色粒子为采样，红色粒子内部有黄色箭头（很小），指示了粒子的方向。蓝绿色点是所有粒子按照权重加权平均的结果（带权重心），黄色点是真值。</p>
<table>
<colgroup>
<col style="width: 51%">
<col style="width: 48%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;"><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/pic0.png"></th>
<th style="text-align: center;"><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/pic1.png"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">开始阶段：粒子簇在平移均匀分布（略带噪声）</td>
<td style="text-align: center;">移动一段距离，每个粒子都更新了自己的位置</td>
</tr>
<tr>
<td style="text-align: center;"><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/pic2.png"></td>
<td style="text-align: center;"><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/pic3.png"></td>
</tr>
<tr>
<td style="text-align: center;">收敛中：粒子均值已经收敛到真值附近</td>
<td style="text-align: center;">收敛，有偏差，这是初值估计可以容忍的</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://developer.download.nvidia.com/CUDA/training/StreamsAndConcurrencyWebinar.pdf">Steve
Rennich - CUDA C/C++ Streams and Concurrency</a></p>
<p>[2] <a href="https://www.olcf.ornl.gov/wp-content/uploads/2020/07/07_Concurrency.pdf">Nvidia
Bob Crovella CUDA Concurrency</a></p>
<p>[3] <a href="https://on-demand.gputechconf.com/gtc/2014/presentations/S4158-cuda-streams-best-practices-common-pitfalls.pdf">Justin
Luitjens - CUDA streams best practices common pitfalls</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>GPU</tag>
        <tag>CUDA</tag>
      </tags>
  </entry>
  <entry>
    <title>Correspondence Problem Papers</title>
    <url>/2021/10/15/Correspondence-Problem-Papers/</url>
    <content><![CDATA[<h1 id="correspondence-problem">Correspondence Problem</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<blockquote>
<p>The <strong>correspondence problem</strong> refers to the problem of
ascertaining which parts of one image correspond to which parts of
another image, where differences are due to movement of the camera, the
elapse of time, and/or movement of objects in the photos.
---Wikipedia</p>
</blockquote>
<p>​
最近一直在做与匹配相关的问题：点云配准。点云配准就是一个非常经典的匹配问题，在基于特征的方法下，找到两帧点云对应位置的特征，建立匹配关系，可以根据计算好的匹配算出位姿变换，而由于引入特征以及特征匹配，通常情况下可以使得配准算法具有全局性。</p>
<p>​
我在最近的一次组会上做了论文分享，讲了两篇具有很强关联性的论文（这两篇论文都很好懂，ICCV
2005的尤其简单，看完就能写出代码来）：</p>
<ul>
<li><a href="https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/leordeanu-iccv-05.pdf">ICCV
2005: A Spectral Technique for Correspondence Problems Using Pairwise
Constraints</a></li>
<li><a href="https://arxiv.org/abs/2103.05465">CVPR 2021: PointDSC:
Robust Point Cloud Registration using Deep Spatial Consistency</a></li>
</ul>
<p>​ 我将本人论文分享时做的PPT贴在本文内。</p>
<span id="more"></span>
<hr>
<h2 id="ii.-ppts">II. PPTs</h2>
<p><img src="/2021/10/15/Correspondence-Problem-Papers/2021-10-15%20(1).png"></p>
<center>
Figure 1. 典型匹配对问题：点云配准
</center>
<p><img src="/2021/10/15/Correspondence-Problem-Papers/2021-10-15%20(2).png"></p>
<center>
Figure 2. 变换一致性在刚体变换中的应用：旋转平移距离不变性
</center>
<p><img src="/2021/10/15/Correspondence-Problem-Papers/2021-10-15%20(3).png"></p>
<center>
Figure 3. 思想：构建图问题，使用谱方法
</center>
<p><img src="/2021/10/15/Correspondence-Problem-Papers/2021-10-15%20(8).png"></p>
<center>
Figure 4. 本人对论文I的方法总结
</center>
<p><img src="/2021/10/15/Correspondence-Problem-Papers/2021-10-15%20(5).png"></p>
<center>
Figure 5. 论文I存在的问题（毕竟是很老的工作了）
</center>
<p><img src="/2021/10/15/Correspondence-Problem-Papers/2021-10-15%20(6).png"></p>
<center>
Figure 6.
方法总结：第一部分，包含变换一致性的全局神经网络模块以及种子点选取的特征筛选
</center>
<p><img src="/2021/10/15/Correspondence-Problem-Papers/2021-10-15%20(7).png"></p>
<center>
Figure 7.
方法总结：第二部分，KNN子集扩增，NSM概率计算，加权最小二乘，propose and
verify
</center>
<hr>
<h2 id="今日快乐">今日快乐</h2>
<p>​ 击败了巨人（快乐），但是之后被国王之手干死了（不快乐）：</p>
<p><img src="/2021/10/15/Correspondence-Problem-Papers/2021-10-15.png"></p>
<center>
Figure 8. 我的王啊... 真他妈是个不可救药的混蛋
</center>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title>CUDA踩坑实录【1】</title>
    <url>/2021/09/23/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%901%E3%80%91/</url>
    <content><![CDATA[<h1 id="cuda-i">CUDA I</h1>
<hr>
<h2 id="i.-introduction">I. Introduction</h2>
<p>​ 在复现<a href="https://arxiv.org/abs/2104.07516"><strong>A
Decomposition Model for Stereo
Matching</strong></a>这篇论文的时候，发现其Sparse
matching并不是直接的pytorch实现。本来我想直接pytorch了事的，但仔细一思考后觉得虽然反向传播实现不用考虑了，但是整体变得很慢。阅读官方源码发现时看到一些我不太懂的东西，后来我才知道这些是CUDA自定义pytorch算子，是pytorch的CUDA
extension。出于以下目的：</p>
<ul>
<li>复习CUDA（特别是在学习完GPU存储结构与计算之后，急需实践）</li>
<li>学习setuptools的使用以及torch的CUDA extension写法</li>
</ul>
<p>​ 我给自己定了一个小型的CUDA任务，与SDF以及marching
cubes算法十分相关。项目见<a href="https://github.com/Enigmatisms/CuTorch">[🔗Enigmatisms/CuTorch]</a></p>
<span id="more"></span>
<hr>
<h2 id="ii.-任务设定">II. 任务设定</h2>
<p>​
在一个800x600的画布内，随机生成一些“泡泡”，这些泡泡在运动过程中应该可以自由地融合。泡泡的融合不是简单地叠加，叠加应当是平滑的。如下图所示：</p>
<p><img src="/2021/09/23/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%901%E3%80%91/bubbles.PNG" style="zoom: 67%;"></p>
<center>
Figure 1. 泡泡融合问题
</center>
<p>​ 每个泡泡对应着2D平面上半径为r，中心为(x,
y)的一个圆。那么需要计算：</p>
<ul>
<li>每个泡泡对应圆的SDF，并且将其叠加在一起</li>
<li>设置一个阈值，跨越此阈值的部分将形成边结构（也就是等高线）</li>
</ul>
<p>​ 整个小项目的完整知识在这里：<a href="http://jamie-wong.com/2014/08/19/metaballs-and-marching-squares/">【Jamie
Wong: Metaballs and Marching
Squares】</a>。写得非常不错，6月份做SDF的点云融合时，曾经参考过其marching
cubes的实现方法。本文与具体的算法实现没有太大的关系，因为算法本身非常简单。</p>
<hr>
<h3 id="基础知识">2.1 基础知识</h3>
<h4 id="dims">2.1.1 Dims</h4>
<p>​ grid 与
block是CUDA的分级管理的两个层次，grid相当于是block的集合，而block相当于是thread的集合（或者warp的集合）。但我在写CUDA的时候好像并没有看到warp的直接使用。注意grid与block两者的维度
gridDim以及blockDim 千万别搞混了。对于一个kernel:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">kernel_function &lt;&lt;&lt;A, B&gt;&gt;&gt; ();</span><br></pre></td></tr></table></figure>
<p>​
A指定的是grid的形状，可以是dim3类型，也可以是一个数字（指定block），A是数字的情形很常用，二维图像处理一般可以这么做：A，B分别代表图像的某一个维度。</p>
<p>​
B指定的是block形状，数据类型同理。那么gridDim则反映了A的输入，blockDim反映B的输入，比如：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>)</span></span>;</span><br><span class="line">kernel_func &lt;&lt;&lt;grid, block&gt;&gt;&gt; ();</span><br></pre></td></tr></table></figure>
<p>​ 在kernel内部，会有：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">(gridDim.x, gridDim.y, gridDim.z)=(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>);</span><br><span class="line">(blockDim.x, blockDim.y, blockDim.z)=(<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>);</span><br></pre></td></tr></table></figure>
<p>​ 相应地，blockIdx.x <span class="math inline">\(\in\)</span> [0,
gridDim.x ), threadIdx.x <span class="math inline">\(\in\)</span> [0,
blockDim.x)。每一个实际的id，其范围是层级式的。block
id与grid有关，thread id与block有关。并且也要注意以下的问题：</p>
<blockquote>
<p>Goal: Have enough transactions in flight to saturate the memory
bus.</p>
<p>Latency can be hidden by having more transactions in flight. [1]</p>
</blockquote>
<p><img src="/2021/09/23/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%901%E3%80%91/block.png"></p>
<center>
Figure 2. occupancy注意事项（来源<a href="#refs">[1]</a>)
</center>
<h3 id="dynamic-parallelism踩坑">2.2 Dynamic Parallelism踩坑</h3>
<p>​ Dynamic parallelism，我更愿意直观地称之为：nested
kernels（嵌套的核函数）。以我自己的代码为例，我尝试了一下嵌套核函数：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">fineGrainedTask</span><span class="params">(<span class="type">const</span> <span class="type">float</span>* <span class="type">const</span> bubbles, <span class="type">const</span> <span class="type">int</span> x, <span class="type">const</span> <span class="type">int</span> y, <span class="type">float</span>* shared_tmp)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> id = threadIdx.x, base = <span class="number">3</span> * id;</span><br><span class="line">    <span class="type">const</span> <span class="type">float</span> cx = bubbles[base], cy = bubbles[base + <span class="number">1</span>], radius = bubbles[base + <span class="number">2</span>];</span><br><span class="line">    shared_tmp[id] = <span class="built_in">signedDistance</span>(x, y, cx, cy, radius);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">calculateSDF</span><span class="params">(<span class="type">const</span> <span class="type">float</span>* <span class="type">const</span> bubbles, <span class="type">const</span> <span class="type">int</span> num, <span class="type">float</span>* output)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> y = threadIdx.x, x = blockIdx.x, id = y * gridDim.x + x;</span><br><span class="line">    <span class="type">float</span> distance = <span class="number">0.0</span>;</span><br><span class="line">    <span class="comment">// fineGrainedTask &lt;&lt;&lt; 1, num &gt;&gt;&gt; (bubbles, x, y, tmp);</span></span><br><span class="line">    <span class="comment">// cudaDeviceSynchronize();</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; num; i++) &#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> base = <span class="number">3</span> * i;</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span> cx = bubbles[base], cy = bubbles[base + <span class="number">1</span>], radius = bubbles[base + <span class="number">2</span>];</span><br><span class="line">        distance += <span class="built_in">signedDistance</span>(x, y, cx, cy, radius);</span><br><span class="line">    &#125;</span><br><span class="line">    output[id] = distance - <span class="number">1.0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 第二个函数 <code>__global__ void calculateSDF</code>
是主核函数。其目的是求二维矩阵中每一个点(i,
j)的SDF值。而显然，每次输入的泡泡数量(num)可以很大，那么内部求signed
distance的for循环，应该是可以并行化的。第一个函数<code>__global__ void fineGrainedTask</code>
就是为了做这样的并行，在第十行也被调用了（num路并行，使用__shared__保存临时的结果）。</p>
<p>​ CUDA在 architecture 35以及之后就支持这种nested的dynamic
parallelism结构，允许核函数内部调用核函数，因为确实也是会有层次并行的需求的。</p>
<div class="note danger"><center>
<h3>
但是CUDA dynamic parallelism + Python却有一大堆坑
</h3>
</center>
</div>
<p>​ 假如只是使用CUDA +
CPP进行嵌套核函数的编写，虽然有点小坑，但是很快就能过编译：</p>
<p>​ Dynamic parallelism需要separate
compilation，CMake里面有很简单的设置：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set_property</span>(CUDA_SEPARABLE_COMPILATION <span class="keyword">ON</span>)</span><br></pre></td></tr></table></figure>
<p>​ 但需要注意两点：</p>
<ul>
<li>separate compilation需要指定arch：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-gencode=arch=compute_35,code=sm_35</span><br></pre></td></tr></table></figure>
<ul>
<li>nvcc编译的时候，会指定：<code>-lcudadevrt -lcudart</code>，在/usr的某个文件夹下有一个动态库(libcudart.so)以及一个静态库（我的设备上是静态库：cudadevrt.a）。不方便设置这两个编译flag的时候，在target_link_libraries中可以手动链接。</li>
</ul>
<p>​ 但是Python
setuptools编译并没有那么友好。首先我也知道我需要进行separate
compilation，所以我需要指定：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">setup(</span><br><span class="line">    name=<span class="string">&#x27;march&#x27;</span>,</span><br><span class="line">    ext_modules=[</span><br><span class="line">        CUDAExtension(<span class="string">&#x27;march&#x27;</span>, [</span><br><span class="line">                <span class="string">&#x27;src/marchingCubes.cu&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;src/sdf_kernel.cu&#x27;</span>,</span><br><span class="line">            ],</span><br><span class="line">            include_dirs=[include_dirs],</span><br><span class="line">            extra_compile_args=&#123;<span class="string">&#x27;cxx&#x27;</span>: [<span class="string">&#x27;-g&#x27;</span>,</span><br><span class="line">            ],</span><br><span class="line">                <span class="string">&#x27;nvcc&#x27;</span>: [<span class="string">&#x27;-O3&#x27;</span>, <span class="string">&#x27;-use_fast_math&#x27;</span>,</span><br><span class="line">                 <span class="comment">################# Here #############</span></span><br><span class="line">				<span class="string">&#x27;-rdc=true&#x27;</span>, <span class="string">&#x27;-gencode=arch=compute_35,code=sm_35&#x27;</span></span><br><span class="line">            ]&#125;,</span><br><span class="line">        )</span><br><span class="line">    ],</span><br><span class="line">    cmdclass=&#123;</span><br><span class="line">        <span class="string">&#x27;build_ext&#x27;</span>: BuildExtension</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p>​
<code>-rdc=true</code>貌似和<code>-dc</code>作用差不多。还需要手动指定一下架构代数，默认好像是一个很小的代。好，不要忘了增加<code>-lcudadevrt</code>以及<code>-lcudart</code>以“保证”可以链接到CUDA的一些库。</p>
<p>​ 看起来很简单，编它。编译通过，很好，跑它。首先import
torch（由于本项目C++内部使用了libtorch，里面的libc10.so需要torch导入，不先import的话会报错）。再import
march（我的库名称），这一步直接死掉：</p>
<blockquote>
<p>什么什么undefined symbol，与CUDA库相关。</p>
</blockquote>
<p>​
大概意思就是：<code>cudadevrt.a</code>你根本没有链接上，里面还有一些函数定义呢。好家伙，python的所有库都是动态加载的，你一个静态库你叫我怎么加载（简单的方法就是：(1)
重新编译静态库为动态库 (2)
编译整个项目为一个extension，具体原理我也不懂）？我还指望你直接给我编译到march这个库里面呢。</p>
<p>​ 尝试了很多方法，无论是在C++ 编译flags里面链接，还是nvcc
flags，还是stackoverflow上说的所谓：setup函数的extra_compile_objects参数，没有一个有效果的。</p>
<p>​ 我也尝试过手动分别编译：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nvcc -O3 -use_fast_math -gencode=arch=compute_70,code=sm_70 -dc -I/opt/libtorch/include/ -I/opt/libtorch/include/torch/csrc/api/include/ -I//usr/include/python3.6m src/sdf_kernel.cu src/marchingCubes.cu -Xcompiler -fPIC </span><br><span class="line">nvcc -O3 -use_fast_math -gencode=arch=compute_70,code=sm_70 -dlink -L/usr/local/cuda-10.1/targets/x86_64-linux/lib/ -lcudadevrt -lcudart sdf_kernel.o marchingCubes.o -shared -o libdlink.so</span><br></pre></td></tr></table></figure>
<p>​
想把两个cuda文件编译跟原有的静态动态库一起编译成一个动态库，但是中途报了有关fPIC的错误，说是这样编译是不被允许的，反正不是那种很简单的错误。。。搞了半天，无果。各种问题都出了，最后我甚至都怀疑是编译器的bug（自信！）。最后貌似在CUDA
forum的某个地方看见有人说，Python现在对这个的支持还不是特别好，就弃坑了。</p>
<p>​
最后一个小坑就是：tmd不要随便用很高的代数！不知道为什么，我在setup函数nvcc参数设置时，定代数为：<code>-gencode=arch=compute_70,code=sm_70</code>。结果跑结果的时候，输出图像一片漆黑。最后查出来结果是：<strong><u>核函数根本没有被执行，跳过了</u></strong>，开始我以为出了内存问题（老
千（次）越（界）了）（PS：CUDA
runtime出错可能导致核函数不执行），写了个CUDA错误检查，发现完全没有错误。最后灵光一闪，我把代数改成了35，好了。。。</p>
<p>​
感觉被坑死了。原本预计一个下午解决，结果因为grid/block搞混，结果错误，多调了3小时，又因为dynamic
parallelism，多调了6小时。</p>
<p>​ 菜，或许就是这样的吧？</p>
<p>​ 完整的项目以及结果见<a href="https://github.com/Enigmatisms/CuTorch">[🔗Enigmatisms/CuTorch]</a></p>
<hr>
<h2 id="reference">Reference</h2>
<p><span id="refs"></span></p>
<p>[1] <a href="https://on-demand.gputechconf.com/gtc-express/2011/presentations/cuda_webinars_WarpsAndOccupancy.pdf">CUDA
Warps and Occupancy</a></p>
<p></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>GPU</tag>
        <tag>CUDA</tag>
      </tags>
  </entry>
  <entry>
    <title>【笔记】两篇双目相关论文</title>
    <url>/2021/09/04/%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%A4%E7%AF%87%E5%8F%8C%E7%9B%AE%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/</url>
    <content><![CDATA[<h1 id="stereo">Stereo!</h1>
<hr>
<p>​
最开始的时候，我在人机所的工作是搞双目开发，但是当时还完全不懂深度学习，觉得这就是个玄学玩意（事实上我现在还是这么觉得，只不过有些简单的网络，具有很好的理论解释，我觉得还挺妙的）。但是当年（也就是2020）的KITTI榜就已经被深度学习刷爆了啊，前100目测98个非传统方法。现在我对深度学习有了一定了解，也有了很多实践的经验，所以想着挑战一些更难的问题领域，一些不一样的应用场景（毕竟老研究奇奇怪怪的网络结构，复现不同的CV基础网络结构就跟调参一点区别没有）。</p>
<p>​
本文没有任何附带的实现，我只把这两篇CVPR2021论文只作为回归双目研究的起始“研读性”文章，不尝试复现，或者咱们不找借口，我之后理解得更透彻再来复现😝。</p>
<span id="more"></span>
<hr>
<h2 id="ii.-a-decomposition-model-for-stereo-matching1">II. <strong>A
Decomposition Model for Stereo Matching</strong>[1]</h2>
<p>​
加速了。作者能加速10-100倍，并且把复杂度降得很低，使用的思想我之前思考过，但是我之前并不知道怎么做，只是有个类似的想法：</p>
<div class="note primary"><p>​
如果我只需要在一个较小的图像上进行双目匹配（下采样图像），在上采样的过程中使用另一个网络进行refine，只需要对部分像素进行refine，是不是能提速？</p>
</div>
<p>​
产生这个想法的原因很简单，之前在尝试孙剑老师的“上古”论文（BP）时，对于无纹理区域的匹配效果不太好。大面积无纹理区域在下采样图像中就应该被解决。</p>
<h3 id="主要思想">2.1 主要思想</h3>
<p>​ 首先把网络总结构放一下：</p>
<p><img src="/2021/09/04/%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%A4%E7%AF%87%E5%8F%8C%E7%9B%AE%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/arch.PNG"></p>
<center>
Figure 2. Decomposition model 网络架构
</center>
<p>​
读完还是觉得这篇文章里有些<strong><u>很魔法</u></strong>的东西，但是也有很不错的思想。文章的方法主要可以分为以下四步：</p>
<div class="note danger"><ol type="1">
<li>最底层使用full cost
volume（可以认为是双目匹配里面的内存暴力法）以及cost
regularization（文中使用了一个如Figure 3所示的网络，对cost
volume又重新映射了一边）。文章称cost regularization的作用是“rectify cost
volume”，但是我半天没看明白这和rectify的关系（双目就有rectification操作，难不成是用Conv3d做了一个深度rectification？）。在这样固定大小的左右视图上进行full
cost volume匹配的开销是完全可以接受的。</li>
</ol>
</div>
<div class="note warning"><ol start="2" type="1">
<li>【稀疏的【损失细节】】检测。也就是使用一个无监督的网络，输入是：特征金字塔上一层（经过下采样的一层）的特征图的上采样结果，和特征金字塔本层特征图。无监督地学出可能因为下采样操作而丢失的特征（对应的position）。无监督学习，就是nice。</li>
</ol>
</div>
<div class="note info"><ol start="3" type="1">
<li>稀疏匹配。既然在上一步操作中，我们已经清楚有些地方就是没有匹配好，那么这一步我可以对那些没有匹配好的【损失细节】进行稀疏的匹配。由于稀疏匹配对应的特征们分布不规则并且大小不固定，使用cost
volume搜索对应的方法是不好的。论文使用了一种agreement思想，使用cross
correlation（相当于找到最大“卷积”响应点），转换结果为softmax，再求期望，这个想法不错。</li>
</ol>
</div>
<div class="note success"><ol start="4" type="1">
<li>视差融合。也就是稀疏视差图融合到稠密视差图上的操作。这个操作又分为两步：</li>
</ol>
<ul>
<li>视差图上采样。要把上一层视差金字塔的结果用上我总要上采样吧，但是做固定上采样不好玩，我们来搞一个CARAFE[2]
，一种更骚的上采样方法，具有【content-aware】能力，很玄乎吧，这个还好。最玄乎的是它做了一个大concatenation（我很讨厌无端的concat操作，把不相关的信息拼接在一起会让信息失去其原有的物理意义，这是个人粗浅的见解，会在稍后进行说明），对concat的结果进行了几次卷积，得到一个mask（也就是content-aware的权重），通过这个pixel-wise的权重将上一层上采样视差和本层融合。</li>
</ul>
</div>
<p><img src="/2021/09/04/%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%A4%E7%AF%87%E5%8F%8C%E7%9B%AE%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/conv3d.PNG"></p>
<center>
Figure 3. cost regularization
</center>
<h3 id="gradient-flow">2.2 Gradient Flow</h3>
<p>​
我们需要考虑梯度流的问题，也就是说：我到底需要优化谁？我的loss最终作用在哪些单元？在没有看附录之前，就应该思考这样的问题。</p>
<p>​
首先我们发现，这篇文章不是pixel2pixel的匹配，而是特征到特征的匹配（可能深度学习上了就是这样的），特征提取在文章中说的是：</p>
<blockquote>
<p>As shown in Figure 2, we first use <strong><u>U-Net</u></strong> to
obtain deep features Fl on each level l for the stereo matching.</p>
</blockquote>
<p>​ 我当时反应了一下，之前读过一篇做风格迁移的文章（对应博客<a href="https://enigmatisms.github.io/2021/04/21/CNN-Style-Transfer论文复现/">【CNN
Style
Transfer论文复现】</a>，截止到9.5我都还没有填坑），文章直接使用了一个预训练好的VGG-19，固定参数不优化，提取特征。本文是这样吗？并不是，特征提取网络是需要进行优化的。那么与loss直接相关的待优化参数最后除了特征提取网络之外，还有什么吗？</p>
<table>
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;"><img src="/2021/09/04/%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%A4%E7%AF%87%E5%8F%8C%E7%9B%AE%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/part1.PNG"></th>
<th style="text-align: center;"><img src="/2021/09/04/%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%A4%E7%AF%87%E5%8F%8C%E7%9B%AE%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/part2.PNG"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">步骤II</td>
<td style="text-align: center;">步骤I</td>
</tr>
</tbody>
</table>
<p>​
这两个步骤虽然在网络中，但是其参数并不直接根据整个架构对应的输出以及loss进行优化。毕竟：</p>
<ul>
<li>步骤II对应的操作是自监督的，应该完全可以独立训练</li>
<li>步骤I也是可以独立的（看实现），假如使用的方法是独立于输入的传统cost
volume法，那完全可以。否则的话可能会收到U-Net输出的影响，内部的参数也需要参与优化。</li>
</ul>
<p>​ 在附录中，作者主要讨论的是U-Net生成的特征图作为自变量时的求导。</p>
<h3 id="一些问题">2.3 一些问题</h3>
<h4 id="detailed-loss-detection">2.3.1 Detailed Loss Detection</h4>
<p>​
无监督的loss听起来很棒，但是我总感觉作者用学习的方式解决了一个NP-hard的问题（应该是NP-hard），我甚至有点怀疑可行性（虽然我在RM灯条检测里面也这么干过）。</p>
<p>​ 如果需要人工标注lost detail
mask的话，那工作量太大了，作者希望使用这样一个无监督loss，使得两个集合的差异最大：<strong><u>属于lost
detail的特征点集合（A） 与
不属于前一个集合的特征点集合（B）</u></strong>（是一个覆盖）</p>
<p>​
差异体现在：集合A的平均特征误差应该较大（低精度上采样后无法恢复的区域），集合B的平均特征误差小。那么作者使用了这个loss：
<span class="math display">\[
\begin{equation}\label{dld}
\mathcal{L}^{DLD}=|FA_l|-\alpha\frac{\sum_{(h,w)\in FA_l}\Vert F_l(h,
w)-F_{l-1}&#39;(h,w)\Vert_2}{\vert FA_l \vert}
\end{equation}
\]</span> ​ 其中<span class="math inline">\(FA_l\)</span>为特征金字塔第l层的fine-grained（细粒度）特征，<span class="math inline">\(F_{l-1}&#39;\)</span>则是上采样的上一层特征。这个式子非常容易理解，但是...
从一个集合中挑选一个子集使得对于这个集合和子集定义的某个损失最小，感觉就是一个NP-hard的问题，毕竟暴力穷举之外貌似没有别的方法。并且，在这里优化问题遇到的是
<u><strong>分支的处理</strong></u>，我优化的是一个决策？（应不应该认为这个特征属于<span class="math inline">\(FA_l\)</span>），我记得好像TF由于是静态图的缘故不方便设置分支？另一方面，我又觉得解决方案可能类似分类问题，输出是模拟的，但是计算cross
entropy loss的时候转换成了long型（硬的）的index。</p>
<h4 id="sparse-matching">2.3.2 Sparse Matching</h4>
<p>​ 这个想法我觉得还挺不错的。我得到左右视图的lost
details，现在要进行匹配了。由于occlusion存在一定一致性（并且由于存在对极约束），还是可以将lost
details在一个方向左右滑动。那么对于这样的：两个信号滑动求最大匹配的问题，显然可以使用cross
correlation。作者由此产生了一个三维空间的概率volume（注意不是分布，因为这是按照第三个维度也就是disparity归一化的）。
<span class="math display">\[
\begin{align}
&amp;
P_l(h,w,d)=\frac{e^{C_l(h,w,d)-C_l^{max}(h,w)}}{\sum_{d=0}e^{C_l(h,w,d)-C_l^{max}(h,w)}}\\
&amp; C_l(h,w,d)=\text{cross
correlation}(F_{\text{left}}(h,w),F_{\text{right}}(h,w-d))\\
&amp; C_l^{max}(h,w)=\max_d C_l(h,w,d)
\end{align}
\]</span> ​
最后，每个稀疏点的视差就由期望决定了（作者为什么把这个叫做regress？）
<span class="math display">\[
\begin{equation}\label{reg}
\hat{D}_l(h,w)=\sum_{d=0}P_l(h,w,d)\times d
\end{equation}
\]</span></p>
<h4 id="supervised-loss">2.3.3 Supervised Loss</h4>
<p>​ 简单地提一下论文使用的有监督loss。无监督loss在lost detail
detection阶段使用了，用于判定哪些是丢失细节，见公式<span class="math inline">\(\eqref{dld}\)</span>。而计算视差图的过程中，我们有特征提取网络，Fusion网络，底层full
cost volume对应的网络需要训练，这些都是基于disparity真值训练的。</p>
<p>​
多层的disparity就需要用到多层的真值，那么多层真值可以使用降采样来得到。然后作者使用了一系列的smooth
L1 Loss。好玄乎哦，实际上就是Huber Loss。</p>
<hr>
<h2 id="iii.-smd-nets-stereo-mixture-density-networks3">III. SMD-Nets:
Stereo Mixture Density Networks[3]</h2>
<p>​
个人认为这篇文章没有那么魔法，读起来觉得还挺有道理的。最主要的思想就是：使用双模态描述结果。之前读的对比学习相关的文章，里面就提到过不同的模态数的优缺点：</p>
<ul>
<li>单模态：计算十分方便，建模简单，并且也具有广泛的应用范围，但表征能力有限。</li>
<li>完全生成式模型（终极多模态）：表征能力极其强，但是计算量一般都很大（比如对抗网络）</li>
<li>模态数少一些的多模表征：折衷。</li>
</ul>
<p>​ 本文使用双模态描述前景和背景，并且网络结构 /
输入不那么魔法，也具有一定的超分辨率能力（虽然感觉方法有点普通？）。</p>
<p><img src="/2021/09/04/%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%A4%E7%AF%87%E5%8F%8C%E7%9B%AE%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/smd.PNG"></p>
<center>
Figure 4. SMD-Nets的网络结构
</center>
<h3 id="主要思想-1">3.1 主要思想</h3>
<p>​ 主要可以分为以下三步：</p>
<p><span id="quest"></span></p>
<div class="note danger"><ol type="1">
<li>前端使用了一个经典的双目视觉网络作为骨架，用于提取特征。就如Figure
4最左边，先下采样再上采样的典型结构（常用于Semantic/Detection/Mono/Stereo）。我不是特别了解这个网络提取出来的特征是否与原输入图像保持了空间一致性，虽然卷积可能可以做到这一点，但具体是如何保证的【一个特定区域】对应的【特征图元素】一定在特征图对应的位置上？而且看起来，深度学习的引入产生了很多特征-特征匹配的方法。</li>
</ol>
</div>
<p></p>
<div class="note warning"><ol start="2" type="1">
<li>超分辨率：插值操作，插值操作只是为了能够得到任意精度位置的特征向量。个人对于第二步的理解是，作者对于每一个点都计算了双模态分布的参数，形成了一个双模态分布的二维结构（图像）。对每一个特征向量，都过一遍MLP，最后得到五个参数:</li>
</ol>
<ul>
<li><span class="math inline">\((\mu_1,b_1),(\mu_2,b_2)\)</span>是分布的均值（期望）与不确定度</li>
<li><span class="math inline">\(\pi\)</span>是两个模态的选择参数（相当于前景背景mask）</li>
</ul>
</div>
<div class="note info"><ol start="3" type="1">
<li>输出：根据模态选择参数，从两个模态中的均值中选择对应的视差值。</li>
</ol>
</div>
<h3 id="some-points">3.2 Some points</h3>
<p>​
这篇论文我倒是没有什么特别想说的，感觉想法倒是挺简单的（简单不代表我能一下想到）。虽然我个人存在一些疑问，感觉作者也没有解释清楚（要怪就怪神经网络不可解释？）：</p>
<ul>
<li>前景(foreground)与背景(background)的区别在哪？disparity明显很大的叫foreground（虽然我感觉作者就是叫着玩的）？作者更被没有说两个mode的生成方式有何不同。为什么能恰好产生这种，在关键区域有互补性的两个模态呢？又为什么只使用两个模态呢？</li>
<li>当然，这确实可以用不可解释性来说。毕竟像<span class="math inline">\(\pi\)</span>这种学出来的东西，真的就说不清楚其深层次的原理...</li>
</ul>
<p>​
另外，我不知道别的网络是否进行稠密的训练，本文中，网络并不进行稠密的disparity训练（可以说是半稠密？）。首先对生成好的特征图进行采样，对采样得到的（稍微稀疏一些）点进行训练。由于作者需要更多地聚焦于边缘点的处理，所以作者使用了一种不同的采样方法：</p>
<ul>
<li>生成边缘点mask，具体的方式也就是：首先检测深度不连续点（根据4-连通性），对检测结果进行膨胀
<ul>
<li>在边缘点mask内采样一半的稀疏训练点样本</li>
</ul></li>
<li>在全图的非边缘点区域进行均匀的采样，采样得到另一半样本。</li>
</ul>
<p>​
整个框架是有监督的，并且没有金字塔结构。其使用的backbone模型，PSM内部也是有一个大的cost
volume的。</p>
<hr>
<h2 id="iv.-dl立体匹配">IV. DL立体匹配</h2>
<p>​
深度学习用在立体匹配中？知道能用，但是具体的实现是什么样的呢？基于特征向量的匹配的流程具体是什么呢？完全不知道了。所以我在这里补充一篇综述性论文[4]，帮自己补一补领域知识。只不过，这篇文章包含了很多方法，我在此只讨论基础的DL-based方法。</p>
<h3 id="pipeline">4.1 Pipeline</h3>
<p>​ 主要流程仍然大体相同：</p>
<p><img src="/2021/09/04/%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%A4%E7%AF%87%E5%8F%8C%E7%9B%AE%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/flow.PNG"></p>
<center>
Figure 5. 双目配准网络一般的流程
</center>
<p>​
那么典型的几个网络结构，论文也贴心地列了出来（这篇论文真的很适合入门了解行业啊）：</p>
<p><img src="/2021/09/04/%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%A4%E7%AF%87%E5%8F%8C%E7%9B%AE%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/nets.PNG"></p>
<center>
Figure 6. 双目配准网络的一些典型结构
</center>
<p>​
视差图生成网络的训练输入可以通过采样而来，也可以通过直接卷积而来。</p>
<ul>
<li>采样的方法是：在输入图像中均匀“播撒”一些点（对应于一种稀疏的训练方式），切取点以及其领域的信息作为对应视图的输入。如果是有监督的结构，那么就在另一个视图中查找：
<ul>
<li>disparity图真值对应位置的patch（作为正样本）</li>
<li>其他disparity值对应的patch作为负样本</li>
</ul></li>
<li>直接卷积：每个点对应的卷积输出就已经是特征了。但是这种方法如何保证左右特征一致？一种简单的想法就是直接共用完全相同的encoder（孪生网络）。</li>
<li>当然也可以直接跳过特征描述，直接端到端生成一个cost出来</li>
</ul>
<p>​
这种基于DL特征的描述，实际上是对人工描述子的升级，卷积操作对每个点都会有个特异的表征输出，假设我们的卷积就是奇数大小的kernel并且以其中心为anchor，那么在(x,y)位置的卷积显然就会得到以(x,y)为中心的领域特征描述，能保证<a href="#quest">[3.1中(1)里提出问题的解决]</a>。这一环节，我们的目的不是只得到特征（然后神奇海螺：什么也不做），而是使用特征来衡量两个像素位置是否存在关系，比如使用L1或者L2距离来判定特征的相似度，越相似说明两个位置匹配度越高。</p>
<p>​ 根据loss函数可以计算出一个cost volume，为了方便起见，我只讨论3D cost
volume。3D cost volume每一个(x,
y)位置都对应了一串可能匹配的cost，我们需要根据我们选定的策略来计算一个最好的disparity。方法有很多。我确实是开了眼了，学到了，见下一小节。</p>
<h3 id="cost-volume-regularization">4.2 Cost Volume Regularization</h3>
<p>​ 有了cost volume之后，紧接着就要进行<strong><u>cost volume
regularization</u></strong>。但是这是个什么操作，与regularization又是什么关系？</p>
<p>​
我们知道，正则化（regularization）在深度学习中是被用来防止过拟合的，因为引入正则化惩罚之后，原本起伏不平的超平面，会变得平滑。这是因为正则化项要么限制了描述超平面的参数个数，要么限制了其取值，使之描述力下降（不那么活跃）。也就可以认为，正则化项<span class="math inline">\(\approx\)</span>平滑项。</p>
<p>​
巧了，双目视觉通常也有平滑项（虽然我感觉SMD-Nets一定程度上在鄙视平滑假设）。我们希望网络的输出不要那么起伏不平的，一个深度差不多的平面就不要因为噪声而有太大的小范围波动了吧。所以需要施加平滑项，当然还存在一些其他的约束项，比如：</p>
<ul>
<li>(x, y)已知与(x+d, y)完美配上了，那么(x+1, y)
对应的视差必定不可能小于d-1（右视图匹配不交叉）</li>
<li>保证深度不连续边缘锐利性的一些约束项</li>
</ul>
<p>​
那么施加约束项/平滑项就是在做正则化！目的就是优化输出图像，所以叫regularization。一般来说，cost
volume
regularization伴随最终视差图的产生，这是因为regularization之后，full
cost就求出来了啊。当然是选full cost最小的。故可以将cost volume
regularization看作是视差图求解。</p>
<p>​ <img src="/2021/09/04/%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%A4%E7%AF%87%E5%8F%8C%E7%9B%AE%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/agg.PNG"></p>
<center>
Figure 7. 最终disparity的计算
</center>
<p>​ 论文贴心地把几种常用的regularization方法可视化了出来：</p>
<ul>
<li>滢者通吃！（误，在这里简单地cue一下我的女朋友）。谁小选谁。</li>
<li>考虑空域特性：2D卷积，综合空域信息。</li>
<li>考虑不同的disparity上的信息：基于RNN的正则化</li>
<li>3D卷积：全域正则化（这个结构在两篇论文的regularization中都有）</li>
</ul>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] Yao C, Jia Y, Di H, et al. A Decomposition Model for Stereo
Matching[C]//Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition. 2021: 6091-6100.</p>
<p>[2] Wang. Carafe: Content-aware reassembly of features. In
Proceedings of the IEEE International Conference on Computer Vision
(ICCV), 2019</p>
<p>[3] Tosi F, Liao Y, Schmitt C, et al. SMD-Nets: Stereo Mixture
Density Networks[C]//Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition. 2021: 8942-8952.</p>
<p>[4] Laga H, Jospin L V, Boussaid F, et al. A survey on deep learning
techniques for stereo-based depth estimation[J]. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 2020.</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>stereo</tag>
      </tags>
  </entry>
  <entry>
    <title>GPU Architecture Intros</title>
    <url>/2021/09/03/GPU-Architecture-Intros/</url>
    <content><![CDATA[<h1 id="gpu">GPU</h1>
<hr>
<p>​
懂GPU加速必须要懂GPU设计，GPU和CPU太不一样了。之前写CUDA的时候感觉都是瞎写。在开学花个时间补了补，花一天时间（没有实践的那种）看完了加州理工的CS179以及一些附属资料：</p>
<center>
<img src="/2021/09/03/GPU-Architecture-Intros/amd.gif" style="zoom:120%;">
</center>
<center>
Figure 1. 什么？CUDA是Nvidia的？
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-preliminaries">II. Preliminaries</h2>
<h3 id="名词解释">2.1 名词解释</h3>
<h4 id="vertex-与-vertex-shader">Vertex 与 Vertex Shader</h4>
<p>​ 顶点表示了什么，这很好理解，wikipedia一看就懂：</p>
<blockquote>
<p>A vertex (plural vertices) in computer graphics is a data structure
that describes certain attributes, like the position of a point in 2D or
3D space, or multiple points on a surface.</p>
</blockquote>
<p>​
但是，vertex从何而来，为什么会有这个数据结构，其存在的意义是什么？这个貌似没有那种一搜就能明白的解释。对于以上的这几个问题，我的理解是：</p>
<div class="note info"><p>​
顶点可以就是模型数据本身，比如模型就给定了一个需要进行渲染的mesh。或者，给定的是一个更加精细的模型，根据某种采样+生成算法，得到的vertex。注意vertex在意义上就有别于point，point是无空间关联关系的，而vertex是存在邻接结构的。</p>
</div>
<p>​
而节点着色器的职责则是：把原本模型空间中的顶点，转换（transform）到屏幕空间坐标下。根据个人的理解，我觉得相机模型就是一个非常简单的顶点着色器，根据外参内参将世界系下的点转换到二维屏幕上。</p>
<h4 id="primitives-基本图形">Primitives 基本图形</h4>
<p>​
GPU渲染管线用于渲染的最基本图形，比如根据顶点着色器的输出，生成很多小的三角形进行后续处理。一般来说，这些primitive都是不可再分的（atomic），这些基本图形之后会被送到。。。比如，光栅化器（rasterizer）中进行一种采样量化操作（因为屏幕的表示能力受到了分辨率的限制）。</p>
<h4 id="fragment-rasterizer">Fragment &amp; Rasterizer</h4>
<p>​
Fragment可以认为是每个基本图形量化后的结果，也就是一堆没有着色的像素集合。我们的采样量化精细程度就决定了图像的质量，比如说：当我们需要抗锯齿的时候，可以提高rasterizer的采样精细度，并辅助羽化。光栅化则是我们这段时间接触过的内容，光栅化就是一种采样过程，对于不同精度的数据，将其采样到合适的分辨率下。</p>
<center>
<img src="/2021/09/03/GPU-Architecture-Intros/raster.gif" style="zoom:67%;">
</center>
<center>
Figure 2. Top-left triangle rasterization rule[1]
</center>
<p>​
在光栅化过程中，经常遇到的问题就是：锯齿。解决锯齿问题就需要一些亚像素精度的操作。</p>
<p>​
而片段着色器的作用则是：对已经生成的raster图像，进行渲染。比如光照，根据光照模型渲染像素的颜色，或者根据alpha通道信息进行绘制。</p>
<h3 id="pipeline-加速方式">2.2 Pipeline &amp; 加速方式</h3>
<p><img src="/2021/09/03/GPU-Architecture-Intros/pipeline.PNG"></p>
<center>
Figure 3. GPU简化管线示意图
</center>
<p>​
从CPU如何到GPU？可能是需要摒弃一些CPU的设计思想的，毕竟CPU/GPU的功能非常不同，自然就应该对应不同的结构，不同的结构就会引出不同的特性。</p>
<p>​ CPU通常有很多针对一条指令流程优化的方式：</p>
<ul>
<li>多级cache（prefetching），嵌入式课讲过</li>
<li>分支预测（branch），嵌入式也讲过</li>
<li>乱序执行（这个嵌入式课程中没有显式提到，但是实际上存在于分支处理中，比如将一些指令移动位置以填充分支）</li>
</ul>
<p>​
但是这些在GPU中显得不那么重要。GPU的并行任务通常都是：对大量数据做类似的操作，比如Fragment渲染，深度学习。CPU中ALU资源是有限的，每次就只能处理几个输入数据，显然没有办法很好地并行，那么这种需求很可能要求我们需要多个数据处理单元（比如ALU）。如果每个处理单元（比如ALU）都配置多级cache，分支预测等等CPU标配，那么谁来控制芯片的面积？谁来控制不同单元的分支预测？涉及到CPU的一些耗时操作怎么办（比如上下文切换，cache
coherence等等）看看：</p>
<blockquote>
<p>In computer architecture, a branch predictor is a digital circuit
that tries to guess which way a branch (e.g., an if–then–else structure)
will go before this is known definitively. --Wikipedia</p>
</blockquote>
<p>​ 直接复制CPU cores肯定会让GPU变得笨重。所以这些特性可以都砍掉。</p>
<p>​ 针对我们的第一个要求，显然最好的处理方式是：引入SIMD（single
instruction multiple
data）的思想。毕竟GPU最常做的事情就是这个，输入不同，操作相同。那么这就涉及到：</p>
<ul>
<li>多个处理单元fetch/decode/execute同一条指令</li>
<li>多路数据同时输入：取数据不再像CPU处理一样，比如进行像素处理时，一个个位置访问，而是一组组位置访问。有N个处理单元就一次同时访问N个位置，取数据，可以节省大量fetch
data的时间。</li>
</ul>
<p>​ 那么可以认为，CPU是一种<strong><u>标量</u></strong> (literally)
处理器（这里说的标量和 scalar
processor不一样），GPU是一种向量处理器（一次处理一个向量，因为有多个处理单元）。将这些处理单元归为一组，GPU可以有多个这样的组。组间可以遵循流水线设计（避免长时间阻滞带来的吞吐量下降）。</p>
<p>​
当GPU有多个这样的SIMD核可以并行时，可能可以演化为MIMD。实际上有些架构（比如N卡中），使用的是SIMT（multiple
threads），每个线程是独立的，可以存在不同线程不同分支或者是非连续访问的情况。</p>
<h3 id="更多关键词">2.4 更多关键词</h3>
<p>​ 参考加州理工CS179 <a href="http://courses.cms.caltech.edu/cs179/2021_lectures/cs179_2021_lec02.pdf">lecture
2</a> [2]，这里就不赘述了。</p>
<hr>
<h2 id="iii.-gpu存储结构">III. GPU存储结构</h2>
<p>​ GPU（CUDA为例）的存储结构大致如下：</p>
<center>
<img src="/2021/09/03/GPU-Architecture-Intros/structure.PNG" style="zoom:67%;">
</center>
<center>
Figure 4. GPU存储结构
</center>
<p>​
如果要说这几个不同的存储空间的特点，网上应该有很多介绍了。无非就是：</p>
<ul>
<li>constant/texture是可以由host修改的不可变内存，被cache掉了</li>
<li>global memory是host device可以共同修改的，最慢的内存，shared
memory应该多用，因为通常很快，shared memory是同一个block的</li>
</ul>
<p>​
之前太年轻，写CUDA程序的时候也没有特别去学过CUDA的内存管理，疯狂使用全局内存，应该是会很慢的吧？global
memory倒是没有太多可以说的，接下来主要讲一下shared memory吧。</p>
<h3 id="shared-memory">3.1 Shared memory</h3>
<p>​ shared memory是一种存取很快的内存，硬件实现与L1
cache是一样的（那么可以体会一下其速度级别）。有些地方说，shared
memory存取只需要1个周期，有些材料（比如加州理工的PPT）说是5ns（这也很快，毕竟我记得GPU的时钟一般会比CPU慢一些？emmm，说GPU是低频高吞吐率）。</p>
<p>​ 但是shared memory有两个限制：</p>
<ul>
<li>shared memory物理实现与L1 cache相同，这意味着shared
memory不可能太大（SRAM很贵），对于一个block中的warps来说，所有warps使用的共享内存不能超过每个block所具有的内存。这就需要一定的精巧设计：充分利用shared
memory使得尽可能多的warps工作。</li>
<li><strong><u>Bank conflict，这是一个有趣的问题。</u></strong>Bank
conflict很像在嵌入式课程中学到的cache冲突问题，cache频繁冲突会引起cache内容的频繁擦写，由于cache
coherence，导致多个存储器需要被修改，这很不好。而Bank
conflict产生则是引起读写操作的并行化。</li>
</ul>
<p>​ Bank conflict的定义：</p>
<blockquote>
<p>A <strong>bank conflict</strong> occurs when 2 threads in a warp
access different elements in the same bank. Shared memory is setup as 32
<strong>banks</strong></p>
</blockquote>
<p>​ 根据stackoverflow上一个佬外“可视化”的bank（或者shared
memory分块），加入我们假设管理内存的单元是4字节，那么：</p>
<table>
<thead>
<tr>
<th style="text-align: center;">0-3</th>
<th style="text-align: center;">4-7</th>
<th style="text-align: center;">...</th>
<th style="text-align: center;">120-123</th>
<th style="text-align: center;">124-127</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">data</td>
<td style="text-align: center;">data</td>
<td style="text-align: center;">...</td>
<td style="text-align: center;">data</td>
<td style="text-align: center;">data</td>
</tr>
<tr>
<td style="text-align: center;">data</td>
<td style="text-align: center;">data</td>
<td style="text-align: center;">...</td>
<td style="text-align: center;">data</td>
<td style="text-align: center;">data</td>
</tr>
<tr>
<td style="text-align: center;">...</td>
<td style="text-align: center;">...</td>
<td style="text-align: center;">...</td>
<td style="text-align: center;">...</td>
<td style="text-align: center;">...</td>
</tr>
</tbody>
</table>
<p>​
也就是说，这是一个“循环索引”的存储空间。连续的字节流会直接在不同bank之间切换，到末尾bank就会循环切回到第一个bank上。那么，当32个线程（一个warp）所需的内存是线性连续的，那么此时就不会出现两个线程同时访问一个bank的情况。</p>
<p>​
假设我们的bank设置就是按照如上方式进行的，并且假设线程数量为32。那么当每个线程访问的步长为1是，没有bank
conflict。</p>
<p>​
当步长为2时，显然，只有一半的bank被访问，16个线程之后就会循环回到第一个bank。那么此时会引发两路冲突的bank
conflict。</p>
<p>​ 同理，步长为4时，会引发4路冲突...</p>
<p>​ 当步长为32时。有两种说法：</p>
<ul>
<li>shared memory 也存在broadcast机制，多路访问我直接广播。</li>
<li>32路冲突，这种情况完全串行，需要进行+1步长的padding。</li>
</ul>
<p>​ 当前的GPU对于bank
conflict基本上都更友好，遇到多路同时访问时，可以采用多播(multicast)或者广播策略。这是global
memory所没有的。</p>
<h3 id="reduction-example-sum">3.2 Reduction Example: Sum</h3>
<p>​ CS179的lecture
7讲了两个很有意思的例子。第一个就是：并行时我如何对一个数组进行求和？</p>
<p>​
显然，要利用并行计算的资源，两两求和的过程不能顺序进行（否则就是串行）。显然，求和过程可以分层进行，比如数组长度为32，第一层我就并行执行16个两两相加，保存，同步。第二层就执行8个...</p>
<p>​ 这例子看起来很简单嘛。都能想出来怎么做呢，但实际上这里全是坑。</p>
<p><img src="/2021/09/03/GPU-Architecture-Intros/bin1.PNG"></p>
<center>
Figure 5. 直接二分树状分解并行[3]
</center>
<p>​ 看起来不错。但是会遇上一个巨大的问题，warp
divergence。显然，上图中我们实际使用了16个线程（奇数id线程什么都没做，但是由于处在同一个warp中，还是要执行NOP）。这非常不好，意味着我们每次相加操作之后，还有一段时间的NOP。（很奇怪，为什么可以使用数量为16的warp）</p>
<p>​ 既然这样，那我们可以：</p>
<p><img src="/2021/09/03/GPU-Architecture-Intros/bin2.PNG"></p>
<center>
Figure 6. 连续线程并行[3]
</center>
<p>​
虽然我觉得这里有点奇怪，我用了一个大小为8的warp，之后又用了大小为4的warp...
并且bank的组织和我每次使用的warp大小是一致的。</p>
<p>​ 这样确实可以避免warp divergence，但是又会引起新的问题：bank
conflict。由于第一次我使用了一个大小为8的block（属实理解不了这个组织，所以我查了一下为什么，列在了3.2末尾），那么bank根据线程数组织：8个bank，啊哦，这就是一个步长为2的2路冲突。因为此时，bank从10这个位置开始，到3，5（5
exactly）位置结束。后面是循环回到第一个bank存储。</p>
<p>​ 第二个循环中，4线程的block是4 banks，那么直接导致了4路冲突...
依此类推。</p>
<p><img src="/2021/09/03/GPU-Architecture-Intros/bin3.PNG"></p>
<center>
Figure 7. 序列寻址并行[3]
</center>
<p>​ 这样就完全好了。</p>
<p>​ 而关于：“What happens when threads per block is less than
32”问题，我一直觉得这里是存在warp divergence的。来自这个回答 <a href="https://stackoverflow.com/questions/40112959/what-will-happen-if-the-number-of-threads-in-a-warp-are-less-than-32">stackoverflow/What
will happen if the number of threads in a warp are less than 32?</a></p>
<blockquote>
<p>Regarding warps, it's important to remember that warp and their size
is a property of the hardware. Warps are a grouping of hardware threads
that execute the same instruction (these days) every cycle. In other
words, the size width indicates the SIMD-style execution width,
something that the programmer can not change. In CUDA you launch blocks
of threads which, when mapped to the hardware, get <strong><u>executed
in warp-sized bunches</u></strong>. If you start blocks with thread
count that is not divisible by the warp size, the hardware will simply
execute the last warp with some of the threads "<strong><u>masked
out</u></strong>"</p>
</blockquote>
<p>​
CUDA官方的论坛上，技术大佬貌似没有看懂提问者的问题，提问者想问（就跟我的问题一致）：</p>
<blockquote>
<p>I know that you can specify a block size that is less than 32, but I
expect that will make part of the <strong><u>warp idle</u></strong>, and
reduce resource utilization.</p>
</blockquote>
<p>​ 那。。。这些不就是warp
divergence吗？除非，GPU做了一些实际的优化，对于一个warp中没有用到的线程直接mask掉，那么第一种实现又有何不可呢？感觉要么就是自己没理解透，再要么就是自己没理解透，最后要么就是
这个例子就是有问题，只能强行解释。</p>
<h3 id="parallelism-example-quick-sort">3.3 Parallelism Example: Quick
sort</h3>
<p>​ 这是另一个很有趣的例子：如何在GPU上并行快排？</p>
<p>​
首先，老师们把这个问题拆解成了两部分。第一部分是：根据条件，选择出符合要求的数组元素形成新的数组。比如：[4,
5, 2, 5, 8, 9, 1, 0, 3, 7] 选出大于4的部分：[5, 5, 8, 9, 7]。</p>
<p>​
GPU能并行做这个事情吗？回答是可以的，但是不是一步并行的，因为这种往数组中
<strong><u>保序</u></strong>
添加是不好做的。这样一个任务被拆解为三个串行部分：</p>
<ul>
<li>True / False
标签：创建一个等大小的flag数组来指示每个元素是否满足要求，满足为1，不满足为0，这个可以全并行。比如例子中[0,
1, 0, 1, 1, 1, 0, 0, 0, 1]</li>
<li>prefix sum，讲flag数组prefix sum求和：[0, 1, 1, 2, 3, 4, 4, 4, 4,
5]，这也是可以并行（分级）的（数组记作prefix）</li>
<li>最后：并行访问flag数组以及prefix sum数组，如果flag[i] =
1，那么原数组[i]保存在新数组的prefix[i]-1位置。也是可以全并行的</li>
</ul>
<p>​
这件事做完之后就是标准的快排流程了。选pivot，甚至可以在GPU里递归。</p>
<h3 id="practical-slides">3.4 Practical slides</h3>
<p>​
很有用，总结的也很好，我没有产生自己的新理解，就直接把这些slides[6]放上来当作保存了。</p>
<p><img src="/2021/09/03/GPU-Architecture-Intros/2021-09-05%20(1).png"></p>
<p><img src="/2021/09/03/GPU-Architecture-Intros/2021-09-05%20(2).png"></p>
<p><img src="/2021/09/03/GPU-Architecture-Intros/2021-09-05.png"></p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://en.wikipedia.org/wiki/Rasterisation">Wikipedia -
Rasterization</a></p>
<p>[2] <a href="http://courses.cms.caltech.edu/cs179/2021_lectures/cs179_2021_lec02.pdf">CalTech
CS 179 lecture 2</a></p>
<p>[3] <a href="http://courses.cms.caltech.edu/cs179/2021_lectures/cs179_2021_lec07.pdf">CalTech
CS 179 lecture 7</a></p>
<p>[4] <a href="http://courses.cms.caltech.edu/cs179/">California Tech
CS179</a></p>
<p>[5] <a href="https://www.cs.cmu.edu/afs/cs/academic/class/15462-f11/www/lec_slides/lec19.pdf">CMU/How
a GPU works</a></p>
<p>[6] <a href="https://www.techylib.com/en/view/sizzlepicture/introduction_to_nvidia_cuda">Introduction
to Nvidia CUDA</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>GPU</tag>
      </tags>
  </entry>
  <entry>
    <title>Contrastive Learning Intros</title>
    <url>/2021/08/29/Contrastive-Learning-Intros/</url>
    <content><![CDATA[<h1 id="cl">CL</h1>
<hr>
<h2 id="i.-introduction">I. Introduction</h2>
<p>​
根据个人粗浅的了解，有监督的简单图像分类在高一些奇怪的东西，比如我觉得Inception就很奇怪，强行变宽，更不要说它的改进了。新的网络结构感觉就是，没什么理论道理，全是
empirical
xxxx的，让人看得一头雾水，做这样的浅层次理解或者是复现也没有什么太大意思，只能让Pytorch技术更加熟练罢了，没有别的作用。为了寻找新的有趣理论，我入门了一下无监督学习（入门水准），这个领域里面有些很有趣的理论以及思想值得借鉴。本文在回顾了一下一些概率论理论之后，内容主要有：</p>
<ul>
<li>Contrastive Predictive Coding (CPC) 论文的理解</li>
<li>何恺明大神（同样姓何为何我这么菜）Momentum Contrast (MoCo)
论文的理解</li>
<li>MoCo实现以及与基于ResNet思想的baseline模型比较（实现见：<a href="https://github.com/Enigmatisms/MoCo">🔗Enigmatisms/MoCo</a>）</li>
</ul>
<span id="more"></span>
<hr>
<h2 id="ii.-两个曾经的sota">II. 两个曾经的SOTA</h2>
<h3 id="nce">2.1 NCE？</h3>
<p>​
在之前我们已经介绍了CL的工作原理：对输入数据进行encode，在某一个高维metric
space下对两个输入encode后的特征向量进行相似度比较。给定正负样本（正负样本的获得是无监督的）后，我们需要通过训练集来优化我们的encoder，使得经过encode之后，原空间下就相似的样本能在变换后也十分相似（表现在内积上）。那么这就要求我们使用一个loss来优化encoder，论文中使用的是InfoNCE。</p>
<div class="note warning"><p><strong><u>注意，NCE不是 negative cross
entropy！（这是开始时本人认为的东西）</u></strong>。但是既然那么有缘，还是复习一下NCE相关的知识。</p>
</div>
<p>​
首先简单地回忆一下交叉熵与KL散度（长时间不用就容易忘），首先是信息熵（与最小编码有关）
<span class="math display">\[
\begin{equation}\label{ent}
H(x)=-\sum p(x)\log\left(p(x)\right)
\end{equation}
\]</span> ​ 而KL散度的定义是： <span class="math display">\[
\begin{equation}\label{kl}
D_{KL}(P||Q)=\sum P(x)\log\frac{P(x)}{Q(x)}
\end{equation}
\]</span> ​
在之前的一些博文中我们分析过，KL散度是用来衡量两个分布的近似程度的。</p>
<div class="note info"><p>​ 原始的信息论问题是：对于两个不同概率分布的字母表P,
Q，如果已经在Q上计算出了最优编码，那么只要字母表P的分布越接近Q，那么编码整个字母表P所需的平均信息就越接近Q的理论最小值。显然，这个问题的推广就是衡量两个分布的近似性。</p>
</div>
<p>​ 而交叉熵可以用KL散度来定义（Wiki上说的）： <span class="math display">\[
\begin{equation}\label{ce}
\text{CE}(x)=H(p)+D_{KL}(p||q)=-\sum P(x)\log{Q(x)}
\end{equation}
\]</span> ​ 那么请问此式的意义应该如何解读？由于<span class="math inline">\(P(x),Q(x)\)</span>都是概率分布，越接近1则<span class="math inline">\(-\log
f(x)\)</span>越小，那么以下两种极端情况可以定性解释这个loss的正确性：</p>
<p><img src="/2021/08/29/Contrastive-Learning-Intros/1.PNG"></p>
<p>​ 如果如上左图，两个分布相差较大，那么会有这样的情况：<span class="math inline">\(-\log Q(x)\)</span>较大时（也就是<span class="math inline">\(Q(x)\)</span>较小），<span class="math inline">\(P(x)\)</span>恰好较大，相当于对大值，加大权重。那么最后的loss很大。如果分布较为相似，那么则相反，对大值加小权，对小值加大权，这样得到的loss很小，也就直观上说明了Cross
Entropy的作用方式。而二分类中，交叉熵的写法如下： <span class="math display">\[
\begin{equation}\label{cel}
\text{CEL}(x)=-(y\log(p)+(1-y)\log(1-p))
\end{equation}
\]</span> ​
为什么会是这样的呢？显然，二分类情况下，只有错分才会有loss。根据交叉熵表达式<span class="math inline">\(\eqref{ce}\)</span>，假定<span class="math inline">\(P(x)\)</span>是真实分布，<span class="math inline">\(Q(x)\)</span>是估计分布。</p>
<p>​
讲完了CE，要来讲讲真正的NCE与InfoNCE是什么了，在这里我只简要说说，因为我也是查出来的（精力有限，不能过分地递归学习），知乎上有篇文章讲得还行[1]。在这个文章中，作者开始就从NLP切入，我觉得这个切入点还不错，因为NLP中很多问题都是和序列有关的，于是存在这种：context，通过context来进行推断的语言模型之类的东西。那么InfoNCE的作用原理是什么？首先给出公式：
<span class="math display">\[
\begin{equation}\label{infonce}
L_q=-\log\frac{\exp(q\cdot k_{+}/\tau)}{\sum_{i=0}^K\exp{(q\cdot
k_i/\tau})}
\end{equation}
\]</span> ​ 其中，<span class="math inline">\(k_+\)</span>是与query <span class="math inline">\(q\)</span> 能够match的正sample
key。其余的都是负sample key。可以发现这种 Q K V
设计还是非常普遍的，对每一个需要使用的value，都存在一个对应的key，以应对不同query，虽然在CL问题中没有显式的value，因为value就是key。</p>
<p>​ 那么上式就是一个负对数表达，因为概率越小
loss越大。在MoCo中，个人的理解是：由于MoCo的queue以及momentum
update设计，使得key
dictionary相对不变，提供的key相对稳定，在假设key正确的情况下，需要找到一个好的encoder参数<span class="math inline">\(f_q\)</span>使得产生的<span class="math inline">\(q\)</span>能够与其中一个key完成匹配。不过这个<span class="math inline">\(k_{+}\)</span>的选取倒是没有说过。</p>
<h3 id="infonce-in-cpc">2.2 InfoNCE in CPC</h3>
<p>​
CPC[3]论文中明确定义了InfoNCE（应该是首次出现）。这篇文章的理论部分更加清楚，并且用到了一些概率论知识，我重点理解和推导一下。首先需要搞清楚的是：什么是context，关于context，CPC论文中说了它具体的产生：</p>
<blockquote>
<p>Next, an autoregressive model gar summarizes all z≤t in the latent
space and produces a context latent representation ct = gar(z≤t).</p>
</blockquote>
<p>​
那么可以认为，context实际上就是对一个序列信息（或者有顺序关联性的信息），前述信息的一个提炼，相当于提供了一个背景。CPC后文中提到的使用上下文指导的prediction，可以佐证这样的理解：context信息就是生成对应prediction的背景信息，只有给定背景，predict才不会漫无目的地乱猜。于是才会有两种不同的概率：</p>
<ul>
<li>条件概率<span class="math inline">\(P(x_{t+k}|c_t)\)</span>，<span class="math inline">\(c_t\)</span>可以认为是截止到t时刻的上下文信息，<span class="math inline">\(x_{t+k}\)</span>是一个正样本（为什么？等会儿说）（prediction），或者就如论文自己说的：理解成一个生成式模型，根据latent
vector <span class="math inline">\(c_t\)</span>来生成prediction的一个分布模型</li>
<li>直接概率<span class="math inline">\(P(x_{t+k})\)</span>则是被预测量的分布，是我们想知道的那个分布吗？并不是这样理解的，论文中自己说到了：</li>
</ul>
<blockquote>
<p>N-1 negative samples from the ’proposal’ distribution <span class="math inline">\(p(x_{t+k})\)</span></p>
</blockquote>
<p>​ 这个<span class="math inline">\(P(x_{t+k})\)</span>就是我们随机采样的
<u><strong>噪声建议分布</strong></u>。</p>
<p>​ 当时觉得，诶有点似曾相识。当我看到论文中写到importance
sampling以及"proposal
distribution"的时候我感觉，坏了，开始有点像粒子滤波了。那么可以结合起来理解，只需要简单回顾一下重要性采样即可。</p>
<div class="note success"><p>回顾一下重要性采样，也就是“建议分布 (proposal)
”如何转向“目标分布”</p>
</div>
<p>​ 假设我们需要计算关于<span class="math inline">\(f(x)\)</span>的某个积分（比如期望），但是要么<span class="math inline">\(f(x)\)</span> 是高维复杂分布，要么<span class="math inline">\(f(x)\)</span>难以积分，总之就是不方便从此分布中直接采样，而同时我们又有另一个简单的分布<span class="math inline">\(g(x)\)</span>，那么有： <span class="math display">\[
\begin{equation}\label{imp}
\int f(x)dx=\int\frac{f(x)}{g(x)}g(x)dx
\end{equation}
\]</span> ​ 相当于是：我们在求<span class="math inline">\(g(x)\)</span>的某个积分，对应的随机变量函数是<span class="math inline">\(f(x)/g(x)\)</span>，在粒子滤波中是有相应应用的。那么<span class="math inline">\(f(x)/g(x)\)</span>看起来还是和<span class="math inline">\(f(x)\)</span>有关，是不是也很难求呢？在粒子滤波里面我们已经说明了，这个值并不难求，<span class="math inline">\(f(x)/g(x)\)</span>相当于对建议分布<span class="math inline">\(g(x)\)</span>的一个加权因子，这个加权因子由<u><strong>建议分布和目标分布的一致性</strong></u>决定，在localization问题中，我们通过粒子在对应位置模拟的scan与实际scan的相似度估计出了这个值，粒子滤波妙就妙在这里。我不需要知道任何与<span class="math inline">\(f(x)\)</span>有关的计算公式，我也可以巧妙地设计加权因子求出与<span class="math inline">\(f(x)\)</span>相关的值。</p>
<p>​ 而在CPC论文中，作者希望的应该是最大化<span class="math inline">\(x_{t+k}\)</span>与上下文<span class="math inline">\(c_t\)</span>的互信息： <span class="math display">\[
\begin{equation}\label{info}
I(x,c)=\sum_{x,c}p(x,c)\log\frac{p(x|c)}{p(x)}
\end{equation}
\]</span> ​ 作者显式地去建模<span class="math inline">\(p(x|c)/p(x)\)</span>，并且作者使用的这个比值不一定需要有归一化属性，只需要建模一个函数<span class="math inline">\(f(x)\)</span>与<span class="math inline">\(p(x|c)/p(x)\)</span>成正比即可。关于公式<span class="math inline">\(\eqref{info}\)</span>，作者自己是这么说的：</p>
<blockquote>
<p>By using a density ratio <span class="math inline">\(f(x_{t+k},c)\)</span> and inferring $ {z_{t+k}}$
with an encoder, we relieve the model from modeling the <strong><u>high
dimensional distribution</u></strong> <span class="math inline">\(x_{t+k}\)</span>. Although we cannot evaluate p(x)
or p(x|c) directly, we can use samples from these distributions,
allowing us to use techniques such as Noise-Contrastive Estimation and
<u><strong>Importance Sampling</strong></u> that are based on comparing
the target value with randomly sampled negative values.</p>
</blockquote>
<p>​
确实，作者没有用生成式模型去直接建模概率分布，而是使用类似重要性采样的方式去保证互信息可以得到尽可能大的值。</p>
<h3 id="cpcmoco的基本思想">2.3 CPC/MoCo的基本思想</h3>
<p>​
是啊，理论很妙，是啊。。。但是？他们用这些理论在干什么来着？推了那么久公式，我们仿佛忘记了他们的目标究竟是什么。注意CPC中使用了NCE（<strong><u>Noise
Contrastive</u></strong>
Estimation），并且也要记住，这种<strong><u>无监督的</u></strong>对比学习方法核心就在于【对比】。那么和谁对比？<strong><u>噪声分布</u></strong>的数据对比，所以会有NCE。</p>
<ul>
<li><span class="math inline">\(P(x_{t+k}|c_t)\)</span>是根据上下文进行的采样，采样得到的结果就是正样本</li>
<li><span class="math inline">\(P(x_{t+k})\)</span>是负样本的来源分布</li>
</ul>
<p>​
最大化正样本和负样本之间的互信息（衡量两个随机变量的独立性，或者说观察其中一个变量可以得到另一个变量的信息）。这里是在最大化<span class="math inline">\(x_{t+k}\)</span>与<span class="math inline">\(c_t\)</span>这两个随机变量的互信息，我们希望，根据上下文信息<span class="math inline">\(c_t\)</span>就能很好地对<span class="math inline">\(x_{t+k}\)</span>进行预测。但是在对比学习里面，预测并不是我们的目的。个人认为，对比学习的目的应该是：</p>
<div class="note primary"><p>​
为了更好地区分正负样本，需要一个特征向量提取器，将所有输入映射为某个metric
space中的一些向量。将这些向量用在下游任务上，比如用一个简单的MLP接受CL输出的向量的输出进行分类。（我在写这个的时候，我还完全没有实现过，并且也没有看到两篇论文的实验部分）。</p>
</div>
<p>​ 为了实现以上目的，两篇论文使用了不同的方法。</p>
<h4 id="cpc总体思想">2.3.1 CPC总体思想</h4>
<p>​ CPC最后希望生成encoder或者autoregressive
model，来接收一个数据或者是一个数据序列，生成高维表征。CPC对于InfoNCE的优化，实际上是在优化一个交叉熵函数（二分类），由于二分类的交叉熵函数可以被写为：</p>
<p><span class="math display">\[
\begin{equation}\label{infonce2}
p(d=i|X,c_t)=\frac{p(x_i|c_t)\prod_{l\neq i}p(x_l)}{\sum_{j=1}^N
p(x_j|c_t)\prod_{l\neq j}p(x_l)}
\end{equation}
\]</span> ​ <span class="math inline">\(p(x_i|c_t)\prod_{l\neq
i}p(x_l)\)</span>表示了当<span class="math inline">\(x_i\)</span>是从正样本的上下文条件分布中采样得到，而其他的<span class="math inline">\(x_j\)</span>都是噪声采样时的概率。上式的所有连乘中均缺少本<span class="math inline">\(p(x_i)\)</span>，于是可以很容易写成<span class="math inline">\({p(x|c)}/{p(x)}\)</span>的形式。写成这个形式就可以使用CPC中对这个比值的建模了。总之也是构建encoder，encoder最终输出<span class="math inline">\(f(x_{t+k},c_t)\)</span>而中间产生的变量<span class="math inline">\(z_t\)</span>（隐变量）可以拿去用。</p>
<h4 id="moco总体思想">2.3.2 MoCo总体思想</h4>
<p>​
对于CPC而言，其encoder每个minibatch都会更新，变化很快，可能就是属于MoCo论文中三种分类的第一种。</p>
<p><img src="/2021/08/29/Contrastive-Learning-Intros/2.PNG" style="zoom: 50%;"></p>
<center>
Figure 2. MoCo论文中对CL结构的三种分类
</center>
<p>​ 为了避免end2end造成的不稳定性（没有一致性），MoCo的key
encoder相当于是在query encoder上做了一个指数平均（低通滤波），使得key
encoder的参数变化很平滑。使得更新具有一致性。MoCo其他方面的基本思想与CPC也类似：</p>
<ul>
<li>对一个batch中的每一张图片，自身的增强为正样本，其他图片的增强为负样本</li>
<li>优化InfoNCE定义的函数：使得正样本最能被正确区分出来</li>
<li>使用query encoder的参数缓慢更新key encoder，并且key
encoder不参与反向传播</li>
</ul>
<hr>
<h2 id="iii.-实现---moco">III. 实现 - MoCo</h2>
<p>​ Momentum contrast 的实现非常简单，论文中也提供了pseudo
code，所以在实现过程中并没有遇到什么十分困难的问题。我倒是在训练过程中遇上了一些问题。首先，我实现了一个Encoder（轻量级的具有一些Residual
Blocks的网络），结构大概是这样的：</p>
<p><img src="/2021/08/29/Contrastive-Learning-Intros/3.PNG"></p>
<center>
Figure 3. Encoder网络
</center>
<p>​
因为我料到我可能跑不动论文里说的ResNet50以及ImageNet的巨大数据集，所以我针对CIFAR10设计了一个无监督pretext
task。本来就是打算用这个网络结构当encoder来跑MoCo，但是发现，这个网络会使得loss一直卡在一个值上不动（极其长的时间，长到我没有耐心等待）并且波动很小。我怀疑这不能成功地训练，所以用这个网络直接做了一个Baseline训练了一下，emmm，结果很不错：大约96%的测试集准确率，虽然我不知道这是怎么算出超过1来的。不过训练集的准确率有时甚至可以达到1.00，说明这个网络还是有能力做好分类的。</p>
<p><img src="/2021/08/29/Contrastive-Learning-Intros/4.PNG"></p>
<center>
Figure 4. 简单ResNet结构的Baseline
</center>
<p>​ 我最后因为受不了垃圾MX150显卡，跑去租了一个云电脑。很爽啊，推荐<a href="http://gpu.ai-galaxy.cn/console">【智星云】</a>✨。租了一个这玩意：</p>
<p><img src="/2021/08/29/Contrastive-Learning-Intros/5.PNG"></p>
<p>​
3.5元1h，不知道算不算便宜。我知道这个设备肯定能跑更强的网络，于是用torchvision内置的ResNet18（没有预训练）+一个从1000到128的ReLU
FC层，训练了200个epochs，batch
size为100。确实还挺快的，1秒多一个batch，要我的渣机跑可能得10s一个batch。训练的Loss结果如下。这个loss就比较符合预期了。</p>
<p><img src="/2021/08/29/Contrastive-Learning-Intros/6.PNG"></p>
<center>
Figure 5. ResNet18 MoCo Encoder loss训练成果
</center>
<p>​
随后，使用这个训练好的Encoder，固定参数进行下游任务：有监督的MLP分类训练。MLP结构是128-&gt;64-&gt;64-&gt;32-&gt;10。结果挺
拉的💢，完全比不上Baseline，不知道为什么，个人觉得可能有几个tricks没用：</p>
<ul>
<li>loss是单向的，也就是说，生成出的q就当q用，k就当k用，只存k不存q，虽然q，k是不同的两次transform，但是没有做反向的loss</li>
<li>Shuffle BN，整个resnet内部都使用了BN，作者说直接使用BN是不好的</li>
<li>反正最后的结果也就是50%的样子，太拉了。</li>
</ul>
<p><img src="/2021/08/29/Contrastive-Learning-Intros/7.PNG"></p>
<center>
Figure 5. MLP 有监督evaluation 45 epochs batch_size 50
</center>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://zhuanlan.zhihu.com/p/334772391">Noise
Contrastive Estimation 前世今生——从 NCE 到 InfoNCE</a></p>
<p>[2] <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html">He
K, Fan H, Wu Y, et al. Momentum contrast for unsupervised visual
representation learning[C]//Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition. 2020: 9729-9738.</a></p>
<p>[3] <a href="https://arxiv.org/pdf/1807.03748.pdf?fbclid=IwAR2G_jEkb54YSIvN0uY7JbW9kfhogUq9KhKrmHuXPi34KYOE8L5LD1RGPTo">Oord
A, Li Y, Vinyals O. Representation learning with contrastive predictive
coding[J]. arXiv preprint arXiv:1807.03748, 2018.</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>无监督</tag>
      </tags>
  </entry>
  <entry>
    <title>2D LiDAR Simulator Release Notice</title>
    <url>/2021/08/28/2D-LiDAR-Simulator-Release-Notice/</url>
    <content><![CDATA[<h1 id="d-lidar-simulator-v-1.0">2D LiDAR Simulator V 1.0</h1>
<hr>
<p>2D LiDAR Simulator V 1.0🎇 is built upon the repository🎉🎉: <a href>Github🔗: Enigamtisms/Volume2D</a>, which is, recently, updated.
This simulator contains:</p>
<ul>
<li><strong><u>map editor</u></strong>🎛 (with which you can build your
own map),</li>
<li><strong><u>ROS integration</u></strong>🚀:
<ul>
<li>rosbag generation without publishing</li>
<li>rviz visualization for LaserScan, tf, Odometry (perturbed)</li>
<li>Direct message publishing</li>
</ul></li>
<li><strong><u>Easy-to-use</u></strong>👌 roslaunch <strong><u>parameter
setting</u></strong>🗝 for simulated LiDAR and other perimeter
settings.</li>
<li>Fluent opencv-based k<strong><u>eyboard / mouse
control</u></strong>⌨🖱 with <strong><u>high FPS</u></strong>⏲,
visualizing free space and scan.</li>
</ul>
<p>Some demo pictures are shown as follows:</p>
<p><img src="/2021/08/28/2D-LiDAR-Simulator-Release-Notice/1.png"></p>
<p><img src="/2021/08/28/2D-LiDAR-Simulator-Release-Notice/2.png"></p>
<span id="more"></span>
<hr>
<h2 id="dependencies">Dependencies</h2>
<p>The implementations are done in Ubuntu 18.04, under some of the key
libraries:</p>
<table>
<thead>
<tr>
<th>Library name</th>
<th>Version</th>
</tr>
</thead>
<tbody>
<tr>
<td>ROS</td>
<td>Melodic (for Ubuntu 18.04)</td>
</tr>
<tr>
<td>OpenCV</td>
<td>3.x.x or above</td>
</tr>
<tr>
<td>Eigen</td>
<td>Usually bond with ROS</td>
</tr>
</tbody>
</table>
<p>For compilation, C++ 17 standards are recommended.</p>
<hr>
<h2 id="download-compile">Download &amp; Compile</h2>
<p>In the repository <a href="https://github.com/Enigmatisms/LiDARSim2D">Enigmatisms/LiDAR2DSim</a>,
click clone would suffice.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone git@github.com:Enigmatisms/LiDARSim2D.git</span><br><span class="line">cd LiDARSim2D</span><br></pre></td></tr></table></figure>
<p>Usually, for a ROS package we can compile the code via
<code>catkin_make</code>. Yet, sometimes we want to compile A debug
version, i.e. <code>-DCMAKE_BUILD_TYPE=DEBUG</code> and a release
version at the same time for debugging convenience, therefore,
<code>catkin_make</code> might not be quick to use. I have written a
shell script named <code>make.sh</code> in the root directory, you can
thereby run:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo chmod 777 ./make.sh</span><br><span class="line">./make.sh &lt;thread num for compilation&gt; &lt;if not empty, DCMAKE_BUILD_TYPE=DEBUG&gt;</span><br></pre></td></tr></table></figure>
<p>This script receives two params (the second one is optional). The
former one declares the number of thread for compilation and the latter
one is for debug mode specification. <code>make.sh</code> is simply an
encapsulation of <code>catkin_make</code>.</p>
<p>Notice that if debug mode is on, cmake files will be output to folder
<code>build_debug</code>, <code>devel</code> thereby contains the
executable file of the most recent compilation (regardless of
compilation mode <code>DCMAKE_BUILD_TYPE</code>)</p>
<hr>
<h2 id="run">Run</h2>
<p>Before run any of the code, make sure to:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$ </span><span class="language-bash">~/LiDAR2DSim: <span class="built_in">source</span> devel/setup.bash</span></span><br></pre></td></tr></table></figure>
<p>Otherwise, ROS package <code>lidar_sim</code> will not be found.</p>
<h3 id="the-editor">1. The Editor</h3>
<p>​ Map editor is for the people who want to create their own maps.
Run:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">roslaunch lidar_sim editor.launch</span><br></pre></td></tr></table></figure>
<p>​ You can find the param settings in
<code>src/lidar_sim/launch/editor.launch</code></p>
<ul>
<li>map_name: specified output file name in folder <code>maps</code> (
<code>maps</code> is in the root directory)</li>
</ul>
<p>​ There are some other things to be noticed:</p>
<ul>
<li>The outer boundaries are given (30-pixel-thin), therefore don't draw
anything in the border.</li>
<li>Objects (Obstacles) are <strong>directional</strong> (all the points
of each any one of the obstacles should be drawn in a anti-clockwise
way)</li>
<li><strong><u>Press left button of the mouse</u></strong> to add a new
point.</li>
<li><strong><u>Press <code>E</code></u></strong> if one obstacle is
drawn, and it will automatically enclose itself.</li>
<li><strong><u>Press <code>S</code></u></strong> to save the map and
quit.</li>
<li><strong><u>Press <code>P</code></u></strong> to pop the points
added, if the new points are empty, the enclosed objects will be
popped.</li>
<li><strong><u>Press <code>ESC</code></u></strong> to exit without
saving the map.</li>
</ul>
<h3 id="particle-filter">2. Particle filter</h3>
<p>This repository is once a repo for <strong><u>Particle
filter</u></strong>, I implemented one simple particle filter for
localization purposes. Therefore you can play with it.</p>
<p>This particle filter includes a <strong>2D LiDAR simulator</strong>,
which is based on the <strong>Volume2D Shader of mine</strong>[<a href="https://github.com/Enigmatisms/Volume">Github Repo:
Enigmatisms/Volume]</a>. Using this LiDAR simulator, I implemented an
interesting little localization program via <strong>Particle
Filter</strong>. The localization experiments are only done in a 2D-2DoF
(translation position x and y) problem.</p>
<p>Under the condition of 2000 particles, the FPS of this algorithm is
about 16-50 hz, and the convergence is fast and accurate. Run:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">roslaunch lidar_sim filter.launch</span><br></pre></td></tr></table></figure>
<p>To find out.</p>
<h3 id="scan-simulator">3. Scan simulator</h3>
<p>The main content of this repo. Run:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">roslaunch lidar_sim scan.launch</span><br></pre></td></tr></table></figure>
<p>On initialization, two new windows will pop up:</p>
<ul>
<li>An opencv window for free space, LiDAR scan visualization and
scanner controlling.</li>
<li>An rviz window for sensor_msgs / nav_msgs visualization</li>
</ul>
<p>Check the launch file, you can find <strong><u>a lot of</u></strong>
params.</p>
<ul>
<li>Controller settings:
<ul>
<li>trans_speed: translation speed (pixel per move, which is 2cm per
move)</li>
<li>rot_vel: rotation velocity, in degree, which is only available in
keyboard control</li>
<li>init_x, init_y: initial position of the scanner</li>
<li>kp, ki, kd: PID parameters for mouse controller, which allows smooth
control.</li>
</ul></li>
<li>LiDAR settings
<ul>
<li>angle_min, angle_max: angle range in rad</li>
<li>angle_incre: angle resolution (increment) in rad</li>
<li>lidar_noise: noise level (gaussian sigma) for the noise in
<strong><u>range.</u></strong></li>
<li>lidar_fps: frame rate of LiDAR</li>
</ul></li>
<li>Odometry settings: for nav_msgs::Odometry publishing
<ul>
<li>translation_noise: translation noise level</li>
<li>rotation_noise: rotation noise level (both gaussian)</li>
</ul></li>
<li>other settings:
<ul>
<li>map_name: which map to run</li>
<li>bag_name: the name of output rosbag</li>
<li>skip_selection: if true, the program will not ask you to select the
initial position of the scanner, (init_x, init_y) will come into
use.</li>
<li>direct_pub: publish the ROS messages in the program</li>
</ul></li>
</ul>
<hr>
<h2 id="demo">Demo</h2>
<video src="scan.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>release</tag>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title>诡异bug背后的一些知识</title>
    <url>/2021/08/28/%E8%AF%A1%E5%BC%82bug%E8%83%8C%E5%90%8E%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<h1 id="untitled-no.1">Untitled-NO.1</h1>
<hr>
<p>​
在构建2D激光雷达模拟器的时候，在某个自定义地图中碰上一个奇怪的bug。当然，我从现在完全弄明白这个问题的角度出发，这个bug一点也不奇怪，反倒是警示我要多查cppreference，使用一个STL提供的工具就要看一份文档。</p>
<center>
<a class="btn" href="https://en.cppreference.com/w/"><i class="fa fa-circle-notch"></i>CPP Reference</a>
</center>
<span id="more"></span>
<hr>
<h2 id="bug-表现">Bug 表现</h2>
<p>​ 首先我们声明一些记号：</p>
<ul>
<li><code>A</code>
是一个class，与之对应的容器是std::vector&lt;A&gt;</li>
<li>func
是一个函数，大概长这样：<code>void func(const A&amp; a, std::vector&lt;A&gt;&amp; arr)</code>。也就是，传入一个A的常引用，并且传入一个A的容器的引用。</li>
</ul>
<p>​
func的行为是：根据a，进行计算，有可能往arr尾部push新的A实例。a的来源是：a是一个常引用，但是是这样在外部定义的：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">A&amp; a_ref = arr[id];</span><br><span class="line"><span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; arr.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    <span class="built_in">func</span>(a, arr);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
for循环外部的，对arr这个vector内某一已经存在元素的引用。之后，将其传入func中，隐式转换为常引用。这实际上对应了我代码中的：阴影在物体内部的投影。比如一个object，需要先计算内部的有效遮挡边如何被内部其他边遮挡。于是A就相当于是
遮挡边class类型，以上的代码就可以认为是：a_ref是当前进行投影的边，arr中保存了这个object的所有遮挡边，使用func来判定a是否遮挡或者如何遮挡其他遮挡边。见<a href="https://github.com/Enigmatisms/LiDARSim2D/blob/master/src/lidar_sim/src/Object.cc">Enigmatisms/LiDAR2DSim🔗</a>定义的函数<code>internalOcclusion</code>。</p>
<p>​ 于是我得到了一个这样的结果：</p>
<p><img src="/2021/08/28/%E8%AF%A1%E5%BC%82bug%E8%83%8C%E5%90%8E%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9F%A5%E8%AF%86/2.png"></p>
<center>
Figure 1. GDB调试，projectEdge2Edge的输入有问题
</center>
<p>​
其中projectEdge2Edge函数就是func，其中参数src（是一个继承了<code>std::vector&lt;Eigen::Vector2d&gt;</code>的class）就是类型A。src的内容出错了。</p>
<p>​ 当然这个问题的定位费了好阵子gdb，打conditional
breakpoint才查到（不得不吹一波vscode的内置调试）。可以看到，src（一条投影边）的第一个点（<code>Eigen::Vector2d</code>）值变得奇怪（很小，不应该有）。我首先就猜测是引用失效了（废话），此后猜测
可能是push_back（在breakEdge中进行了push_back，可以说很隐蔽了，breakEdge没有直接传入src，并且src是个const，要是之前我是不会想到引用失效的）导致了引用失效。于是我做了个这样的事情：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> (heap.<span class="built_in">empty</span>() == <span class="literal">false</span>) &#123;</span><br><span class="line">    <span class="type">size_t</span> top = heap.<span class="built_in">top</span>();</span><br><span class="line">    heap.<span class="built_in">pop</span>();</span><br><span class="line">    <span class="comment">// Edge&amp; this_edge = edges[top] 	  (删除这一行)</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; edges.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">        Edge&amp; eg = edges[i];</span><br><span class="line">        Edge&amp; this_edge = edges[top] 	<span class="comment">//(加入这一行)</span></span><br><span class="line">        <span class="keyword">if</span> (eg.valid == <span class="literal">false</span> || &amp;eg == &amp;this_edge)</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        <span class="built_in">projectEdge2Edge</span>(this_edge, obs, eg, heap);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
由于projectEdge2Edge（func）在执行完push_back之后没有对src（a）有任何后续操作，所以我让引用的设置在for循环中执行，每一次都是最新的引用。这样操作之后果然好了。但是不清楚原因。</p>
<hr>
<h2 id="原因">原因</h2>
<p>​ 我先是问了我佬哥。得到的回复是：</p>
<blockquote>
<p>往vector pushback确定可能导致它的引用失效，因为它可能resize
那就换了块内存了</p>
</blockquote>
<p>​ emmm。很有道理，我又去查了一波资料[1]：</p>
<blockquote>
<p>If the new <a href="https://en.cppreference.com/w/cpp/container/vector/size">size()</a>
is greater than <a href="https://en.cppreference.com/w/cpp/container/vector/capacity">capacity()</a>
then all iterators and references (including the past-the-end iterator)
are invalidated. Otherwise only the past-the-end iterator is
invalidated.</p>
</blockquote>
<p>​
这个capacity是什么呢？vector是动态分配大小的，之前学数据结构与算法的时候，定义动态数组，当时就需要realloc操作，我当时的实现是每次往背后多加4个空余位置。vector也是动态分配的，从它的类函数shrink_to_fit()可以看出来，据说是：每一次realloc到大于当前元素个数的最小二的幂次。那么，举个例子，当vector原来的size是4时，push_back会导致重新分配内存（应该也伴随内存的移动）。这个很好理解，毕竟加入原来分配的内存块是经过了表映射的，如果连续的空间不足，根据vector的又一特性：</p>
<blockquote>
<p>The elements are stored contiguously, which means that elements can
be accessed not only through iterators, but also <strong><u>using
offsets to regular pointers to elements</u></strong>.</p>
</blockquote>
<p>​
要保证连续的话，只能整个挪动原来存储的东西。而引用？虽然我一直以为，如果是指针的话，指向的地址可能没东西了导致出错，引用应该安全的多，应该就能完全指向vector中的元素吧。可惜并不是，stackoverflow上的佬哥这么解释：</p>
<blockquote>
<ul>
<li>Reference, internally is <em>implemented</em> as a constant pointer
which is automatically de-referenced.</li>
<li>The natural implementation of a reference is indeed a pointer.</li>
<li>Though a reference is in reality a pointer, but it shouldn't be used
like a pointer but as an alias.</li>
</ul>
</blockquote>
<p>​
常指针或者指针，编译器为了使得reference的设计更安全，要求必须初始化。也就是说，这个引用指向了一块具体的地址，但是由于reallocation，失效了。Nice.</p>
<hr>
<h2 id="意外收获">意外收获</h2>
<h3 id="迭代器失效">1. 迭代器失效</h3>
<p><img src="/2021/08/28/%E8%AF%A1%E5%BC%82bug%E8%83%8C%E5%90%8E%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9F%A5%E8%AF%86/3.PNG"></p>
<center>
Figure 2. 迭代器失效情况
</center>
<p>​
我之前还写带代码还把迭代器装在一个容器里，知道很不优雅，但现在知道除了不优雅，还很危险（富贵险中求！！）。</p>
<h3 id="stdvectorbool">2. std::vector&lt;bool&gt;</h3>
<blockquote>
<p>std::vector&lt;bool&gt; is a possibly space-efficient specialization
of std::vector for the type bool.</p>
</blockquote>
<p>​ 最有意思的是，cppreference说，空间节约的目的导致bool
vector在内存中可能不是连续的。</p>
<p>​
并且std::vector&lt;bool&gt;有一个新的方法（有别于其他的vector），叫做flip，可以取反内部所有元素。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] https://en.cppreference.com/w/cpp/container/vector/push_back</p>
<p>[2] <a href="https://stackoverflow.com/questions/3954764/how-are-references-implemented-internally">How
are references implemented internally?</a></p>
]]></content>
      <categories>
        <category>learning</category>
        <category>debugs</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>关于变形金刚的一些思考</title>
    <url>/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[<h1 id="transformer">Transformer</h1>
<hr>
<h2 id="i.-引入">I. 引入</h2>
<p>​ 在NLP（Natural Language Processing 而不是 Non-Linear
Programming）问题中，经常涉及到sequence to
sequence的问题，在这种问题上最广为人知的应用就是【机器翻译】：</p>
<blockquote>
<p>Watch out everybody, the potato is really hot. Nice.</p>
<p>大家快看外面有一个特别性感的土豆。好棒啊。</p>
</blockquote>
<p>​
而RNN及其变体如GRU/LSTM，既然属于RNN范畴，那就免不了<strong><u>串行</u></strong>以及自递归（auto-regression）。在数字信号处理课程中学的知识：自递归对应了IIR，时域上比FIR复杂一些。由于这两个显著的弱点，导致其慢并且长距离下的语义解析能力差，Vaswani等人提出了一种新的
基于注意力机制的可并行处理框架 - the
变形金刚。在此基础上，Juho-Lee等人构建了一种对集合数据具有置换不变性的网络（集合无序，输入顺序不影响输出）。因为从小就是看变形金刚系列电影长大的（？），我实现了这两篇论文中提到的神经网络结构，用在了Set
Transformer论文中的Toy Problem - Max regression
上。结果如下图，本文是对Transformer相关理论以及实现的总结，实现已经挂在Github上了，见<a href="https://github.com/Enigmatisms/Set-Transformer">Github🔗：Enigmatisms/Set-Transformer</a>。</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/1.png" style="zoom:75%;"></p>
<center>
Figure 1. Set Transformer Max Regression Problem实验结果
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-attention机制的理解">II. Attention机制的理解</h2>
<h3 id="与rnn的关系">2.1 与RNN的关系</h3>
<p>​
RNN中的典型结构（我也不记得叫什么了），总之是一个有记忆能力的Gate。神经元的上一个输出，可以作为本次输入的一部分，那么这可以被简单地表示成：
<span class="math display">\[
\begin{equation}\label{rnn}
y[n]=a\times h[n]+b\times x[n],\text{ where }h[n]=y[n-1]
\end{equation}
\]</span> ​
显然，一个简单的记忆单元可以被表示成一个<strong><u>离散一阶系统</u></strong>，那就是一个惯性环节嘛。这也就是一个自递归单元。很可惜，这样的系统阶数越高，表示力才越强，但作为代价的是，需要系统提供存储单元，并且对于一个k阶系统，前k个值如果没有完全计算完成，那么第k+1个值是无法得到的，这也就阻止了并行，这太不优雅了，虽然可能
一定程度上模仿了人类的理解方式：顺序读，再处理顺序输入的信息。</p>
<p>​
我个人不是很了解RNN，因为个人觉得这个网络结构就是不是特别优雅（虽然看起来很有道理），加上我偏CV，一般也用不到RNN。我在想，RNN能做到以下的事情吗？</p>
<blockquote>
<p>另外，在常规接当种中我也们发现，免疫相对功能较低人的群，以及60岁上以的人群，他们接踵产生后的免效疫没有果18-59岁的好，但是这类人群又是恰恰感的染后高危人群</p>
</blockquote>
<p>​
上面这段话的内容，存在一些颠倒的字词，人可能没有太大的阅读障碍，但是依赖顺序输入的网络表现会如何？</p>
<p>​
与之相比，Transformer是一种FIR，它无需依赖记忆单元，在输入时也没有顺序要求（Attention
is All You Need一文中使用三角函数Position
encoding），于是可以很方便地进行并行。并且Transformer使用的注意力机制，就是模仿人类理解信息时，有所侧重的特性。</p>
<h3 id="单头细节">2.2 单头细节</h3>
<p>​ Query，Key，Value（Q K
V）的物理含义应该如何理解？假设问题的背景是机器翻译，那么有两种情况：</p>
<ul>
<li>Q是输入语言，(K,V)是目标语言对应的信息。输入的每一个token，变为Q之后查应该对应目标语言中的哪一个词。</li>
<li>Q是目标语言，(K,V)是输入语言信息。目标语言查自己应该如何选择目标token才能使得最类似输入</li>
</ul>
<p>​
个人认为在Transformer中，应该是用第一种方式来处理问题。那么Q，K，V在其中的作用个人认为分别是：</p>
<ul>
<li>Q：输入embedding信息，用于与目标语言的信息进行比较</li>
<li>K：<strong><u>目标语言</u></strong>构建的，<strong><u>方便源语言（Q）进行比较</u></strong>的，包含目标embedding信息的张量</li>
<li>V：用于输出的目标embedding信息部分</li>
</ul>
<p>​ 考虑batch的情况下，一般的张量shape（以Q为例），大概是这样的：<span class="math inline">\((N_{\text{batch}},M_{\text{seq-len}},K_{\text{embedding-dim}})\)</span>​​。也就是，三维张量已经足够表示：batch
size，序列长度，以及embedding维度。有的时候，Q与K的shape会相同，以下以QK处于同一个线性空间为例，那么Q/K所在的空间内可以形成Gram矩阵：</p>
<blockquote>
<p>在线性代数中，内积空间中一族向量的格拉姆矩阵（Gramian matrix 或 Gram
matrix, Gramian）是<strong><u>内积的对称矩阵</u></strong>，其元素由<span class="math inline">\(G_{ij}=(v_j|v_i)\)</span>​​给出。</p>
</blockquote>
<p>​ 之前在CNN style
transfer中接触过，这个矩阵用于衡量两组向量的相似程度。因为内积可以用于衡量相似度。使用内积就会有一种使用agreement概念的感觉。最后的输出是：
<span class="math display">\[
\begin{equation}\label{qkv}
Att(Q,K,V,\omega)=\omega(\frac{QK^T}{\sqrt{k}})V
\end{equation}
\]</span> ​ <span class="math inline">\(QK^T\)</span>就是Gram矩阵，要注意KV的对应性。可以这么说：假如<span class="math inline">\(Q_i\)</span>与<span class="math inline">\(K_j\)</span>的相似度高，那么<span class="math inline">\(V_j\)</span>​应该有更大的权值。<span class="math inline">\(\omega\)</span>​是非线性函数，论文中使用的是softmax，变换为多元素的概率，进行概率加权。</p>
<p>Softmax沿着哪一个维度做？已知QK的计算是：<span class="math inline">\(QK^T\)</span>也就是<span class="math inline">\((n\times k)\times(k\times
n)\)</span>，最后生成<span class="math inline">\((n\times
n)\)</span>​​矩阵</p>
<details class="note primary"><summary><p>每一个Query token与key匹配的关系有两个选择：</p>
</summary>
<ul>
<li>一个query可以选择多个key，也就是选择不同key的概率是归一的，那么就是行和为一（）</li>
<li>一个key对应了多个query，那么就是列和为1（列方向求和）（这个在2.2节开头就已经说过了，属于方式2，应该是不对的）。</li>
</ul>

</details>
<p>​
个人更加倾向于，一个query可以对应多个key，也就是一个query可以找到多个value？也就是每一个query字，与所有value字的注意力，对应的概率应该和为1。</p>
<h3 id="单头理解-多头化">2.3 单头理解 &amp; 多头化</h3>
<table>
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;"><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/single.PNG" style="zoom:60%;"></th>
<th style="text-align: center;"><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/multi.PNG" style="zoom:50%;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">单头QKV注意力块</td>
<td style="text-align: center;">多头QKV注意力块</td>
</tr>
</tbody>
</table>
<p>​
单头QKV可以理解成：源数据经过特征提取得到Q，目标空间由V对应的元素展成（span），并且提供一个与Q中元素相同维度的比较信息（K）。源信息（Q）与部分目标信息（K）元素两两求相似，通过相似度转化为的概率对V进行加权输出。</p>
<p>​ 多头则是指：Q K
V并不直接进行内积运算。一是因为可能是大矩阵，直接内积计算时间长，二是因为这样学习得出的内容太单一。多头注意力就是希望通过多重低维度映射的方法，使得不同的head能够学习到不同的源
/ 目的数据关系，<strong><u>这是产生多重语义理解的一步。</u></strong></p>
<hr>
<h2 id="iii.-set-transformer">III. Set Transformer</h2>
<h3 id="inducing-point-isab">3.1 Inducing Point &amp; ISAB</h3>
<p>​ ISAB中的Inducing
Points与PMA中的seeds实际上是一回事，叫法不同。从论文中摘录的框图说明了ISAB的实现结构。它的提出是为了解决SAB平方复杂度导致的问题。比如当集合特别大的时候，会因为平方级别的复杂度计算很长时间。</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/isab.PNG"></p>
<center>
Figure 2. Attention Blocks
</center>
<p>​ SAB的时间复杂度为什么是<span class="math inline">\(O(n^2)\)</span>？SAB作为自注意力网络块，Multi-head
attention输入的Q K
V都是X，也就是说：对于一个输入X，不考虑其batch大小，假设其为（<span class="math inline">\(n\times
k\)</span>），n为集合大小（或者在NLP中，token的数量），k为embedding的大小。那么根据内积：
<span class="math display">\[
\begin{equation}\label{self_att}
Att(X,X,X,\omega)=\omega(\frac{XX^T}{\sqrt{k}})X
\end{equation}
\]</span> ​ 过程大概是：<span class="math inline">\((n\times
k)\times(k\times n)\times(n\times
k)\)</span>​。第一个QK阶段就已经需要n平方次计算了。这个就是<span class="math inline">\(O(n^2)\)</span>复杂度的。所以作者希望，可以固定某一维度的大小，以降低复杂度。</p>
<p>​ MAB是<span class="math inline">\(Att(X,Y,Y,\omega)\)</span>形式的，那么当MAB的输入是：<span class="math inline">\((I,X,X)\)</span>，最终的计算会成为：<span class="math inline">\((m\times k)\times(k\times n)\times(n\times
k)\)</span>。在QK阶段，内积运算只进行<span class="math inline">\((mn)\)</span>次，复杂度是<span class="math inline">\(O(mn)\)</span>，当输入为大集合时，可能可以显著减小计算负担。所以两层MAB的交替输入，第一层输出<span class="math inline">\((m\times
k)\)</span>作为第二层MAB的Y，X本身作为第二层的X，可以最后重新映射回到<span class="math inline">\((n\times k)\)</span>维度。</p>
<p>​
作者自己也说（我觉得作者这个类比很不错，很直观），ISAB就像一个编码器，或者说常见的Detection
/ Segmentation的两头大中间小结构：</p>
<blockquote>
<p>This is analogous to low-rank projection or autoencoder models, where
inputs (X) are first projected onto a low-dimensional object (H) and
then reconstructed to produce outputs.</p>
</blockquote>
<h3 id="实现细节维度">3.2 实现细节：维度？</h3>
<p>​ 开始时，我实现了一版这一样的MAB，请看：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MAB</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, batch_size, head_num, dk_model, dv_model, use_layer_norm</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.att = Multihead(batch_size, head_num, dk_model, dv_model, use_layer_norm)</span><br><span class="line">        self.ff = nn.Sequential(</span><br><span class="line">            nn.Linear(dv_mode, dv_model),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.layer_norm = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> use_layer_norm == <span class="literal">True</span>:</span><br><span class="line">            self.layer_norm = nn.LayerNorm(dv_model)</span><br><span class="line">        self.remap = nn.Linear(dk_model, dv_model)</span><br></pre></td></tr></table></figure>
<p>​ Multihead这个模块就是根据<em>Attention is All You
Need</em>这篇文章来的（至少我觉得我是这么实现的）。但是发现，这没办法实现维度变换。为什么？我发现我在解决中位数问题时，遇到了这样的难题：</p>
<ul>
<li>一个训练用例，显然是<span class="math inline">\(\{x_1,x_2,...,x_n\}\)</span>​​，x是标量，使用SAB时，内积还是标量，用处不大。</li>
<li>低维数据能向高维转移吗？自己实现的这一版SAB，输出就是：(batch_size,
token_num_Q,
embedding_dim_V)，如果内部不对数据做变换，那么输出的embedding维度就是1</li>
</ul>
<p>​ 不管是在Transformer论文还是在Set
Transformer论文中，提到Multi-head一定做的是这个事情：首先将Q K
V变换到低维度上（以Q为例） <span class="math display">\[
\begin{equation}
Q_i=QW_q^i,\text{ where } W_q^i\text{ has shape }(N_{batch},d_q,d_q/M)
\end{equation}
\]</span> ​ 将变换后的Q K V输入到single-head
attention模块中。巧了，我就是这么做的，只不过感觉会引起维度问题。所以我们需要：</p>
<ul>
<li>可以设置输入输出维度（设置输出维度极为重要，就像我们用CNN输出多少个Channel一样，应该是可调的）</li>
<li>输入时对较小的维度进行升维，以便进行Multi-head操作、</li>
</ul>
<div class="note warning"><p>​ 所以Transformer在实现时，到底应该如何操作？Q K
V看起来很简单的三个维度设置，需要统一维度吗？</p>
</div>
<p>​ 个人认为，在Set
transformer中，多头注意力机制模块应当完全不需要对输入进行变换，直接使用。这样才可以模块独立。而不同的Block之间的连接，有赖于Feed
forward层，或者说，有些Block的输出（比如MAB），就会经过FFN。</p>
<p>​ row-wise feed forward
层，一般来说也就是一个单层的线性网络（不过要记得激活，<strong><u>开始时忘记</u></strong>加ReLU了，既然是层，那就要有激活，除非是输出）。可以认为，此处就是一个类似残差块的东西。虽然在Attention
is All You Need中，FFN是这样定义的： <span class="math display">\[
\text{FFN}(x)=\max(0,xW_1+b_1)W_2+b_2
\]</span> ​ 相当于nn.Linear + nn.ReLU + nn.Linear。但是在Set
transformer中，实现的貌似叫做 row-wise（all you
need中叫做position-wise）。但是为什么要这么做？作者没有给出明确的答案，而是说：</p>
<blockquote>
<p>It could reduce to applying a residual block on X. In practice, it
learns more complicated functions due to linear projections of X inside
attention heads.</p>
</blockquote>
<p>​
感觉挺无力的，这些深度学习新的网络架构看起来好像确实没什么可以解释的，数学上也不好说。残差连接在这似乎也与其被提出时所要解决的问题对应的目的不同，因为不会有什么梯度爆炸。</p>
<h3 id="多头注意力的实现">3.3 多头注意力的实现</h3>
<p>​ 多头注意力是我在本文中最觉得困惑的部分。因为官方的实现与自己的论文 /
All you need是不一样的。不管是在Transformer 还是 Set
Transformer论文中，提到的多头的实现方式时，总会将以下公式列出来： <span class="math display">\[
\begin{align}
&amp;\text{output}=\text{cat}[O_1,O_2,...,O_h]\cdot W_o,\text{ where
}O_i \label{out}\\
&amp;O_i=Att(Q_i,K_i,V_i,w)\\
&amp;Q_i=QW_Q^i,K_i=KW_K^i,V_i=VW_V^i,
\end{align}
\]</span> ​ 也就是：对Q K V 每一项分别使用多个权重<span class="math inline">\(W\)</span>​​，从原来的embedding dimension
k映射到一个更低的维度（实现低维多输入，低维上的注意力）。​公式<span class="math inline">\(\eqref{out}\)</span>​​​​是两篇论文中都有的，但是作者并没有这样实现。作者直接使用了split（fron
Github juho-lee/set_transformer）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Q_ = torch.cat(Q.split(dim_split, <span class="number">2</span>), <span class="number">0</span>)</span><br><span class="line">K_ = torch.cat(K.split(dim_split, <span class="number">2</span>), <span class="number">0</span>)</span><br><span class="line">V_ = torch.cat(V.split(dim_split, <span class="number">2</span>), <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>​ 相当于，本来应该使用线性映射到低维的Q K V，直接在embedding
dimension维度切开，成为head
number份。这和你的论文里写的也不一样啊，为什么呀大哥。此后，官方实现有些更迷惑的操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">A = torch.softmax(Q_.bmm(K_.transpose(<span class="number">1</span>,<span class="number">2</span>))/math.sqrt(self.dim_V), <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>​
连起来就是：首先embedding直接split成块，拼接到第一个维度上（一般来说是batch维度），相当于原来batch
size为n现在变成了<span class="math inline">\(h\times
n\)</span>，batch之间不会有相互作用。计算内积之后，再拆分回到原来的shape。所以我也不是很懂为什么不按部就班实现。。。可能这就是强者吧。我的实现，只能说按着论文来的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Qs = Q.split(self.dk, dim = -<span class="number">1</span>)</span><br><span class="line">Ks = K.split(self.dk, dim = -<span class="number">1</span>)</span><br><span class="line">Vs = V.split(self.dv, dim = -<span class="number">1</span>)</span><br><span class="line">heads = [self.singleHeadQKVAtt(Qs[i], Ks[i], Vs[i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.head_num)]</span><br><span class="line"><span class="comment"># 或者不使用split</span></span><br><span class="line">Qs = [Q @ self.Wqs[i].repeat(batch_size, <span class="number">1</span>, <span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.head_num)]</span><br><span class="line">Ks = [K @ self.Wqs[i].repeat(batch_size, <span class="number">1</span>, <span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.head_num)]</span><br><span class="line">Vs = [V @ self.Wvs[i].repeat(batch_size, <span class="number">1</span>, <span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.head_num)]</span><br><span class="line"><span class="comment"># each head outputs (n, token_num, token_num) @ (n, token_num, dv_model / head)</span></span><br><span class="line">heads = [self.singleHeadQKVAtt(Qs[i], Ks[i], Vs[i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.head_num)]</span><br></pre></td></tr></table></figure>
<p>​
split本质上与线性映射没有什么区别，甚至split实现会简单很多，并且少一些参数。</p>
<hr>
<h2 id="iv.-复现结果">IV. 复现结果</h2>
<ul>
<li>学习率设置</li>
</ul>
<h3 id="学习率">4.1 学习率</h3>
<p>​ 测试的问题是Set Transformer中的Max
Regression问题，找一个集合的最大数，本来想实现中位数的，但是发现中位数简直没办法直接训练出东西来。训练参数：batch
size = 64，一个集合32个数，也就是每次的X是<span class="math inline">\(64
\times 32\)</span>​矩阵。模型非常难训练，主要体现在：</p>
<ul>
<li><p>我使用exponential learning rate
scheduler，初始学习率1e-3，gamma大概为0.9999（衰减慢），正常情况下，在初始的几百个样本，loss下降非常快。到loss约等于2时，可能一直卡在这直到结束，最后的acc也就20%。</p></li>
<li><p>有很小的概率，学习率减到很小时，跳出局部最优解。acc继续上升，但是由于ExpoLR让学习率变得很小了，训练很慢，训练完也只能让模型acc到50%。</p></li>
<li><p>官方实现可以在较大学习率时跳出局部最优。所以最后学得很快，训练结束时到了90%。</p></li>
</ul>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/2.png"></p>
<center>
Figure 3. 测试用例acc（每次测试10个集合）
</center>
<p>​
上图中，在15k个epoch突然飙起来的橙色曲线是官方实现思路的MAB，很快就收敛了。深蓝色曲线则是我说的那个exponential
LR训练结果。</p>
<p>​ 之后我换成Multi Step
LR，开始200个epoch学习率很大，loss下降很快，[200,1000]内的学习率是上一阶段的1/10，此后则是1/100。看起来真的是学习率过大。此后其他的曲线都是学习率精调得到的结果。</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/4.png"></p>
<center>
Figure 4. 测试用例loss（每次测试10个集合）
</center>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/5.png"></p>
<center>
Figure 5. 训练用例loss
</center>
<p>​
可以看到，灰色的曲线是最后一次的训练结果。也就是说，我的实现比官方实现训练次数多了好几倍，达到的acc之比官方高了个4%。</p>
<hr>
<h2 id="v.-funny-thing-about-transformer">V. Funny Thing about
Transformer</h2>
<p>​ 谁让Vaswani起了一个倍具争议的名字呢？</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/a1.PNG"></p>
<p>​ 实名赞同楼上：</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/a3.PNG"></p>
<p>​ 赞同，但是我要提方案：</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/a2.PNG"></p>
<p>​ 我有些疑问：</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/a4.PNG"></p>
<p>​ 实名反对楼主：</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/a5.PNG"></p>
<p>​ 反对反对（nm啊，这名字真的很踢馆）</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/a6.PNG"></p>
<p>​ 我来折衷：</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/a7.PNG"></p>
<p>​ 注意力？小马宝莉（My Little Pony简称MLP）最强：</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/a8.PNG"></p>
<p>​ 你们搞NLP的还挺有意思的。</p>
<hr>
<h2 id="reference">Reference</h2>
<ul>
<li><p><a href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">Vaswani
A, Shazeer N, Parmar N, et al. Attention is all you need[C]//Advances in
neural information processing systems. 2017: 5998-6008.</a></p></li>
<li><p><a href="http://proceedings.mlr.press/v97/lee19d.html">Lee J, Lee
Y, Kim J, et al. Set transformer: A framework for attention-based
permutation-invariant neural networks[C]//International Conference on
Machine Learning. PMLR, 2019: 3744-3753.</a></p></li>
<li><p><a href="https://github.com/juho-lee/set_transformer">Github:
juho-lee/set_transformer</a></p></li>
<li><p><a href="https://spaces.ac.cn/archives/4765/comment-page-1#Attention%E5%AE%9A%E4%B9%89">苏剑林的科学空间:《Attention
is All You Need》浅读（简介+代码）</a></p></li>
</ul>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>Particle Filter Simulation</title>
    <url>/2021/08/07/Particle-Filter-Simulation/</url>
    <content><![CDATA[<h1 id="particle-filter">Particle Filter</h1>
<hr>
<h2 id="i.-introduction">I. Introduction</h2>
<p>​ 大二买了一本 <em>Probability Robotics(of Sebastian Thrun, et
al)</em>，其中粒子滤波的概率论知识讲得很清楚。大二学完概率论之后给我看明白了，人生第一次在理论学习上那么有成就感。但是看完之后总觉得干巴巴的，不知道如何应用。最近写完了
Volume2D
Shader，突然想到一个很好的方法可以应用粒子滤波，于是实现了一版。半天写完，效果不错，见<a href="https://github.com/Enigmatisms/ParticleFilter">[Github
Repo🔗:Enigmatisms/ParticleFilter]</a>：</p>
<p><img src="/2021/08/07/Particle-Filter-Simulation/ray2.png"></p>
<center>
Figure 1. Particle Filter 中使用Volume2D Shader进行的激光雷达scan仿真
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-理论推导">II. 理论推导</h2>
<h3 id="目标">2.1 目标</h3>
<p>​
我仅仅讨论粒子滤波在localization中的作用，虽然localization只是PF理论应用的一个小方向。如果没有给定初值，也没有很好地利用观测信息，localization基本就是在乱猜其在空间中的位置。并且，通常情况下，只使用当前scan也无法准确获得定位，因为可能存在大量的重复地图特征。</p>
<p>​ 好在我们有连续的观测以及连续的控制，假设控制与观测序列：</p>
<ul>
<li>控制序列: <span class="math inline">\(U_t:\{u_1,u_2,...u_{t}\}\)</span>​​，<span class="math inline">\(u_t\)</span>​表示从状态<span class="math inline">\(x_{t-1}\)</span>​过渡到<span class="math inline">\(x_t\)</span>​的控制​</li>
<li>观测序列：<span class="math inline">\(Z_t:\{z_0,z_1,....z_{t}\}\)</span>​​，<span class="math inline">\(z_t\)</span>​表示在状态<span class="math inline">\(x_t\)</span>​​下的观测​</li>
</ul>
<p>​ 我们不希求通过<span class="math inline">\(z_t\)</span>​来求使得<span class="math inline">\(P(x_t|z_t)\)</span>​​最大的<span class="math inline">\(x_t\)</span>，而是需要求： <span class="math display">\[
\begin{equation}\label{post}
x_t^* = \mathop{\arg \max}_{x_t}P(x_t|Z_t,U_t)
\end{equation}
\]</span> ​ 实际上，可以说公式<span class="math inline">\(\eqref{post}\)</span>定义的是一个后验概率。也就是最大化一个后验概率了，啊这不就是
贝叶斯滤波吗？确实，粒子滤波就是贝叶斯滤波的一个非参数实现。</p>
<p>​
但是一般来说，没有马尔可夫假设，事情会变得很复杂，如果我们需要对一大串控制
/ 状态序列进行处理，应该怎么做？</p>
<h3 id="粒子与采样">2.2 粒子与采样</h3>
<p>​ 这是不是自然计算？粒子是一个个的可能状态：<span class="math inline">\(x_{t,1},x_{t,2},...x_{t,k}\)</span>​，假设我们有k个假设的状态。此时我们应该运用贝叶斯学派知识，首先由信息包含关系（之前的观测与控制包含在状态<span class="math inline">\(x_{t-1,i}\)</span>中） <span class="math display">\[
\begin{equation}\label{info}
P(x_{t,i}|Z_t,U_t,x_{0,i})=P(x_{t,i}|z_t,u_t,x_{t-1,i})
\end{equation}
\]</span> ​ 接下来的贝叶斯滤波变换可以说很妙了： <span class="math display">\[
\begin{equation}
P(x_{t,i}|z_t,u_t,x_{t-1,i}) = \frac{P(x_{t,i},
z_t,u_t,x_{t-1,i})}{P(z_t,u_t,x_{t-1,i})}
\end{equation}
\]</span> ​ 既然是要使用贝叶斯，那么就要想办法把观测和状态互换位置：
<span class="math display">\[
\begin{equation}\label{eqn4}
\frac{P(x_{t,i},
z_t,u_t,x_{t-1,i})}{P(z_t,u_t,x_{t-1,i})}=\frac{P(z_t|x_{t,i},u_t,x_{t-1,i})P(x_{t,i},u_t,x_{t-1,i})}{P(z_t|u_t,x_{t-1,i})P(x_{t-1,i},u_t)}
=\frac{P(z_t|x_{t,i},u_t,x_{t-1,i})P(x_{t,i}|u_t,x_{t-1,i})}{P(z_t|u_t,x_{t-1,i})}
\end{equation}
\]</span> ​ 注意，我们有如下两个论断成立： <span class="math display">\[
\begin{align}
&amp; P(z_t|x_{t,i},u_t,x_{t-1,i}) = P(z_t|x_{t,i})\label{within} \\
&amp; P(x_{t,i}|u_t,x_{t-1,i}) \text{ is a known prior}\label{prior}
\end{align}
\]</span> ​ 公式<span class="math inline">\(\eqref{within}\)</span>​说的是：观测<span class="math inline">\(z_t\)</span>​只与当前状态<span class="math inline">\(x_t\)</span>​有关。论断<span class="math inline">\(\eqref{prior}\)</span>​指的是，由控制引起的状态转移误差分布是已知的（比如本实现中，我假设我的控制噪声是白噪声，那么此处就是一个高斯项）。​</p>
<p>​ 那么公式<span class="math inline">\(\eqref{eqn4}\)</span>​可以被进一步化简为下式，其中<span class="math inline">\(\eta\)</span>是我们不关心的归一化因子。 <span class="math display">\[
\begin{equation}\label{eqn7}
\eta P(z_t|x_{t,i})P(x_{t,i}|u_t,x_{t-1,i})
\end{equation}
\]</span> ​ 那么可以这么理解：状态粒子i在第t时刻的观测<span class="math inline">\(z_t\)</span>​​下，拥有状态<span class="math inline">\(x_{t,i}\)</span>​的概率为<span class="math inline">\(\eqref{eqn7}\)</span>，包含两个组份：</p>
<ul>
<li>状态粒子与观测的契合程度（给定状态能生成对应观测吗）<span class="math inline">\(P(z_t|x_{t,i})\)</span></li>
<li>控制状态转移噪声先验<span class="math inline">\(P(x_{t,i}|u_t,x_{t-1,i})\)</span>​</li>
</ul>
<p>​ 在2.5小节里，我简单地说一下我是如何对这个问题进行建模的。</p>
<h3 id="分布变换">2.3 分布变换</h3>
<p>​ 粒子滤波实际上是用粒子与采样来近似任意分布，在公式<span class="math inline">\(\eqref{eqn7}\)</span>​​​中，已经说明了<span class="math inline">\(P(x_{t,i}|x_{t-1,i},z_t,u_t)\)</span>​的组成成分。粒子滤波实际上还做了一个这样的事情，我们知道概率论中，概率是需要归一化的，而归一化因子在连续PDF中一般都涉及到积分。很多时候，积分是很难的，不一定能积出来。要获取目标分布，就存在一定难度了。这个时候，粒子滤波可以通过一个简单的建议分布，去推导一个复杂的目标分布。</p>
<p>​ 我们重新定义一下问题。<span class="math inline">\(P(x_{t,i}|x_{t-1,i},z_t,u_t)\)</span>是当前点的存在置信度，而我们希望，算法可以是迭代式（马尔可夫）的，也就是要从上一个迭代的粒子对应的置信度，计算本次迭代对应粒子的置信度。于是根据控制状态转移分布，可以得到建议分布：
<span class="math display">\[
P(x_{t,i}|x_{t-1,i},z_t,u_t)=P(x_{t,i}|x_{t-1,i},u_t)P(x_{t-1,i}|x_{t-2,i},z_{t-1},u_{t-1})
\]</span> ​
可以发现，等号右边第二项就是上一次迭代对应粒子的分布。根据状态转移进行了分布变换，得到了新的建议分布。<strong><u>但是我们并非直接接受新的建议分布，</u></strong>为什么？</p>
<blockquote>
<p>状态的转移带来新的信息。通俗地说，到一个新的地点，就可以从不同的角度观察环境。</p>
</blockquote>
<p>​
我们可以通过新的观测，来衡量，这些新的点是否适合？原来的粒子，是分布的采样。那么，符合新的观测的粒子，自然可以给一个大权重，而不符合新观测的粒子，自然也就不那么重视。这就涉及到对粒子进行加权以及重采样。</p>
<h3 id="加权-重采样">2.4 加权 重采样</h3>
<p>​
我们希望给粒子impose一个权重。但是粒子已经是分布的一个例化了（采样），这个时候有两种方案：</p>
<ul>
<li>每个粒子维护一个权重，每次更新权重</li>
<li>每次重新生成一群粒子，根据权重进行生成</li>
</ul>
<p>​
第一种思想很好理解。比如在localization问题中，我在位姿空间中有很多位姿的估计粒子，那么最后粒子求加权平均应该就是结果。</p>
<p>​
而第二种思想，则是把权重隐含在粒子数量中，这种思想是真正符合“粒子是对应分布的采样”的。显然，在N维空间中某个区域粒子数多，自然此处分布就应该比较大。</p>
<p>​
直接进行随机的Metropolis-Hasting采样，需要的时间开销比较大？为什么？根据这篇文章[2]，里面说：</p>
<blockquote>
<p>简单随机重采样：（1）生成N个均匀分布随机数（2）随机数数列排序（3）根据随机数数列以及粒子的权重进行重采样。</p>
</blockquote>
<p>​ 这个步骤是：设点i的权重是<span class="math inline">\(w_i\)</span>，生成的随机数数列是<span class="math inline">\(y_i\)</span>。则对于所有的<span class="math inline">\(y_i\)</span>，如果<span class="math inline">\(y_i\)</span>落在<span class="math inline">\(\left(\sum_{k=1}^iw_k,\sum_{k=1}^{i+1}w_k\right]\)</span>中，那么对应粒子的采样数+1。可知这样的采样方法，复杂度是<span class="math inline">\(O(NlogN)\)</span>，毕竟需要排序，但是这是完全随机的。完全随机的两个坏处就体现出来了：</p>
<ul>
<li>不能保证数据集的遍历性，有些数据可能根本没有办法被采样到</li>
<li>计算复杂度大，大型采样时间消耗大。</li>
</ul>
<p>​
更好的算法，这里就不再赘述了，详见《概率机器人》第四章。我的实现中，使用的就是《概率机器人》中的“低方差采样”，时间复杂度为O(N)，并且是遍历性的。</p>
<p>​
重采样的目的就是使得建议分布转化为目标分布。对于粒子滤波，如果我们这样理解问题：滤波的完整迭代过程（从0到收敛有t个迭代），那么希望最大化：
<span class="math display">\[
\begin{equation}\label{new_obj}
P(x_{0:t,i}|z_{1:t},u_{1:t})
\end{equation}
\]</span> ​
以localization任务来说。如果一个状态是比较正确的，那么不管如何迭代，其置信度在不同的迭代中都应该比较大。那么根据公式<span class="math inline">\(\eqref{eqn7}\)</span>​​，可以展开为类似的结构（这是目标分布）：
<span class="math display">\[
\begin{equation}\label{eqn11}
\eta P(z_t|x_{0:t,i}, z_{1:t},u_{1:t})P(x_{0:t,i}|u_t,z_{1:t-1,i})
\end{equation}
\]</span> ​
进一步根据贝叶斯和马尔可夫性，可以作进一步展开，可得到建议分布与目标分布之比与<span class="math inline">\(P(z_t|x_{t_i})\)</span>​成正比。</p>
<h3 id="简单建模">2.5 简单建模</h3>
<p>​ 此部分，我简要介绍一下在基于Volume2D
Shader的激光雷达模拟器中，如何建模一些分布。最为重要的首先就是似然<span class="math inline">\(P(z_t|x_t)\)</span>，也即，给定状态下，产生观测<span class="math inline">\(z_t\)</span>的可能性。此处我将其建模为：</p>
<ul>
<li>给定<span class="math inline">\(x_t\)</span>（状态，也即粒子对应的位姿），我在此处模拟一个激光点云（因为已知地图），与实际的观测<span class="math inline">\(z_t\)</span>进行比较。相似则对应的概率大，不相似则概率小。</li>
<li>那么相似性的比较，则是基于模拟激光点云对应角度上的range差值。其实只要理解似然在此处的作用，这个模型很好建立。</li>
</ul>
<p>​
另一方面，是状态转移模型。此处直接使用了一个方差与移动大小相关的高斯噪声。</p>
<hr>
<h2 id="iii.-结果">III. 结果</h2>
<table>
<colgroup>
<col style="width: 49%">
<col style="width: 50%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;"><img src="/2021/08/07/Particle-Filter-Simulation/img1.png"></th>
<th style="text-align: center;"><img src="/2021/08/07/Particle-Filter-Simulation/img3.png"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">长走廊问题 初始化</td>
<td style="text-align: center;">长走廊问题 第三次迭代（移动3次）</td>
</tr>
<tr>
<td style="text-align: center;"><img src="/2021/08/07/Particle-Filter-Simulation/img9.png"></td>
<td style="text-align: center;"><img src="/2021/08/07/Particle-Filter-Simulation/img16.png"></td>
</tr>
<tr>
<td style="text-align: center;">长走廊问题 第九次迭代（移动9次）</td>
<td style="text-align: center;">长走廊问题 第十六次迭代（移动16次）</td>
</tr>
</tbody>
</table>
<p>​
对于不完全的长走廊问题（虽然相似但是还有一定区别的环境），粒子滤波还是可以应对的。（2000个粒子）。</p>
<video src="cv_output.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<center>
Video 1. 长走廊问题迭代过程（慢速）
</center>
<video src="cv_output2.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<center>
Video 2. 随机地图定位问题（慢速）
</center>
<hr>
<h3 id="reference">Reference</h3>
<p>[1] Probability Robotics (Sebastian Thrun, et al)</p>
<p>[2] 粒子滤波常用重采样算法分析比较，范澎湃等</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>SLAM</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title>Volume2D Shader Pro</title>
    <url>/2021/08/02/Volume2D-Shader-Pro/</url>
    <content><![CDATA[<h1 id="volume2d-pro">Volume2D Pro</h1>
<hr>
<h2 id="i.-preface">I. Preface</h2>
<p>​
觉得之前的算法太菜了，只能处理方形障碍物（虽然如果要给我的游戏用也够了），所以想着升级一下算法。近期实习刚好也做了一些类似的事情，但实习期间设计的算法很难debug（bug制造机就是我），在实习末期重新设计了一下，见Github
Repo：<a href="https://github.com/Enigmatisms/Volume">[Enigmatisms/Volume]</a></p>
<video src="cv_output.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<center>
Video 1. 不规则障碍物体积光算法效果
</center>
<p>​
不得不说，叠buff式编程真的很恶心，从实习开始到现在我都处于叠buff式编程中。</p>
<details class="note primary"><summary><p>什么叫叠buff式编程</p>
</summary>
<p>叠buff式编程指的是编写的代码不能一次性通过所有测试用例，需要一点一点测试之前没有考虑到的方面（定义来自
HQY）</p>

</details>
<span id="more"></span>
<hr>
<h2 id="ii.-算法设计简介">II. 算法设计简介</h2>
<h3 id="数据表示">2.1 数据表示</h3>
<div class="tabs" id="two-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#two-unique-name-1">Edge</a></li><li class="tab"><a href="#two-unique-name-2">Object</a></li></ul><div class="tab-content"><div class="tab-pane active" id="two-unique-name-1"><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Edge</span>: <span class="keyword">public</span> std::deque&lt;Eigen::Vector3d&gt; &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    std::pair&lt;<span class="type">int</span>, <span class="type">int</span>&gt; proj_ids;           <span class="comment">// 待投影点的id</span></span><br><span class="line">    <span class="type">double</span> min_dist = <span class="number">1e9</span>;</span><br><span class="line">    <span class="type">bool</span> valid = <span class="literal">true</span>;                      <span class="comment">// 是否完全被遮挡</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>​
Edge是一个继承了<code>std::vector&lt;Eigen::Vector3d&gt;</code>的类，除了包含vector的所有特性之外，还实现了一些方法，诸如<strong><u>旋转数组二分查找</u></strong>，带奇异性的角度判定等等。Edge实际上就是每一条参与投影的边，在Edge之上有Object来进行管理。Edge是<strong><u>不断开的，面向光源的障碍物边界部分</u></strong>。</p>
<p>​
Vector3d在此处表示的是：x，y，角度（点到观测点形成的向量，求反正切的角度）。</p></div><div class="tab-pane" id="two-unique-name-2"><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Object</span> &#123;</span><br><span class="line"><span class="keyword">using</span> HeapType = std::priority_queue&lt;<span class="type">size_t</span>, std::vector&lt;<span class="type">size_t</span>&gt;, EdgeCompFunctor&gt;;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="type">int</span> id;</span><br><span class="line">    <span class="type">bool</span> valid;</span><br><span class="line">    <span class="type">double</span> min_dist;</span><br><span class="line">    std::vector&lt;Edge&gt; edges;</span><br><span class="line">    std::pair&lt;<span class="type">double</span>, <span class="type">double</span>&gt; angle_range;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>​
Object是Edge的集合体，除了Edge之外还封装了一些附加信息，用于判定：</p>
<ul>
<li>哪些Edge先参与投影</li>
<li>哪些Edge完全被遮挡等等</li>
</ul>
<p>​
Object内部有一个Edge的堆，堆结构在Volume2D中也曾使用，本次使用了双层堆，并且堆称为了临时变量（因为调试过程中发现全局堆有些问题）。</p></div></div></div>
<h3 id="边界分割">2.2 边界分割</h3>
<p>​ 之前在做点云相关工作的时候，知道：</p>
<blockquote>
<p>LaserScan内部的点都是具有方向性的，可根据两个点形成线段的法向量判定面向激光器与背向激光器的scan</p>
</blockquote>
<p>​ 和Volume 2D一样，我也不希望太多无效的边界参与投影过程，进行“Back
Culling”理论上可以减少一半的计算量（障碍物面向以及背向光源的部分正常来说各占一半）。故在做边界分割时，只保留面向光源边对应的点。</p>
<p>​
此外由于边界是使用vector进行顺序保存的，存在以下的几种情况需要考虑：</p>
<p><img src="/2021/08/02/Volume2D-Shader-Pro/cases.PNG"></p>
<center>
Figure 1. 三种不同的情况
</center>
<div class="tabs" id="fourth-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#fourth-unique-name-1">最简单的情形</a></li><li class="tab"><a href="#fourth-unique-name-2">循环添加1</a></li><li class="tab"><a href="#fourth-unique-name-3">循环添加2</a></li></ul><div class="tab-content"><div class="tab-pane active" id="fourth-unique-name-1"><p>​
最简单的显然就是：需要添加的边从front()或者中间位置开始，最多需要添加到back()处的点。这种情况下可以直接遍历添加，无需下标循环。</p></div><div class="tab-pane" id="fourth-unique-name-2"><p>​
第二种情况在开始撰写代码时考虑到了，觉得可能会有这种需要从front()到back()循环连接的情况。所以一开始设计Edge类就使用了双端队列（真的号用）。因为已知：同一个Object上由于中间有不可视（背向光源）的段，可能会将一条完整的边界分割为若干段面向光源的edges，那：front()处加入的点留在对应的edge种，而back()对应的edges则需要反向加入到front()对应edge的头部。也就像这样：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (Edge::const_reverse_iterator rit = to_add.<span class="built_in">crbegin</span>(); rit != to_add.<span class="built_in">crend</span>(); rit++)</span><br><span class="line">	front.<span class="built_in">push_front</span>(*rit);</span><br></pre></td></tr></table></figure></div><div class="tab-pane" id="fourth-unique-name-3"><p>​
第三种情况开始没有考虑到（不周啊），头部只有一个点加入。我的逻辑是不会保存孤立点的（形成Edge至少要两个点），而如果front()确实应该加入，但遍历时，front()联系的边都是背向边，那么可能会错误地丢弃front()。最后是多加入了几个判断才完成这部分。</p></div></div></div>
<h3 id="内外投影">2.3 内外投影</h3>
<h4 id="内外投影简介">2.3.1 内外投影简介</h4>
<p>​ 已知，我的算法对于Edge的管理基于类Object，其逻辑是：</p>
<ul>
<li>内投影：首先选择离光源最近的物体，计算该物体内部的遮挡（内部的形状复杂时）</li>
<li>外投影：此物体如何影响别的物体，如何判定遮挡关系</li>
</ul>
<p>​
为什么要区分内外投影呢？内投影与外投影有什么关系呢？在我最初的构想中，区别挺大的，但仔细思考后发现，内外都会有如下的情况发生：</p>
<p><img src="/2021/08/02/Volume2D-Shader-Pro/proj.PNG" style="zoom:67%;"></p>
<center>
Figure 2. 两种内部遮挡情况
</center>
<p>​
尤其是第一种，开始时我认为第一种情况是不会出在内投影的情况中的，我开始认为：内部不会有切分一条边为两条的情况。（我对应的切分函数<code>breakEdge</code>开始是给外部投影实现的），但事实上是，都有可能。</p>
<h4 id="两个设计">2.3.2 两个设计</h4>
<h5 id="proj_ids">proj_ids</h5>
<p>​
proj_ids是每一个Edge都携带的结构，是一个<code>std::pair&lt;int, int&gt;</code>。使用这个pair可以快速查找，此edge有哪些是需要参与后续内外投影的点。示意图如下：</p>
<p><img src="/2021/08/02/Volume2D-Shader-Pro/examples.PNG"></p>
<center>
Figure 3. proj_ids 使用
</center>
<p>​
图中蓝色点是投影形成的点，在判断外部遮挡时，显然应该由外侧点（意味着范围更大）来进行投影（也就是红色点）。也就是说，蓝色点只保存，不参与后续的投影，但是红色点与后续投影有很大的关系。蓝色点不参与计算可以减少部分计算负担。</p>
<h5 id="eigenvector3d">Eigen::Vector3d</h5>
<p>​
为什么不好好地使用Eigen::Vector2d，反倒要使用Vector3d，保存一个角度？首先我对问题做了一个这样的假设：</p>
<blockquote>
<p>我们的每一个edge，上面每一个点的角度（相对于观测点的反正切角度）都不同，并且由于做了背面剔除，在非奇异（atan函数角度从<span class="math inline">\(-\pi\)</span>到<span class="math inline">\(\pi\)</span>的奇异跃迁）情况下，是一个按角度递增的数组。存在奇异的情况下，是一个旋转数组，front()必然大于back()</p>
</blockquote>
<p>​
顺序化或者旋转顺序化的数据结构可以使用二分查找或是旋转数组二分查找，在障碍物表面特别不平（比如激光点云）时，可以显著加快交点搜索速度。此处我们使用旋转数组二分查找，查找投影关系：</p>
<ul>
<li>主投影边src上的点，如何投影到被投影边dst上，src的front() / back()
角度对应到dst的哪两个点之间？</li>
<li>使用这两个点以及已知的src投影光线，进行交点计算</li>
</ul>
<h4 id="主要函数-projedge2edge">2.3.2 主要函数 projEdge2Edge</h4>
<p>​
<code>projEdge2Edge</code>是用于投影的主要函数，此函数适用于内外投影。其主要逻辑是：</p>
<div class="note info"><p>首先规定：主投影边（产生遮挡的边）为src，dst则为被遮挡的边。一般来说，主投影边的min_dist（内部点到光源的最小距离）会比dst的min_dist更小，但是也有例外。见下图。</p>
</div>
<center>
<img src="/2021/08/02/Volume2D-Shader-Pro/special.PNG" style="zoom:50%;">
</center>
<center>
Figure 4. 按照最小距离建立堆产生的问题
</center>
<p>​
上图首先选中更长的边（蓝色线连接的长边），因为最小距离长边对应最小（观测点选得好就会这样）。那么场边会先于两个实际上应该判定为更近的小障碍物进行投影，这样就会出现问题。比如：</p>
<p><img src="/2021/08/02/Volume2D-Shader-Pro/Screenshot from 2021-08-02 02-13-46.png" style="zoom:60%;"></p>
<center>
Figure 5. 边异常消失问题
</center>
<p>​
可能原因是，由于开始的实现是：只要dst在src的角度范围内（角度上完全覆盖），那么dst就会被设为valid
= false（完全覆盖不需要再投影）。但是如果src选错，就会出现如上问题。</p>
<p>​ 本函数的逻辑为：</p>
<ul>
<li>首先判定src可用投影点数为（proj_ids中有多少个大于等于0者），如果有两个，可能出现breakEdge的情况（投影产生新的Edge）</li>
<li>如果只有一个可用点，需要判定（实际逻辑比下面简介的复杂得多，因为情况太多了）：
<ul>
<li>src /
dst首尾两点到观测点的连线夹角是否小于90度？不小于则可能是反方向的障碍物，不应该参与</li>
<li>判定src是否完全覆盖dst。为了避免atan角度奇异性，这里使用了基于内积的相对判定方法。具体实现不讲了。</li>
<li>如果可能存在完全覆盖，需要反向筛查（查找dst首尾两点会被src内部那两对点“夹住”），如果存在这样的点对，才能认为是完全覆盖的。</li>
</ul></li>
<li>根据计算结果求解交点（省略了很多逻辑，不想讲，逻辑太复杂了，包括奇异处理，裕量处理，一些意想不到的情况）</li>
</ul>
<h4 id="交点求解">2.4 交点求解</h4>
<p>​
求解两对点对应的两条直线的交点，只需要一些数学上的处理。首先我们知道，不能使用斜截式，因为
<strong><u>在本问题中，可能存在斜率无穷大的直线，导致病态</u></strong>。而另一方面，我们知道线段上一点可以使用线段的法向量表示：</p>
<blockquote>
<p>直线上一点(x, y)到直线上已知一点<span class="math inline">\((x_0,y_0)\)</span>的向量会垂直于法向量</p>
</blockquote>
<p>​ 那么由此，交点可以列两个方程。假设光线发射点为<span class="math inline">\((x_0, y_0)\)</span>，交点位置为<span class="math inline">\((x,y)\)</span>，障碍物的edges对应两点为<span class="math inline">\((x_1,y_1),(x_2,y_2)\)</span>，光线的方向向量为<span class="math inline">\((v_x,v_y)\)</span>那么有： <span class="math display">\[
\begin{align}
&amp; (u_x,u_y)=(x_1-x_2,y_1-y_2) \\
&amp; (-v_y,v_x)\cdot(x-x_0,y-y_0)=0\tag{eq 1}\\
&amp; (-u_y,u_x)\cdot(x-x_1,y-y_1)=0\tag{eq 2}
\end{align}
\]</span> ​ 由(eq 1), (eq 2)组成两个方程，可以解出<span class="math inline">\((x,
y)\)</span>，只需判定对应齐次方程系数矩阵行列式是否很小（不可逆），如果不可逆，直接返回被投影点更近的那个点，如果可逆，那么解出的<span class="math inline">\((x,y)\)</span>就是结果。</p>
<h4 id="其他">2.5 其他</h4>
<p>​
还有很多！逻辑是真的很复杂，情况很多，我不想写这个，要一一解释太麻烦了。</p>
<hr>
<h2 id="iii.-效果一览">III. 效果一览</h2>
<video src="cv_output.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<center>
Video 1. 不规则障碍物体积光算法效果
</center>
<video src="cv_output2.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<center>
Video 2. 更多障碍物下的表现
</center>
<p>​ 边界计算结果使用截图的方式记录了一下：</p>
<p><img src="/2021/08/02/Volume2D-Shader-Pro/Screenshot%20from%202021-08-02%2016-49-37.png"></p>
<center>
Figure 6.
边界计算（demo1），图中绿色点是观测点，黄色是计算最后需要绘制的边
</center>
<p><img src="/2021/08/02/Volume2D-Shader-Pro/Screenshot%20from%202021-08-02%2016-50-01.png"></p>
<center>
Figure 7.
边界计算（demo2），图中绿色点是观测点，黄色是计算最后需要绘制的边
</center>
<hr>
<h2 id="iv.-库的使用">IV. 库的使用</h2>
<p>​ 本项目已经上传至Github，见Github库<a href="https://github.com/Enigmatisms/Volume">[Enigmatisms/Volume]</a>，里面有非常详细的说明，不过是英文的。怎么说呢，关于这个问题，我想到了一个绝妙的解决办法，可惜今晚很困，写不完（老费马了）。如果有细节方面的疑问，欢迎直接联系我。</p>
<hr>
<h3 id="reference">Reference</h3>
<p>​ 关于<code>EdgeCompFunctor</code>这个还是有必要说一下的：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">EdgeCompFunctor</span>&#123;</span><br><span class="line">    <span class="built_in">EdgeCompFunctor</span>(<span class="type">const</span> std::vector&lt;Edge&gt;&amp; _egs): <span class="built_in">egs</span>(_egs) &#123;&#125;</span><br><span class="line">    <span class="type">const</span> std::vector&lt;Edge&gt;&amp; egs;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">operator</span><span class="params">()</span> <span class="params">(<span class="type">const</span> <span class="type">size_t</span>&amp; e1, <span class="type">const</span> <span class="type">size_t</span>&amp; e2)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> egs[e1].min_dist &gt; egs[e2].min_dist;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>​
std::priority_queue接收一个自定义的比较函数，由于C++高版本的匿名函数特性很不错，一般都使用匿名函数来填充这个自定义比较函数，但也可以使用较为老式的Functor写法。而此处，我更改了在Volume2D算法中使用的“保存Edge*”的实现，因为已知保存在堆中的指针没有办法正确指向vector。原因我哥已经帮我解释了：</p>
<blockquote>
<ul>
<li>因为vector的内部存储的地址是会变的</li>
<li>比如resize的时候 它会构造一个新的数组 把原来的数据复制进去
然后销毁之前的数组 这样地址就变了</li>
<li>如果直接存指针 是会失效的</li>
</ul>
</blockquote>
<p>​
这种携带了一个常引用，初始化EdgeCompFunctor时需要传入edges这个vector常应用的写法来自于<a href="https://stackoverflow.com/questions/8372918/c-std-list-sort-with-custom-comparator-that-depends-on-an-member-variable-for">[stackoverflow/C++
std list sort with custom comparator that depends on an member variable
for the object instance]</a>。显然，保存索引比保存指针优雅多了。</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>algos</tag>
      </tags>
  </entry>
  <entry>
    <title>被SCAE折磨的一天</title>
    <url>/2021/07/18/%E8%A2%ABSCAE%E6%8A%98%E7%A3%A8%E7%9A%84%E4%B8%80%E5%A4%A9/</url>
    <content><![CDATA[<h1 id="scae">SCAE</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​ 在复现完CapsNet第一版之后，想复现这篇论文（第三版CapsNet：<a href="https://arxiv.org/abs/1906.06818"><em>Stacked Capsule
Autoencoders, Adam R. Kosiorek, et
al.</em></a>）。复现的基础是看懂，理解其意义。本篇博客为我读这篇论文时的一些思考，其中当然还有些(很多)不够透彻的地方。要是完全透彻了我估计就可以直接动手复现了。</p>
<p><img src="/2021/07/18/%E8%A2%ABSCAE%E6%8A%98%E7%A3%A8%E7%9A%84%E4%B8%80%E5%A4%A9/2.PNG"></p>
<center>
Figure 1.Stacked Capsule Autoencoders网络结构图
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-ccae">II. CCAE</h2>
<h3 id="ccae结构">2.1 CCAE结构</h3>
<p>​ 很顶啊，CCAE上来就使用Set
Transformer进行了特征学习，变形金刚牛逼：</p>
<ul>
<li>输入一堆n维向量，输出是一堆object
capsules（k个）。这个capsules包含：
<ul>
<li>object—viewer 3 * 3图像仿射变换（9）</li>
<li>feature向量（未知）</li>
<li>此capsule表示的物体是否存在的概率（1）</li>
<li><strong><u>此部分为Transformer输入输出，n输入-&gt;k胶囊输出</u></strong></li>
</ul></li>
<li>每个胶囊都会进行内部的MLP，这个MLP将利用自己的特征向量（比如自己是<span class="math inline">\(\pmb{c}_k\)</span>）去推测，N个候选的part（这个part就是物体部件）的相关信息:
<ul>
<li>此后的MLP学习的是：部件 / 物体的变换，而已经学到的有：物体 /
观测者（也就是部件在图像上的pose），那么部件 /
观测者的位姿变换也就有了。</li>
<li>学习条件概率（<strong><u>这个涉及到CCAE高斯混合体的理解</u></strong>），<span class="math inline">\(a_{k, n}\)</span></li>
</ul></li>
</ul>
<p><span class="math display">\[
\begin{equation}
a_{k, n}=P(p_n|cap_k)
\end{equation}
\]</span></p>
<p>​ 也即，一个object capsule k存在时，部件n存在的概率。而之前在Set
transformer实际上学习了，cap
k存在的概率，那么实际上结合起来就可以得到联合概率。</p>
<p>​ 我感觉这里做了一个很妙的最大后验估计操作，理解一下：</p>
<ul>
<li>使用高斯混合模型，那么其中的高斯分布参数：均值是原有高斯分布均值经过OV,OP位姿变换得到的，而协方差已经经过MLP学习到了。我们可以通过均值和协方差写出：</li>
</ul>
<p><span class="math display">\[
\begin{equation}
p(\pmb{x}_m|k,n)=N(\pmb{x}_m|\mu_{k,n},\lambda_{k,n})
\end{equation}
\]</span></p>
<p>​ 结合这个高斯混合 +
极大似然的意义，我们再来理解一下均值和方差以及其对应下标的意义。</p>
<h3 id="ccae-mle">2.2 CCAE &amp; MLE</h3>
<p>​ 对于论文中的公式(5): <span class="math display">\[
\begin{equation}
p(\mathbf{x}_{1:M})=\prod_{m=1}^M\sum_{k=1}^K \sum_{n=1}^{N}
\frac{a_ka_{k,n}} {\sum_i\left(a_i\sum_ja_{i,j}\right)}
p(\mathbf{x}_m|k,n)
\end{equation}
\]</span> ​ 个人的理解是，对于给定的一张图像：</p>
<ul>
<li>一方面，我们可以通过Set Transformer 求出k个object
capsules，再由这学习到的k个capsule组成n个物体部件，也就是学习一些隐含信息</li>
<li>另一方面，我们可以根据隐含信息重构物体，我们认为物体是由抽象的几个部件组成的，部件的生成与object
capsules也有一定关系。那么部件以及object capsules产生的贡献可以被写为
<span class="math inline">\(p(\pmb{x}_m|k,n)\)</span>，换句话说，就是：我从图像（训练集）上学习出object
capsule给定为k且存在部件为n的情况下，为目标<span class="math inline">\(\pmb{x}_m\)</span>的概率。</li>
</ul>
<p>​
训练集可以看作是样本总体分布的抽样，那么在根据样本进行学习时，可以使用极大似然估计的方法：<strong><u>使得抽样（训练集）出现的概率最大</u></strong>，也就是：
<span class="math display">\[
\begin{equation}
\max P(X)=\max\prod_{i=1}^nP(\pmb{x}_i)
\end{equation}
\]</span> ​ 在这里<span class="math inline">\(p(\pmb{x}_m|k,n)\)</span>只是条件概率，我们需要去掉条件部分，所以需要根据之前Set
Transformer以及MLP的输出，可以得到： <span class="math display">\[
\begin{equation}
\frac{a_ka_{k,n}}{\sum_i\left(a_i\sum_ja_{i,j}\right)}=\frac{p(k,n)}{\sum_i\sum_jp(i,j)}=p(k,n)
\end{equation}
\]</span> ​
那么公式5很容易从左边转化为右边。而左边和右边相等的意义是？</p>
<ul>
<li>左式是我们的目标函数（极大似然估计需要最大化的联合概率分布，由于训练集是独立同分布的）</li>
<li>右式是由特征提取 / 训练 的输出构成的：
<ul>
<li><span class="math inline">\(p(\pmb{x}_m|k,n)\)</span>是高斯混合体，高斯分布的参数一方面由Set
Transformer的OV /
MLP的OP对原均值进行线性变换组成，另一方面则是MLP直接输出的方差值。GM模型可以是多个高斯混合在一起形成的，所以其参数很多。</li>
<li><span class="math inline">\(a_k,a_{k,n}\)</span>是由Set Transformer
/ MLP分别输出的。</li>
</ul></li>
<li>那么右式由于是网络输出的结果，是存在网络参数的，可以对输出进行一定的loss变换之后，对其求导以调整网络参数。</li>
</ul>
<p>​ part capsules是什么？输入的原始数据向量就是part
capsule，但是为什么叫part
capsule？可能在后续的论文中会提到，下面第一次提到 part
capsules，但是貌似是由别的东西来“替代”真正的 part capsules
来进行说明：</p>
<div class="note info"><p>All input points (which take the role of part capsules).</p>
</div>
<hr>
<h2 id="iii-pcae">III PCAE</h2>
<p>​ PCAE用于获得part templates，也就是学习模板。比如说：</p>
<ul>
<li>我们先通过encoder（结构是CNN特征提取 + Attention
Pooling，所以Attention思想你还是得王权搞明白啊）从图像中学习一些表征（part
capsule）出来：
<ul>
<li>pose，比如旋转 / 缩放 / 斜切 /
平移，出现的概率，特征向量（<strong><u>独特属性</u></strong>）</li>
<li>特征向量可以用于推测模板的颜色等等抽象信息（MLP），比如从特征向量中，直接获得模板输出的三通道强度（也就是模板图像本身的值）</li>
<li>得到模板之后，通过pose进行仿射变换</li>
<li>注意模板本身会携带一个alpha通道，相当于我们搞PS的时候，为了使图抹更加真实，调整画笔透明度，允许不同的templates叠在一起。</li>
<li>图像上每一点的输出，实际上都是不同的part按照概率 +
alpha通道结合得到的（相当于一个decoder操作），使之与原图接近，或者可以说成是：对原图的极大似然估计。</li>
</ul></li>
</ul>
<p>​ 那么一套流程下来，实际上我们要得到是一个可以生成part capsule的auto
encoder，之后的decoder层个人认为：只是用于计算loss或者产生一个part
capsule生成好坏的evaluation方法。以上的文字叙述部分已经把PCAE的思想概括了一下，这是个人开始的理解，其中存在一些偏差：</p>
<div class="note warning"><p>此论文中的Template不是学出来的？使用的是Fixed
templates？（4通道）</p>
</div>
<p>​ 就是说我对现有的part
templates，学习变换（pose），独有特征（比如MLP输出颜色），出现概率。虽然我感觉论文的这三句话有点冲突：</p>
<blockquote>
<p>I. while the decoder <strong><u>learns an image template</u></strong>
<span class="math inline">\(T_m\)</span> for each part</p>
<ol start="2" type="I">
<li><p>SCAE under-performs on CIFAR10, which could be because of using
<strong><u>fixed templates</u></strong>, which are not expressive enough
to model real data</p></li>
<li><p>Training the PCAE results in <strong><u>learning
templates</u></strong> for object parts</p></li>
</ol>
</blockquote>
<p>​
所以开始时<strong><u>晕了</u></strong>，到底是学出来的还是给定的？个人感觉学出来的templates肯定是更加不错的（只要学得好就行，作者自己也承认）。</p>
<hr>
<h2 id="iv.-ocae">IV. OCAE</h2>
<h3 id="ocae作用">4.1 OCAE作用</h3>
<p>​ OCAE：通过已经学习到的part
capsule去组成object（这个和PCAE的decoder区别在哪？）。OCAE与之前的CCAE很类似，但是它受到了来自part
capsule的概率影响：</p>
<p>​ OCAE与CCAE结构类似，也存在Set Transformer的encoder，那么part
capsules输出的概率会影响encoder，使得Transformer忽略一些没有出现的输入（或者说part）。part
capsules输出的概率会使得log
likelihood（在MLE过程中）进行幂加权，使得概率小者造成的影响小</p>
<p>​
个人感觉，由于OCAE结构上很类似CCAE，CCAE的输入是简单的星星点，那么OCAE应该是CCAE的一般化：</p>
<blockquote>
<p>We first encode all input points (which take the role of part
capsules)</p>
</blockquote>
<p>​ 所以这里说的就是这个意思，CCAE是：</p>
<ul>
<li>输入是简单点而非part capsules的OCAE</li>
<li>一些part capsule 概率加权不存在的OCAE</li>
</ul>
<p>​ CCAE最后求出了part
capsule的似然（作为MLE的优化目标），而PCAE自己也有关于自己生成的part
capsule的似然。</p>
<h3 id="ocae-ccae-联系谈">4.2 OCAE / CCAE 联系谈</h3>
<p>​
CCAE部分，作者已经说了，CCAE的输入是简单的星座点。而一般化的OCAE，输入是上层PCAE的part
capsule输出：</p>
<blockquote>
<p>In the <strong><u>first stage</u></strong>, the model predicts
presences and poses of part templates directly from the image and tries
to reconstruct the image by appropriately arranging the templates. In
the <strong><u>second stage</u></strong>, SCAE predicts parameters of a
few object capsules, which are then used to reconstruct part poses.
---<em>From Abstract</em></p>
</blockquote>
<p>​ 个人的理解就是：PCAE为first
stage，其目的是得到templates，学习templates的目标函数通过<em>"reconstruct
the image"</em>来完成。OCAE就是接收stage I输出的second
stage，通过学习object又来反推part pose？</p>
<p>​
<strong><u>所以明确目的是多么重要！</u></strong>PCAE并没有得到用于MLE的log
likelihood，论文中的公式(9),(10)都是为了构建PCAE的loss（重构图像的重构loss），可以这么说：</p>
<ul>
<li>一个普通的CNN分类网络，其输出结构可以用于直接计算loss，我们使用的也就是其输出结果</li>
<li>而PCAE，输出结果需要经过一定变换（reconstructed
image），才能用于构建loss，而用于构建loss的部分，并不是我们使用的那部分。PCAE的目的是获得一个好的image
template。</li>
<li>之前的部分已经说过了，CCAE（特殊化的OCAE）：
<ul>
<li>首先经过Set Transformer学习K个object capsules。</li>
<li>每个object
capsule都会使用MLP（M个MLP），学出组成这个object的M个part，但这个学习过程不涉及到具体的part
capsule输出，输出的是：OP，条件概率以及协方差，用于获得GMM的分布</li>
</ul></li>
</ul>
<h3 id="ocae的作用">4.3 OCAE的作用</h3>
<p>​
为什么OCAE又要重构part？它具体重构了part的什么部分？达到了什么效果？这是本篇论文的一个重点问题，作者在一行脚注里这么说：</p>
<blockquote>
<p>Discovered objects are <em>not</em> used top-down to refine the
presences or poses of the parts during inference. However, the
derivatives backpropagated via OCAE <strong><u>refine the lower-level
encoder</u></strong> network that infers the parts.</p>
</blockquote>
<p>​ 可能可以这么理解：</p>
<ul>
<li>PCAE学出来的part
capsules，需要经过检验。这样的part组成object到底合不合适？这种合适度通过likelihood来衡量。</li>
<li>如果说，part
capsules直接重建图像，是一种直接的具体的metrics，OCAE对应的likelihood就是抽象的metrics。如果要用极大似然的思想来解释：</li>
</ul>
<blockquote>
<p>It learns to discover <strong><u>further structure</u></strong> in
previously identified parts.</p>
</blockquote>
<p>​ 此处的衡量metrics是part likelihood，是通过：</p>
<ul>
<li>与object
capsules有关的一个条件概率分布（比如CCAE中的高斯混合分布），与object学习过程中的其他概率组成，相当于是：MLE在优化的过程中，只优化<span class="math inline">\(p(x|\theta)\)</span>的参数<span class="math inline">\(\theta\)</span>部分，而此处由BP，会将MLE的“抽样”<span class="math inline">\(x\)</span>一起进行优化，使得<span class="math inline">\(p(x|\theta)\)</span>最大。</li>
<li>虽然我感觉这样就不是MLE了，但可能可以这么理解吧：我学习的分布，参数是<span class="math inline">\(\theta\)</span>，已经能很好地表示真实情况（总体分布）了，考虑到我如此强而输入有一定噪声，那输入也进行一定的修改吧，因为学到的分布觉得你的输入有些问题。这MLE可以说是很另类的了。</li>
<li>所以总结起来就是：通过一层抽象的学习，MLE同时优化object
capsule生成网络参数（<span class="math inline">\(\theta\)</span>）也反过来优化输入（输入就是part
capsules）</li>
</ul>
<hr>
<h2 id="v.-sparse-regularization">V. Sparse Regularization</h2>
<p>​ 论文中说，直接使用Capsules结构，容易导致：</p>
<ul>
<li>object capsules滥用，导致难以训练 +
模型描述力下降（显然，有些object不存在于一些图片中，但是还要用对应object强行解释，这是不行的）
<ul>
<li>与之相对的，我们希望每个图像能有特定的少量object
capsules（以及相应的part capsules）来描述</li>
</ul></li>
<li>mode collapse，只使用特定的一些object，发生过拟合。
<ul>
<li>与之相对的，我们希望对于整个训练集，object
capsules尽量都能用上（否则相当于是出现了训练集label分布不均的情况）</li>
</ul></li>
</ul>
<p>​
那么，作者设计了两个正则化项，用<strong><u>期望</u></strong>的思想很好理解了：</p>
<ul>
<li><span class="math inline">\(\bar{u}_k\)</span>是第k个object
capsule的出现概率总和（对不同的样本）：</li>
</ul>
<p><span class="math display">\[
\begin{align}
&amp; \bar{u}_k=\sum_{b=1}^M a_{b,k}^{\text{prior}} \label{uni_b}\\
&amp; \bar{u}_b=\sum_{k=1}^K a_{b,k}^{\text{prior}} \label{uni_k}\\
\end{align}
\]</span></p>
<p>​ 则我们希望，不同的类别能用上尽可能一样数量的object
capsules，假设有C类，K个object capsules，那么每一类可以用：<span class="math inline">\(K/C\)</span>个capsules来描述。而由于对于K个capsules，每个出现的概率是<span class="math inline">\(a_k^{\text{prior}}\)</span>，每一个capsule出现的期望（因为是两点分布）就是概率本身，那么根据期望的运算，一个minibatch内B个训练用例，期望capsule数量应该是公式<span class="math inline">\(\eqref{uni_b}\)</span>。则我们令<span class="math inline">\(\bar{u}_k\leftrightarrow
K/C\)</span>两者足够接近即可。</p>
<p>​ 另一方面，我们希望：每个用例能仅用部分object
capsules来描述。假设总体不同class均匀分布，那么一个minibatch内部，每个类别有<span class="math inline">\(B/C\)</span>类，那么每个用例object
capsules的期望实际上就是公式<span class="math inline">\(\eqref{uni_k}\)</span>定义的概率和，那么可以得到论文中的第一个稀疏性先验。</p>
<p>​
后验稀疏性很好理解，可以认为是LDA思想：类内熵最小化，类间熵最大化（也即类内的后验分布趋于一致，类间趋于不同）。</p>
<hr>
<h2 id="todos">TODOs</h2>
<p>​
本论文看第一遍之后，感觉实现部分很模糊，论文图6感觉好像也非常粗略，前面的Attention机制也没有特别体现（只在Part
Capsules到Object Capsule时有），但是前面所说的 Part
Capsules特征提取部分应该也包括了Attention-based
pooling。梯度阻断机制也让我觉得有点奇怪，templates方面也有相关问题没理解。那么在过段时间重读这篇论文时，希望能够在这几个问题上得到更好的理解：</p>
<details class="note primary"><summary><p>需要进一步理解的问题们：</p>
</summary>
<ul>
<li><p>Attention都在什么地方使用到了？为什么schematic图中看起来只有一处？</p>
<ul>
<li>个人认为只是没写出来罢了，只要是capsule
autoencoders就逃不开attention机制，内部会有一个类似CCAE的（attention +
MLP）实现，当然对于part capsules来说，可能更加复杂。</li>
</ul></li>
<li><p>Capsule在schematic图里面是输出还是网络层？个人的感觉应该是网络层，Part
Capsule之上还stack了很多个Object Capsules，但是具体结构为何？</p></li>
<li><p>Templates为什么没有来自CNN或者Part Capsules的梯度流？</p>
<ul>
<li>个人感觉：Transformed
templates可以组成图像，而由于capsules携带transformation信息，templates应该可以直接去transform得到，但是为何templates到
tf templates也有梯度？</li>
<li>既然Templates被标注为Trainable
variables，为什么说templates是fixed的？</li>
<li>Template的color是学出来的，而color可以被认为是三通道的图像，那么templates在图像上的值不也就是学出来的了吗？</li>
</ul></li>
<li><p>Fixed Object-Part Relations是什么？在哪里起作用？</p></li>
<li><p>PCAE /
OCAE的作用，虽然现在感觉自己懂了，但是总有种说不上来的“不透彻感”。</p></li>
</ul>

</details>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title>Dynamic Routing Between Capsules 复现</title>
    <url>/2021/07/18/Dynamic-Routing-Between-Capsules-%E5%A4%8D%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="capsules-network">Capsules Network</h1>
<hr>
<p>​ 上一次看这篇论文：<a href="https://arxiv.org/abs/1710.09829"><em>Dynamic Routing Between
Capsules</em></a>
的时候，Pytorch技术还很菜，不是特别熟练，被矩阵计算的维数问题搞傻了，写得很痛苦，loss没写完就放弃了。这次在重新读完论文之后，重新试着复现了一波，最后差点败在一个softmax的执行维度上（可以说很奇异了）。第一版caps
net网络结构非常简单，对应的evaluation / experiments也很简单。实现见<a href="https://github.com/Enigmatisms/CapsNet">[Github🔗Enigmatisms/CapsNet]</a></p>
<table>
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;"><img src="/2021/07/18/Dynamic-Routing-Between-Capsules-%E5%A4%8D%E7%8E%B0/G_1101.jpg" alt="G_1101" style="zoom:150%;"></th>
<th style="text-align: center;"><img src="/2021/07/18/Dynamic-Routing-Between-Capsules-%E5%A4%8D%E7%8E%B0/G_1151.jpg" alt="G_1151" style="zoom:150%;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">根据digital capsule重建（MNIST 7
epochs）</td>
<td style="text-align: center;">根据digital capsule重建（MNIST 7
epochs）</td>
</tr>
</tbody>
</table>
<span id="more"></span>
<hr>
<p>​ 等待填坑</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title>编译原理小知识</title>
    <url>/2021/07/16/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%B0%8F%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<h1 id="为什么我不能乱链接">为什么我不能乱链接</h1>
<h2 id="i.-缘从何起">I. 缘从何起？</h2>
<p>​
机队的小伙伴问了我一个问题，说是在一个<code>.hpp</code>文件中，定义了一个namespace，<code>.hpp</code>也有头文件保护，在namespace下也<strong><u>定义（声明
/
定义都在这个文件里）</u></strong>了几个函数（非类函数），<code>.hpp</code>文件中同时还有一个类的定义。那么自然这个文件会被至少两个<code>.cc</code>文件给include：</p>
<ul>
<li>类定义文件 / main函数所在的可执行文件</li>
</ul>
<p>​
结果编译的时候报了redefined的错误，说是namespace下面的函数重复定义了。小伙伴很疑惑。我也很疑惑，开始我觉得是不应该把定义写在<code>.hpp</code>中，但想到类函数好像可以这么做啊？作为一个没有学过编译原理的自动化学生（请问自动化学生都在学些啥啊？），感到疑惑，于是查了点资料。</p>
<span id="more"></span>
<hr>
<h2 id="ii.-编译单元">II. 编译单元</h2>
<p>​ 首先，一个名词：translation unit</p>
<blockquote>
<p>A translation unit is the basic unit of compilation in C++. It
consists of the contents of a single <strong><u>source
file</u></strong>, <strong><u>plus</u></strong> the contents of any
<strong><u>header files</u></strong> directly or indirectly included by
it, <strong><u>minus</u></strong> those lines that were ignored using
<strong><u>conditional preprocessing statements</u></strong>.</p>
</blockquote>
<p>​ 也即，一个translation
unit包含源文件，直接或者间接include的头文件以及排除通过头文件保护排除的文件。</p>
<p>​ 而编译形成最终的可执行文件需要通过：</p>
<ul>
<li>编译+汇编（分别编译，汇编形成各自的机器指令文件）</li>
<li><strong><u>链接</u></strong>：多重符号，跨文件符号问题</li>
</ul>
<p>​ 而你现在的情况是：</p>
<ul>
<li>main.cc 文件（主函数，将会产生一个translation unit）</li>
<li>xxx.cc 文件（类定义，将会产生一个translation unit）</li>
</ul>
<p>​ 最终在链接阶段会将两个translation
unit<strong><u>内容合并</u></strong>（链接过程工作的通俗说法）。但是很不巧，你的namespace下的函数<strong><u>同时进入了两个</u></strong>translation
unit中。</p>
<p>​ 也就是在两个translation unit中，各被编译一次。如果两个translation
unit分属不同的可执行文件（不被链接到一块儿去），那还好说。但是现在他们被链接到一起去了，也就形成了重定义，两个translation
unit中各有一份定义。</p>
<p>​
也就是说，最好的解决方案是：<strong><u>只在hpp中声明函数，在cc中定义函数，这样不会错。</u></strong></p>
<hr>
<h2 id="iii.-头文件保护">III. 头文件保护？</h2>
<p>​ 头文件保护作用与单一的translation unit中。也即，比如：</p>
<ul>
<li><code>b.h</code> 中</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;a.h&quot;</span></span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<ul>
<li><code>test.c</code> 中</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;a.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;b.h&quot;</span></span></span><br></pre></td></tr></table></figure>
<p>​
那么两次include导致<code>a.h</code>两次代码复制到<code>test.c</code>，将由头文件保护的存在而不被编译两次。头文件保护和跨translation
unit的链接没有关系，它只是防止一个translation
unit内部，不因为多重间接include导致重定义。</p>
<p>​ 不仅是namespace不行，直接裸函数定义在 <code>.hpp</code>
中，之后又被多重引用 +
链接到同一个可执行文件中，也会导致问题，比如我试了试：</p>
<ul>
<li><code>name.hpp</code> 内容如下</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> __NAME_HPP</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __NAME_HPP</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">sub</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a - b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span>  <span class="comment">//__NAME_HPP</span></span></span><br></pre></td></tr></table></figure>
<ul>
<li>此后在<code>test.cc</code> , <code>main.cc</code>两个文件都
include<code>name.hpp</code>，进行编译，输出结果如下：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="language-bash">&gt;&gt; g++ ./main.cc ./test.cc -o main.exe</span></span><br><span class="line"></span><br><span class="line">~\ccMq7p5P.o:test.cc:(.text+0x0): multiple definition of `sub(int, int)&#x27;</span><br><span class="line">~\cces7mzx.o:main.cc:(.text+0x0): first defined here</span><br><span class="line">collect2.exe: error: ld returned 1 exit status</span><br></pre></td></tr></table></figure>
<p>​ 也直接报错了。</p>
<hr>
<h2 id="iv.-class可以在hpp内定义">IV. class可以在hpp内定义</h2>
<p>​ class可以在 hpp 内定义函数，同样都是被<code>定义.cc</code>，
<code>主函数.cc</code>include，为什么类函数可以过编译？</p>
<p>​ 因为类函数有<strong><u>特殊性</u></strong>：声明 和
定义放在一起时，函数<strong><u>自动内联</u></strong>（inline）。inline函数在多重定义存在时，只会处理inline声明位置的定义。</p>
<p>​ 所以，另一种解决方案是：在namespace下的函数前面加上
<strong><u>inline</u></strong>。但是我个人非常不建议这么做。</p>
]]></content>
      <categories>
        <category>learning</category>
        <category>debugs</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>编译原理</tag>
      </tags>
  </entry>
  <entry>
    <title>滤波＆卡尔曼</title>
    <url>/2021/05/31/%E6%BB%A4%E6%B3%A2%EF%BC%86%E5%8D%A1%E5%B0%94%E6%9B%BC/</url>
    <content><![CDATA[<h1 id="filtering-kalman">Filtering &amp; Kalman</h1>
<hr>
<h2 id="i.-引入">I. 引入</h2>
<p>​
2021赛季充分认识到滤波的美妙之处。虽然只前学了DSP，但是在进行实际系统控制的时候，很少有意识地进行滤波或者平滑。2020赛季中设置过一个静止目标滑动平均，在此前没有做过非常大量的滤波。</p>
<p><img src="/2021/05/31/%E6%BB%A4%E6%B3%A2%EF%BC%86%E5%8D%A1%E5%B0%94%E6%9B%BC/disp-1622393689154.png"></p>
<center>
Figure 1. 单方向ARKF滤波预测
</center>
<p>​ 本文是对近段时间使用的滤波方法进行的一个比较肤浅的总结，包括：</p>
<ul>
<li>ARKF（自适应抗差KF）</li>
<li>MEE &amp; CMEE（约束最小误差熵KF）</li>
<li>ESKF（Error State KF）</li>
</ul>
<span id="more"></span>
<hr>
<h2 id="ii.-arkf">II. ARKF</h2>
<h3 id="理论分析">2.1 理论分析</h3>
<h4 id="抗差">2.1.1 抗差</h4>
<p>​
ARKF[1]是很老的工作了，大创答辩的时候老师还特地问我为什么要引那么老的文献（1999，比我还大）（小声：但人家简单有效啊）。我已经在<a href="https://enigmatisms.github.io/2021/04/03/%E4%BC%98%E9%9B%85%E7%BA%BF%E4%BB%A3%E4%B8%8E%E7%BE%8E%E5%A6%99%E4%BC%98%E5%8C%96/">[优雅线代与美妙优化]</a>一文中说了，卡尔曼滤波是怎么与最小二乘联系起来的。这里简单回顾一下：
<span class="math display">\[
\begin{equation}\label{lsp}
W(k){x}(k)+\xi(k)=Y(k)
\end{equation}
\]</span> ​ 其中<span class="math inline">\(W(k)\)</span>（实际是上面那篇博客中提到的<span class="math inline">\(X(k)\)</span>，但是<span class="math inline">\(X\)</span>用于表示非状态矩阵，容易与<span class="math inline">\(x\)</span>发生冲突）以及<span class="math inline">\(Y(k)\)</span>的意义直接看上面提到的博文吧。<span class="math inline">\(\xi(k)\)</span>则是状态转移噪声 /
观测噪声concatenation的白化变换。我们提到，KF实际上是根据<span class="math inline">\(\eqref{lsp}\)</span>进行MSE最小化的过程。</p>
<p>​
但是MSE在很多问题下的表现并不好，特别是外点很多的时候。想想在最小二乘直线拟合的时候，一个外点就能让直线拟合出来的参数变得比原来离谱很多，这是由于误差函数的性质决定的：MSE对偏差大的数据产生的cost是平方级别的cost，而Huber则是线性的cost。</p>
<center>
<img src="/2021/05/31/%E6%BB%A4%E6%B3%A2%EF%BC%86%E5%8D%A1%E5%B0%94%E6%9B%BC/huber.png" style="zoom:72%;">
</center>
<center>
Figure 2. Huber函数和MSE
</center>
<p>​
这就决定了Huber函数存在一定的外点鲁棒性，对于外点多的数据，Huber函数的KF将会更加稳定。但是很可惜，由于Huber函数的表达式比MSE复杂，并且原始Huber函数是存在非线性的（if判定，虽然导数以及原函数是连续的），我个人没有推出其解析解（我也没推，我也不会Mathematica），所以对于公式<span class="math inline">\(\eqref{lsp}\)</span>定义的“状态转移”，由于公式<span class="math inline">\(\eqref{lsp}\)</span>展开是： <span class="math display">\[
\begin{equation}\label{optim}
\begin{pmatrix}
I\\
H
\end{pmatrix}\breve{x}(k)=
\begin{pmatrix}
A\hat{x}(k-1)\\
z(k)
\end{pmatrix} +
\begin{pmatrix}
w(k)\\
v(k)
\end{pmatrix}=
\begin{pmatrix}
A\hat{x}(k-1)\\
z(k)
\end{pmatrix} + E(k)
\end{equation}
\]</span> ​ 其中'<span class="math inline">\(\breve{}\)</span>'表示先验，'<span class="math inline">\(\hat{}\)</span>'表示后验，我们需要估计的是公式<span class="math inline">\(\eqref{optim}\)</span>中的<span class="math inline">\(\breve{x}(k)\)</span>（也就是KF需要估计的当前状态，实际就是公式<span class="math inline">\(\eqref{lsp}\)</span>的<span class="math inline">\(x(k)\)</span>），那么<span class="math inline">\(x(k)\)</span>可以写为： <span class="math display">\[
\begin{equation}\label{optim2}
x(k)^*=\mathop{\arg \min}_{x(k)}\sum \Phi(y_i-w_i^Tx(k))
\end{equation}
\]</span></p>
<p>​ 此处，<span class="math inline">\(w_i^T\)</span>是公式<span class="math inline">\(\eqref{lsp}\)</span>中提到的矩阵<span class="math inline">\(W(k)\)</span>的第i行。<span class="math inline">\(\Phi(·)\)</span>是鲁棒核函数，此处可以为Huber。普通卡尔曼滤波则此处为<span class="math inline">\((·)^2\)</span>函数，平方则是存在闭式解的，甚至可以不用化为求和式，只需要简单用pseudo逆就可求出。</p>
<p>​ 而由于<span class="math inline">\(y_i,w_i\)</span>都是已知的，具有具体的意义，只剩下未知的待估计位姿<span class="math inline">\(x(k)\)</span>，那么只需要求解公式<span class="math inline">\(\eqref{optim2}\)</span>定义的优化问题即可。这步在Kalman滤波中称为：抗差（Robust）化，因为解抗差最小二乘问题得到的解将更加稳定。</p>
<h4 id="自适应">2.1.2 自适应</h4>
<p>​
朴素KF的噪声协方差不是自适应的，而是开始就设置好的。Q和R两个矩阵，一个代表状态转移噪声协方差，另一个代表观测噪声协方差，都是固定的（非自适应，固定就意味着高斯噪声假设）。这两个矩阵的意义比较明确：反映了不同的物理过程的噪声大小。比如：</p>
<ul>
<li>若要让结果倾向于数学模型（状态转移模型），那么状态转移噪声应该显著小于观测噪声。</li>
<li>如果要让结果倾向于观测（观测模型），那么观测噪声应该显著小于状态转移噪声。</li>
</ul>
<p>​ 但是实际使用中，关于【状态转移 /
观测两者谁更可靠】的问题是非常不好回答的。我可以凭借先验知识来判定，状态转移更好还是观测更好，但是这也仅限于“定性判定”，此后的KF甚至还需要进行调参，才能得到较好的收敛结果。此外，两个噪声协方差的固定性限制了我们可以处理的噪声种类（只能是高斯噪声），显然限制了KF在某些问题下的泛化。自适应的过程可以认为是：</p>
<div class="note info"><p>使得KF可以处理的噪声类型摆脱高斯噪声限制</p>
</div>
<p>​ 作者使用的是中值偏差（median deviation）。说实在的，这个median
deviation公式可以说是很奇怪了： <span class="math display">\[
\begin{equation}\label{med}
\hat{d}(k)=\text{median}\vert
\frac{r(i)-\text{median}(r(i))}{0.6745}\vert
\end{equation}
\]</span> ​ 其中，<span class="math inline">\(r(i)\)</span>是滑动窗口内的一个新息（innovation），其实就是偏差：<span class="math inline">\(z(i)-Hx(i)\)</span>。所以这做的是什么？相当于是：计算误差协方差时（尤其是方差计算），本身是可以通过标准差（standard
deviation）计算出来的，但是可以计算标准差的替代品（别的deviation）。而此处，新息的最优估计也使用了鲁棒核函数：
<span class="math display">\[
\begin{equation}\label{innov}
r^*(k)=\mathop{\arg\min}_{\hat{r}(k)}\sum^{k}_{i=k-N+1}\Psi\left(\frac{r(i)-\hat{r}(k)}{\hat
d(k)}\right)
\end{equation}
\]</span> ​ 即，已知一个滑动窗口内的所有新息的信息<span class="math inline">\(r(i)\)</span>，根据中值偏差进行的re-scale操作加权
+
Huber鲁棒核函数，优化这个问题，得到新息的最优估计，根据新息计算噪声水平。</p>
<h3 id="代码">2.2 代码</h3>
<p>​ 代码可见<a href="https://github.com/Enigmatisms/Algorithms-Plus/tree/master/cpp/KF">[Github🔗:Algorithm-Plus/KF]</a>。其中<code>KFTest.cc</code>是对一个带有运动噪声的小球进行的仿真，使用的就是ARKF。当前效果已经比传统KF稳定了很多（不过同时也结合了很多简单滤波器）。</p>
<video src="arkf_simulation.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<hr>
<h2 id="iii.-mee-cmee">III. MEE &amp; CMEE</h2>
<p>​ [2]。这是KF最近的工作，使用EE（Error Entropy）替换原来的MSE / Robust
MSE准则。实际上，这些人关于KF的想法就是：</p>
<ul>
<li>粒子滤波太慢了，但是它很棒，可以处理任意的分布</li>
<li>KF不太行，因为其噪声要求是高斯的，而且不自适应</li>
</ul>
<p>​ 理解此论文的内容需要有一定的理论储备。</p>
<h3 id="error-entropy-kernel">3.1 Error Entropy &amp; Kernel</h3>
<h4 id="简单介绍">3.1.1 简单介绍</h4>
<p>​
这篇论文[3]详细地介绍了MEE的思想以及其与M-estimation的关系，我结合这篇论文简单说一下吧（这篇论文做的modification就不说了）。</p>
<p>​ 此处使用的Entropy有别于通常说的香农熵（Shannon），这个熵被称为Renyi
entropy，与香农熵的区别如下： <span class="math display">\[
\begin{align}
&amp; H_s(X)=-\sum\log(P_i(x))P_i(x)\label{shannon} \\
&amp; H_a(X)=\frac{1}{1-a}\log(\sum P^a(x))\label{renyi}
\end{align}
\]</span> ​ 公式<span class="math inline">\(\eqref{shannon}\)</span>是香农熵，而公式<span class="math inline">\(\eqref{renyi}\)</span>是Renyi熵。这两个式子让我想到了在DIP课上学到的两个滤波器，一个是普通的均值滤波器，另一个则是逆谐波均值滤波器（阶数可变那种）。香农熵就是Renyi熵在a趋近于1的一个特例。MEE中常用的是a=2（称为quadratic
Renyi entropy）。论文[3]做作者提到的EE做的事实际上是：</p>
<blockquote class="blockquote-center">
<p>The concept of ‘close’, implicitly or explicitly employs a distance
function or similarity measure.</p>

</blockquote>
<p>​ 也即，EE定义的是一种相似 /
接近的度量。而由于EE在计算时引入了概率，普通的<strong><u>误差（或者说是偏差）</u></strong>是没有概率的归一、范围性质的，不能直接参与运算。核函数就起到了一个映射为概率的作用，我们可以理解为这是一个sigmoid
/ softmax： <span class="math display">\[
\begin{align}
&amp; H_2(e)=-\log V(e) \label{h2}\\
&amp; V(e)=\frac 1 {L^2} \sum_{j=1}^N\sum_{i=1}^Nk_{\sigma}(e_i-e_j)
\label{kernel}\\
&amp;
k_{\sigma}(x)=\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{x^2}{2\sigma^2}\right)
\end{align}
\]</span> ​ 最后的Renyi EE就如公式<span class="math inline">\(\eqref{h2}\)</span>所定义。最小化Renyi
EE就是要最大化公式<span class="math inline">\(\eqref{kernel}\)</span>定义的<span class="math inline">\(V(e)\)</span>，也即误差的QIP（quadratic
information
potential）。KF本质求解的加权最小二乘问题，ARKF为自适应加权鲁棒最小二乘问题。而其中的e，以我个人对论文的理解，应该表示的是新息。但是论文[2]里面实际说的是，<span class="math inline">\(e\)</span>是滤波器输出与“期望输出”的偏差。嗯？期望输出是什么东西？其实是最优滤波器的输出，<span class="math inline">\(e\)</span>是最优滤波器与当前参数滤波器输出的差异。</p>
<p>​ 所以可以知道：</p>
<div class="note info"><p>​ MEE准则是在优化最优滤波器和当前参数滤波器输出之间误差的误差熵。</p>
</div>
<p>​
然后我发现了有趣的东西：论文[4]是人机所老师们的文章，完全介绍了MEE-KF。而论文[2]对MEE-KF的介绍并不透彻，甚至看完之后我还不是很清楚如何实现。论文[4]则说得将一些细节说的更加清楚。</p>
<h4 id="parzen窗与renyi-entropy">3.1.2 Parzen窗与Renyi Entropy</h4>
<p>​
没想到还能和Parzen窗联系起来，当时没往这方面想。Parzen窗是一种核密度估计方法（非参数地估计概率密度函数，在我大三下学期的《模式识别与机器学习》课程中学了）。实际上公式<span class="math inline">\(\eqref{kernel}\)</span>定义的就是一个Parzen窗操作，怎么理解？</p>
<ul>
<li>首先，进行Renyi entropy计算需要计算IP（information potential）</li>
<li>IP的计算需要依赖概率密度函数，这可以用Parzen窗估计出来</li>
</ul>
<p>​ 首先，Parzen窗法是这样的： <span class="math display">\[
\begin{equation}\label{parzen}
\hat{p}(x)=\frac 1N \sum_{i=1}^N G_{\sigma}(x-e_i)
\end{equation}
\]</span> ​ 相当于在一堆<span class="math inline">\(\{e_i\}\)</span>（已经采样得到的error）上放一个Gauss分布函数，再进行归一化，得到密度估计。通过采样得到的<span class="math inline">\(\{e_i\}\)</span>可以估计出error的分布，从而计算信息势<span class="math inline">\(V_a(e)\)</span>。二阶离散情况下计算为： <span class="math display">\[
\begin{equation}\label{potential}
\hat{V}_2(e)=\frac 1N \sum_{i=1}^N\hat{p}(e_i)=\frac 1{N^2} \sum_{i=1}^N
\sum_{j=1}^N G_{\sigma}(e_i-e_j)
\end{equation}
\]</span> ​ 但上述公式还存在一些奇怪的地方，比如说<span class="math inline">\(\hat{V}_2(e)=\frac 1N
\sum_{i=1}^N\hat{p}(e_i)\)</span>。明明正常情况下，二阶信息势应该是：
<span class="math display">\[
\begin{equation}\label{v2}
V_2(x)=\int p^2(x)dx\rightarrow\sum_{i=1}^N p^2(x)
\end{equation}
\]</span> ​ 此处直接把二次项去掉了，相当于对<span class="math inline">\(p(x)\)</span>按其自身的加权平均变成了直接平均。可能是一种近似计算方法吧，因为平方确实会麻烦一些，将会写成以下形式：
<span class="math display">\[
\begin{equation}\label{right}
V_2(x)=\sum_{i=1}^N p^2(x)=\frac 1{N^2}\sum_{i=1}^N
\left(\sum_{j=1}^NG_{\sigma}(e_i-e_j)\right)
\left(\sum_{j=1}^NG_{\sigma}(e_i-e_j)\right)
\end{equation}
\]</span> ​ 这显然是与公式<span class="math inline">\(\eqref{potential}\)</span>有一定差别的。相当于公式<span class="math inline">\(\eqref{right}\)</span>是将其中一个内求和式近似为了1（这合理吗？虽然论文说的就是：<code>one can obtain an estimate of the second order (α = 2) information potential</code>），感觉Parzen窗（一次近似）+
均匀分布（第二次近似）是两次近似啊？还是我理解错了？但是确实这样的近似会让Renyi
Entropy更方便计算。之后的推导就<strong><u>非常复杂</u></strong>了。之后开单独的一篇进行分析，我可能自己也会尝试实现一下，既然有闭式解那么可能实现起来并不会太复杂吧（？飘了）。</p>
<h3 id="约束与闭式解">3.2 约束与闭式解</h3>
<p>​
说实在的，我觉得这个略有点“强行创新”的感觉。不知道怎么说这个比较好，可能是我太菜了没看明白。论文[2]做的事情是增加了一个约束（还是等式约束）：
<span class="math display">\[
\begin{equation}\label{const}
\mathop{\arg\max}_{\pmb{w}}\hat{V}_2(e_n)\text{ subject to
}\mathbf{C}^T\pmb{w}_n=\mathbf{f}
\end{equation}
\]</span> ​
后面这个约束是用来干什么的呢？什么实际问题下会有这样的约束呢？就抓住这样一点小的改动就可以有一篇论文嘛？虽然后序的推导还是很有意思的，作者通过约束
+ 变换求出了对应的拉格朗日乘子的取值。其中需要设置的是约束参数<span class="math inline">\(\mathbf{C}\)</span>以及<span class="math inline">\(\mathbf{f}\)</span>。</p>
<p>​
仔细一看，还是我们学校的老师（陈霸东教授）作为其中一位作者。当然也有可能是因为，论文长度只有5页（因为是篇brief），有些推导不是特别的详细。但可能我还是觉得，就多讨论了一个约束的情况，没什么太大的意思吧。</p>
<hr>
<h2 id="iv.-eskf">IV. ESKF</h2>
<p>​ 我在做机队的某项定位任务的时候用到了ESKF（Error-State
KF）[5]，对机器人的轮速 / IMU /
UWB（定位信号）进行融合。ESKF与普通KF最根本的区别在于：</p>
<ul>
<li>普通KF的状态就是可以直接使用的，具有明确物理含义的状态，比如速度 /
位置 / 角度。</li>
<li>ESKF的状态是误差，状态转移 / 观测都是有关误差的（比如位置误差 /
速度误差），相当于是一个对误差进行滤波得到结果，每次使用滤波估计出的系统误差进行原状态的计算。</li>
<li>可以理解为：KF是位置式的控制（每次滤波得到的都是最终结果），而ESKF都是增量式的控制（每次滤波得到的是状态应有的变化值）。</li>
</ul>
<div class="note primary"><p>​ 状态总是由两部分组成：实际状态（true state）=
<strong>理想状态（nominal state）</strong>+ <strong>噪声状态（error
state）</strong></p>
</div>
<p>​
KF对实际状态进行滤波，ESKF对噪声状态进行滤波，而理想状态进行无误差假设，直接更新。关于ESKF的使用，这里就不赘述了，因为我也赘述不出来：</p>
<p><img src="/2021/05/31/%E6%BB%A4%E6%B3%A2%EF%BC%86%E5%8D%A1%E5%B0%94%E6%9B%BC/eskf.jpg"></p>
<center>
Figure 3. ESKF 95页论文中的 状态变量截图
</center>
<p>​ 涉及到大量的四元数 / 运动学 /
机器人学知识，常用于定位，因为它有很显著的优点：</p>
<ul>
<li>error-state很小（因为是误差），相当于使用相对量进行计算，一般不会出现奇异
/ 万向锁之类的问题。</li>
<li>另一方面，由于其很小（一般都在0附近，并且范围不太大），对于复杂的运动学问题（特别是非线性系统），Taylor展开后高阶项一般都是可以忽略的，性质很好。</li>
</ul>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] Durovic Z M, Kovacevic B D. Robust estimation with unknown noise
statistics[J]. IEEE Transactions on Automatic Control, 1999, 44(6):
1292-1296.</p>
<p>[2] Peng S, Ser W, Chen B, et al. Robust constrained adaptive
filtering under minimum error entropy criterion[J]. IEEE Transactions on
Circuits and Systems II: Express Briefs, 2018, 65(8): 1119-1123.</p>
<p>[3] Liu W, Pokharel P P, Principe J C. Error entropy, correntropy and
m-estimation[C]//2006 16th IEEE Signal Processing Society Workshop on
Machine Learning for Signal Processing. IEEE, 2006: 179-184.</p>
<p>[4] Chen B, Dang L, Gu Y, et al. Minimum error entropy Kalman
filter[J]. IEEE Transactions on Systems, Man, and Cybernetics: Systems,
2019.</p>
<p>[5] Sola J. Quaternion kinematics for the error-state Kalman
filter[J]. arXiv preprint arXiv:1711.02508, 2017.</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>线性代数</tag>
        <tag>控制理论</tag>
      </tags>
  </entry>
  <entry>
    <title>CNN Style Transfer论文复现</title>
    <url>/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/</url>
    <content><![CDATA[<h2 id="neuralstyle"># NeuralStyle</h2>
<p>My own implementation of CVPR 2016 paper: Image Style Transfer Using
Convolutional Neural Networks. This work is, I think, simple but elegant
(I mean the paper, not my implementation) with good
interpretability.</p>
<ul>
<li>CVPR 2016 OpenAccess Link is here: <a href="https://openaccess.thecvf.com/content_cvpr_2016/html/Gatys_Image_Style_Transfer_CVPR_2016_paper.html">CVPR
2016 open access</a></li>
<li>Personal understanding of this paper [Chinese]: <a href="https://enigmatisms.github.io/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/">Blog
of Enigmatisms/CNN Style Transfer论文复现</a></li>
</ul>
<div class="note success"><p>2021.11.15 complement: I have no intention to analyze and explain
this paper, because I think it's simple, and I have a deep impression of
this, therefore there is no point recording anything on the blog.
Original Github Repo: <a href="https://github.com/Enigmatisms/NeuralStyle">Github🔗:
Enigmatisms/NeuralStyle</a>. This post is exactly the README.md of the
repo.</p>
</div>
<span id="more"></span>
<hr>
<h3 id="to-run-the-code">To run the code</h3>
<p>Make sure to have Pytorch / Tensorboard on your device, CUDA is
available too yet I failed to use it (GPU memory not enough, yet API is
good to go). I am currently using Pytorch 1.7.0 + CU101.</p>
<p>On Init, it might require you to download pretrained VGG-19 network,
which requires network connection.</p>
<hr>
<h3 id="tree---working-directory">Tree - Working Directory</h3>
<ul>
<li>folder <code>content</code>: Where I keep content images.</li>
<li>folder <code>imgs</code>: To which the output goes.</li>
<li>folder <code>style</code>:
<ul>
<li><code>lossTerm.py</code>: Style loss and Content loss are
implemented here.</li>
<li><code>precompute.py</code>: VGG-19 utilization, style and content
extractors.</li>
<li><strong><code>transfer.py</code></strong>: executable script.</li>
</ul></li>
</ul>
<hr>
<h3 id="a-little-help">A Little Help</h3>
<p>Always run <code>transfer.py</code> in folder <code>style/</code>,
using <code>python ./transfer.py -h</code>， you'll get:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">usage: transfer.py [-h] [--alpha ALPHA] [--epoches EPOCHES]</span><br><span class="line">                   [--max_iter MAX_ITER] [--save_time SAVE_TIME] [-d] [-g]</span><br><span class="line">                   [-c]</span><br><span class="line">optional arguments:</span><br><span class="line">  -h, --help            show this help message and exit</span><br><span class="line">  --alpha ALPHA         Ratio of content loss in the total loss</span><br><span class="line">  --epoches EPOCHES     Training lasts for . epoches (for LBFGS)</span><br><span class="line">  --max_iter MAX_ITER   LBFGS max iteration number</span><br><span class="line">  --save_time SAVE_TIME</span><br><span class="line">                        Save image every &lt;save_time&gt; epoches</span><br><span class="line">  -d, --del_dir         Delete dir ./logs and start new tensorboard records</span><br><span class="line">  -g, --gray            Using grayscale image as initialization for generated</span><br><span class="line">                        image</span><br><span class="line">  -c, --cuda            Use CUDA to speed up training</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="requirements">Requirements</h3>
<ul>
<li>Run:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python3 -m pip install -r requirements.py</span><br></pre></td></tr></table></figure>
<p>To find out.</p>
<hr>
<h3 id="training-process">Training Process</h3>
<ul>
<li>Something strange happened. Loss exploded twice (but recovered.).
Tensorboard graphs:</li>
</ul>
<p><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/training.JPG"></p>
<p>Therefore, parameter images change like this (Initialized with
grayscale image).</p>
<table>
<colgroup>
<col style="width: 31%">
<col style="width: 35%">
<col style="width: 32%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/G_star_71.jpg"></th>
<th style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/G_star_221.jpg"></th>
<th style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/G_star_481.jpg"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/G_chaos_11.jpg"></td>
<td style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/G_chaos_181.jpg"></td>
<td style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/G_chaos_241.jpg"></td>
</tr>
<tr>
<td style="text-align: center;">First few epochs</td>
<td style="text-align: center;">Exploded, for 2th row image</td>
<td style="text-align: center;">Recovered</td>
</tr>
</tbody>
</table>
<hr>
<h3 id="results">Results</h3>
<ul>
<li>CPU training is tooooooo slow. Took me <strong><u>2+
hours</u></strong> for 800 iterations. (i5-8250U 8th Gen @ 1.60Hz)</li>
</ul>
<table>
<colgroup>
<col style="width: 39%">
<col style="width: 29%">
<col style="width: 31%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/star.jpg" style="zoom:80%;"></th>
<th style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/content.jpg"></th>
<th style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/G_star_801.jpg"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/chaos.jpg" style="zoom:80%;"></td>
<td style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/content.jpg"></td>
<td style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/G_chaos_801.jpg"></td>
</tr>
<tr>
<td style="text-align: center;">Style</td>
<td style="text-align: center;">Content</td>
<td style="text-align: center;">Output(800 Iterations)</td>
</tr>
</tbody>
</table>
<ul>
<li>I've also done the style transfer of Van Gogh's self portrait for my
dad, which is not appropriate to display, but worked.</li>
</ul>
<hr>
<h3 id="possible-todos">Possible TODOs</h3>
<ul class="task-list">
<li><label><input type="checkbox">Try adding InstanceNorm into VGG-19
? Useful ? Meaningful ?</label></li>
</ul>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>English</tag>
        <tag>knowings</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title>优雅线代与美妙优化</title>
    <url>/2021/04/03/%E4%BC%98%E9%9B%85%E7%BA%BF%E4%BB%A3%E4%B8%8E%E7%BE%8E%E5%A6%99%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h1 id="矩阵分析-优化">矩阵分析 &amp; 优化</h1>
<p>​ 最近接触了一些有趣的 机器学习 /
控制算法，其中的数学原理非常有意思，大多数都涉及到了矩阵分解以及线性代数解析解的求取。推导这些理论可以帮助深入理解矩阵分解（以及分解后子矩阵的数学意义）以及
矩阵分析和优化理论的数学联系，这些理论都非常优雅而且美妙。</p>
<p><img src="/2021/04/03/%E4%BC%98%E9%9B%85%E7%BA%BF%E4%BB%A3%E4%B8%8E%E7%BE%8E%E5%A6%99%E4%BC%98%E5%8C%96/decomp.jpg"></p>
<center>
Figure 1. 矩阵分解的真谛：图为 上三角分解
</center>
<p>​ 本文将包括以下四个部分：</p>
<ul>
<li>卡尔曼滤波的最小二乘解释</li>
<li>最小二乘的几何解释</li>
<li>谱聚类的矩阵分析</li>
<li>PCA的矩阵分析</li>
</ul>
<span id="more"></span>
<hr>
<h2 id="kf最小二乘解释">KF最小二乘解释</h2>
<p>​ Kalman
Filter，作为一种“最小二乘”滤波器，其应用极其广泛。个人使用KF设计过：</p>
<ul>
<li>目标跟踪算法（Adaptive Robust KF）<a href="https://github.com/Enigmatisms/Algorithms-Plus/tree/master/cpp/KF">[Github🔗：Algorithm_Plus/KF]</a></li>
<li>语音信号处理（白噪声滤波）：<a href="https://github.com/Enigmatisms/AudioDSP">[Github🔗:
AudioDSP]</a></li>
</ul>
<p>​
虽然说，KF是“最小二乘”的迭代式滤波器，但自己从来没有里结果其中的数学原理，也即：<strong>(1)
最小二乘最优性是如何得到的</strong>？<strong>(2)为什么KF是迭代式的</strong>？而关于KF的深入分析（包括参数整定，自适应化，收敛性谈，将会在另一篇博文中细讲<a href="https://enigmatisms.github.io/2021/03/07/%E5%8D%A1%E5%B0%94%E6%9B%BC%E8%BF%9B%E9%98%B6%E4%B8%8E%E7%B2%92%E5%AD%90%E6%BB%A4%E6%B3%A2%E5%AE%9E%E7%8E%B0/">【卡尔曼进阶与粒子滤波实现】</a>）。</p>
<h3 id="kf最小二乘性">KF最小二乘性</h3>
<p>​
我们将最为一般的KF迭代公式重写如下（实际上个人认为实现KF最难的地方就是记公式）：
<span class="math display">\[
\begin{align}
&amp; \breve{x}(k)=A\hat{x}(k-1)+Bu(k)+w(k) \label{transit}\\
&amp; \breve{P}(k)=A\hat{P}(k-1)A^T+Q       \label{covup}\\
&amp; z(k)=H\breve{x}(k)+v(k) \label{obs}\\
&amp; K=\breve{P}(k)H^T(H\breve{P}(k)H^T+R)^{-1}\label{gain}\\
&amp; \hat{x}(k)=\breve{x}(k)+K(z(k)-H\breve{x}(k)) \label{xcor}\\
&amp; \hat{P}(k)=\breve{P}(k)-KH\breve{P}(k)\label{covcor}
\end{align}
\]</span> ​ 其中，“<span class="math inline">\(\breve{
}\)</span>”表示先验，“<span class="math inline">\(\hat{
}\)</span>”表示后验。也就是说：</p>
<table>
<colgroup>
<col style="width: 49%">
<col style="width: 45%">
<col style="width: 4%">
</colgroup>
<thead>
<tr>
<th>先验（前两行）</th>
<th>后验（前两行）</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math inline">\(\breve{x}(k)\)</span>
迭代k的状态（先验均值）</td>
<td><span class="math inline">\(\hat{x}\)</span>(k) 后验均值</td>
<td></td>
</tr>
<tr>
<td><span class="math inline">\(\breve{P}\)</span>(k)
状态k的协方差（先验协方差）</td>
<td><span class="math inline">\(\hat{P}\)</span>(k) 后验协方差</td>
<td></td>
</tr>
<tr>
<td>Q 状态转移噪声协方差</td>
<td>R 观测噪声协方差</td>
<td></td>
</tr>
<tr>
<td>A 状态转移矩阵，H观测矩阵</td>
<td>B 控制矩阵 <span class="math inline">\(u(k)\)</span>系统控制量（外界输入）</td>
<td></td>
</tr>
<tr>
<td><span class="math inline">\(w(k),v(k)\)</span>
噪声（一般讨论白噪声）</td>
<td>K 卡尔曼增益</td>
<td></td>
</tr>
</tbody>
</table>
<p>​
光看这个迭代式根本不知道为什么KF会得出最小二乘最优来，在《概率机器人》一书上，作者使用的是概率分布的转移以及推导来看待KF的迭代优化过程，并没有从最小二乘的角度看待这个问题。下面我们尝试从最小二乘角度来分析KF。</p>
<p>​
考虑一个拟合问题，拟合曲线时，数据点都是给定的（而且一般有噪声）。个人认为这是个平滑问题（因为使用者有unlimited
access to all the data【随便写段英文】），根据<a href="https://www.intechopen.com/books/smoothing-filtering-and-prediction-estimating-the-past-present-and-future">Smoothing,
Filtering and Prediction</a>所说，平滑 / 滤波 /
预测是针对三个不同的时间点：处理过去的数据（已经接收并且存储），处理当下的数据（比如确定更准确的测量值），处理未来的可能数据（预测）。而KF的一种常用领域-控制，是有实时性要求的，要求至少需要达到【滤波】的标准，最好能进行【预测】。而一般的拟合，基本都是一次性计算所有的点，所以着导致了一般的拟合问题
<strong><u>不是增量性的（也即有新的数据点，需要全部重新计算，比如loss与梯度）</u></strong>。</p>
<p>​
KF显然并不是这样的，KF需要实时更新，并且不能依赖太久远的历史信息（低阶的马尔可夫性）。KF的预测输出期望能与观测贴合（但这也不完全一定，由于观测是存在一定的噪声的）。根据论文"<strong><em>Robust
Estimation with Unknown Noise
Statistics</em></strong>"，我们可以把KF问题重写成如下形式： <span class="math display">\[
\begin{equation}\label{optim}
\begin{pmatrix}
I\\
H
\end{pmatrix}\breve{x}(k)=
\begin{pmatrix}
A\hat{x}(k-1)\\
z(k)
\end{pmatrix} +
\begin{pmatrix}
w(k)\\
v(k)
\end{pmatrix}=
\begin{pmatrix}
A\hat{x}(k-1)\\
z(k)
\end{pmatrix} + E(k)
\end{equation}
\]</span></p>
<p>​ 假设我们求解噪声矩阵<span class="math inline">\(E(k)\)</span>的协方差，那么它应该是这样的： <span class="math display">\[
\begin{equation}\label{ecov}
\mathbb{E}(E(k)E(k)^T)=\begin{pmatrix}
\breve{P}(k) &amp; \mathbf{0}   \\
\mathbf{0} &amp; R(k)
\end{pmatrix}
\end{equation}
\]</span></p>
<p>​ 协方差为什么长成这样呢？很显然：<span class="math inline">\(w(x)\)</span>自己的协方差就是状态转移协方差（注意不是噪声协方差Q，因为Q需要进行状态转移），而<span class="math inline">\(v(x)\)</span>的协方差是噪声协方差。而<span class="math inline">\(w(x),v(x)\)</span>默认是相互独立的，故非对角线矩阵块为0。接下来，对这个协方差进行矩阵分解：
<span class="math display">\[
\begin{equation}
Cholesky(\mathbb{E}(E(k)E(k)^T))=SS^T
\end{equation}
\]</span></p>
<p>​ 此后所做的事情有点奇怪，矩阵<span class="math inline">\(S\)</span>被单独使用了（协方差矩阵的矩阵LU分解代表了什么意义？）。实际上，这里是要使linear
transform之后的噪声协方差为单位阵（也就是说，此处做了一个白化变换）。我们看公式<span class="math inline">\(\eqref{optim}\)</span>，<span class="math inline">\(E(k)\)</span>是系统的噪声，而系统高斯噪声并不为单位阵，问题并非标准问题，也可以说是：输入没有进行标准化。那么对于<span class="math inline">\(\eqref{optim}\)</span>而言，等号左右乘以<span class="math inline">\(S^{-1}\)</span>实际上就是在做白化变换： <span class="math display">\[
\begin{align}
&amp;S^{-1}\begin{pmatrix}
I\\
H
\end{pmatrix}\breve{x}(k)=
S^{-1}\begin{pmatrix}
A\hat{x}(k-1)\\
z(k)
\end{pmatrix} +
S^{-1}\begin{pmatrix}
w(k)\\
v(k)
\end{pmatrix}=
S^{-1}\begin{pmatrix}
A\hat{x}(k-1)\\
z(k)
\end{pmatrix} + S^{-1}E(k)\label{optim2}
\end{align}
\]</span></p>
<p><span class="math display">\[
\begin{equation}\label{lsp}
X(k){x}(k)+\xi(k)=Y(k)
\end{equation}
\]</span></p>
<p>​ 这就是个标准的最小二乘问题，由于此处<span class="math inline">\(\mathbb{E}\{\xi(k)\xi(k)^T\}\)</span>是单位阵。有没有发现此处我们已经不写<span class="math inline">\(\breve{x}\)</span>了？虽然从推导式<span class="math inline">\(\eqref{optim}\)</span>来说，此处确实应该是先验<span class="math inline">\(\breve{x}\)</span>，但是此问题的解（由于涉及到本次观测<span class="math inline">\(z(k)\)</span>进行的后验修正）已经是后验了，那么可以根据pseudo逆理论求得<span class="math inline">\(x(k)\)</span>的解： <span class="math display">\[
\begin{align}
&amp;\hat{x}(k)=\mathop{\text{arg min}}_{x}\Vert Y(k)-X(k)x(k)\Vert^2 \\
&amp;x^*(k)=(X^T(k)X(k))^{-1}X^T(k)Y(k)\label{optim3}
\end{align}
\]</span> ​
从而得到了后验估计。这就是KF的优化表达式，而我们能从中推出KF的迭代性质吗？</p>
<h3 id="kf迭代性质">KF迭代性质</h3>
<p>​ 分析不难得到如下关系： <span class="math display">\[
\begin{equation}
X^T(k)X(k)=
(I\quad H^T)(S^{-1})^T(S^{-1})
\begin{pmatrix}
I\\
H
\end{pmatrix}=(I\quad H^T)(SS^T)^{-1}
\begin{pmatrix}
I\\
H
\end{pmatrix}
\end{equation}
\]</span></p>
<p>​ 而<span class="math inline">\(SS^T\)</span>是公式<span class="math inline">\(\eqref{ecov}\)</span>中的协方差矩阵，那么可以进一步得到：
<span class="math display">\[
\begin{equation}
X^T(k)X(k)=
(I\quad H)
\begin{pmatrix}
P^{-1}(k) &amp; \mathbf{0} \\
\mathbf{0} &amp; R^{-1}(k)
\end{pmatrix}
\begin{pmatrix}
I\\
H
\end{pmatrix}
\end{equation}
\]</span></p>
<p>​ 展开以上式子可以得到： <span class="math display">\[
\begin{equation}
(X^T(k)X(k))^{-1}=(P^{-1}+H^TR^{-1}H)^{-1}=P+H^{-1}R(H^{-1})^{T}
\end{equation}
\]</span></p>
<p>​
诶，只需要顺着这样的分解下去，不难发现（真的不难，所以费篇幅在这推公式了），优化结果<span class="math inline">\(\eqref{optim3}\)</span>与之前的后验更新式<span class="math inline">\(\eqref{xcor}\)</span>是完全一致的。而协方差的先验后验更新实际上是类似的，这里就不再详细推导了。妙啊兄弟们，这样我们就推出了最小二乘与KF的关系。</p>
<hr>
<h2 id="最小二乘的几何解释">最小二乘的几何解释</h2>
<p>​ 上DIP（数字图像处理）的时候，老师突然抛出一个问题来：</p>
<p>​ <img src="/2021/04/03/%E4%BC%98%E9%9B%85%E7%BA%BF%E4%BB%A3%E4%B8%8E%E7%BE%8E%E5%A6%99%E4%BC%98%E5%8C%96/proj.JPG"></p>
<center>
Figure 2. 观测 误差 与真值的空间表示
</center>
<div class="note default"><p>​
为什么说，观测平面需要和误差正交？（也就是说观测平面的法向量和误差的方向是重合的？）</p>
</div>
<p>​ 惊讶，竟然没有人说上来为什么（可能大家都比较谦虚吧）。</p>
<p>​ 从几何<strong>直观</strong>上非常好理解为什么。显然，观测<span class="math inline">\(\hat{x}\)</span>是由真值的投影<span class="math inline">\(\breve{x}\)</span>与误差<span class="math inline">\(e\)</span>投影的结合，而如果投影平面（观测面）正好与误差是正交的，那么误差的投影将会是0。而在最小二乘意义下，误差的平均投影长度是最小的。</p>
<p><img src="/2021/04/03/%E4%BC%98%E9%9B%85%E7%BA%BF%E4%BB%A3%E4%B8%8E%E7%BE%8E%E5%A6%99%E4%BC%98%E5%8C%96/err.JPG"></p>
<center>
Figure 3. 误差投影 投影后影响观测（实际观测是绿色 + 紫色）
</center>
<p>​ 那么要求最优的投影面，实际上是要优化这个问题： <span class="math display">\[
\begin{equation}\label{f17}
\left\{
\begin{array}{ll}
\text{min }\Vert \pmb{e}-(\pmb{a}^T\pmb{e})\pmb{a}\Vert^2\\
\text{s.t. }\pmb{a}^T\pmb{a}=1
\end{array}
\right.
\end{equation}
\]</span></p>
<p>​ 什么意思？意思就是，假设<span class="math inline">\(\pmb{a}\)</span>是投影平面的单位法向量，那么<span class="math inline">\(\pmb{a}^T\pmb{e}\)</span>就是误差在单位法向量上的投影，而<span class="math inline">\(\pmb{e}-(\pmb{a}^T\pmb{e})\pmb{a}\)</span>就是误差在观测平面上的投影。需要使得这个投影最短。</p>
<p>​ 那么解这个问题，实际上最后会求出：需要对误差的协方差<span class="math inline">\(\pmb{e}\pmb{e}^T=\Sigma\)</span>进行矩阵分解，求最大特征值对应的特征向量，就是<span class="math inline">\(\pmb{a}\)</span>。而这个特征向量实际上对应了误差的主方向（PCA部分中会提到这个思想），如果只有一个观测的话，则就是误差的方向。至于为什么，<strong><u>很简单</u></strong>，公式<span class="math inline">\(\eqref{f17}\)</span>留给读者作为练习。</p>
<hr>
<h2 id="谱聚类矩阵分析">谱聚类矩阵分析</h2>
<p>​ 谱聚类（spectrum
clustering）是一种很美妙的聚类理论，它包含了<strong><u>图论</u></strong>，
<strong><u>矩阵分析</u></strong>，<strong><u>优化理论</u></strong>以及<strong><u>机器学习理论</u></strong>，综合性的一个算法，理解这个算法可以帮助对以上四个方面的理论都有进一步的认识。</p>
<h3 id="laplace算子">Laplace算子</h3>
<p>​
这是我DIP课程中刚讲的空域滤波器kernel，虽然之前就知道Laplace长什么样，但是从来没有从DSP的角度去思考，也没有思考其数学原理。Laplace算子用
<strong><u>求二阶导</u></strong>，这是为什么呢？小编也不知道，小编也觉得很有趣。一个典型的Laplace
kernel长这样： <span class="math display">\[
\begin{equation}
\begin{pmatrix}
0 &amp; -1 &amp; 0 \\
-1 &amp; 4 &amp; -1 \\
0 &amp; -1 &amp; 0
\end{pmatrix}
\end{equation}
\]</span></p>
<p>​
从DSP的角度考虑Laplace算子的设计，这也就是一个高通滤波器嘛（求边缘使用），而对于直流分量这种显然是低频的信号成分来说，它是要被高通滤波器滤除的。于是高通滤波器不能保留任何直流的能量，需要保证对于平滑区域（比如ones），卷积结果为0。而图分析（graph）中，对于离散的图而言也有Laplace算子，并且其物理意义非常明确：<strong><u>求图上的最小割</u></strong>。首先推一下离散的二阶导，使用一个简单的一阶导表达式：
<span class="math display">\[
\begin{equation}\label{de_1}
\frac{df}{dx}=f&#39;(x)=f(x)-f(x-1)
\end{equation}
\]</span></p>
<p>​ 而需要求二阶导，也就需要在本函数的基础上再求一阶导： <span class="math display">\[
\begin{equation}\label{de_2}
\frac{d^2f}{dx^2}=f&#39;&#39;(x)=f&#39;(x)-f&#39;(x-1)=f(x)-2f(x-1)+f(x-2)
\end{equation}
\]</span></p>
<p>​ 接下来分析无向带权图上的Laplace矩阵。</p>
<p>​ 首先定义<span class="math inline">\(W\)</span>为权重矩阵（无向带权图的邻接矩阵，注意<span class="math inline">\(w_{i,i}=0\)</span>），<span class="math inline">\(W\)</span>就刻画了节点之间的联系程度（或者cost）。在聚类问题中，我们设定，假设两个样本点之间的关系越紧密，特征越类似，对应节点之间的边权也就越大。那么聚类实际上就是在这样的图上寻找一个最小割（最小权的边集合），使得经过这个cut之后可以分为k个指定类。</p>
<p>​ 此外，定义<span class="math inline">\(D\)</span>为度矩阵，与普通的度定义不同（这个度是有权的），<span class="math inline">\(D\)</span>为对角矩阵，元素<span class="math inline">\(d_{i,j}\)</span>的意义是： <span class="math display">\[
\begin{equation}
d_{i,j}=\left\{
\begin{array}{l}
\sum_{j=1}^nw(i,j),\text{ if }i=j \\
0,\text{ otherwise}
\end{array}
\right.{}
\end{equation}
\]</span></p>
<p>​
D衡量的实际是一个节点与其他所有节点的联系紧密程度。则有了这两个矩阵，我们接下来定义<span class="math inline">\(L=D-W\)</span></p>
<p>​
也就是度矩阵减去邻接矩阵，看起来非常抽象？直接看L是难以得到其物理意义的，需要有其他向量的帮助</p>
<h5 id="性质1-向量差异">性质1 向量“差异”</h5>
<p><span class="math display">\[
\begin{equation}
\text{Given vector }x,\text{ }Lx=
\begin{pmatrix}
\sum_{j\neq1}w_{1j} &amp; -w_{12} &amp; ... &amp; -w_{1n}\\
-w_{21} &amp; \sum_{j\neq2}w_{2j} &amp; ... &amp; -w_{2n}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
-w_{n1} &amp; -w_{n,2} &amp; ... &amp; \sum_{j\neq n}w_{nj}
\end{pmatrix}
\begin{pmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{pmatrix}
\end{equation}
\]</span></p>
<p>​ 将上式展开可以得到： <span class="math display">\[
\begin{equation}\label{diff1}
\begin{pmatrix}
\sum_{j\neq1}w_{1j} &amp; -w_{12} &amp; ... &amp; -w_{1n}\\
-w_{21} &amp; \sum_{j\neq2}w_{2j} &amp; ... &amp; -w_{2n}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
-w_{n1} &amp; -w_{n,2} &amp; ... &amp; \sum_{j\neq n}w_{nj}
\end{pmatrix}
\begin{pmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{pmatrix}=
\begin{pmatrix}
\sum_{j\neq 1}w_{1j}(x_1-x_j)\\
\sum_{j\neq 1}w_{2j}(x_1-x_j)\\
\vdots\\
\sum_{j\neq 1}w_{nj}(x_n-x_j)\\
\end{pmatrix}
\end{equation}
\]</span></p>
<p>​
证明就是暴力展开。可以发现一个x时，对x做线性变换实际上求了x各个元素之间的差异。</p>
<h5 id="性质2-标量输出">性质2 标量输出</h5>
<p><span class="math display">\[
\begin{equation}\label{diff2}
x^TLx=\sum_{i=1}^n\sum_{j=1}^nw_{ij}(x_i-x_j)^2
\end{equation}
\]</span></p>
<p>​ 根据矩阵乘法，对公式<span class="math inline">\(\eqref{diff1}\)</span>进行左乘x操作再展开很容易就能得到。此处，<span class="math inline">\(x^TLx\)</span>的意义实际上就是：根据每个节点的关联关系
<strong><u>加权</u></strong> 的向量内部差异。但是这个向量<span class="math inline">\(x\)</span>到底是什么？</p>
<h5 id="向量x意义的讨论">向量x意义的讨论</h5>
<p>​
我们讨论问题的背景是聚类，聚类中除了每对节点之间的特征差异之外，最显著的差异就是
<strong><u>聚类对应的类别差异</u></strong>了。那么x恰好可以作为一个指示向量，给定一个k=2簇的聚类问题，设：
<span class="math display">\[
\begin{equation}\label{indicate}
x_i=\left\{
\begin{array}{ll}
1, \text{ if }\pmb{x}\in\mathbb{C}_1\\
-1,\text{ if }\pmb{x}\in\mathbb{C}_2
\end{array}
\right.
\end{equation}
\]</span></p>
<p>​ 那么<span class="math inline">\(Lx\)</span>实际上就是不同节点之间label的差异，比如两个点为同一个簇，则<span class="math inline">\(Lx\)</span>对应分量为0，否则为一个非0的值（正数）。现在要找一种方式割开这个点集（也就是找一个x），使得两个类之间的联系是最小的。那么实际上，切开两类的割对应的值就是两类之间被丢弃的（割开）类间联系，实际可以对应于<span class="math inline">\(x^TLx\)</span>。在不同的formulation下，<span class="math inline">\(x\)</span>可以有不同形式，但是其意义基本一致：割。</p>
<p>​ k=2时，完全可以使用一个向量进行运算（<span class="math inline">\(\pm1\)</span>），而涉及到多类时，可能<span class="math inline">\(x\)</span>就会是一个矩阵了（因为不存在一种赋值方式使得任意两类不同的结点的cost相减是相同的，举个例子：0为A，1为B，2为C，虽然AB，BC之间相差1，但是AC之间差2）。</p>
<h4 id="二类cut">二类Cut</h4>
<p>​ k=2聚类直接使用如<span class="math inline">\(\eqref{indicate}\)</span>所定义的向量x即可。</p>
<div class="note info"><p><strong>说了这么久矩阵分析，还没正经地开始分析呢。</strong></p>
<p>可以看一下<span class="math inline">\(x^TLx\)</span>的取值范围应该是什么？与矩阵L的特征值有什么关系？</p>
</div>
<p>​
由于矩阵的特征向量是相互正交的，它们实际上张成了一个与x所在线性空间等价的一个空间。从而可以知道，由于x存在于特征向量张成的线性空间中，x可在以特征向量为基时被特征向量的线性组合表示：
<span class="math display">\[
\begin{equation}
x^TLx=(\sum_{i=1}^na_i\pmb{v}_i)^TL(\sum_{i=1}^na_i\pmb{v}_i),\text{
where }\pmb{v}_i\text{ is the eigen vec of }L
\end{equation}
\]</span></p>
<p>​ 由于特征向量的定义，那么上式实际上就等于： <span class="math display">\[
\begin{equation}
x^TLx=\sum_{i=1}^na_i^2\lambda_i,\text{ where }\lambda_i\text{ is the
eigen value of }L
\end{equation}
\]</span></p>
<p>​ <span class="math inline">\(x^TLx\)</span>中的x并非是没有约束的，在二分类问题中，x是正负1的向量，而<span class="math inline">\(\pmb{v}_i\)</span>为归一化之后的特征向量，故<span class="math inline">\(a_i\)</span>的最大值不可能小于<span class="math inline">\(1/\sqrt{n}\)</span>，既然如此，设<span class="math inline">\(\max(a_i)=a_m\)</span>，<span class="math inline">\(a_m\)</span>必然会作用到其中一个特征值上。那么可以发现，如果要求最小的话，显然让<span class="math inline">\(a_m\)</span>作用到最小特征值上就可以让<span class="math inline">\(x^TLx\)</span>等价地最小。那么求第j小也就相当于使用第j小特征值，那么对应的解向量也就是<span class="math inline">\(v_{\text{min
jth}}\)</span>。其实特征值最大最小性在之前就已经提过：</p>
<p>​
最大化类间方差时，就需要使用到协方差矩阵最大特征值对应的特征向量。而求平面
/
线段的normal时，就需要使用到最小特征值，不过这里的最小特征值可以有两种方法解释，以求线段的法线为例：</p>
<ul>
<li>最小二乘得到线段的最优估计过程也就等价得到了法线的最优估计，那么最小二乘问题本身对应着最小特征值
以及其对应的特征向量</li>
<li>以矩阵特征向量的方向性来说，线段对应的方向向量就是最大特征值对应的特征向量（元素主方向），而与之正交的（次要方向，特征向量也是相互正交的，就跟方向向量与法线向量正交一样）法向量就是最小特征值对应的特征向量。</li>
</ul>
<p>​
那么此处需要选择最小的几个特征向量作为“割”。取多少个（k）特征向量，相当于割出多少个簇，相当于割上k-1次，每一次可以得到新的簇。比如，举个例子：
<span class="math display">\[
\begin{equation}
\begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; \sqrt{\frac{1}{2}} &amp; \sqrt{\frac{1}{2}} &amp; 0 \\
0 &amp; -\sqrt{\frac{1}{2}} &amp; \sqrt{\frac{1}{2}} &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{pmatrix}
\end{equation}
\]</span></p>
<p>​
这是四个特征向量，已经按照从左到右特征值逐渐减小的顺序排列了。假设我们最终需要得到簇k
= 3，那么可以知道需要选择两个最小特征值对应的特征向量进行cut。</p>
<ul>
<li>首先自然选取的是最后一个，这说的意义是：需要把最后一个结点单独割开，其他的结点暂时不管。</li>
<li>倒数第二个特征向量，两个正数，说明第二，第三个点是同一类的，割为一类。那么最后得到：<span class="math inline">\(\{1,\{2,3\},4\}\)</span></li>
</ul>
<hr>
<h2 id="pca矩阵分析">PCA矩阵分析</h2>
<h3 id="直观理解">直观理解</h3>
<p>​
仿佛在之前从来没有认真想过，PCA为什么要选取k个最大特征值对应的特征向量进行降维？之前对于PCA的理解只是停留在：</p>
<div class="note warning"><p>​ 矩阵分解可以得到其主方向，主方向的保留可以保留矩阵的更多信息。</p>
</div>
<p>​
但是这只是直观上的理解，“信息”保留的多少并没有得到数学上的推导，只能算作对PCA理论的通俗理解。所以PCA为什么要选取最大k个特征值对应的特征向量？</p>
<p>​
首先，PCA分解的是什么？经过【去中心化】【标准差归一化的】数据，数据在经过如上的白化处理之后，需要进行<span class="math inline">\(\pmb{x}\pmb{x}^T\)</span>操作，得到其协方差矩阵，维度
d * d，d为特征空间的维数，降维实际上就是要组合特征。那么协方差矩阵<span class="math inline">\(\Sigma\)</span>有什么特殊之处？ <span class="math display">\[
\begin{equation}\label{svd}
\text{SVD}(\Sigma)=USU^T
\end{equation}
\]</span></p>
<p>​ 直接进行SVD分解，由于<span class="math inline">\(\Sigma\)</span>的对称性，可以得到如公式<span class="math inline">\(\eqref{svd}\)</span>所示的分解式，其中S是对角矩阵。如果说其他矩阵的分解结果没有那么直观的物理意义的话，PCA则完全不一样。对协方差的矩阵分解有非常清晰的物理意义：<span class="math inline">\(S\)</span>是“标准”的协方差，也就是在没有经过旋转的方差。可以给一个简单的高斯函数的例子。</p>
<p><img src="/2021/04/03/%E4%BC%98%E9%9B%85%E7%BA%BF%E4%BB%A3%E4%B8%8E%E7%BE%8E%E5%A6%99%E4%BC%98%E5%8C%96/gauss.JPG"></p>
<center>
Figure 4. 独立情况下的协方差与一般协方差 高斯
</center>
<p>​ 而<span class="math inline">\(U\)</span>的意义则是：对方差进行旋转。那么也就是说，分解得到了：独立时的协方差矩阵<span class="math inline">\(S\)</span>以及协方差矩阵<span class="math inline">\(S\)</span>如何旋转得到当前的<span class="math inline">\(\Sigma\)</span>。而恰好，<span class="math inline">\(S\)</span>对角元素对应了特征值。特征值大等价于独立时的方差大，而<span class="math inline">\(U\)</span>特征向量则是：<strong><u>对于d个特征的线性组合向量</u></strong>（比如<span class="math inline">\((1\;\;3\;-2)^T\)</span>，其意义就是新的组合特征：一份特征一
加
三份特征二再减去两份的特征三），在对应特征向量也就是独立情况下，按照特征向量组合的特征在这个空间下的方差就是特征值。</p>
<hr>
<h3 id="特征分量差异期望最大">特征分量差异期望最大</h3>
<p>​
那么我们希望投影之后，数据之间还能有比较好的区分度（如果全部投影到一个点上了，那么就说明投影后的大部分信息都损失了），于是要选择方差大的方向投影。可以这样具体地看：对于一个特征（特征空间的一个分量），假设有两个样本<span class="math inline">\(\pmb{x}_1\)</span>与<span class="math inline">\(\pmb{x}_2\)</span>，样本(1 *
d)在经过一个一维的线性变换之后变成了一个标量（也就是求新特征的一个维度，综合（线性组合）原来所有维度的信息），设为<span class="math inline">\(z_1,z_2\)</span>，那么为了使得任意两个样本产生的新特征差异期望尽可能大
<span class="math display">\[
\begin{align}
&amp;z_1=F^T\pmb{x}_1\\
&amp;z_2=F^T\pmb{x}_2\\
&amp;\text{max } \mathbb E((z_1-z_2)^2)=\mathbb
E(F^T(\pmb{x}_1-\pmb{x}_2)(\pmb{x}_1-\pmb{x}_2)^TF)\label{obj}\\
&amp;\text{s.t. }\Vert F\Vert=1
\end{align}
\]</span></p>
<p>​ 由于F是确定性的变换，所以实际只需要对内部的<span class="math inline">\((\pmb{x}_1-\pmb{x}_2)((\pmb{x}_1-\pmb{x}_2))^T\)</span>进行期望求取即可，可知这个实际上就是协方差矩阵<span class="math inline">\(\Sigma\)</span>。那么公式<span class="math inline">\(\eqref{obj}\)</span>实际上变成了下式（注意F有约束）
<span class="math display">\[
\begin{equation}
\text{max } \mathbb{E}(F^T\Sigma F)
\end{equation}
\]</span></p>
<p>​
也就是求这个二次型（标量结果）的最大。由特征向量构成等价线性空间基的性质以及特征值存在一定取值范围，可知差异最大就是要选取最大的特征值。也就是说，选取前k个最大的特征值是完全能够保证新特征在特征空间下，样本间两两差异的期望最大。</p>
<p>​
啊，其实这个解释多么接近正确答案啊。我在4.17晚上复习LDA的时候，突然想到了如何正确地从数学角度而非直观角度解释为什么需要选择最大特征值对应的特征向量。LDA中（可见于博文<a href="https://enigmatisms.github.io/2021/03/02/%E7%BA%BF%E6%80%A7-%E6%A0%91%E5%9E%8B%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%BA%AF%E7%90%86%E8%AE%BA%E5%88%86%E6%9E%90/">[线性/树型分类器的纯理论分析]</a>），LDA巧妙变换了类间方差和类内方差的表示形式。而PCA中，实际上也是相求方差最大！并且还是<strong><u>类内方差</u></strong>，因为我们希望降维后的数据能够有最好的区分度，保留的信息量最大，也就对应着方差最大，个体差异大代表了丰富性。假设降维到1维，也即需要寻找一个线性组合向量<span class="math inline">\(w_{k\times
1}\)</span>，使得投影后（线性组合后）的特征向量<span class="math inline">\(y=w^T\pmb{x}_{k\times 1}\)</span>方差最大，也即：
<span class="math display">\[
\begin{equation}\label{max2}
\text{max }\sum^{n}(y_i-\overline y)^2\rightarrow \text{max
}\sum^{n}(w^T\pmb{x}_i-w^T\overline {\pmb{x}})^2
\end{equation}
\]</span></p>
<p>​ 那么把非随机变量<span class="math inline">\(w\)</span>提出来有：
<span class="math display">\[
\begin{align}
\label{max3}
&amp;\text{max }\sum^{n}(y_i-\overline y)^2\rightarrow \text{max
}\sum^{n}w^T(\pmb{x}_i-\overline {\pmb{x}})(\pmb{x}_i-\overline
{\pmb{x}})^Tw\rightarrow \\
&amp;\text{max }w^T\sum^{n}(\pmb{x}_i-\overline
{\pmb{x}})(\pmb{x}_i-\overline {\pmb{x}})^Tw
\end{align}
\]</span></p>
<p>​ 像LDA一样，把<span class="math inline">\(\sum^{n}(\pmb{x}_i-\overline
{\pmb{x}})(\pmb{x}_i-\overline
{\pmb{x}})^T\)</span>设为类内散度矩阵<span class="math inline">\(S_w\)</span>，其意义就是对原空间下方差的一种度量。这样我们可以求<span class="math inline">\(\eqref{max3}\)</span>定义的最大化问题了，但是还有个小小的问题：<span class="math inline">\(w\)</span>的模长可以无限大，导致<span class="math inline">\(\eqref{max3}\)</span>无限大。那么我们只需要限定<span class="math inline">\(w\)</span>是单位向量，模长为1即可（实际上，这恰好符合之后矩阵分解<span class="math inline">\(w\)</span>为特征向量的特性）： <span class="math display">\[
\begin{equation}\label{max4}
\text{max }w^TS_bw\\
\text{s.t. } \Vert w\Vert=1
\end{equation}
\]</span></p>
<p>​ 则根据Lagrange乘子，可以写为： <span class="math display">\[
\begin{equation}\label{lag}
\text{max }w^TS_bw - \lambda (w^Tw-1)\\
\end{equation}
\]</span></p>
<p>​ KKT条件，对<span class="math inline">\(w\)</span>求导，使用分子布局（结果转置，那分子布局和分母布局没有什么不同）：
<span class="math display">\[
\begin{equation}\label{res}
S_bw=\lambda w
\end{equation}
\]</span></p>
<p>​ 也就是说，<span class="math inline">\(w\)</span>为一个特征向量（我们的线性组合是个特征向量，<span class="math inline">\(S_b\)</span>的特征向量，<strong><u><span class="math inline">\(S_b\)</span>恰好是原来样本的协方差矩阵</u></strong>）。而根据<span class="math inline">\(\eqref{res}\)</span>，等式左右左乘以<span class="math inline">\(w^T\)</span>，得到：<span class="math inline">\(w^TS_bw=\lambda w^Tw\)</span>，根据<span class="math inline">\(w^Tw=1\)</span>，可知，<span class="math inline">\(w^TS_bw=\lambda\)</span>。又由于需要让<span class="math inline">\(w^TS_bw\)</span>最大，那么<span class="math inline">\(\lambda\)</span>作为特征值需要选择最大的。在多维的情况下，最大的被选走了，就按照特征值大小排序，依次选取次大的特征值对应的特征向量即可。</p>
<p>​
这样就可以明白，为什么PCA要选择最大的特征值对应的特征向量作为降维组合方式了。很可惜的是，在<span class="math inline">\(\eqref{obj}\)</span>式分析时，并没有这样去思考，但是原来的想法已经非常接近这个我认为最有解释力的答案了。</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title>协方差 &amp; 特征值的交集</title>
    <url>/2021/03/12/%E5%8D%8F%E6%96%B9%E5%B7%AE-%E7%89%B9%E5%BE%81%E5%80%BC%E7%9A%84%E4%BA%A4%E9%9B%86/</url>
    <content><![CDATA[<h1 id="eigens-covs">Eigens &amp; Covs</h1>
<hr>
<p>​ 线性代数确实很有趣，但是展开成<span class="math inline">\(\sum\)</span>的形式就没有趣了。本文意在分析矩阵特征值在某些场合下的应用以及一些线性代数结论（特别是矩阵/向量求导）（烦人的分子分母布局）。</p>
<p><img src="/2021/03/12/%E5%8D%8F%E6%96%B9%E5%B7%AE-%E7%89%B9%E5%BE%81%E5%80%BC%E7%9A%84%E4%BA%A4%E9%9B%86/stitch.jpg"></p>
<center>
Figure 1. 2D-2D单应匹配
</center>
<span id="more"></span>
<hr>
<h2 id="矩阵特征量与法向量估计">矩阵特征量与法向量估计</h2>
<p>​ 对于一个给定矩阵A而言，其特征方程是： <span class="math display">\[
\begin{equation}\label{eigen}
\begin{array}{l}
A\pmb{x}=\lambda\pmb{x}\\
(I-\lambda A)\pmb{x}=\pmb{0}
\end{array}
\end{equation}
\]</span> ​
以上两个式子定义实际是同一个意思，只不过写法不同。如何理解特征（eigen）量呢？对于特征向量<span class="math inline">\(\pmb{x}\)</span>，在矩阵A的映射下（线性变换），会导致<span class="math inline">\(\pmb{x}\)</span>的方向完全不变（可能反向）。而另一方面，空间变换与矩阵运算的联系也有着紧密的联系，比如3
* 3矩阵就能完全表征二维平面上的平移以及旋转。实际上 3 *
3矩阵能表示任何的透视（perspective）变换： <span class="math display">\[
\begin{equation}
(x&#39;,y&#39;,z&#39;)^T=\begin{pmatrix}
a_{11} &amp; a_{12} &amp; a_{13} \\
a_{21} &amp; a_{22} &amp; a_{23} \\
a_{31} &amp; a_{32} &amp; a_{33}
\end{pmatrix}\begin{pmatrix}
x \\
y \\
z
\end{pmatrix}
=A\pmb{x}
\end{equation}
\]</span> ​
那么对A可以求其特征量。这些特征量表征的是什么呢？为了简单以及便于人类进行空间想象，以下讨论主要集中于二维矩阵与三维矩阵的讨论。</p>
<h3 id="二维直线法向量估计">二维直线法向量估计</h3>
<p>​
实际上，在二维的情况下，估计法向量与估计直线是同一个问题。假设有一堆点，如下图所示，存在噪声并且由于实际表面是个曲面，需要选择一个合理的范围，利用范围内点的信息进行法向量估计：</p>
<p><img src="/2021/03/12/%E5%8D%8F%E6%96%B9%E5%B7%AE-%E7%89%B9%E5%BE%81%E5%80%BC%E7%9A%84%E4%BA%A4%E9%9B%86/normal.JPG"></p>
<center>
Figure 2. 2D法向量估计
</center>
<p>​ 我们需要估计一条直线（法向量形式）： <span class="math display">\[
\begin{equation}\label{normal}
a^T\pmb{x}-b=0
\end{equation}
\]</span> ​ 那么对于n个离散的点<span class="math inline">\((x_i,y_i)\rightarrow\pmb{x}_i\)</span>，如果能找到参数<span class="math inline">\(a,b\)</span>使得： <span class="math display">\[
\begin{equation}\label{res1}
|b-a^T\pmb{x}|
\end{equation}
\]</span> ​ 这是由需要估计的参数直线<span class="math inline">\(\eqref{normal}\)</span>决定的，那么可以将<span class="math inline">\(\eqref{res1}\)</span>化为模平方的形式，这也就是我们需要优化的目标，实际上点的信息已经包含在直线中了，虽然没有写成常见的直线拟合最小二乘表示：
<span class="math display">\[
\begin{equation}\label{cost}
C=\sum_i(b-a^T\pmb{x})^T(b-a^T\pmb{x})
\end{equation}
\]</span> ​ 加上约束，可以得到一个带约束优化问题。约束是：<span class="math inline">\(a^Ta=1\)</span>。也就是说希望法向量是单位向量：
<span class="math display">\[
\begin{equation}
\left\{
\begin{array}{ll}\label{obj}
\text{min }\sum_i(b-a^T\pmb{x})^T(b-a^T\pmb{x}) \\
\text{s.t. } a^Ta=1
\end{array}
\right.\rightarrow
\text{min }\sum_i(b-a^T\pmb{x})^T(b-a^T\pmb{x}) + \lambda(a^Ta-1)\\
\end{equation}
\]</span> ​
也就是又用Lagrange乘子法将有约束问题转化为无约束问题了。对KKT条件进行讨论，等式约束的KKT条件就不用说了。对<span class="math inline">\(a\)</span>求导，有（这里有必要穿插一下矩阵与向量的求导知识）。如果x是一个
n *
1的列向量，那么一个关于x的标量函数关于x求导，求出将会是一个行向量。进一步地，可以证明（见<a href="#app">【Appendix】</a>）： <span class="math display">\[
\begin{equation}\label{lemma}
\begin{array}{ll}
\text{if }\alpha=x^TAx,\text{where }A\text{ is }n \times n \\
\text{then } \frac{\partial\alpha}{\partial x}=x^T(A+A^T)
\end{array}
\end{equation}
\]</span> ​ 那么根据公式<span class="math inline">\(\eqref{lemma}\)</span>，并且对<span class="math inline">\(\eqref{obj}\)</span>进行关于a（2 *
1列向量）求导，此处求导的结果是： <span class="math display">\[
\begin{equation}\label{der}
2\lambda a^T-2bn\overline{x}^T+\sum_{i=1}^n2a^T(x_ix_i^T)
\end{equation}
\]</span> ​ 而对b求导实际上也能得到重要的结论：即<span class="math inline">\(b=a^T\overline{x}\)</span>，那么带入到公式<span class="math inline">\(\eqref{der}\)</span>中就会有： <span class="math display">\[
\begin{equation}\label{der2}
2\lambda
a^T+2a^T\sum_{i=1}^n(x_ix_i^T)-(\overline{x}\overline{x}^T)=2\lambda
a^T+2a^T\sum_{i=1}^n(x_i-\overline{x})(x_i-\overline{x})^T
\end{equation}
\]</span> ​ 而<span class="math inline">\(\eqref{der2}\)</span>的右半部分求和式实际上是点集的协方差，最后也就得到了（忽略负号给<span class="math inline">\(\lambda\)</span>代来的影响）： <span class="math display">\[
\begin{equation}\label{eig}
\left(\sum_{i=1}^n(x_i-\overline{x})(x_i-\overline{x})^T\right)a=\lambda
a
\end{equation}
\]</span> ​ 也就是说，<span class="math inline">\(\lambda\)</span>为点集协方差矩阵的一个特征值，而<span class="math inline">\(a\)</span>则为对应的特征向量。也就是说，<span class="math inline">\(a\)</span>（法向量）的解实际上是点集协方差的一个特征向量，但是对于二维问题而言，特征向量有两个（一个最大特征向量，一个最小特征向量）。那么显然，根据<span class="math inline">\(\eqref{eig}\)</span>以及<span class="math inline">\(b=a^T\overline{x}\)</span>，带入到目标函数<span class="math inline">\(\eqref{obj}\)</span>中可以得到： <span class="math display">\[
\begin{equation}
L=0+\sum_{i=1}^n[a^T(x_i-\overline{x})][a^T(x_i-\overline{x})]^T=n\lambda
\end{equation}
\]</span> ​ 可以知道，<span class="math inline">\(\lambda\)</span>应该选择最小特征值。那么<span class="math inline">\(a\)</span>的解就是最小特征值对应的特征向量。感觉这个过程就十分的精妙，主要是要完全利用KKT条件，一个都不能漏，并且有意识地构造协方差
/ 均值以及<span class="math inline">\(x^Tx /
xx^T\)</span>两种形式。<strong><u>不难发现</u></strong>，这种表示形式可以自然推广到三维空间中去，此时求取的不再是直线的法向量，而是平面的法向量。</p>
<hr>
<h2 id="d图像配准闭式解">2D图像配准闭式解</h2>
<p>​ 考虑一个2D问题，两幅图像的配准。假设我们通过SIFT算子 +
RANSAC优化，得到了准确的特征点配对关系，那么如何求这个单应矩阵呢？</p>
<div class="note warning"><p>​
实际上，纯2D-2D匹配并不能称为单应矩阵（单应矩阵是同一物体3D-3D投影变换的表征）</p>
</div>
<p>​ 考虑简单的仿射变换，假设仿射变换矩阵为<span class="math inline">\(H\)</span>，给定source点集与target点集： <span class="math display">\[
\begin{equation}
P=(p_1,p_2,...p_n),Q=(q_1,q_2,...,q_2),P,Q\in \mathbb{R}^{3\times n}
\end{equation}
\]</span> ​ 那么假设<span class="math inline">\(HP=Q\)</span>,也即点集<span class="math inline">\(P\)</span>经过变换<span class="math inline">\(H\)</span>后直接成了<span class="math inline">\(Q\)</span>，那么为了使变换后的投影误差最小，考虑最小二乘问题：
<span class="math display">\[
\begin{equation}
L=\Vert HP-Q\Vert^2=tr[(HP-Q)^T(HP-Q)]\Longleftrightarrow
tr[(HP-Q)(HP-Q)^T]
\end{equation}
\]</span> ​ 那么根据矩阵迹的求导（以下性质将在<a href="#app">【Appendix】</a>中进行简要的分析）</p>
<table>
<colgroup>
<col style="width: 6%">
<col style="width: 45%">
<col style="width: 47%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;">性质</th>
<th>结论（分母布局）</th>
<th>分子布局</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">轮换性</td>
<td><span class="math inline">\(tr(ABC)=tr(BCA)\)</span></td>
<td><span class="math inline">\(tr(ABC)=tr(BCA)\)</span></td>
</tr>
<tr>
<td style="text-align: center;">线性1</td>
<td><span class="math inline">\(\frac{\partial tr(A^TB)}{\partial
A}=B\)</span></td>
<td><span class="math inline">\(\frac{\partial tr(A^TB)}{\partial
A}=B^T\)</span></td>
</tr>
<tr>
<td style="text-align: center;">线性2</td>
<td><span class="math inline">\(\frac{\partial tr(AB)}{\partial
A}=B^T\)</span></td>
<td><span class="math inline">\(\frac{\partial tr(AB)}{\partial
A}=B\)</span></td>
</tr>
<tr>
<td style="text-align: center;">二次型1</td>
<td><span class="math inline">\(\frac{\partial tr(ABA^T)}{\partial
A}=A(B+B^T)\)</span></td>
<td><span class="math inline">\(\frac{\partial tr(ABA^T)}{\partial
A}=(B+B^T)A^T\)</span></td>
</tr>
<tr>
<td style="text-align: center;">二次型2</td>
<td><span class="math inline">\(\frac{\partial tr(A^TBA)}{\partial
A}=(B+B^T)A\)</span></td>
<td><span class="math inline">\(\frac{\partial tr(A^TBA)}{\partial
A}=(B+B^T)A^T\)</span></td>
</tr>
</tbody>
</table>
<p>​ 可以得到： <span class="math display">\[
\begin{equation}\label{H}
\frac{\partial \text{ tr}[(HP-Q)(HP-Q)^T]}{\partial H}=2HPP^T-2QP^T=0
\end{equation}
\]</span> ​ 则可以得到：<span class="math inline">\(H=QP^T(PP^T)^{-1}\)</span>是解。其中<span class="math inline">\((PP^T)^{-1}\)</span>是伪逆，由于其行列式可能为0。可以用SVD分解得到，正常情况则使用LDLT进行分解即可。</p>
<hr>
<h2 id="appendix">Appendix</h2>
<p><span id="app"></span></p>
<h3 id="向量矩阵求导法则以及基本结论证明">向量矩阵求导法则以及基本结论证明</h3>
<p>​
这里涉及的都是基本的线性代数（以及高数中的多元函数Jacobian求解），但是自己从来认真推过。向量矩阵求导主要分析其中几个公式：</p>
<h4 id="基本法则">基本法则</h4>
<ul>
<li>标量对行向量求导，结果是行向量（朴素结论）</li>
<li>标量对列向量求导，结果是列向量（朴素结论）</li>
<li>标量对矩阵，结果是同样大小的矩阵，并且每个元素与求导矩阵对应（朴素结论）</li>
</ul>
<h4 id="行列求导">行列求导</h4>
<p>​
行向量对列向量求导，结果显然是个雅可比，由于求导元素是列向量，那么雅可比矩阵是按列组织的：
<span class="math display">\[
\begin{equation}
d(y_1,y_2,...,y_n)/d
\begin{pmatrix}
x_1\\
x_2\\
\vdots \\
x_m
\end{pmatrix}=
\begin{pmatrix}
\frac{\partial y_1}{\partial x_1} &amp; \frac{\partial y_2}{\partial
x_1} &amp; ... &amp; \frac{\partial y_1}{\partial x_1}\\
\frac{\partial y_1}{\partial x_2} &amp; \frac{\partial y_2}{\partial
x_2} &amp; ... &amp; \frac{\partial y_1}{\partial x_2} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
\frac{\partial y_1}{\partial x_m} &amp; \frac{\partial y_2}{\partial
x_m} &amp; ... &amp; \frac{\partial y_1}{\partial x_m}
\end{pmatrix}
\end{equation}
\]</span> ​
则反之，如果是列向量对行向量求导，那么将会是上矩阵的转置。注意，上式我写的是分母布局，之后我将完全使用分子布局，因为比较自然。分子布局与分母布局的区别是：</p>
<ul>
<li>分子布局：如果f是个列向量，x是个标量，那么<span class="math inline">\(\frac{\partial f}{\partial
x}\)</span>为列向量（自然表达）</li>
<li>分母布局：如果f是个标量，x是个列向量，那么<span class="math inline">\(\frac{\partial f}{\partial
x}\)</span>是个列向量（感觉不太自然嗷）</li>
</ul>
<p>​
也就是说，列向量对标量求导是不变形的，矩阵对标量求导也是不变形的（那么自然，行向量对标量求导也不变形，这就是一个比较自然的表达）。接下来讨论的公式都基于几个共同点：</p>
<ul>
<li>向量<span class="math inline">\(\pmb{x}\)</span>是列向量（n * 1）
<ul>
<li>矩阵A是m * n矩阵或是n * n矩阵79</li>
</ul></li>
</ul>
<p><span class="math display">\[
\begin{equation}
\frac{\partial A\pmb{x}}{\partial \pmb{x}}=A\tag{prop 1}
\end{equation}
\]</span></p>
<p>​ 这个很显然，讨论<span class="math inline">\(A\pmb{x}\)</span>时只需要将A按行分块，<span class="math inline">\(A\pmb{x}\)</span>每个元素都是<span class="math inline">\(\pmb{a}_j\pmb{x}\)</span>（标量），那么一个列向量<span class="math inline">\(A\pmb{x}\)</span>中的每个标量元素对列向量求导，得到一个行向量：
<span class="math display">\[
\begin{equation}
\pmb{a}_j\pmb{x}=\sum_{i=1}^na_{ji}x_i
\end{equation}
\]</span> ​ 显然，对这个标量求导得到<span class="math inline">\(\pmb{a}_j\)</span>本身。 <span class="math display">\[
\begin{equation}
\frac{\partial \pmb{x}^TA\pmb{x}}{\partial
\pmb{x}}=\pmb{x}^T(A+A^T)\tag{prop 2}
\end{equation}
\]</span> ​ 展开之后易于证明，由于<span class="math inline">\(\pmb{x}^TA\pmb{x}\)</span>是标量，标量对列向量求导是行向量，可以得到，行内的第j个元素为：
<span class="math display">\[
\begin{equation}
\sum_{i=1}^na_{ji}x_i+\sum_{j=1}^na_{ji}x_j
\end{equation}
\]</span> ​ 上式前半部分是行向量<span class="math inline">\(\pmb{x}^T\)</span>与矩阵<span class="math inline">\(A^T\)</span>的某一列进行相乘，后半部分则与<span class="math inline">\(A\)</span>的某一列相乘。<span class="math inline">\(\text{prop
2}\)</span>的证明又是比较容易的，可以根据基本的求和式与矩阵运算性质得到，关于矩阵行列求导操作，就只提这两个。</p>
<h3 id="矩阵迹的求导法则">矩阵迹的求导法则</h3>
<p>​ 迹是针对n * n矩阵而言的（对角线之和），假设<span class="math inline">\(A_{n\times k},B_{k\times n}\)</span>，则<span class="math inline">\(\text{tr}(AB)\)</span>有： <span class="math display">\[
\begin{equation}\label{tr}
\text{tr}(AB)=\sum_{i=1}^n\sum_{j=1}^ka_{ij}b_{ji}
\end{equation}
\]</span> ​ 那么假设<span class="math inline">\(\text{tr}(AB)\)</span>对A求导，由分子布局，将A看成一个行向量，每个行元素为一个列向量。可以知道，分子布局下，标量对行求导，得到列向量，列向量的元素将由原来行向量内的元素决定。那么由于原来行向量（1
* k）元素是一个个的列向量（n * 1），那么求导后的每个分量是个行向量（1 *
n），也即最后的结果是（k * n）的，下面证明这就是矩阵B。</p>
<p>​ 我们假设当前正在对行向量<span class="math inline">\(A\)</span>的元素<span class="math inline">\(\pmb{a}_p\)</span>进行求导，<span class="math inline">\(\pmb{a}_p=(a_{1p},a_{2p},...,a_{np})^T\)</span>是A矩阵的第p列。那么由公式<span class="math inline">\(\eqref{tr}\)</span>，迹中与<span class="math inline">\(a_{ip}\)</span>有关的只有： <span class="math display">\[
\begin{equation}
\sum_{i=1}^na_{ip}b_{pi}
\end{equation}
\]</span> ​ 对其求导，由于上式是一个标量而<span class="math inline">\(\pmb{a}_p\)</span>是一个列向量，应该得到一个行向量结果
<span class="math display">\[
\begin{equation}
\sum_{i=1}^na_{ip}b_{pi}\mathop{\Longrightarrow}^{d\pmb{a}_p}(b_{p1},b_{p2},...,b_{pn})
\end{equation}
\]</span> ​ 也就是说，矩阵迹对<span class="math inline">\(A\)</span>矩阵的第p个列求导，得到B的第p行。那么由此可以得到<span class="math inline">\(d\text{
tr}(AB)/dA=B\)</span>。（注意，这和我们上面所列表格不一致，表格是分母布局的，分母布局下这里确实是<span class="math inline">\(B^T\)</span>）。分母布局和分子布局恰是转置关系，那么公式<span class="math inline">\(\eqref{H}\)</span>在分子布局下应该是不变的（因为减号前后都进行了转置）。</p>
<p></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title>贝叶斯学习的理解</title>
    <url>/2021/03/10/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<h1 id="bayesian">Bayesian</h1>
<hr>
<h2 id="贝叶斯分类器">贝叶斯分类器</h2>
<p>​ 个人很喜欢贝叶斯学派的理论，感觉贝叶斯理论非常具有美感。</p>
<p>​ 贝叶斯分类器是典型的生成式模型。对于分类问题的概率形式，有<span class="math inline">\(P(c|x)\)</span>是给定特征情况下，分类结果为c的概率，显然这是我们想知道的（而反过来<span class="math inline">\(P(x|c)\)</span>可能是Encoder模型所讨论的）。判别式模型直接对<span class="math inline">\(P(c|x)\)</span>进行建模，举个例子，决策树吧。决策树根据x的不同分量进行划分，每层选取信息增益或者基尼指数最大的属性进行分支。那么决策树这个判别式模型，具体是如何对<span class="math inline">\(P(c|x)\)</span>进行建模的？</p>
<span id="more"></span>
<p>​ 个人的理解是：假设样本特征<span class="math inline">\(x=\{x_1,x_2,x_3,...,x_n\}\)</span>，其中，<span class="math inline">\(x_i\)</span>的下标表示分支顺序。在根节点处，假设分支基于特征分量<span class="math inline">\(x_1\)</span>，那么在根向下一层，概率会有如下形式：
<span class="math display">\[
P(c|x/\{x_1\},x_1=...)
\]</span> ​ 也就是基于<span class="math inline">\(x_1\)</span>确定后的结果进一步分支，直到无法分支为止。也就是说<span class="math inline">\(P(c|x)\)</span>中，x的每个分量逐步确定，对应到叶节点上的<span class="math inline">\(P(c|x)\)</span>也就确定了。</p>
<p>​ 而生成式模型（比如贝叶斯），建模的是联合分布或者是似然： <span class="math display">\[
\begin{equation}\label{bayes}
P(c|x)=\frac{P(x,c)}{P(x)}=\frac{P(x|c)P(c)}{P(x)}
\end{equation}
\]</span> ​ P(c)可直接根据样本估计（样本中分类为<span class="math inline">\(c_i\)</span>的占比，近似为先验概率，啊贝叶斯学派也用频率学派的结论了？）<span class="math inline">\(P(x)\)</span>为归一化常数，无需讨论。</p>
<p>​ 关于<span class="math inline">\(P(c|x)\)</span>我们要做什么？我们只希望将其计算出来（估计出来），就可以根据特征计算分类概率了。那么<span class="math inline">\(P(c|x)\)</span>分布的参数可以通过优化估计<span class="math inline">\(P(x|c)\)</span>来完成，简单的方法，就是进行极大似然估计（因为<span class="math inline">\(P(x|c)\)</span>是似然，是可以从样本中估计的）</p>
<hr>
<h2 id="朴素贝叶斯">朴素贝叶斯</h2>
<h3 id="最朴素的版本">最朴素的版本</h3>
<p>​ <span class="math inline">\(P(x|c)\)</span>好求吗？不好求，<span class="math inline">\(P(x|c)\)</span>的意义是：给定分类下，特征取值为x的概率。首先，有可能对应x根本没有在训练集样本中出现，其次，即使出现也可能因为组合爆炸导致可用样本数量少到无法正确用于估计，另外也可能产生样本某个属性值缺失的情况。</p>
<div class="note info"><p><strong>朴素贝叶斯认为</strong></p>
<p>假设样本所有的属性都是相互独立的，那么<span class="math inline">\(P(x|c)\)</span>就可以由独立条件拆开</p>
</div>
<p><span class="math display">\[
\begin{equation}\label{naive}
P(x|c)=\prod_{i=1}^nP(x_i|c)P(c)
\end{equation}
\]</span> ​
这好吗？很好，对某个属性的分布估计是比较简单的，并且样本数据一般都是充足的。但是这又不好，因为
<strong><u>通常属性之间都不会有太好的独立性</u></strong>（但是PCA之后可以用贝叶斯，由于PCA之后的特征不相关）。由于这个强独立性假设，所以这种贝叶斯称为“朴素的（你们啊，naive）”。</p>
<h3 id="独依赖版本">独依赖版本</h3>
<p>​ 由于朴素贝叶斯 sometimes
naive，导致使用者angry。为了减轻这种效应，首先进行协方差分析，找到与每一个属性关联性最强的另一个属性，讨论联合分布：
<span class="math display">\[
\begin{equation}\label{ode}
P(x|c) \propto P(c)\prod_{i=1}^nP(x_i|c,x_{i,k})=P(c)\prod_{i=1}^n
\frac{P(x_i,x_{i,k}|c)}{P(x_{i,k}|c)}
\end{equation}
\]</span> ​ 公式<span class="math inline">\(\eqref{ode}\)</span>最右部分个人感觉好像可以直接从样本中推出来，并且不会遇到组合爆炸效应，对独立性假设有放松作用。</p>
<h4 id="条件互信息">条件互信息</h4>
<p>​ 在<a href="https://enigmatisms.github.io/2021/03/02/%E7%BA%BF%E6%80%A7-%E6%A0%91%E5%9E%8B%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%BA%AF%E7%90%86%E8%AE%BA%E5%88%86%E6%9E%90/">[线性-树型分类器的纯理论分析]</a>中，提到了互信息，是指联合分布<span class="math inline">\(P_{X,Y}\)</span>与独立假设下边缘分布乘积<span class="math inline">\(P_XP_Y\)</span>的KL散度。那么条件互信息就是增加了一个条件概率：
<span class="math display">\[
\begin{equation}\label{cmi}
I(x,y|c)=\int_y\int_x p(x,y|c)\log\frac{p(x,y|c)}{p(x|c)p(y|c)}
\end{equation}
\]</span> ​
条件互信息就刻画了给定条件（分类为c）下，两个属性之间的关联关系。那么生成ODE结构可以以此为指导。</p>
<hr>
<h2 id="最小风险贝叶斯决策">最小风险贝叶斯决策</h2>
<p>​ 定义风险矩阵<span class="math inline">\(\Lambda\)</span>: <span class="math display">\[
\begin{pmatrix}
\lambda_{11} &amp; \lambda_{12} &amp; ... &amp;\lambda_{1n} \\
\lambda_{21} &amp; \lambda_{22} &amp; ... &amp;\lambda_{2n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\lambda_{n1} &amp; \lambda_{n2} &amp; ... &amp;\lambda_{nn} \\
\end{pmatrix}
\]</span> ​ 其中，<span class="math inline">\(\lambda_{i,j}\)</span>表示本身是第j类，但是分类结果是第i类的风险。（注意顺序啊，因为决策表的横轴一般定义为实际情况，而纵轴为决策）。那么给定一个样本x，进行分类得到c，根据c进行决策<span class="math inline">\(\alpha\)</span>，由此产生的损失是r，那么： <span class="math display">\[
\begin{align}
&amp; P(c_i|x)=\frac{P(x|c_i)P(c_i)}{\sum_{i=1}^nP(x|c_i)}\\
&amp; R(\alpha_i|x)=\sum_{j=1}^n\lambda_{i, j}P(c_i|x) \label{rsingle}\\
&amp; R_{total} = \sum_{x}R(\alpha(x)|x)    \label{rtotal} \\
&amp; E(R) =\sum_x R(\alpha(x)|x)P(x)
\end{align}
\]</span> ​ 我们实际上要最小化<span class="math inline">\(\eqref{rtotal}\)</span>，也就是对于每一个样本x，其分类函数<span class="math inline">\(\alpha(x)\)</span>需要让的总体决策风险的期望最低，因为实际上<span class="math inline">\(R_{total}\)</span>的指导意义并不大，它是局限于训练样本的，我们希望能独立于样本得到泛化能力，通过给不同特征的样本进行加权，求得期望（事实上不变成期望也没办法进行数值上的估计）。
<span class="math display">\[
\begin{equation}\label{arg}
\alpha^*=\mathop{\text{argmin}}_\alpha
E(R)\leftarrow\mathop{\text{argmin}}_{i=1,2...n}R(\alpha_i|x)
\end{equation}
\]</span> ​
每个样本都能得到最优的决策时，总体看起来决策结果也是最优的，则需要选择决策风险最小的分类结果。那么现在的问题是：会不会出现选择的决策函数<span class="math inline">\(\alpha(x)\)</span>对某些x'而言是<span class="math inline">\(R(a(x&#39;)|x&#39;)\)</span>最小，而另一些并不是最小，但总的期望却是最小的情况？<strong><u>其实个人认为这是有可能的</u></strong>，但是我还是觉得需要确定一下，之后问老师吧。我的想法是：如果固定训练集，只在训练集上讨论，那么确实是有办法让所有x的风险最小的（<strong><u>疯狂过拟合，产生奇异的分类边界</u></strong>），但是这未必是对全局都最优的，只是在训练集上的风险表现最小。</p>
<hr>
<h2 id="吉布斯采样">吉布斯采样</h2>
<p>​ 吉布斯采样（Gibbs
sampling）作为一种MCMC延伸的随机采样方式，基于的理论是Markov链逐渐收敛到平稳分布（stationary
distribution）时的性质。针对的问题是：</p>
<div class="note info"><p>​
对于一个多元分布，联合概率一般难以获得，但已知一些变量的条件分布情况下，如何通过采样来估计联合概率分布？</p>
</div>
<p>​
从联合分布采样确实是很难的事情，因为联合分布综合的信息最多。通过边缘化操作，可以得到边缘分布，通过联合分布和边缘分布可以得到条件分布。也即联合分布已经包含了一个多元分布的所有信息了。既然包含的信息越多，获取必然也就越困难。对此，Wikipedia[1]也说：</p>
<blockquote class="blockquote-center">
<p>The point of Gibbs sampling is that given a multivariate distribution
it is simpler to sample from a conditional distribution than to
marginalize by integrating over a joint distribution.</p>

</blockquote>
<h3 id="简单理解">简单理解</h3>
<p>​ 假设可怜的卷怪有如下几种状态：</p>
<ul>
<li>学习空间：<span class="math inline">\(X=\)</span>
概率，线代，离散</li>
<li>观测时间：$Y = $ 上午，中午，下午</li>
<li>状态空间：<span class="math inline">\(Z=\)</span>
高效，一般，不想学</li>
</ul>
<p>​ 对于联合分布<span class="math inline">\(P(X,Y,Z)\)</span>，直接讨论是极其复杂的。但是有一些先验知识却比较好获得：</p>
<ul>
<li>学习的可能：<span class="math inline">\(P(X|Y,Z)\)</span>：在给定学习状态以及当前观测时间时，卷怪可能学什么的分布。</li>
<li>观测时间：<span class="math inline">\(P(Y|X,Z)\)</span>：已知当前卷怪的状态以及ta在学什么，得到当前时间的分布。</li>
<li>状态推测：<span class="math inline">\(P(Z|X,Y)\)</span>：已知当前时间以及科目，求卷怪的学习状态。</li>
</ul>
<p>​
以上三种条件概率都比较好讨论，比如观察半学期该卷怪的学习习惯，也就能总结出来规律，作为先验知识。Gibbs
sampling就是利用Markov链以及这几种条件分布的关联性，逼近联合分布的，方法如下：</p>
<ol type="1">
<li>获取一个初始的变量，比如X = 概率，Y = 中午，Z =
不想学。这个变量不一定需要有来源的理由。将这个随机初始生成的状态变量设为<span class="math inline">\(S^0\)</span>（0时刻的状态）</li>
<li>从<span class="math inline">\(S^0\)</span>出发，根据定义的条件分布，<strong><u>每次选择一个变量进行改变</u></strong>。举个例子，<span class="math inline">\(S^0\rightarrow
S^1\)</span>的状态转移时，固定中午以及不想学两个状态（对应Y,Z），根据条件概率<span class="math inline">\(P(X|Y,Z)\)</span>，从这个条件分布里采样一个可能的<span class="math inline">\(X\)</span>状态。修改此X。</li>
<li><span class="math inline">\(S^t\rightarrow
S^{t+1}\)</span>也是这样做，每次选择一个变量进行修改（为了保证均匀性，可以顺序遍历所有存在条件分布的变量）。</li>
<li>Markov链收敛后（采样次数比较大），生成的样本实际是按照近似联合分布生成的。从这些样本中，可以求出所有边缘分布（假设采样足够），那么联合分布可以顺势推导出来。</li>
</ol>
<p>​ 有关Markov以及平稳分布的数学原理，见<a href>【Post:无向图模型
&amp; Markov的“家具”】</a>。</p>
<hr>
<h2 id="em算法">EM算法</h2>
<p>​
这个算法之前一直没有搞懂其数学意义，因为不管是《西瓜书》还是Wikipedia，对于其数学性解释都极其简略。在查找资料的过程中偶然看到一篇CSDN博客[2]（可能不是[2]对应的网址，由于原网页没有被我保存），觉得说得很对。但是毕竟这是别人的推导，加上CSDN等等网站的博主都是你抄我我抄你的，个人觉得有必要自己推一遍，加深理解。</p>
<h3 id="基本流程的解释">基本流程的解释</h3>
<p>​
EM算法要解决什么问题？<strong><u>概率推理问题</u></strong>，并且还是无监督的。给定一个随机状态<span class="math inline">\(X&#39;\)</span>，但<span class="math inline">\(X&#39;\)</span>实际包含了已经被观测到的状态<span class="math inline">\(X\)</span>以及未被观测的状态<span class="math inline">\(Z\)</span>，这个Z十分烦人（称为隐变量，latent
vector），存在这种未知信息的情况下，要进行模型参数<span class="math inline">\(\pmb{\theta}\)</span>的估计。一般情况下，我们是使用MLE来估计的，首先需要构造似然：
<span class="math display">\[
\begin{equation}\label{likely}
L(\pmb{\theta}|X)=P(X|\pmb{\theta})\rightarrow
L(\pmb{\theta}|X,Z)=P(X,Z|\pmb{\theta})
\end{equation}
\]</span> ​ 关于Z的信息是缺失的，即使我们给定参数（比如<span class="math inline">\(\pmb{\theta}\)</span>是限定某个分布的参数）也无法直接估计<span class="math inline">\(P(X,Z|\pmb{\theta})\)</span>。当然，对于公式<span class="math inline">\(\eqref{likely}\)</span>定义的似然，处理Z的一个方法是让他不存在。怎么搞呢？边缘化就好了：
<span class="math display">\[
\begin{equation}\label{margin}
L(\pmb{\theta}|X)=\int_ZL(\pmb{\theta}|X,Z)dZ=\int_ZP(X,Z|\pmb{\theta})dZ
\end{equation}
\]</span> ​ 但Wikipedia这么说：</p>
<blockquote class="blockquote-center">
<p>However, this quantity is often <strong><u>intractable</u></strong>
(e.g. if <span class="math inline">\(\mathbf {Z}\)</span> is a sequence
of events, so that the number of values grows
<strong><u>exponentially</u></strong> with the sequence length, the
exact calculation of the sum will be <strong><u>extremely
difficult</u></strong>).</p>

</blockquote>
<p>​ 什么意思呢？看公式<span class="math inline">\(\eqref{margin}\)</span>，我们是对Z进行积分，而Z可能是多元变量，正如上述引用所说，要是有<span class="math inline">\(Z =
\{X_{n-k},...X_{n-1},X_n\}\)</span>，那在边缘化的时候我们不得不这样：
<span class="math display">\[
\begin{equation}\label{awful}
L(\pmb{\theta}|X)=\int_ZP(X,Z|\pmb{\theta})dZ=\int_{X_n}\int_{X_{n-1}}...\int_{X_{n-k}}P(X,Z|\pmb{\theta})dZ
\end{equation}
\]</span> ​
这好吗？这不好。太丑陋了，而且难以计算。所以我们需要其他算法！那么EM(Expectation
Maximization)算法就是来干这个的。好，我来摘抄一下令人疑惑的基本优化过程，虽然基本优化过程的数学表达乍一看难以理解，但是意思还是比较明确的：</p>
<ol type="1">
<li>构造似然：<span class="math inline">\(Q(\pmb{\theta}|\pmb{\theta}^{(t)})\)</span>，这个似然是在：<strong><u>估计得到当前最优的条件分布<span class="math inline">\(P(Z|X,\pmb{\theta})\)</span></u></strong>下定义的，也即是：</li>
</ol>
<p><span class="math display">\[
\begin{equation}\label{estep}
Q(\pmb{\theta}|\pmb{\theta}^{(t)})=E_{P_{Z|X,\pmb{\theta}^{(t)}}}[\text{log}
L(\pmb{\theta}|X,Z)]
\end{equation}
\]</span></p>
<ol start="2" type="1">
<li>优化似然：使得<span class="math inline">\(\pmb{\theta}\)</span>最大化：</li>
</ol>
<p><span class="math display">\[
\begin{equation}\label{mstep}
\pmb{\theta}^{(t+1)}=\mathop{\text{arg
max}}_{\pmb{\theta}}Q(\pmb{\theta}|\pmb{\theta}^{(t)})
\end{equation}
\]</span></p>
<p>​
个人的初步理解大概是这样的：类似于机队预判敌方位置使用的双迭代算法：</p>
<ul>
<li>构造似然的过程（称为E-step）：根据最优<span class="math inline">\(\pmb{\theta}\)</span>更新条件分布<span class="math inline">\(P(Z|X,\pmb{\theta})\)</span>并且生成目标的过程。</li>
<li>优化似然的过程（称为M-step）：根据<span class="math inline">\(P(Z|X,\pmb{\theta})\)</span>优化<span class="math inline">\(\pmb{\theta}\)</span>的过程</li>
</ul>
<p>​
实际上，在下面一小节（【数学理论】）中，这两个过程的意义将更加清晰。个人比较笨，觉得上面<span class="math inline">\(\eqref{estep}\)</span>以及<span class="math inline">\(\eqref{mstep}\)</span>定义的公式（<span class="math inline">\(\eqref{mstep}\)</span>还好些），直接看根本不知道EM算法到底在搞什么，取什么期望，算什么分布，怎么算。</p>
<h3 id="优化目标的数学理论">优化目标的数学理论</h3>
<h4 id="jensen不等式">Jensen不等式</h4>
<p>​
数学竞赛，啊熟悉的不等式。在函数或者多元函数里的琴生不等式说的是：对于凸函数而言，函数值的加权平均会大于加权平均的函数值。这个不再多提，很简单。而在概率（信息论）中，琴生不等式的定义如下：
<span class="math display">\[
\begin{equation}\label{jensen}
\begin{array}{ll}
\psi\left( E(X)\right) \leq E(\psi(X)),\\
\text{where }\psi \text{ is convex function}
\end{array}
\end{equation}
\]</span> ​
而琴生不等式并不是我的讨论重点，这显然也是一个非常基础的结论：凸函数映射后的随机变量取值存在的性质。但是这个结论很重要，一会儿要用到。</p>
<h4 id="重要性采样">重要性采样</h4>
<p>​ 由公式<span class="math inline">\(\eqref{margin}\)</span>的离散化形式，展开似然函数式子，并且注意，此处要符合我们在E-step中构建的似然（也就是取对数，将连乘变成连加，下式展示的是：取对数似然之前的Z边缘化操作
<span class="math display">\[
L(\pmb{\theta}|x_i)=\text{log}P(x_i|\pmb{\theta})=\text{log}\sum_ZP(x_i,Z|\pmb{\theta})
\]</span> ​ 那么，似然可以写为： <span class="math display">\[
\begin{equation}\label{like}
L(\pmb{\theta}|X)=\sum_i\text{log}P(x_i|\pmb{\theta})=\sum_i\text{log}\sum_ZP(x_i,Z|\pmb{\theta})
\end{equation}
\]</span> ​ 首先需要知道，log是个凹函数，那么凹函数琴生不等式有<span class="math inline">\(\eqref{jensen}\)</span>相反的结论，接下来就是要想办法让log换个位置，我们考虑将<span class="math inline">\(P(x_i,Z|\pmb{\theta})\)</span>拆开为： <span class="math display">\[
\begin{equation}\label{trans1}
P(x_i,z_i|\pmb{\theta})=Q(z_i)\frac{P(x_i,z_i|\pmb{\theta})}{Q(z_i)}
\end{equation}
\]</span> ​ 根据公式<span class="math inline">\(\eqref{trans1}\)</span>，可以将公式<span class="math inline">\(\eqref{like}\)</span>化成如下形式，注意，对Z进行边缘化操作实际上与取期望存在等价之处，都是消除Z的影响（消除Z的随机变量性）：
<span class="math display">\[
\begin{equation}\label{equ1}
L(\pmb{\theta}|X)=\sum_i\text{log}\sum_ZP(x_i,Z|\pmb{\theta})=\sum_iQ(z_i)\text{log}\sum_Z\frac{P(x_i,z_i|\pmb{\theta})}{Q(z_i)}
\end{equation}
\]</span> ​ <span class="math inline">\(Q(z_i)\)</span>是隐变量的一种分布，但是形式暂时未知。我们可以将公式<span class="math inline">\(\eqref{equ1}\)</span>的log内部看成是对Z的期望（实际上，把<span class="math inline">\(Q(z_i)\)</span>移动到z累加式内部，就能看出来，概率<span class="math inline">\(Q(z_i)\)</span>乘以某一个值的期望形式）。这部分很像《概率机器人》[3]中，说粒子滤波时的重要性采样：
<span class="math display">\[
\begin{equation}\label{imp}
E(X)=\int_xxp(x)\text{d}x=\int_xx\frac{p(x)}{q(x)}q(x)\text{d}x
\end{equation}
\]</span> ​
也就相当于，将一个难以求取的期望，转化为另一个分布下，另一个随机变量函数的期望。而实际上，在重要性采样中，<span class="math inline">\(p(x)/q(x)\)</span>是一个经过估计的权值。关于这一点，我将会在<a href="https://enigmatisms.github.io/2021/03/07/%E5%8D%A1%E5%B0%94%E6%9B%BC%E8%BF%9B%E9%98%B6%E4%B8%8E%E7%B2%92%E5%AD%90%E6%BB%A4%E6%B3%A2%E5%AE%9E%E7%8E%B0/">【Post:
卡尔曼进阶与粒子滤波实现 】</a>中提到。</p>
<p>​ 由log的性质（log是凹函数）与琴生不等式，有： <span class="math display">\[
\text{log}\sum_Z\frac{P(x_i,z_i|\pmb{\theta})}{Q(z_i)} \geq
\sum_Z\text{log}\frac{P(x_i,z_i|\pmb{\theta})}{Q(z_i)}
\]</span> ​ 那么似然<span class="math inline">\(\eqref{equ1}\)</span>的一个下界已经找到了： <span class="math display">\[
\begin{align}
L(\pmb{\theta}|X)=\sum_iQ(z_i)\text{log}\sum_Z\frac{P(x_i,z_i|\pmb{\theta})}{Q(z_i)}
\geq \\
L_{lb}(\pmb{\theta}|X)=\sum_iQ(z_i)\sum_Z\text{log}\frac{P(x_i,z_i|\pmb{\theta})}{Q(z_i)}
\label{lb}
\end{align}
\]</span> ​ 如何优化？EM算法的想法实际上是：</p>
<ul>
<li>E-step：确定似然函数，求得当前Z的分布，计算得到的是<strong><u>似然函数的下界</u></strong>。</li>
<li>M-step：根据下界，优化这个下界。使下界更大，根据夹逼准则，最大值的期望也将更大。</li>
</ul>
<p>​ 那如何最大化这个下界？</p>
<h4 id="似然转化">似然转化</h4>
<p>​ 琴生不等式告诉我们，<span class="math inline">\(\eqref{equ1}\)</span>是永远大于等于<span class="math inline">\(\eqref{lb}\)</span>的，成立的条件是：X是确定变量。哦？那么此处X就是<span class="math inline">\(\eqref{lb}\)</span>log里面的部分。如果这是个常数，也即：
<span class="math display">\[
\frac{P(x_i,z_i|\pmb{\theta})}{Q(z_i)} =C\rightarrow
P(x_i,z_i|\pmb{\theta})=CQ(z_i)
\]</span> ​ 由于<span class="math inline">\(\sum
Q(z_i)=1\)</span>（概率归一化性质），则<span class="math inline">\(P(x_i|\pmb{\theta})=C\)</span>，也就得到了这样的结论：
<span class="math display">\[
\begin{equation}\label{qres}
Q(z_i)=\frac{P(x_i,z_i|\pmb{\theta})}{P(x_i|\pmb{\theta})}=\frac{P(x_i,z_i,\pmb{\theta})}{P(x_i,\pmb{\theta})}=P(z_i|x_i,\pmb{\theta})
\end{equation}
\]</span> ​
wow。这说明了什么？这说明，使得下界最大的，Z分布的估计应该是<span class="math inline">\(P(Z|X,\pmb{\theta})\)</span>。那么这样一操作，我们把似然objective写了出来，并且最大化了下界，得到了此时关于Z分布的估计。因为我们实际上不知道Z的分布，但是为了进行这个MLE，我们做了一个最大化下界操作，也就估计出了隐变量Z的分布。</p>
<p>​ 下一步当然是M-step，固定已经选择优化完的<span class="math inline">\(Q(Z)\)</span>，开始argmax <span class="math inline">\(\pmb{\theta}\)</span>。这里就有点像coordinate
descent了，跟我写的灯条优化算法是类似的，固定某几个分量，优化剩余的一个分量。E-step就是固定<span class="math inline">\(\pmb{\theta}\)</span>，而M-step就是固定Q。M-step的工作是进一步优化下界。</p>
<p>​ 我们优化的是哪个式子？优化的是下界式<span class="math inline">\(\eqref{lb}\)</span>，需要进一步调整<span class="math inline">\(\pmb{\theta}\)</span>。由于<span class="math inline">\(\eqref{lb}\)</span>实际上已经完全确定了，所以M-step实际上在优化一个仅关于<span class="math inline">\(\theta\)</span>的表达式： <span class="math display">\[
\begin{equation}\label{obj}
Q^{*}_{lb}=\sum_iQ(z_i)\sum_Z\text{log}\frac{P(x_i,z_i|\pmb{\theta})}{Q(z_i)}
=\sum_iP(Z|x_i,\pmb{\theta})\sum_zP(X|\pmb{\theta})
\end{equation}
\]</span> ​ 实际上这成了一个优化问题。Wikipedia上举了关于高斯分布<span class="math inline">\(\theta\)</span>参数的优化过程。这里就省略了。</p>
<h4 id="收敛分析">收敛分析</h4>
<p>​
证明收敛？也就是需要证明，每一次的结果（似然函数）不会比前一次低即可。推导过程倒是比较直接：</p>
<ul>
<li>由于M-step才更新<span class="math inline">\(\pmb{\theta}^t
\rightarrow
\pmb{\theta}^{t+1}\)</span>，而更新过程保证了（因为我们希望优化下界，使得似然变大）</li>
</ul>
<p><span class="math display">\[
Q_{lb}(\pmb{\theta}|\pmb{\theta}^{t+1}) \geq
Q_{lb}(\pmb{\theta}|\pmb{\theta}^{t})\rightarrow
\sum_iQ(z_i)\sum_Z\text{log}\frac{P(x_i,z_i|\pmb{\theta}^{t+1})}{Q(z_i)}
\geq
\sum_iQ(z_i)\sum_Z\text{log}\frac{P(x_i,z_i|\pmb{\theta}^{t})}{Q(z_i)}
\]</span></p>
<ul>
<li>而我们知道<span class="math inline">\(Q_{lb}(\pmb{\theta}|\pmb{\theta}^{t+1})\)</span>只是似然<span class="math inline">\(L(\pmb{\theta}^{t+1}|X)\)</span>的下界，所以t+1迭代的似然必然大于等于下界。</li>
<li>而由于，琴生不等式我们取了等号成立，那么下式成立：</li>
</ul>
<p><span class="math display">\[
\sum_iQ(z_i)\sum_Z\text{log}\frac{P(x_i,z_i|\pmb{\theta}^{t})}{Q(z_i)}=L(\pmb{\theta}^{t}|X)
\]</span></p>
<ul>
<li>故综上，每次更新之后，似然函数不会比原来小。EM算法是收敛的。</li>
</ul>
<hr>
<h2 id="neyman-pearson决策">Neyman-Pearson决策</h2>
<p>​
说实话，决策这部分完全可以单独开一篇讲。决策是要做什么？举一个简单的例子，新冠。</p>
<ul>
<li>医院将阴性患者识别为阳性（TN-&gt;FP），称之为第一类错误（拒真，虚警，假阳性率，也就是实际阴性的人中，检测结果为阳性人的比例）</li>
<li>医院将阳性患者识别为阴性（TP-&gt;FN），称之为第二类错误（存伪，漏报，假阴性率）（注意此处存伪，拒真两个定义其实意思上互换没什么大问题）</li>
</ul>
<p>​
那么作为医院，这两种判定必然存在，但是哪一种更严重？显然是第二类错误，把阳性存下来了。医院需要对检测结果存在的情况进行加权，尽量减少两类，但是两类中又各有侧重，加权地给出风险。Neyman-Pearson决策是贝叶斯决策的一种特殊情况，但是很常见：两类错误各有概率，但是我们希望：</p>
<ul>
<li>犯其中一类错误的概率能达到某个标准值（比如<span class="math inline">\(\epsilon_0\)</span>）</li>
<li>与此同时，犯另一种错误的概率越小越好</li>
</ul>
<p>​
这就是Neyman-Pearson决策讨论的问题，其表达式可以写为（以其中一种情况为例）：
<span class="math display">\[
\begin{equation}\label{np}
\begin{array}{ll}
\text{min }P_1\\
\text{s.t. } P_2=\epsilon_0
\end{array}
\end{equation}
\]</span> ​ 此处表达的意思是：当犯第二类错误的概率为<span class="math inline">\(\epsilon_0\)</span>时（达到第二类错误规定的标准），犯第一类错误概率尽可能小。</p>
<h3 id="形式变换">形式变换</h3>
<p>​ 首先我们先写出<span class="math inline">\(P_1,P_2\)</span>的表达式，假设类1对应了阴性，类2对应了阳性。那么阳性判别范围是<span class="math inline">\(R_2\)</span>，阴性判别范围是<span class="math inline">\(R_1\)</span>。 <span class="math display">\[
\begin{align}
&amp;P_1=\int_{R_2}p(x|w_1)dx\label{p1}\\
&amp;P_2=\int_{R_1}p(x|w_2)dx\label{p2}
\end{align}
\]</span> ​
其意义是什么？P1是第一类错误犯错概率，也就是假阳性率（实际为阴性<span class="math inline">\(w_1\)</span>的样本，却在阳性判别范围内当作阳性检测出）。P2是第二类错误犯错概率，意义类似。那么由公式<span class="math inline">\(\eqref{np}\)</span>可以知道，问题是约束极小值求解问题，可以使用Lagrange法处理，那么乘子化后的objective带入公式<span class="math inline">\(\eqref{p1}\)</span>以及<span class="math inline">\(\eqref{p2}\)</span>有： <span class="math display">\[
\begin{equation}\label{obj2}
L=\int_{R_2}p(x|w_1)dx+\lambda\left( \int_{R_1}p(x|w_2)dx-\epsilon_0
\right)
\end{equation}
\]</span> ​ 而实际上，<span class="math inline">\(\eqref{obj2}\)</span>是可以拆解的（有关假阳性率部分），根据概率公式拆解：
<span class="math display">\[
\begin{equation}\label{obj3}
L=1-\int_{R_1}p(x|w_1)dx+\lambda\left( \int_{R_1}p(x|w_2)dx-\epsilon_0
\right) =
1-\lambda\epsilon_0+\int_{R_1}\lambda p(x|w_2)-p(x|w_1)dx
\end{equation}
\]</span> ​ 好，回顾熟悉的KKT条件，<span class="math inline">\(L\)</span>相对于<span class="math inline">\(\lambda\)</span>的偏导数是要为0的，实际上就是等式约束要成立，这里就不写了。而还有什么可以求导的吗？千万不要忘记自己要干什么。讨论这个决策objective，最小化它是为了找到一个最好的决策模型，也就是说，模型参数是我们想知道的！此处我们像书[4]上一样，只简单讨论模型参数【决策边界】的划定，也即参数t。对t求偏导会发生什么？
<span class="math display">\[
\frac{\partial}{\partial t}\int_{R_1}\lambda p(x|w_2)-p(x|w_1)dx
=\frac{\partial R_1}{\partial t}\times[\lambda p(x|w_2)-p(x|w_1)]
\]</span> ​
书上没写清楚，但个人认为是这样的。这是由变限积分的性质决定的。那么边界对t的偏导不好求，可以是0，也可以不是0。由KKT偏导为0要求，显然下式成立是较优的选择：
<span class="math display">\[
\begin{equation}\label{cond}
\lambda = \frac{p(x|w_1)}{p(x|w_2)}
\end{equation}
\]</span> ​ 注意KKT条件产生了两个约束。而对于公式<span class="math inline">\(\eqref{obj3}\)</span>的积分，我们发现，如果可以让积分符号里面的项小于0，那么积分结果必然负的程度最大，L最小，这是最期望的情况。于是实际上我们有<span class="math inline">\(\eqref{cond}\)</span>稍微修改一下的要求：左边应该小于右边。也就是：
<span class="math display">\[
\begin{equation}\label{cond2}
\lambda &lt; \frac{p(x|w_1)}{p(x|w_2)}
\end{equation}
\]</span> ​ 公式<span class="math inline">\(\eqref{obj3}\)</span>定义的积分项是在<span class="math inline">\(R_1\)</span>上的，也就是说，在<span class="math inline">\(R_1\)</span>上时，条件<span class="math inline">\(\eqref{cond2}\)</span>成立，就可以让L变小。那么，就自然可以综上所述：
<span class="math display">\[
\begin{align}
&amp; \int_{R_1}p(x|w_2)dx = \epsilon_0 \tag{KKT condition 1}\\
&amp; \lambda = \frac{p(x|w_1)}{p(x|w_2)} (\large{\text{说明决策边界}})
\tag{KKT condition 2} \\
&amp; \lambda &lt; \frac{p(x|w_1)}{p(x|w_2)}
(R_1\large{\text{内部要求}})  \tag{int op}
\end{align}
\]</span> ​ 理解起来还是比较简单的。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://en.wikipedia.org/wiki/Gibbs_sampling">[Wikipedia, Gibbs
sampling]</a></p>
<p>[2] <a href="https://blog.csdn.net/yzheately/article/details/51164441">CSDN-EM算法-数学原理及其证明</a></p>
<p>[3] Sebastian Thrun, Wolfram Burgard, Dieter Fox
<strong><em>Probabilistic Robotics</em></strong>.</p>
<p>[4] 张学工（编著），模式识别（第三版），清华大学出版社</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>概率论</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>线性/树型分类器的纯理论分析</title>
    <url>/2021/03/02/%E7%BA%BF%E6%80%A7-%E6%A0%91%E5%9E%8B%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%BA%AF%E7%90%86%E8%AE%BA%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="纯理论分析">纯理论分析</h1>
<hr>
<h2 id="preface">Preface</h2>
<p>​
周志华老师的《机器学习》看到了第五章，可总感觉看得太快了（可惜起步太晚了，大三下才系统地学ML）。个人认为走马观花地看完全没有用处，最好是能自己将所有碰到的轮子都写一遍（理想情况），但人的精力毕竟有限，开学了时间也比较紧张，实现这一步就先跳过吧，而细致的理论分析与理解是完全必要的。LDA之前实现过<a href="https://github.com/Enigmatisms/Algorithms-Plus/blob/master/py/LDA/lda_learn.py">Github
Algorithm-Plus🔗</a>，决策树倒是连理论都没怎么细看，只调过库。为了不当调库侠，有写轮子的能力，个人将对这两章进行一下梳理，写一下自己的理解。</p>
<p><img src="/2021/03/02/%E7%BA%BF%E6%80%A7-%E6%A0%91%E5%9E%8B%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%BA%AF%E7%90%86%E8%AE%BA%E5%88%86%E6%9E%90/melon.jpg"></p>
<center>
Figure 1. 西瓜
</center>
<p>​ LDA（消歧义：Linear Discriminant Analysis，不是Latent Dirichlet
Allocation）和决策树都是两个非常简单但是又很优雅的分类器。</p>
<span id="more"></span>
<hr>
<h2 id="lda的数学推导">LDA的数学推导</h2>
<p>​ <blockquote class="blockquote-center">
<p>同类样本的类内方差最小，而不同类样本的类间方差最大</p>

</blockquote></p>
<p>​
LDA是给定标签下的有监督降维方式，希望找到更低维度上的投影，可以满足上述属性。而对于高维而言，协方差是描述样本关系的指标。协方差的定义如下（大二下学的，回忆一下）：描述n维随机变量<span class="math inline">\(X=(X_1,X_2,...X_n)\)</span>每个分量之间存在的关系，协方差可以定义为：
<span class="math display">\[
\begin{equation}
C = \begin{pmatrix}
c_{11} &amp; c_{12} &amp; ... &amp; c_{1n} \\
c_{11} &amp; c_{12} &amp; ... &amp; c_{1n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
c_{n1} &amp; c_{n2} &amp; ... &amp; c_{nn} \\
\end{pmatrix}
\end{equation}
\]</span> ​ 其中，<span class="math inline">\(c_{ij}\)</span>是两个分量<span class="math inline">\(X_i,X_j\)</span>的协方差<span class="math inline">\(Cov(X_i, X_j) =
E[(X_i-E_i)(X_j-E_j)]\)</span>。协方差存在一些性质，比如说： <span class="math display">\[
\text{let }Cov(X)=\Sigma\\
Cov(AX+b)=A\Sigma A^T
\]</span> ​ 证明就省略了，根据期望的性质，推导还是比较简单的。</p>
<h3 id="二分类">二分类</h3>
<p>​ 假设有两类样本，<span class="math inline">\(D_1\)</span>以及<span class="math inline">\(D_2\)</span>，<span class="math inline">\(D_1\)</span>的样本中心（根据矩法可以求出来）为<span class="math inline">\(\mu_1\)</span>，对应地<span class="math inline">\(D_2\)</span>有<span class="math inline">\(\mu_2\)</span>，那么假设存在一个低维过原点的超平面（由于是平行投影，是否过原点不影响结果，但原点较好讨论），这个超平面方程为：<span class="math inline">\(w^Tx=0\)</span>，那么投影在这个超平面上的数据点应该有什么形式？中心点应该有什么形式？协方差是否改变？<span class="math inline">\(w^Tx=0\)</span>确实是降了1维（因为有一个约束方程），但如何使用<span class="math inline">\(w\)</span>进行投影？</p>
<p>​ 实际上，每个样本点<span class="math inline">\(x_i\)</span>都在：<span class="math inline">\(w^Tx+b_i=0\)</span>
这个超平面上，去掉这个相对原点的偏移，就可以得到每一个样本点在低维上的投影。实际是这样操作的：设<span class="math inline">\(x_i\)</span>是超平面<span class="math inline">\(w^Tx = 0\)</span>外一点，那么显然，<span class="math inline">\(x_i\)</span>可以表示为超平面上的投影点<span class="math inline">\(x_i&#39;\)</span>与法向量<span class="math inline">\(w\)</span>的加权组合（因为已经构成基了），比如：
<span class="math display">\[
\begin{equation}
x_i=x_i&#39;+\lambda_iw
\end{equation}
\]</span> ​ 那么<span class="math inline">\(\lambda_i\)</span>显然就是<span class="math inline">\(x_i\)</span>在单位法向量<span class="math inline">\(w_e\)</span>上的投影，那么可以知道： <span class="math display">\[
x_i&#39;=x_i-\frac{w^Tx_iw}{\Vert w\Vert^2}
\]</span> ​
但这是个什么呢？样本中心间的距离又是什么？可以求出样本中心应该在： <span class="math display">\[
\begin{equation}\label{proj}
x_c&#39;=\frac 1N\sum_{i=1}^N\left(x_i-\frac{w^Tx_iw}{\Vert
w\Vert^2}\right)
\end{equation}
\]</span> ​ 显然公式<span class="math inline">\(\eqref{proj}\)</span>是可以进行化简的，对于内积部分（后半部分），需要将内积展开为累加，进行累加次序交换：
<span class="math display">\[
\begin{array}{l}
\frac 1N\sum_{i=1}^N\frac{w^Tx_iw}{\Vert w\Vert^2}=
\frac 1{N{\Vert w\Vert^2}}\sum_{i=1}^N \left(\sum_{j=1}^nw_jx_{ij}
\right)w\\
=\frac 1{\Vert w\Vert^2}\sum_{j=1}^n\frac 1n\sum_{i=1}^N w_jx_{ij}w\\
=\frac w{\Vert w\Vert^2}\sum_{j=1}^nw_j\mu_i
=\frac{w^T\mu w}{\Vert w\Vert^2}
\end{array}
\]</span> ​
前半部分的化简十分简单。那么投影后的两个集合中心的差向量应该是： <span class="math display">\[
\begin{equation}\label{diff}
\pmb{d}=\mu_1-\mu_2-\frac{w^T(\mu_1-\mu_2)w}{\Vert w\Vert^2}
\end{equation}
\]</span> ​
实际上，Fisher的处理方法与我的处理方法完全不同，我是真的求了一个这样的投影，但不管是Fisher还是西瓜书上的推导，均值全部都是：<span class="math inline">\(w^T\mu\)</span>，这让我觉得很奇怪，如果是这样的话，均值的维度不就是1了吗？但实际上维度只应该减1啊？以上都是我看了第一部分产生的想法，但实际上二分类LDA并不是投影到n-1维空间中（特征分量数为n），二分类的LDA直接投影到一维空间上。二分类只需要在一条直线上找到数据的投影即可，在这条直线上判定投影后的新数据离哪一类数据中心最近。</p>
<p>​
由于这是一下从n维降到1维，所以几何直观上并不好理解。个人觉得这样的降维跨度太大了。</p>
<h4 id="为什么要投影到一条直线上">为什么要投影到一条直线上？</h4>
<p>​ 由于二分类输出的指示结果为 <span class="math inline">\(p_1,p_2,\text{ where }
p_1+p_2=1\)</span>，也就是说分为两个类，落在两个类内的概率满足一个归一约束，那么输出就相当是在一条直线上。也就是说，LDA认为：<strong><u>输出在不同类上的概率实际上是所有输入特征经过<span class="math inline">\(w\)</span>映射的线性组合</u></strong>，二分类问题只需要得到直线上的一个值，就能根据归一约束求出分属于两个类的概率。那么：</p>
<ul>
<li>三分类问题只需要求得在二维空间上的一个点，就能求出一个样本分属于三个类的概率。也即线性组合输出了一个二维的点</li>
<li>四分类问题只需求出三维空间中的一个点，就能求出一个样本分属于四个类的概率...</li>
<li>M分类问题只需要求出M-1为空间中的一个点，就能求出一个样本分属于M个类的概率。</li>
</ul>
<p>​
要注意特征空间（n维）和概率空间（M维）的不同。LDA实际上就是在正态分布以及同方差的假设下，认为只要线性组合n个特征，就能求出M维空间中的一个概率解。这也就解释了，为什么我一开始的理解是有问题的。问题的关键就在于：输出分类的概率是输入特征的线性组合。<strong><u>不能简单地想着投影，而要想为什么要这样投影，这样投影如何帮助求得分类概率。</u></strong></p>
<p>​ 那么数学上就比较好理解了：给定一条直线<span class="math inline">\(y=w^Tx\)</span>，说是要投影到直线上，实际上要做的是根据<span class="math inline">\(w\)</span>对样本的不同属性进行线性组合：<span class="math inline">\(w^Tx\)</span>。那么也就有： <span class="math display">\[
\begin{align}\label{class2}
&amp; \mu_1&#39;=w^T\mu_1 \tag{center of projected class 1} \\
&amp; \mu_2&#39;=w^T\mu_2 \tag{center of projected class 2} \\
&amp; \sigma_1=w^T\Sigma_1 w \tag{projected within-class cov 1}\\
&amp; \sigma_2=w^T\Sigma_2 w \tag{projected within-class cov 2}
\end{align}
\]</span> ​ 那么根据类内方差最小，类间方差最大的思想： <span class="math display">\[
\begin{equation}\label{obj1}
\text{max } \frac{\Vert {w^T\mu_1 - w^T\mu_2}
\Vert^2}{w^T(\Sigma_1+\Sigma_2)w}
\end{equation}
\]</span> ​ 分子展开维转置乘积之后，可以定义两个散度矩阵： <span class="math display">\[
\begin{align}
&amp; S_b=(\mu_1-\mu_2)(\mu_1-\mu_2)^T &amp; \tag{within-class scatter
matrix} \\
&amp; S_w=\Sigma_1+\Sigma_2 &amp; \tag{between scatter matrix}
\end{align}
\]</span> ​ 使用这两个散度矩阵，定义问题<span class="math inline">\(\eqref{obj1}\)</span>带有广义瑞利商的形式。解问题<span class="math inline">\(\eqref{obj1}\)</span>就可以得到最优的<span class="math inline">\(w\)</span>。由于<span class="math inline">\(w\)</span>的长度是不影响结果的（看的就是方向），不妨令分母为1，最大化分子，进一步化简为：
<span class="math display">\[
\begin{equation}\label{obj2}
\begin{array}{ll}
\text{min } -w^TS_bw \\
\text{s.t. } w^TS_ww=1
\end{array}
\end{equation}
\]</span> ​ 请Lagrange坐到主席台上来。根据增加了一项乘子项的优化问题<span class="math inline">\(\eqref{obj2}\)</span>，KKT条件梯度为0，得到：
<span class="math display">\[
\begin{equation}\label{kkt1}
S_bw=\lambda S_ww \rightarrow(\mu_1-\mu_2)=S_ww
\end{equation}
\]</span> ​ 等式<span class="math inline">\(\eqref{kkt1}\)</span>可以化简得原因是：<span class="math inline">\(S_b=(\mu_1-\mu_2)(\mu_1-\mu_2)^T\)</span>，也就是说，<span class="math inline">\(S_bw\)</span>实际方向就是<span class="math inline">\(\mu_1-\mu_2\)</span>，根据<span class="math inline">\(w\)</span>尺度任意性，直接令<span class="math inline">\(S_bw=\lambda(\mu_1-\mu_2)\)</span>省事。根据<span class="math inline">\(\eqref{kkt1}\)</span>，进行SVD分解（数值上会比较稳定）就可以得到<span class="math inline">\(w\)</span></p>
<h3 id="多分类">多分类</h3>
<p>​
从上述理解中已经可以知道LDA的“降维分类”方式，实际上是通过原特征的线性组合，将特征空间直接变换到“概率空间”（或者是可以被变换为概率的空间）。当分类数量为M时，只需要知道M-1个类上的概率或者等价概率值就可以求出所有类上的“概率输出”值。</p>
<p>​
也就是说：LDA的降维过程实际上是由n维特征空间变换为M-1维分类空间的过程。回顾二分类的情况，M
= 2，也就是将所有样本投影到一维（直线）上：<span class="math inline">\(y=w^Tx\)</span>，直线上的值显然是一维的。这是由于参与线性组合的函数实际上是一个标量值函数（<span class="math inline">\(w^Tx\)</span>映射），要想输出高维的向量，只需要更改<span class="math inline">\(w\)</span>为一个矩阵<span class="math inline">\(W\)</span>即可。对于需要优化得到的结果，推导有些不同：
<span class="math display">\[
\begin{equation}\label{div1}
S_t=\sum_{i=1}^m(x_i-\mu_t)(x_i-\mu_t)^T
\end{equation}
\]</span> ​ 定义公式<span class="math inline">\(\eqref{div1}\)</span>为全局散度，也就是每个样本点到所有样本的平均点的散度和。个人认为，由于类间差异在大多数情况下都会大于类内差异，所以<span class="math inline">\(S_t\)</span>相当于就是一个类间方差的表征（不同类的均值点到整体均值点的散度）。由于不同于二分类问题，类内散度需要重新定义了。显然类内的散度可以用类内样本与本类均值的差异来衡量：
<span class="math display">\[
\begin{equation}\label{div2}
S_w=\sum_{j=1}^N(x_{ij}-\mu_i)(x_{ij}-\mu_i)^T
\end{equation}
\]</span> ​ 但是至于为什么西瓜书上要使用<span class="math inline">\(\eqref{div2}-\eqref{div1}\)</span>作为最后的类间散度矩阵，我不是很清楚。甚至我觉得，<span class="math inline">\(\eqref{div2}\)</span>的定义是多余的。类间散度实际上可以根据：</p>
<div class="note info"><p>​
类内散度通常小于类间散度，在最优投影取得的情况下就更是这样了。所以每个样本，在类间散度很大的情况下，可以看作一个十分接近类内均值的点（如下图所示）。那么每个样本点都可以近似地被类内均值取代。</p>
</div>
<p><img src="/2021/03/02/%E7%BA%BF%E6%80%A7-%E6%A0%91%E5%9E%8B%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%BA%AF%E7%90%86%E8%AE%BA%E5%88%86%E6%9E%90/lda.JPG"></p>
<center>
Figure 2. 样本与均值的近似性
</center>
<p>​ 那么很自然，类间散度可以定义为（每个样本（近似）与全局均值的散度和）
<span class="math display">\[
\begin{equation}\label{div3}
S_b=\sum_{i=1}^Mm_i(\mu_i-\mu)(\mu_i-\mu)^T
\end{equation}
\]</span> ​
优化目标也需要更改，因为实际的输出式已经变成了如下式所示的多维线性组合矩阵<span class="math inline">\(W\)</span>，输出是多维的，那么可以简单地使用迹进行实现。
<span class="math display">\[
\begin{equation}\label{obj3}
\frac{W^TS_bW}{W^TS_bW}\rightarrow\text{ max
}\frac{tr(W^TS_bW)}{tr(W^TS_bW)}
\end{equation}
\]</span> ​ 对于上式，继续根据拉格朗日乘子法可以得到： <span class="math display">\[
\begin{equation}\label{solve}
S_bW=\lambda S_wW\rightarrow {S_w}^{-1}S_bW=\lambda W
\end{equation}
\]</span> ​ 可知，<span class="math inline">\(W\)</span>是一个(n *
M-1)维矩阵，而显然<span class="math inline">\(\eqref{solve}\)</span>中<span class="math inline">\(W\)</span>的每个列向量分量都是矩阵<span class="math inline">\({S_w}^{-1}S_b\)</span>的一个特征向量（符合特征向量定义，当然可能是广义特征向量），那么<span class="math inline">\(\begin{pmatrix}N-1\\n\end{pmatrix}\)</span>种不同的情况，究竟是哪N-1个特征向量组合成了最终的解<span class="math inline">\(W\)</span>？从公式<span class="math inline">\(\eqref{solve}\)</span>种可以看出，<span class="math inline">\(\lambda\)</span>越大越好（对应最大化<span class="math inline">\(\eqref{obj3}\)</span>）。那么只需要选择<span class="math inline">\({S_w}^{-1}S_b\)</span>最大的N-1个特征值（或者广义特征值）的特征向量组成解即可。</p>
<hr>
<h2 id="树型---决策树">树型 - 决策树</h2>
<blockquote class="blockquote-center">
<p>树越是向往高处的光亮,它的根就越要向下,向泥土,向黑暗的深处。—尼采</p>

</blockquote>
<p>​
emmm。这句话只因为有个“树”字就被我拿出来镇一镇文章了。决策树，利用一个个不相互影响的特征（或者我们认为影响不太大的特征，实际上有影响也是可以通过某些操作进行转化的）进行层层分类。正如猜物游戏，每次只能问一个答案只有“是”和“否”的问题，通过答案产生的分支进行推测。通过对待分类样本的层层分解可以获得最终的分类推测。本节只讨论其相关的数学原理，对于具体的生成
/ 剪枝算法将不会涉及（因为这没有吸引到我）。</p>
<h3 id="信息论相关">信息论相关</h3>
<p>​ 回顾一下信息熵的两个定义： <span class="math display">\[
\begin{equation}\label{ent}
Ent(x)=-\sum_{i=1}^np_ilog(p_i)\text{ or }Ent(x)=-\int p(x)log(p(x))dx
\end{equation}
\]</span> ​
左边为常见的离散型随机变量熵的定义，而右边则为连续变量在其PDF意义下的熵。在讲KL散度的时候已经说过了，熵是用于衡量信息编码的一个概念。一个随机事件的不确定性越大，代表信息量越大，编码这个事件所需要的二进制位数也相应越大。</p>
<p>​ 在决策树一章中，《西瓜书》提到：</p>
<blockquote class="blockquote-center">
<p>"信息熵" (information entropy)
是度量样本集合纯度最常用的一种指标。</p>

</blockquote>
<p>​
为什么这么说呢？集合样本纯度又是指什么？纯度在此处指：同一个划分中，由于划分集合内的元素都存在相应的label，如果集合内的label越趋于一致，那么这个集合的纯度也就越高。如果用比例<span class="math inline">\(p_k\)</span>表示划分集合中，第k类样本所占的比例，那么这个集合的信息熵（纯度）表示如下：
<span class="math display">\[
\begin{equation}\label{purity}
Ent(D) = -\sum_{i=1}^np_ilog(p_i)
\end{equation}
\]</span> ​ 可以看出，公式<span class="math inline">\(\eqref{purity}\)</span>定义的纯度，当某一类完全占据整个集合时熵取得最小值0。为什么要讨论信息熵或者是纯度？处于决策树的生成考虑，我们使用很多特征生成一棵决策树，但在决策树中，不同的特征地位也是不相同的，naive的情况下，每次分支只选择其中一个特征，那么要选哪一个特征作为本结点向下分支的特征？需要进行优选，优选的指标就是纯度。</p>
<p>​
显然，如果一种划分模式可以划分出纯度较高的子结点（样本子集合），那么：</p>
<ul>
<li>全纯结点（只有一类）可以避免进一步分支，减小树结构复杂度</li>
<li>子集合越纯，说明分类效果越好（因为原集合是无序的，熵大，分类可以看作熵减过程）</li>
</ul>
<p>​ 由此我们定义信息增益：对于公式<span class="math inline">\(\eqref{purity}\)</span>定义的“纯度”，个人认为应该叫做“杂度”更好，实际上我看Wikipedia称这个为“impurity”，很显然嘛，值越大杂度越高。那么原集合的杂度为<span class="math inline">\(Ent(D)\)</span>，如何选取划分才能使得系统的杂度下降最大呢？假设我们选取的属性<span class="math inline">\(a\)</span>存在<span class="math inline">\(v\)</span>个不同的值（也就是<span class="math inline">\(v\)</span>分支），那么每个分支（a属性的每种可能取值）都会有一定样本（可以为0），记为<span class="math inline">\(D^v\)</span>。对应地，<span class="math inline">\(Ent(D^v)\)</span>指的是总体为<span class="math inline">\(D^v\)</span>时，分类的杂度。那么根据<span class="math inline">\(\vert D^v\vert / \vert D\vert\)</span>
也即每个属性样本的占比对杂度进行加权，划分后的系统杂度为： <span class="math display">\[
\begin{equation}\label{impurity}
G(D,a)=Ent(D)-\sum_{j = 1}^v\frac{|D^j|}{|D|}Ent(D^j)
\end{equation}
\]</span> ​ 公式<span class="math inline">\(\eqref{impurity}\)</span>是原系统的杂度 减去
划分后的系统杂度。这也就是<strong><u>分类，这个熵减过程到底让系统的熵减了多少</u></strong>。这被称为<strong><u>信息增益</u></strong>（information
gain），实际上衡量的就是分类使系统熵减少的量。显然我们希望，熵减越大越好。那么每次从属性集合中计算
/ 选择信息增益最大的属性进行分支即可。</p>
<h4 id="互信息">互信息</h4>
<p>​ 信息论中，如果需要衡量两个随机变量之间的关系，可以计算
一个随机变量携带的信息包含另一个随机变量信息的量大小，这被定义为互信息（mutual
information）。可以这样认为：两个有关联的变量，给定其中一个变量的信息，另一个变量的不确定性随之减小：
<span class="math display">\[
\begin{equation}\label{mut}
I(X;Y)=D_{KL}(P_{XY}||P_X \otimes P_Y),\text{ where }
x\in\mathcal{X},y\in\mathcal{Y}
\end{equation}
\]</span> ​ 上式说的是：x是空间<span class="math inline">\(\mathcal{X}\)</span>中的随机变量，y是空间<span class="math inline">\(\mathcal{Y}\)</span>中的随机变量，那么互信息是联合分布<span class="math inline">\(P_{XY}\)</span>与边缘分布<span class="math inline">\(P_X\text{ and
}P_Y\)</span>的外积的KL散度。多维空间不好理解的话，讨论一维变量： <span class="math display">\[
\begin{equation}\label{mut1}
I(X;Y)=\int_y\int_xp(x, y)log\left(\frac{p(x, y)}{p(x)p(y)}\right)dxdy
\end{equation}
\]</span> ​
为什么这样可以描述相关程度呢？因为显然，X与Y独立时的联合分布为<span class="math inline">\(p(x)p(y)\)</span>，此处衡量的即是真实联合分布<span class="math inline">\(p(x, y)\)</span>与独立时的联合分布的差别。</p>
<p>​
互信息和信息增益是存在关系的[1]。在划分时，如果对属性集合A（也就是<span class="math inline">\(a\)</span>所在的集合）取上一个期望，那么会有什么发现？也即对公式<span class="math inline">\(\eqref{impurity}\)</span>定义的信息增益取A的期望，为了方便数学变换，我们将<span class="math inline">\(\eqref{impurity}\)</span>展开： <span class="math display">\[
\begin{equation}\label{expand}
G(D,a)=-\sum_{k=1}^Jp_klog_2p_k-\sum_{v=1}^V\frac{|D^v|}{|D|}\left(-\sum_{k=1}^Jp_{D^v,k}log_2p_{D^v,k}\right)
\end{equation}
\]</span> ​ 显然公式<span class="math inline">\(\eqref{expand}\)</span>可以被表示为（原系统熵 -
给定划分下的新集合熵） <span class="math display">\[
\begin{equation}\label{ent1}
G(D,a)=Ent(D)-Ent(D|a)
\end{equation}
\]</span> ​ 进行期望的求取可以得到： <span class="math display">\[
E_A(G(D,a))=Ent(D)-Ent(D|A)
\]</span> ​ 下面证明一个有关互信息的简单结论： <span class="math display">\[
\begin{equation}\label{lemma}
I(X;Y)=Ent(X)-Ent(X|Y)
\end{equation}
\]</span> ​
怎么说呢。推了好长时间没有推出来的原因就是：<strong><u>没有学过信息论，概念不清楚。</u></strong>比如<span class="math inline">\(\eqref{lemma}\)</span>右边的第二项，条件信息熵，定义为：
<span class="math display">\[
\begin{equation}\label{cond}
Ent(X|Y)=\sum_{x\in\mathcal{X},y\in\mathcal{Y}}p(x,y)log(p(x|y)),\text{
but not }\sum_{x\in\mathcal{X}}p(x|y)log(p(x|y))
\end{equation}
\]</span> ​ 那么<span class="math inline">\(\eqref{lemma}\)</span>可以展开为： <span class="math display">\[
I(X;Y)=-\sum_{y\in\mathcal{Y}}\sum_{x\in\mathcal{X}}p(x,y)log(p(x))+\sum_{y\in\mathcal{Y}}\sum_{x\in\mathcal{X}}p(x,y)log\left(
\frac{p(x,y)}{p(y)}\right)
\]</span> ​ 化简可以得到公式<span class="math inline">\(\eqref{lemma}\)</span>成立。那么可以知道，增益率对于A的期望（也就是对于属性集的概率平均）就是决策树结点与属性集的互信息。</p>
<h4 id="增益率">增益率</h4>
<p>​
实际上，纯使用信息增益并不太好。假设某个分支结点只有一个样本，那么显然分支纯度最大（杂度最小），那么假如有一个属性分支极多，可能一下就将所有的样本分到不同结点上了（比如《西瓜书》上提到的，样本序号），这样容易产生过拟合的分支属性是没有意义的，但是只用信息增益的话实际就会选择这个分支方法。所以使用一个因子来限定分支数的影响：
<span class="math display">\[
\begin{equation}\label{int}
IV(a)=-\sum_{v=1}^V\frac{|D^v|}{|D|}log\left( \frac{|D^v|}{|D|}\right)
\end{equation}
\]</span> ​
可以发现，当分支数越多，这个值越大（不会出现单分支）。这个值称为：固有值（intrinsic
value），只需要使用这个值对增益进行惩罚即可（除以此值）。</p>
<h4 id="基尼指数">基尼指数</h4>
<p>​
针对CART决策树的，而以上所说的决策树使用信息增益作为划分属性选择的度量。基尼指数（Gini
impurity）指的是：</p>
<blockquote class="blockquote-center">
<p>Gini impurity is a measure of how often a randomly chosen element
from the set would be incorrectly labeled if it was randomly labeled
according to the distribution of labels in the subset.[1]</p>

</blockquote>
<p>​
翻译很简单：从集合中随机选择一个元素，再根据这个集合中的类别概率分布随机给这个元素进行分类，分类的错误概率就是基尼指数。
<span class="math display">\[
\begin{equation}\label{gini}
Gini(D)=\sum_{i=1}^{|\mathcal Y|}p_i\sum_{k\neq
i}p_k=1-\sum_{k=1}^{|\mathcal Y|}p_k^2
\end{equation}
\]</span> ​
显然，纯度越高的集合，内部随机取元素随机分类错误的概率（期望）越小。</p>
<h3 id="变量缺失处理的理解">变量缺失处理的理解</h3>
<p>​ 在贝叶斯决策论中提到：</p>
<ul>
<li>某一属性组合的变量可能根本不在样本中出现，但是不能直接认为这样的样本不存在。</li>
</ul>
<p>​
而在决策树中，我们更多针对的问题是：当某一个样本某个属性值是未知的，如何处理这样的样本？丢弃是显然不可取的，这样可能损失太多的有效信息。而直接使用确实也不是办法，少掉一个属性要如何继续分支？《西瓜书》上将问题总结地很不错：</p>
<blockquote class="blockquote-center">
<p>我们需解决两个问题: (1) 如何在属性值缺失的情况进行划分属性选择 ? (2)
给定划分属性，若样本在该属性上的值缺失，如何对样本进行划分 ?</p>

</blockquote>
<p>​
第一个问题我开始并没有什么很好的想法。而对于第二个问题，个人开始认为，假设已经知道了划分属性，可以根据其他完好样本来估计本样本在这个缺失属性上的分布，进行分布加权（事实上，这个想法类似《西瓜书》上提供的方法）。</p>
<p>​
问题一实际上比较容易，我想得太复杂了。由于划分属性只考虑<strong><u>一个属性与分类结果的关系</u></strong>，那么完全用不着考虑多属性关系，只需要取出这个属性下对应没有缺失的样本，利用这些样本估计【属性】对【分类结果】的影响即可。以信息增益法为例，考虑<span class="math inline">\(\eqref{impurity}\)</span>定义的信息增益。假设我们讨论属性<span class="math inline">\(a\)</span>，由于有些样本属性是缺失的，在计算时将这些样本剔除再计算新集合<span class="math inline">\(\tilde{D}\)</span>的信息增益<span class="math inline">\(\tilde{G}(\tilde{D},a)\)</span>。注意，此信息增益计算出来后需要加权：
<span class="math display">\[
\begin{equation}\label{weigh}
\tilde{G}(\tilde{D},a)\times\rho,\text{ what is ρ?}
\end{equation}
\]</span> ​ 其中的<span class="math inline">\(\rho\)</span>是加权因子，是什么权重呢？假设属性a在集合中有<span class="math inline">\(|\tilde{D}|\)</span>个未缺失样本，那么<span class="math inline">\(\rho=|\tilde
D|/|D|\)</span>，也就是说，样本缺失越少，信息增益计算越可信。</p>
<p>​
问题2实际上是将“让同一个样本以不同的概率划入到不同的子结点中去”（《西瓜书》言）。也可以使用没有缺失属性a的样本信息，假设某一分支分到属性a的v取值<span class="math inline">\(a^v\)</span>上： <span class="math display">\[
\tilde{r_v}=\frac{\sum_{x\in\tilde{D}_v}w_x}{\sum_{x\in {\tilde{D}}}w_x}
\]</span> ​ 也就是没有缺失属性a的样本中，有<span class="math inline">\(\tilde{r_v}\)</span>比例样本在本属性上取值为v，那么当每个样本权重为<span class="math inline">\(w_x\)</span>时，可以按照比例将缺失样本分配给不同分支（相当于按照概率（比例）割裂一个缺失样本）。</p>
<h3 id="kernelization">Kernelization</h3>
<p>​
普通决策树的分类边界都是垂直于某个轴的（因为决策树是一种“非黑即白”的分类方法）。在某个属性（某个维度）上，只有固定的几种分法：</p>
<p><img src="/2021/03/02/%E7%BA%BF%E6%80%A7-%E6%A0%91%E5%9E%8B%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%BA%AF%E7%90%86%E8%AE%BA%E5%88%86%E6%9E%90/tree.jpg"></p>
<center>
<p>Figure 3. 决策树在单一维度上的分类边界总是垂直于轴的</p>
<p>​
啊这？太过于“一维”了，甚至连简单的线性可分分类都需要经过如下的艰难操作：</p>
<p><img src="/2021/03/02/%E7%BA%BF%E6%80%A7-%E6%A0%91%E5%9E%8B%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%BA%AF%E7%90%86%E8%AE%BA%E5%88%86%E6%9E%90/clf.JPG"></p>
<center>
<p>Figure 4. 决策树扭来扭去</p>
<p>​
一个简单的想法就是：不适用原属性进行分类，我们可以像PCA那样，使用属性的线性组合形成抽象属性，在这个抽象属性对应的新空间中，虽然分类边界仍然垂直于新的空间轴，但在原空间看起来，就成为一般线性分类器了。而进一步地，如果使用其他的非线性特征组合方法，也就是引入某些
<strong><u>kernel</u></strong>，甚至可以通过决策树达到任意分类边界生成的效果。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] Wikipedia, <a href="https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity">Decision
tree learning</a></p>
</center></center>]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>概率论</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>SVM算法与实现</title>
    <url>/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="svm">SVM</h1>
<hr>
<h2 id="preface">Preface</h2>
<p>​ SVM (Support Vector Machine 支持向量机)
曾一度导致深度学习的退潮（1995）。Geoffrey
Hinton提出BP之后，遇到了sigmoid激活函数梯度消失问题，恰好此时Vapnik提出统计学习理论，正式提出非线性SVM并将其应用，使得这个分类器盛行了20年？直到DL的梅开三度。
恰好大三下学期有《模式识别》课，且有学长说他考前每天必推一遍SVM原理，不如现在趁《运筹学》还热着，尝试自己推导一遍，并实现这一个经典算法。</p>
<p><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/history.jpg"></p>
<center>
Figure 1. 深度学习的发展历程 以及95年SVM带来的冲击（图源不明）
</center>
<span id="more"></span>
<p>​ SVM作为经典的“最大间隔”（maximum
margin）分类器，除了其精巧的数学变换（Lagrange对偶，可能是因为我自己推出来了所以觉得很妙吧:laughing:）之外，“支持向量”的思想是最妙之处。这种方法大大减少了训练时使用的维数，避免了内存爆炸问题，并且可以使用少量样本进行训练。</p>
<hr>
<h2 id="超平面的意义">超平面的意义</h2>
<p>​ 假设一个平面，其到原点的法向量为<span class="math inline">\(\pmb{w}\)</span>，到原点的距离为<span class="math inline">\(b\)</span>，那么平面方程应该是： <span class="math display">\[
\begin{equation}\label{equ:hyper}
\pmb{w}^T\pmb{x}+b=0
\end{equation}
\]</span> ​ 实际上这是方程： <span class="math display">\[
\begin{equation}\label{equ:plain}
Ax+By+Cz+....+b=0
\end{equation}
\]</span> ​ 进行的推广，那么对于公式<span class="math inline">\(\eqref{equ:hyper}\)</span>，如此定义方式为什么可以定义一个平面？x为什么一定在一个由<span class="math inline">\(\pmb{w}\)</span>以及<span class="math inline">\(b\)</span>定义的唯一平面上？推导如下，如图(1)，过原点做垂直于超平面的垂线，设交点为P，平面上一点x相对于P点的相对向向量为x'。那么有：
<span class="math display">\[
\begin{align}
&amp; \pmb{v}=\vert b\vert\frac{\pmb{w}}{\Vert\pmb{w}\Vert} \\
&amp; \pmb{x}=\pmb{x}&#39;+\pmb{v}      \\
&amp; \pmb{w}^T\pmb{x}+b = \pmb{w}^T\pmb{x}&#39;+\pmb{w}^T\pmb{v}+b = 0
\end{align}
\]</span> ​ 推导还是比较简单的。</p>
<p><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/svm.JPG"></p>
<center>
Figure 2. 超平面数学意义探究
</center>
<p>​
如果要推算一个点到超平面的距离，比如上图的点y到超平面的距离，相当于是：y交超平面于y'点，而由于y'在超平面上，于是有<span class="math inline">\(\pmb{w}^T\pmb{y}&#39;+b=0\)</span>，那么由于<span class="math inline">\(\pmb{y} =
\pmb{y}&#39;+\pmb{y}&#39;&#39;\)</span>，那么可以知道： <span class="math display">\[
\begin{equation}\label{equ:predist}
\pmb{w}^T\pmb{y}+b=\pmb{w}^T\pmb{y}&#39;&#39;
\end{equation}
\]</span> ​ 而公式<span class="math inline">\(\eqref{equ:predist}\)</span>右侧相当于是y''在未单位化的方向向量上的投影，单位化之后可以得到距离。那么整个点到超平面距离公式如下：
<span class="math display">\[
d = \frac{\vert \pmb{w}^T\pmb{x}+b\vert}{\Vert \pmb{w}\Vert}
\]</span></p>
<hr>
<h2 id="目标函数导出">目标函数导出</h2>
<p>​
对于一个二分类的SVM，我们希望找到<strong>一个</strong>超平面，能够最优地将两类数据分开。如下图所示，图片来源见reference[1]。</p>
<p><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/margin.png"></p>
<center>
Figure 3. SVM与超平面
</center>
<p>​ 联系以下其他的分类方法，比如说LDA（Linear Discriminative
Analysis），在算法构建时就存在一点就是：使类间方差是最大的。也就是希望两类之间的间隔是最大的。在SVM中，不衡量类间方差，衡量的是“margin”（就是Figure
3中的黄色区域）。</p>
<p>​
从简单的例子引入，我们讨论二分类线性分类器。对于一个线性可分的待分类数据集，两个类别间需要找一个超平面。显然，两个类别都会有离这个超平面距离最近的数据点，这个最短距离（表征的是一种错误容限，如果为0则恰好在不可判定的边界上）如果记为<span class="math inline">\(d_1, d_2\)</span>的话，我们显然是希望<span class="math inline">\(d_1,
d_2\)</span>尽可能大的（最容易出现错误的数据点（离分类超平面最近的点）离分类界限越远）。像这样可以定义超平面所在位置的数据点（最容易出现分类错误，最应该被讨论），被称为“支持向量（support
vector）”，此后讨论的都是支持向量确定的超平面间的距离间隔。如何衡量这个距离？显然可以使用几何距离的推广（维数上的推广）。可以通过2-范数来定义空间中两个点之间的距离，但由于这是点与平面之间的距离，需要点与平面的距离公式。</p>
<p>​
从我们上面所说的：“希望最可能分类错误的数据点对应的最短超平面距离间隔-是-最大的”这个想法上来看我们应该将距离的生成分为两步：</p>
<ul>
<li>给定超平面时，如何衡量哪个数据点是最容易分类错误的？</li>
<li>在给定支持向量时，如何进行超平面参数的确定与优化？</li>
</ul>
<p>​
开始时个人感觉，这个问题<strong><u>有点自循环的感觉</u></strong>。超平面确定依赖支持向量？支持向量给定后才能确定超平面参数？这不就产生了鸡生蛋
蛋生鸡的悖论了吗？有关这个问题的讨论，在处理完目标函数的数学变换之后我再从数学的角度上谈一下我个人的理解。</p>
<h3 id="距离衡量">距离衡量</h3>
<p>​ 对于一个二分类问题，超平面已经定义为：<span class="math inline">\(\pmb w^Tx+b =
0\)</span>，那么如果所有数据都能正确分类，两个数据集的数据点一定会呈现：一个类别的数据在超平面的“上方”（正方向上），另一个类别则全部在“下方”。相应地，<span class="math inline">\(\pmb w^Tx+b\)</span>可能大于0或者小于0。也就是说：
<span class="math display">\[
\left\{
\begin{array}{l}
\pmb w^Tx+b &gt; 0,\large{\text{正类}} &amp;\\
\pmb w^Tx+b &lt; 0,\large{\text{负类}} &amp;
\end{array}
\right.
\]</span> ​
而很明显，我们的样本点是有限的，也就是说，每个一定会存在一个点，在正类中，正值最小，负类中赋值最小。那么可以根据这两个最小值进行尺度归一化：
<span class="math display">\[
\left\{
\begin{array}{l}
\pmb w^Tx+b \ge 1,\large{\text{正类}} &amp;\\
\pmb w^Tx+b \le -1,\large{\text{负类}} &amp;
\end{array}
\right.
\]</span> ​ 那么使用一个小trick，用sgn(·) 函数处理以上式子： <span class="math display">\[
\begin{equation}\label{equ:dist}
d_f=y_i(\pmb w^Tx+b),\text{ where } y_i =1 \text{ if 正类 otherwise }
y_i = -1
\end{equation}
\]</span> ​ 这样可以保证：<span class="math inline">\(d_f\)</span>在分类正确时恒为正值，并且让问题尽可能简单化。（<span class="math inline">\(y_i\)</span>当然可以不取正负1，但是取其他的值让问题形式稍微复杂了一点点，没有什么必要）。根据在之前小节讨论的超平面距离公式，已知<span class="math inline">\(\vert\pmb
w^Tx+b=1\vert\)</span>（对于支持向量而言），那么两个类距离超平面的距离是各为<span class="math inline">\(1/\Vert\pmb{w}\Vert\)</span>。那么优化问题即为：
$$ <span class="math display">\[\begin{equation}\label{equ:simple}
\left\{
\begin{array}{l}
\text{max }\frac{2}{\Vert\pmb{w}\Vert} &amp;\\
\text{s.t. } y_i(\pmb w^Tx+b) \ge 1, \text{ for } i\in1,2,...n &amp;
\end{array}
\right.

\rightarrow

\left\{
\begin{array}{l}
\text{min }{ \frac 12 \Vert\pmb{w}\Vert^2} &amp;\\
\text{s.t. } y_i(\pmb w^Tx+b) \ge 1, \text{ for } i\in1,2,...n &amp;
\end{array}
\right.
\end{equation}\]</span> $$ ​ 理想情况下，需要优化的问题就是按照公式<span class="math inline">\(\eqref{equ:simple}\)</span>定义的。</p>
<h3 id="非理想情况">非理想情况</h3>
<p>​
哪有那么多线性可分的数据集？分类错误在大多数情况下都无法避免（他们中出了一个叛徒）。原有的线性可分条件太强了，需要进行一定的松弛才具有泛化能力。聪明的数学家们想到的办法是：设定一个容限<span class="math inline">\(\zeta_i\)</span>，也就是一个松弛因子，不追求找到最小的那对。反之，我们需要在超平面间隔宽度以及允许的错分类深度（某个数据集误入敌营的距离）之间进行权衡。</p>
<p>​ 由于<span class="math inline">\(y_i(\pmb w^Tx+b) \ge
1\)</span>很难达成，那么总可以<span class="math inline">\(y_i(\pmb
w^Tx+b) \ge 1 - \zeta_i，\zeta_i \ge 0\)</span>吧。那么，所有<span class="math inline">\(\zeta_i\)</span>的和（它们都是非负的）显然反映了对这个分类器的松弛程度。问题就在于，我们希望
松弛一点，泛化能力强一点？还是严格一点，正确率高一点？通过一个可调的系数来决定：
<span class="math display">\[
\sum_{i=1}^n\zeta_i+\frac{\lambda}{2}\Vert\pmb{w} \Vert^2
\]</span> ​ <span class="math inline">\(\lambda\)</span>就是起权衡作用的加权系数。</p>
<hr>
<h2 id="目标函数数学变换">目标函数数学变换</h2>
<p>​ 松弛后的问题原目标函数表达式如下： <span class="math display">\[
\begin{equation}\label{equ:tar1}
\left\{
\begin{array}{l}
    \text{min } \frac 1n
\sum_{i=1}^n\zeta_i+\frac{\lambda}{2}\Vert\pmb{w} \Vert^2 &amp;\\
    \text{s.t. }y_i(\pmb{w}^T\pmb{x}_i+b) \ge
1-\zeta_i,\zeta_i\ge0\text{ for }i\in1,2,...n &amp;\\
\text{where } \zeta_i \text{ is max} (0, 1-y_i(\pmb{w}^T\pmb{x}_i+b))
&amp;
\end{array}
\right.
\end{equation}
\]</span> ​
由于这是一个多变量有约束优化问题。可以使用Lagrange乘子法写出其Lagrange乘子函数。根据运筹学学过的知识（运筹学
第三章第五讲 有约束最优化问题的KKT方法）：</p>
<p><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/or.JPG"></p>
<center>
Figure 4. 来自西安交大 运筹学课程 翟桥柱老师等
</center>
<p>​ 需要注意的是，虽然<span class="math inline">\(\zeta_i \text{ = max}
(0, 1-y_i(\pmb{w}^T\pmb{x}_i+b))\)</span>成立，<span class="math inline">\(\zeta_i\)</span>仍然是一个人为选取的参数，用于规定：第i个数据点相对边界的偏离（进入错误分类区的深度）大小容许值，所以实际上<span class="math inline">\(\zeta_i\)</span>并不是<span class="math inline">\(\pmb{w}\)</span>或者<span class="math inline">\(b\)</span>的函数。 <span class="math display">\[
\begin{equation}\label{equ:lag}
L(\pmb{w},b, \zeta_i,\lambda_i,\mu_i)=\frac 1n
\sum_{i=1}^n\zeta_i+\frac{\lambda}{2}\Vert\pmb{w}
\Vert^2-\sum_{i=1}^n\lambda_i[y_i(\pmb{w}^T\pmb{x}_i+b)+\zeta_i-1]-\sum_{i=0}^n\mu_i\zeta_i
\end{equation}
\]</span> ​ 则由KKT条件，需要对<span class="math inline">\(\eqref{equ:lag}\)</span>定义的<span class="math inline">\(L(\pmb{w},b,
\zeta_i,\lambda_i,\mu_i)\)</span>进行微分操作。也即所有偏导数都应该是0：
<span class="math display">\[
\begin{align}
&amp;\frac{\partial L}{\partial \pmb{w}} = \lambda\pmb{w} -
\sum_{i=1}^n\lambda_iy_i\pmb{x_i} = 0\rightarrow\lambda\pmb{w}
=\sum_{i=1}^n\lambda_iy_i\pmb{x_i}\label{equ:pw}\\
&amp;\frac{\partial L}{\partial b} =\sum_{i=1}^n \lambda_iy_i =
0\label{equ:pb}\\
&amp;\frac{\partial L}{\partial \zeta_i} = \frac 1n -\lambda_i-\mu_i =
0\label{equ:pz}
\end{align}
\]</span> ​ 将公式<span class="math inline">\(\eqref{equ:pw}\eqref{equ:pb}\eqref{equ:pz}\)</span>带入到公式<span class="math inline">\(\eqref{equ:lag}\)</span>中，可以得到Lagrange对偶问题，显然有：
<span class="math display">\[
\begin{align}
&amp;\sum_{i=1}^n\lambda_i[y_i(\pmb{w}^T\pmb{x}_i+b)+\zeta_i-1] = 0
\quad\text{(KKT条件)}\\
&amp;\begin{array}
&amp;L=\sum_{i=1}^n(\frac
1n-\lambda_i-\mu_i)\zeta_i+\frac{\lambda}{2}\Vert\pmb{w}
\Vert^2-\sum_{i=1}^n\lambda_iy_i(\pmb{w}^T\pmb{x}_i+b)+\sum_{i=0}^n\lambda_i\\=\frac{\lambda}{2}\Vert\pmb{w}
\Vert^2-\sum_{i=1}^n\lambda_iy_i\pmb{w}^T\pmb{x}_i+\sum_{i=0}^n\lambda_i
\end{array}\\
&amp;L=\frac{1}{2\lambda}\left
(\sum_{i=1}^n\lambda_iy_i\pmb{x_i}\right)^T\sum_{i=1}^n\lambda_iy_i\pmb{x_i}-
\frac{1}{\lambda}\sum_{i=1}^n\lambda_iy_i\left(\sum_{j=1}^n\lambda_jy_j\pmb{x_j}\right)^T\pmb{x}_i+\sum_{i=0}^n\lambda_i
\end{align}
\]</span> ​
最后化简得到，相对于原问题（Primal），此为Lagrange对偶问题，注意在对偶讨论下，需要进行最大化。
<span class="math display">\[
\begin{equation}\label{equ:dual}
L&#39;(\lambda_i)=\sum_{i=0}^n\lambda_i - \frac{1}{2\lambda}\left
(\sum_{i=1}^n\lambda_iy_i\pmb{x_i}\right)^T\sum_{i=1}^n\lambda_iy_i\pmb{x_i}
\end{equation}
\]</span> ​ 约束条件如何变换？也就是此处每个<span class="math inline">\(\lambda_i\)</span>的约束条件是？首先，公式<span class="math inline">\(\eqref{equ:pb}\)</span>定义的约束没有能够带入原问题中，于是称为对偶问题的一个约束项，并且<span class="math inline">\(\lambda_i\)</span>本身就是大于等于0的。那么它有上界吗？有的，由于公式<span class="math inline">\(\eqref{equ:pz}\)</span>中<span class="math inline">\(\mu_i\)</span>是非负的，可以得到： <span class="math display">\[
\begin{equation}\label{equ:cond}
\text{s.t. }\sum_{i=1}^n \lambda_iy_i = 0 \text{ and }
0\le\lambda_i\le\frac 1n
\end{equation}
\]</span></p>
<p>​ 而实际上，只要能求出公式<span class="math inline">\(\eqref{equ:dual}\)</span>对应的对偶问题的解（<span class="math inline">\(\lambda_i\)</span>），也就可以根据公式<span class="math inline">\(\eqref{equ:pw}\)</span>计算出<span class="math inline">\(\pmb{w}\)</span>，而由所有的support
vector以及<span class="math inline">\(\pmb{w}\)</span>可以求出b，也就唯一确定了超平面。之所以进行对偶变换，是因为原问题太难以讨论了，原问题并不是简单的二次规划问题，并且存在烦人的<span class="math inline">\(\zeta_i\)</span>，约束条件也令人难受，而对偶之后，约束变成了线性的，并且目标函数的形式变得简单了，可以使用一些二次规划的算法求出<span class="math inline">\(\lambda_i\)</span>。</p>
<hr>
<h2 id="逻辑自循环">逻辑自循环？</h2>
<p>​ 开始我对这个算法的思想非常不理解。我起初认为：</p>
<blockquote>
<ul>
<li>给定了超平面，才知道不同类别中哪个数据点距离超平面最近</li>
<li>给定了支持向量，才能求出超平面参数来（间隔最大嘛）</li>
</ul>
</blockquote>
<p>​
这两点看起来就跟悖论一样，解决其中一点仿佛是要基于另一点的解决。但最后我们化简得到的目标函数却很有趣：<span class="math inline">\(\eqref{equ:dual}\)</span>中并没有出现【（1）超平面参数（2）选谁为支持向量
】的信息。</p>
<p>​ 解开这个“自循环”的关键在于对偶问题的<span class="math inline">\(\lambda_i\)</span>，对偶问题的解决确实是不依赖于以上信息的，它是根据所有的训练样本点优化出来的，而这个<span class="math inline">\(\lambda_i\)</span>实际上就蕴含了支持向量的信息。假设<span class="math inline">\(\lambda_k = 0\)</span>，由公式<span class="math inline">\(\eqref{equ:pw}\)</span>知，样本<span class="math inline">\(x_k\)</span>就不影响<span class="math inline">\(\pmb{w}\)</span>的计算了，也就是说<span class="math inline">\(x_k\)</span>就不是支持向量。<span class="math inline">\(\lambda_i\)</span>不为0的数据才是我们需要的支持向量，他们才参与计算，决定超平面。</p>
<p>​
也就是说：算法的推导逻辑有赖于这样的一个“逻辑自循环”，因为只要循环之中的一个环节被解决了，另一个环节也就随之解决了。而通过巧妙的数学变换，我们可以找到绕开“自循环”的方法，通过优化先求出蕴含了支持向量选取意义的<span class="math inline">\(\lambda_i\)</span>，再求出超平面参数<span class="math inline">\(\pmb{w},b\)</span>。</p>
<hr>
<h2 id="smo-二次规划求解">SMO 二次规划求解</h2>
<p>​ SMO（Sequential Minimal Optimization）<a href="#ref">[3]</a>
是一个SVM算法对偶问题的快速计算方法，它可以极大地减小内存空间消耗，并且其解是解析的，而不需要对QP对偶问题<span class="math inline">\(\eqref{equ:dual}\)</span>进行复杂的数值解计算。SMO的两大精髓思想是：</p>
<ul>
<li>参数迭代计算“分治”得到一个个的QP
sub-problems，每个sub-problem只需要解一个两参数QP优化问题。</li>
<li>使用一个启发式算法，选择每次进行迭代的两个参数。</li>
</ul>
<p>​ 由于论文<a href="#ref">[3]</a>中，启发式算法部分我没怎么看懂，只看懂子问题分割部分，所以在接下来的算法实现过程中，只实现非启发式（随机的）参数选择，也就是一个非启发的SMO，效率上可能会低一些。</p>
<blockquote>
<p>In order to speed convergence, SMO uses heuristics to choose which
two Lagrange multipliers to jointly optimize.</p>
</blockquote>
<p>​
有关KKT条件不满足点的删除以及非边界点的处理这里没有看懂（不是很清楚这样做的理由究竟是什么，可能对KKT条件的理解不够深入吧，不太能想清楚
不满足KKT条件对优化的影响）。所以整个2.2小节读完之后，在实现中都略过了。</p>
<h3 id="kernel-非线性">Kernel 非线性</h3>
<p>​
为了使讨论不失一般性，上来就应该讨论核函数表示下的SVM，而非之前小节中推导的线性SVM（线性SVM也就是核函数是标准内积的情况）。</p>
<p>​
之前我们介绍的都是标准内积核，也就是两个向量直接进行内积操作。在公式<span class="math inline">\(\eqref{equ:dual}\)</span>中，用到了内积，因为公式<span class="math inline">\(\eqref{equ:dual}\)</span>实际可以写为： <span class="math display">\[
\begin{equation}\label{equ:dot}
L&#39;(\lambda_i)=\sum_{i=0}^n\lambda_i
-\frac{1}{2\lambda}\sum_{i=1}^{n}\sum_{j=1}^n\lambda_i\lambda_jy_iy_j\pmb{x}_i^T\pmb{x}_j
\end{equation}
\]</span> ​
而直接内积对应的是线性的空间。如果对x做非线性变换，达到空间变换的目的，在变换后的空间下是线性的超平面，但在原空间下已经变成别的形状，使得原本线性不可分的数据在新空间下可分。
<span class="math display">\[
\begin{equation}\label{equ:kernel}
k(\pmb{x}_i, \pmb{x}_j)=\phi(\pmb{x}_i)\phi(\pmb{x}_j)
\end{equation}
\]</span> ​ 公式<span class="math inline">\(\eqref{equ:dot}\)</span>中的内积项替换为公式<span class="math inline">\(\eqref{equ:kernel}\)</span>的核函数即可。</p>
<h3 id="参数分治">参数“分治”</h3>
<p>​ SMO算法在干什么呢？个人感觉这有点像coordinate
descent，但是感觉简单的coordinate
descent无法胜任SVM对偶问题的求解。因为式<span class="math inline">\(\eqref{equ:cond}\)</span>中定义了线性约束，coordinate
descent没有办法直接满足线性约束。在论文中（SMO算法论文），作者也说到
问题的最小讨论参数个数为2，因为只讨论一个参数时无法满足线性约束条件。于是作者真就两个两个参数进行讨论，作者说到：</p>
<blockquote>
<p>The advantage of SMO lies in the fact that solving for two Lagrange
multipliers can be done analytically.</p>
</blockquote>
<p>​
确实如此，并且这个解析解的推导还算比较简单。由于SMO中sub-problem求解的论文思路是比较清晰的，在此处只简单回顾一下论文的方法。</p>
<h4 id="i.-约束确定">I. 约束确定</h4>
<p>​
由于只选取两个参数，维度好低啊，可以进行可视化。注意我自己的推导和《模式识别》书以及SMO论文上的问题形式均不同，书以及论文均是<span class="math inline">\(C\)</span>定义的，也就是下式定义的loss，为了与论文一致，我现在就讨论公式<span class="math inline">\(\eqref{equ:book}\)</span>）定义的loss导出的对偶问题：
<span class="math display">\[
\begin{equation}\label{equ:book}
C\sum_{i=1}^n\zeta_i+\frac{1}{2}\Vert\pmb{w} \Vert^2
\end{equation}
\]</span> ​ 由约束项<span class="math inline">\(\eqref{equ:cond}\)</span>结合下图可以看出，选取的<span class="math inline">\(\alpha_i(即\lambda_i),\alpha_j\)</span>的线性约束与constatnt值约束在二维情况下很简单。分<span class="math inline">\(y_i==y_j\)</span>是否为true两种情况来看，每种存在两个情况（论文中每种只画出一条线性约束的可视化图，红线是我后来加上的）：</p>
<p><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/fig1.JPG"></p>
<center>
Figure 5. 二维约束可视化
</center>
<p>​ 每次只需在这斜率为<span class="math inline">\(\pm1\)</span>的线段上求约束极小值（二次函数（线性核）或是其他凸问题（非线性核））即可。</p>
<h4 id="ii.-极值求解">II. 极值求解</h4>
<p>​
显然，由于只有两个参数时，根据线性约束，一个参数可以使用另一个参数表示，使得我们可以先更新一个参数，再根据更新值求另一个参数的值，完成迭代。那么在求其中一个参数时，根据线性约束，问题就优点类似于coordinate
descent了。</p>
<ul>
<li>首先确定带优化参数的值区间(L, H)</li>
<li>求一维最小值问题的极值点<span class="math inline">\(\alpha^{new}\)</span></li>
<li><span class="math inline">\(\alpha^{new}\)</span>可能不在(L,
H)范围内，根据单峰以及凸性需要进行clipping
<ul>
<li><span class="math inline">\(\alpha^{new} &gt;
H\)</span>，则最小值在H处取得</li>
<li>反之<span class="math inline">\(\alpha^{new}&lt;L\)</span>则最小值在L处取得</li>
<li>否则 <span class="math inline">\(\alpha^{new}\in(L,H)\)</span>，最后的极小值点就是<span class="math inline">\(\alpha^{new}\)</span></li>
</ul></li>
</ul>
<p><span class="math display">\[
\begin{equation}\label{equ:update}
\alpha_2^{new}=\alpha_2+\frac{y_2(E_1-E_2)}{\eta}\\
\text{where } \eta = k(\pmb{x}_1, \pmb{x}_1)+k(\pmb{x}_2,
\pmb{x}_2)-2k(\pmb{x}_1, \pmb{x}_2)
\end{equation}
\]</span></p>
<p>​ 此处<span class="math inline">\(\eta\)</span>是公式<span class="math inline">\(\eqref{equ:dot}\)</span>在核函数替换下的目标函数的
二阶导。E则是预测误差<span class="math inline">\(u_{pred}-y_i\)</span>。感觉更新式<span class="math inline">\(\eqref{equ:update}\)</span>有点像牛顿法的迭代过程。则根据线性约束，<span class="math inline">\(\alpha_1\)</span>更新后的值也可以写出来。</p>
<h4 id="iii.-计算需要的结果">III. 计算需要的结果</h4>
<p>​ 每一步<span class="math inline">\(\alpha_1,\alpha_2\)</span>更新都可以根据新的值计算一次<span class="math inline">\(\pmb{w},b\)</span>。当所有参数计算完毕之后，算法也就结束了。<span class="math inline">\(\pmb{w}^{new}\)</span>怎么来的很好懂，而<span class="math inline">\(b\)</span>的更新迭代过程相对麻烦一些。由于<span class="math inline">\(b=\pmb{w}^Tx_i-y_i\)</span>成立，在kernel存在的情况下，b是：
<span class="math display">\[
b=\left[
\sum_{i=1}^n\lambda_iy_ik(\pmb{x}_j, \pmb{x}_i)
\right] -y_i
\]</span> ​ 根据上式进行更新，写出相对值表达式即可。</p>
<hr>
<h2 id="实现smo算法">实现SMO算法</h2>
<p>​ 论文中给出了 给定两个数据时计算的伪代码。按照论文进行实现，代码见<a href="https://github.com/Enigmatisms/TorchLearning/blob/master/optim/svm.py">Github
Repository 🔗:TorchLearning</a>，结果如下：</p>
<table>
<thead>
<tr>
<th style="text-align: center;"><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/res1.png"></th>
<th style="text-align: center;"><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/res2.png"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">距离适中</td>
<td style="text-align: center;">距离较远</td>
</tr>
<tr>
<td style="text-align: center;"><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/res3.png"></td>
<td style="text-align: center;"><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/res4.png"></td>
</tr>
<tr>
<td style="text-align: center;">存在较大重叠</td>
<td style="text-align: center;">存在较小重叠</td>
</tr>
</tbody>
</table>
<p>​
在使用不同的随机数据进行超平面求解时发现，存在当C过大时，导致计算的超平面完全错误的问题。SMO算法的收敛速度看起来极快，通常只需要迭代3-6次就能收敛。注意，在这里数据点并不算多：</p>
<ul>
<li>维数3，正负类总和只有84个样本。</li>
</ul>
<hr>
<h2 id="其他的讨论">其他的讨论</h2>
<h3 id="空间变换">空间变换</h3>
<p>​
之前我就听说，SVM是将低维数据升维到高维空间，低维中不好进行分类的数据，高维下可能可以很好分开。但是读完原理，实现完代码之后也没有发现哪里有维度的升高。</p>
<p>​ 实际上，维度的升高在核函数中“有所体现”，在<a href="https://zhuanlan.zhihu.com/p/57648645">【这篇文章】</a>中，作者提到：</p>
<blockquote>
<p>那我们我们是否可以将数据映射到高维空间呢？即创建一些新的特征。我们可以创建特征
<span class="math inline">\(x_3=x^2,x_4=y^2\)</span></p>
</blockquote>
<p>​ 虽然看起来维数从(x, y)变为了<span class="math inline">\((x, y, x_3,
x_4)\)</span>，但是<span class="math inline">\(x_3,x_4\)</span>并不是独立的维度，个人倾向于认为这是在原空间对数据的空间分布进行了变换。比如说将两类环形（同心圆）分布的数据变换到相同维度的另一个空间下，但是在这个空间下两类数据是线性可分的。当然，非要说这是高维空间，应该也可以吧。</p>
<p>​
核函数方法固然是线性的非线性迈出的一大步，但是个人感觉核函数的选择有赖于数据的空间分布。在不明分布的情况下，随意选择核函数将会造成分类能力的下降，靠人工比较选择显然不是个很好的办法。</p>
<h3 id="多分类问题">多分类问题</h3>
<p>​
SVM是典型的二分类分类器，但我们用的SVM却有多分类的能力。关于多分类，个人的想法是：</p>
<ul>
<li>对每个类，只需要区分本类和其他即可。构建一个个的本类以及其他类的二分类问题应该就可以。</li>
</ul>
<p>​ 维基上说：</p>
<blockquote>
<p>Building binary classifiers that distinguish between one of the
labels and the rest (<em>one-versus-all</em>) or between every pair of
classes (<em>one-versus-one</em>).</p>
</blockquote>
<p>​
个人更倾向于one-versus-one形式的。在《模式识别》一书上介绍了如何处理多分类问题（感觉像是one-versus-all形式的）。而one-versus-one存在这样的特点（个人认为）：</p>
<ul>
<li>实现简单，不需要做过多算法改动，可以直接由多个二分类SVM组合（优点）</li>
<li>内存/计算资源消耗大，每两个数据类别之间都需要计算/储存一个<span class="math inline">\(\pmb{w},b\)</span>（缺点）</li>
</ul>
<p>​
根据one-versus-one思想以及二分类SVM构建的一个多分类SVM结果如下（只画出超平面
/ 数据），如果需要进行predict，predict思想如下：</p>
<ul>
<li>求所有的二分类SVM
predict，对每一类进行累加（可以用一个list保存每一类累加结果）</li>
<li>取累加值最大的类（简单的想法，对于一个数据点，其落在正确的类中时，在每个二分类SVM中的输出应该都为1）作为predict值。</li>
</ul>
<p><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/res5.png"></p>
<center>
Figure 6. 多分类one-versus-one的超平面
</center>
<hr>
<h2 id="reference">Reference</h2>
<p><span id="ref"></span></p>
<p>[1] By Larhmam - Own work, CC BY-SA 4.0,<a href="https://commons.wikimedia.org/w/index.php?curid=73710028">link🔗</a></p>
<p>[2] Wikipedia, <a href="https://en.wikipedia.org/wiki/Support-vector_machine">Support-vector
machine</a></p>
<p>[3] Platt, John (1998). <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-98-14.pdf">"Sequential
Minimal Optimization: A Fast Algorithm for Training Support Vector
Machines"</a></p>
<p>[4] 张学工（编著），模式识别（第三版），清华大学出版社</p>
<p></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>CNN - Capsule Neural Networks</title>
    <url>/2021/02/20/CNN-Capsule-Neural-Networks/</url>
    <content><![CDATA[<h1 id="capsule">Capsule</h1>
<hr>
<h2 id="preface">Preface</h2>
<p>​ Geoffrey Hinton (他的团队 ? 挂名论文 ? )
在2017年提出了一种有别与传统深度网络结构的网络。相对于Convolution层纯参数卷积核表示，Capsule网络的基本结构是胶囊，每个胶囊都有表征一定的空间结构的能力。与其说是胶囊网络，个人对这种网络结构的理解是：向量神经网络。本文是对论文
<strong><em>Dynamic Routing Between Capsules</em></strong> <a href="https://arxiv.org/pdf/1710.09829.pdf">【arxiv链接🔗】</a>
的总结，也包含了复现论文中遇到过的问题的分析。</p>
<span id="more"></span>
<hr>
<h2 id="问题理解">问题理解</h2>
<p>​
Capsule网络与普通网络的区别在哪里？普通卷积网络（Convolution）最突出的特点就是，自动特征的提取。但是由于卷积操作的空间对称性，并且在多层卷积后，特征的空间位置信息发生损失，对于需要明确位置信息的特征无法很好地提取。比如说：给定一张人脸照片，如果人脸照片被PS了，五官的空间位置十分奇怪：</p>
<p><img src="/2021/02/20/CNN-Capsule-Neural-Networks/lena.png"></p>
<center>
Figure 1. 惊悚的Lena照片
</center>
<p>​
对于第二张图像，网络有可能将其分类为“人”，但是实际上这是怪物。而第三章图像，只不过经过了一个旋转，最后的分类结果也可能并不是“人”。我们希望在卷积的处理过程中，仍然保留相对位置信息，但又不想让整个网络变成R-CNN一样的复杂object
detection结构。</p>
<p>​
Capsule结构就是为了解决空间位置信息问题提出的。其基本思想是：Capsule结构可以将图像中的一个物体分解，分解成不同的子结构，而子结构又可以由更加低级的子特征通过空间变换组合得到。</p>
<p><img src="/2021/02/20/CNN-Capsule-Neural-Networks/comp.JPG"></p>
<center>
Figure 2. 特征组合
</center>
<p>​
乍一看，和卷积网络貌似很类似，卷积也是低级特征融合到高级特征图中。但Capsule
特征组合依靠的并不是activation函数进行特征融合，其依靠的是“动态路由”方法。</p>
<hr>
<h2 id="为什么要使用capsule">为什么要使用Capsule</h2>
<h3 id="capsule解决的问题">Capsule解决的问题</h3>
<p>​
作者在文章中提到：基于HMM-GMM的语音识别方法在神经网络普适之前一直是SOTA方法，但是其致命缺陷是需要的内存空间太大（内存开销是平方级别的复杂度）。RNN网络对于内存的开销则是线性增长级别的，结果会好很多。</p>
<p>​
CNN相对于全连接层也存在这样的内存开销优势：不同位置的参数是共享的。但是在处理存在有特征的空间变换（平移旋转）时，CNN需要有参数的平移副本，才能实现对不同位置的同一特征进行识别。这让我想起了KCF的平移样本生成。KCF在训练时，会将选中目标的部分进行大量平移，以获得足够的多的训练样本。也就是用内存换取训练结果了，也许这在训练样本极其多时不利于训练，并且随着问题规模的变大，这种方法也并不好。并且CNN这种采用参数平移副本识别不同位置的特征的方式，非常不符合生物视觉原理。作者在文中开始就提到：</p>
<blockquote>
<p>Human vision ignores irrelevant details by using a carefully
determined sequence of fifixation points to ensure that only a tiny
fraction of the optic array is ever processed at the highest
resolution.</p>
</blockquote>
<p>​
处理视觉特征的时候，应该使用一定的Attention机制，使用非复制的参数，获得图上的特征，并使用简单的位置表示，应该是<strong><u>获取特征的移动位置</u></strong>而非<strong><u>移动（式）获取特征的位置</u></strong>。这种复制方法，必然导致参数占用内存的增加。CNN能够很好地处理平移特征（因为卷积的滑动窗口特性），但是对于其他的Affine
Transformation（仿射变换），处理能力较差。Capsule本身就是带有空间位姿表征的，这样可以防止指数性的参数内存消耗。</p>
<h3 id="capsule的处理原理">Capsule的处理原理</h3>
<p>​
在Preface种说到，Capsule网络实际上是向量神经网络。与一般的标量网络不同，Capsule网络每个输出都是向量，并且向量存在其特定的意义：</p>
<ul>
<li>向量的方向代表了其属性。可以将属性空间每个单独的维度理解为一个坐标轴，在某个方向的分量大小代表了此属性的强度（比如反射率
/ intensity / 斜度等等）。也即此向量代表了其在参数空间中的位置。</li>
<li>向量的模长代表了概率。反映的是沿着某一方向的特征向量存在的概率。一个Capsule层上的所有胶囊可能对某个特征产生不同的意见，组合特征时希望能让意见一致的概率最大（Routing
by agreement）。</li>
</ul>
<p>​ 每个Capsule表示的向量都是一个个的“instantiated
parameter”，表征了一个个小组件（也许这样的小组件没有CNN抽取出来的特征那么抽象）。由于特征是不断融合的，底层特征抽取将会抽取出极其多的小型特征。每一层Capsule网络都是对上一层capsule的融合，第k层的capsule输出需要经过一个投票机制，才能被融合到1第k+1层的网络中去。当第k+1层网络存在输出后，从第k层网络选取出与第k+1层某个capsule输出最类似的一个低层capsule，增大其对应权重。</p>
<hr>
<h2 id="网络结构与计算细节">网络结构与计算细节</h2>
<h3 id="向量处理---路由原理">向量处理 - 路由原理</h3>
<p>​
激活函数并没有被大量使用在Capsule网络中，由于向量网络并不方便使用activation，而且一般激活函数并不能满足上一节提到的：模长的概率表征特性。在此处，作者设计了一个这样的归一化函数，被称作
“<strong><em>squash</em></strong>”： <span class="math display">\[
\begin{equation}\label{equ:squash}
\mathbf{v}_{j} = \frac{\Vert \mathbf{s}_j\Vert^2}{1 +\Vert
\mathbf{s}_j\Vert^2}\frac{\mathbf{s}_j}{\Vert \mathbf{s}_j\Vert}
\end{equation}
\]</span> ​
使用此归一化方法，不仅可以进行长度归一，实际对模长很短的向量存在更大的非线性惩罚。假设第k层网络存在n个capsule
filter，第k+1层存在m个capsule filter。那么<span class="math inline">\(\mathbb{u_{i}}\)</span>就是第k层中第i个filter的输出向量，从第k层第i个结构到第k+1层第j个结构的输出可以使用weight
matrix映射： <span class="math display">\[
\mathbf{\hat{u}}_{j|i}=\mathbf{W}_{ij}\mathbf{u}_i
\]</span> ​ <span class="math inline">\(\mathbf{W}_{ij}\)</span>用于维数变换，并且需要综合不同的输入得到下一层某个capsule的输入。比如本文中，<span class="math inline">\(\mathbf{W}_{ij}\)</span>就是8 * 16的矩阵。<span class="math inline">\(\mathbf{\hat{u}}_{j|i}\)</span>相当于计算出的先验（上层i送到本层j的一个特征向量）。那么：
<span class="math display">\[
\begin{equation}\label{equ:possi}
\mathbf{s}_{j}=\sum_{i=1}^{n}c_{ij}\mathbf{\hat{u}}_{j|i}
\end{equation}
\]</span> ​
就是综合所有上一层的输出，得到本层第j个capsule的输入，使用<span class="math inline">\(\eqref{equ:squash}\)</span>进行非线性归一化得到<span class="math inline">\(\mathbf{v}_{j}\)</span>。<span class="math inline">\(c_{ij}\)</span>是概率加权因子，是由<span class="math inline">\(b_{ij}\)</span>（一个logit值）经过softmax得到的概率。</p>
<h3 id="动态路由过程">动态路由过程</h3>
<h4 id="内积---投票agreement">内积 - 投票（Agreement）</h4>
<p>​
动态路由部分包含了激活函数的作用，并且在此处取代了normalization的作用。动态路由主要是为了计算<span class="math inline">\(\mathbf{v}_{j}\)</span>，通过迭代的方式求出概率加权因子，本质上是一个数学性的投票过程。开始生成的<span class="math inline">\(b_{ij}\)</span>都是0，softmax后，所有的输出路径概率都是相同的（均匀分布）。每一个胶囊的输出都相当于是一个带概率（模长）的特征向量prediction。所有的（weight
matrix映射的）的组合（概率加权）就是某个高层capsule的输入，高层输出一个归一化后的向量。这个向量只需要与低层的输出向量进行内积即可，内积结果大，表示低层的输出与高层的输出较为符合（两个输出向量的方向较为一致），将会响应增强对应的路由路径。</p>
<p><img src="/2021/02/20/CNN-Capsule-Neural-Networks/vote.JPG"></p>
<center>
Figure 3. 基于内积的投票
</center>
<p>​ 根据几次迭代就可以确定低层/高层的输出一致性关系。</p>
<h4 id="算法流程理解">算法流程理解</h4>
<p>​ 整个动态路由算法流程如下：</p>
<p><img src="/2021/02/20/CNN-Capsule-Neural-Networks/routing.JPG"></p>
<center>
Figure 4. 动态路由算法流程
</center>
<p><strong>翻译与理解：</strong></p>
<ul>
<li>初始化logit值
为0，使得初始的routing路径概率分布为均匀分布。默认已经获得了经过weight
matrix变换的先验输出向量。</li>
<li>开始迭代（迭代次数为r，论文中r = 3）
<ul>
<li>softmax 将logit变换为：<span class="math inline">\(c_{i}\)</span>，转换成符合概率定义的值。</li>
<li>计算本层的加权输入：也就是公式<span class="math inline">\(\eqref{equ:possi}\)</span>。计算所有低层prediction对应的高层prediction。</li>
<li>squash操作，非线性归一化。由于内积需要转换成概率，需要squash让模长小于1。</li>
<li>根据两层的输出计算内积，得到logits更新值。</li>
</ul></li>
</ul>
<p>​ 注意，只有两个连续的capsule层才会存在动态路由。由于动态路由是对低层
/
高层capsule连接特性的建模，低层prediction与高层prediction相符时，低层capsule更有可能与相应高层capsule相连。</p>
<h3 id="loss设计">loss设计</h3>
<p>​
Capsule网络在设计时，设计者为了让其拥有同时区分图上多个数字的能力，数字label使用一个长度为10的向量表示（类似one-hot），prediction中，每个位置存分类为对应值的概率。使用的是margin
loss（SVM多分类问题使用的就是margin
loss），由于鼓励图像多分类输出，margin loss
鼓励输出在0.9（正类）以及0.1（负类）附近，分类使用的margin loss
objective为： <span class="math display">\[
\begin{equation}\label{equ:margin}
L_k=T_k\;max(0, m^{+} - \Vert\mathbf{v}_k\Vert)^2+\lambda(1-T_k)min(0,
m^{-} - \Vert\mathbf{v}_k\Vert)^2
\end{equation}
\]</span> ​ 提供label时，如果图像中的数字是对应class k，那么<span class="math inline">\(T_k = 1\)</span>，否则为0。可以看出，<span class="math inline">\(T_k\)</span>不同情况下：</p>
<ul>
<li><span class="math inline">\(T_k\)</span>为1时，<span class="math inline">\(L_k=T_k\;max(0, m^{+} -
\Vert\mathbf{v}_k\Vert)^2\)</span>，需要让输出的概率大概为0.9（<span class="math inline">\(m^+\)</span>=0.9）</li>
<li>反之，<span class="math inline">\(L_k=\lambda(1-T_k)min(0, m^{-} -
\Vert\mathbf{v}_k\Vert)^2\)</span>，负类并不要求概率完全为0。为了多数字判定。(<span class="math inline">\(m^{-}\)</span>=0.1)，λ=0.5（影响削弱）</li>
</ul>
<p>​
由于这是一个特殊的分类问题，输出会用一个向量表征（长度为16）。那么作者希望，通过16维的特征向量可以重建出原来的数字。作者使用了全连接网络作为decoder：</p>
<p><img src="/2021/02/20/CNN-Capsule-Neural-Networks/fc.JPG"></p>
<center>
Figure 5. 文中使用的全连接decoder
</center>
<p>​
输入层是160维的，但我对这个的理解是：digitCaps存在mask，非预测值的数字将会被乘以0。那么160维的输入意义在哪？为什么不使用16维作为输入呢？</p>
<p>​
不讨论这个设计问题的情况下，reconstruction会引入loss（需要让），相当于capsuleNN提取了图像的主要特征（PCA类似，只用几个主要特征值恢复图像），但结果与原图应该尽量接近。（这在CycleGAN中也有类似的操作，不过对应的是Cycle
Consistency Loss）。Full objective: <span class="math display">\[
L_{full}=\sum L_k+0.0005 \times L_{reconstruct}
\]</span> ​ 为了不让reconstruction
loss造成的优化影响过大，需要将其scale到一个较小的值上。</p>
<hr>
<h2 id="复现-问题">复现 &amp; 问题</h2>
<p>​
实现CapsNet遇到了比较大的困难，发现自己之前实现的那些网络都比较简单，不需要用到太多的Pytorch
tensor特性或是torch的API。于是在本次复现论文时，发现在minibatch情形（高维矩阵计算）下，自己明白逻辑，但是不知如何使用Pytorch完成矩阵计算。显然，将sample一个个计算
/ 一维一维计算是可以完成算法的逻辑的，但是这样存在问题：</p>
<ul>
<li>slice / index操作 /
分维度计算（小块矩阵运算）容易导致低下的效率以及内存的消耗</li>
<li>代码变得臃肿，不符合多维矩阵的API设计初衷</li>
</ul>
<p>​
复现尝试了实现网络结构，但是比较失败（我太菜了）。最后我学习了一下别人的实现，对代码进行了细致的注释：<a href="https://github.com/gram-ai/capsule-networks">[Github
Repository🔗:gram-ai/ capsule-networks]</a></p>
<h3 id="实现上的一些点">实现上的一些点</h3>
<p>​ 在实现过程中，主要是Capsule Layer的实现比较困难：</p>
<ul>
<li>nn.ModuleList保存胶囊层的结构，比如保存8个相同的Conv2d
Filter。对同一输入处理8次，再使用cat方法连接，产生向量输出。</li>
<li>nn.Parameter 用于 weight matrix的实现。但我对这个环节产生了<a href="#thinking">一些看法</a>。
<ul>
<li>以上这两种方法都可以自动将参数加入继承了nn.Module的类的<code>.parameter()</code>中</li>
</ul></li>
<li>高维矩阵运算 不知如何进行（开始练运算规则都不知道）
<ul>
<li>输入卷积层的输出结果为：(n, 256, 20, 20)，n为batch size</li>
<li>PrimaryCaps每个胶囊输出的结果应该是：(n, 32, 6, 6,
1)。每个输出需要进行ravel（不同的通道，每个通道内的6 * 6输出），得到(n,
1152, 1) cat之后得到(n, 1152, 8)</li>
<li>PrimaryCaps 经过weight matrix之后，输出的prior应该是（shape）:(10,
n, 1152, 1, 16):
<ul>
<li><code>x[None, :, :, None, :] @ self.route_weights[:, None, :, :, :]</code></li>
<li>x由(n, 1152, 8) 变为(<strong><u>10</u></strong>, n, 1152,
<strong><u>1</u></strong>, 8)，weights(10, 1152, 8, 16)变为：(10,
<strong><u>n</u></strong>, 1152, 1, 16)</li>
</ul></li>
</ul></li>
<li>剩下的主要问题就是：
<ul>
<li>一些基本API的使用不够熟练，不知道如何进行sum / transpose /
max等等。</li>
<li>矩阵维度应该如何进行变换，才能让一个batch不被index /
slice操作分割处理。何时加入一个维度，何时squeeze？应该是经验不足，API使用不熟练的问题。</li>
</ul></li>
</ul>
<hr>
<h2 id="个人看法">个人看法</h2>
<p><span id="thinking"></span></p>
<p>​ 关于CapsuleNet，个人有以下看法：</p>
<ul>
<li>MNIST数据集未免太简单了，这样的实验（虽然作者说，关于Capsule网络只进行浅层的分析）：</li>
</ul>
<blockquote>
<p>The aim of this paper is not to explore this whole space but simply
to show that one fairly straightforward implementation works well and
that dynamic routing helps.</p>
</blockquote>
<ul>
<li>我感觉好像Capsule没有太过跳脱出Convolution以及BP结构，算是一种网络结构
/ 思想方法上的大（great）创新，但是不能算作（radical）的创新</li>
<li>CNN
baseline是否太菜了一点？太浅了吧才三层？（可能是MNIST数据集不需要太花的结构）</li>
</ul>
<p></p>
<hr>
<h2 id="appendix-a---pytorch">Appendix A - Pytorch</h2>
<p>​ 记录一下实现过程中的一些基础但是没有重视的点。希望不要做调库侠。</p>
<h3 id="torch矩阵处理">torch矩阵处理</h3>
<h4 id="torch矩阵乘法的规则">torch矩阵乘法的规则</h4>
<ul>
<li>如果只有2D（size长度为2），需要符合矩阵乘法的尺寸对应要求（(m,n) (n,
k) -&gt; (m, k)）</li>
<li>高维矩阵，除了最后两个维度之外，矩阵乘法需要满足：其他维度完全对应
条件。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.ones((<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.ones(<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.ones((<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>)) </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = a @ b</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c.shape</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<p>​
也即，高维为矩阵乘法不变，最后两维满足矩阵乘法条件。在Pytorch矩阵运算的时候，可能出现矩阵维度不对应的情况，可能需要通过添加维度的方式来进行维度对应。比如本论文中，两层capsule层中，weight
matrix的乘法操作：</p>
<p>​ 在本实现中，训练集batch <span class="math inline">\(x\)</span>卷积 /
PrimaryCaps输出为(n, 32 * 36, 8) （进行了一个ravel操作），<span class="math inline">\(W\)</span> weight matrix是 8 *
16（右乘）的。那么<span class="math inline">\(xW\)</span>导致维度不对应（输出需要到(n, 10,
16)），那么需要增加维度。如果将<span class="math inline">\(x\)</span>
变为(<strong><u>10</u></strong>, n, 32 * 36, <strong><u>1</u></strong>,
8)，<span class="math inline">\(W\)</span>变为(10,
<strong><u>n</u></strong>, 32 * 36, 8, 16)
(下划线加粗的是增加的对应维度)，就可以让输出为(10, n, 32 * 36, 1,
16)。这恰好符合论文中<span class="math inline">\(\hat
u_{i|j}=W_{ij}u_{ij}\)</span>的定义。在Pytorch中，维度增加使用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = x[<span class="literal">None</span>, :, :, <span class="literal">None</span>, :] @ W[:, <span class="literal">None</span>, :, :, :]</span><br></pre></td></tr></table></figure>
<p>​ None用于增加维度。</p>
<h4 id="torch.sum">torch.sum</h4>
<p>​ sum其实是带有两个参数的：</p>
<ul>
<li><code>dim</code> 指定对矩阵第dim维进行sum操作</li>
<li><code>keepdim=False</code>
keepdim将会使矩阵尽可能使用原来的维度进行表示。很显然，sum操作会降维（比如一个二维数组求sum之后，就成了一个一维数组）</li>
</ul>
<p>​
实例：对于<code>torch.FloatTensor(range(16)).view((1, 1, 4, 4))</code>的四个维求sum，输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Only <span class="built_in">sum</span>:  tensor(<span class="number">120.</span>)</span><br><span class="line">Sum dim = <span class="number">0</span>: tensor([[[ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>],</span><br><span class="line">         [ <span class="number">4.</span>,  <span class="number">5.</span>,  <span class="number">6.</span>,  <span class="number">7.</span>],</span><br><span class="line">         [ <span class="number">8.</span>,  <span class="number">9.</span>, <span class="number">10.</span>, <span class="number">11.</span>],</span><br><span class="line">         [<span class="number">12.</span>, <span class="number">13.</span>, <span class="number">14.</span>, <span class="number">15.</span>]]])</span><br><span class="line">Sum dim = <span class="number">1</span>: tensor([[[ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>],</span><br><span class="line">         [ <span class="number">4.</span>,  <span class="number">5.</span>,  <span class="number">6.</span>,  <span class="number">7.</span>],</span><br><span class="line">         [ <span class="number">8.</span>,  <span class="number">9.</span>, <span class="number">10.</span>, <span class="number">11.</span>],</span><br><span class="line">         [<span class="number">12.</span>, <span class="number">13.</span>, <span class="number">14.</span>, <span class="number">15.</span>]]])</span><br><span class="line">Sum dim = <span class="number">2</span>: tensor([[[<span class="number">24.</span>, <span class="number">28.</span>, <span class="number">32.</span>, <span class="number">36.</span>]]])</span><br><span class="line">Sum dim = <span class="number">3</span>: tensor([[[ <span class="number">6.</span>, <span class="number">22.</span>, <span class="number">38.</span>, <span class="number">54.</span>]]])</span><br></pre></td></tr></table></figure>
<p>​
关于sum，使用时需要搞清楚其作用维度。得到作用维度之后可以进行一系列操作，如：</p>
<ul>
<li>平方后sum，求最后一维的和得到模的平方</li>
<li>对应元素相乘后sum，求对应维度的和得到点积结果</li>
</ul>
<h4 id="torch.transpose">torch.transpose</h4>
<p>​
参数很好理解：直接transpose针对一般的二维矩阵，只需要<code>a.transpose()</code>即可。但是高维矩阵，transpose提供了两个可选参数：</p>
<ul>
<li><code>dim0</code> and <code>dim1</code>
表示，这两个dim进行互换（实际上可以不理解为transpose，理解为swap）</li>
</ul>
<h4 id="torch.cat">torch.cat</h4>
<p>​ 简单的concatenate函数。存在两个参数：</p>
<ul>
<li>需要concat的矩阵，不可变时使用tuple，可变可以使用list。</li>
<li>dim（进行concat的维度），要么dim是指定的维度，-1显然表示的是最后一维。比如二维矩阵时，dim
= 0表示按行方向进行cat，为1时按列方向进行cat。</li>
</ul>
<h4 id="torch.norm">torch.norm</h4>
<p>​
求范数。对于向量而言，设<code>a</code>为一个tensor。那么<code>a.norm()</code>直接调用输出2-范数。可以带参数：</p>
<ul>
<li>p = order，其实就是p-范数。1就是绝对值，2就是欧几里得。</li>
<li>dim（可以是int或者tuple）。torch的维度操作确实容易让人困惑。个人的理解是：传入的dim用于组织元素，对需要组织的维度进行范数计算。比如：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.arange(<span class="number">16</span>).view(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">tensor([[[[ <span class="number">0.</span>,  <span class="number">1.</span>],</span><br><span class="line">          [ <span class="number">2.</span>,  <span class="number">3.</span>]],</span><br><span class="line">         [[ <span class="number">4.</span>,  <span class="number">5.</span>],</span><br><span class="line">          [ <span class="number">6.</span>,  <span class="number">7.</span>]]],</span><br><span class="line">        [[[ <span class="number">8.</span>,  <span class="number">9.</span>],</span><br><span class="line">          [<span class="number">10.</span>, <span class="number">11.</span>]],</span><br><span class="line">         [[<span class="number">12.</span>, <span class="number">13.</span>],</span><br><span class="line">          [<span class="number">14.</span>, <span class="number">15.</span>]]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.norm(p = <span class="number">1</span>, dim = (<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">tensor([[ <span class="number">6.</span>, <span class="number">22.</span>],</span><br><span class="line">        [<span class="number">38.</span>, <span class="number">54.</span>]])</span><br></pre></td></tr></table></figure>
<p>​ 可以看出，torch将tensor a的2 / 3维度进行合并，相当于[[a, b], [c,
d]]，其中a为元素[[0, 1], [2,
3]]。求1-范数即求绝对值之和。需要组织（整合成一个元素）的维度为(2,
3)。二维的例子会更加容易明白。</p>
<ul>
<li>keepdim 和sum一样，norm操作也是降维的。</li>
</ul>
<h4 id="torch.max-min">torch.max / min</h4>
<p>​
max/min是存在参数的：<code>dim</code>以及<code>keepdim</code>。dim参数会指定：max/min操作进行的维度。比如一个二维矩阵：
<span class="math display">\[
A=
\begin{pmatrix}
1 &amp; 2 &amp; 3 \\
4 &amp; 5 &amp; 6 \\
7 &amp; 8 &amp; 9
\end{pmatrix}
\]</span> ​ 如果指定A.max(dim =
0)，指定在0维度（行）方向上求最大值，也就是每一列（沿着行变化方向）求最大。输出是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.return_types.<span class="built_in">max</span>(values=tensor([<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]), indices=tensor([<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]))</span><br></pre></td></tr></table></figure>
<p>​ 可以使用解包的方式，左值使用逗号分割。默认情况下会求全局最大值。</p>
<h4 id="torch.argmax-argmin">torch.argmax / argmin</h4>
<p>​
其实max已经可以输出最大值最小值对应的位置了。arg系列可能稍微快一些，因为不用返回值。dim
/ keepdim用法与max/min是一致的。</p>
<h4 id="torch.index_select">torch.index_select</h4>
<p>​
相当于切片的集成。help中说得很清楚，index_select就是用于取出矩阵中某些元素
/ 行列 / 维度的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([[ <span class="number">0.1427</span>,  <span class="number">0.0231</span>, -<span class="number">0.5414</span>, -<span class="number">1.0009</span>],</span><br><span class="line">        [-<span class="number">0.4664</span>,  <span class="number">0.2647</span>, -<span class="number">0.1228</span>, -<span class="number">1.1068</span>],</span><br><span class="line">        [-<span class="number">1.1734</span>, -<span class="number">0.6571</span>,  <span class="number">0.7230</span>, -<span class="number">0.6004</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>indices = torch.tensor([<span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.index_select(x, <span class="number">0</span>, indices)</span><br><span class="line">tensor([[ <span class="number">0.1427</span>,  <span class="number">0.0231</span>, -<span class="number">0.5414</span>, -<span class="number">1.0009</span>],</span><br><span class="line">        [-<span class="number">1.1734</span>, -<span class="number">0.6571</span>,  <span class="number">0.7230</span>, -<span class="number">0.6004</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.index_select(x, <span class="number">1</span>, indices)</span><br><span class="line">tensor([[ <span class="number">0.1427</span>, -<span class="number">0.5414</span>],</span><br><span class="line">        [-<span class="number">0.4664</span>, -<span class="number">0.1228</span>],</span><br><span class="line">        [-<span class="number">1.1734</span>,  <span class="number">0.7230</span>]])</span><br></pre></td></tr></table></figure>
<p>​ dim 用于视角选择。dim =
0时，说明当前index是基于行的，一次取出n行。dim =
1则相对于列进行讨论。</p>
<h4 id="torch.squeeze-unsqueeze">torch.squeeze / unsqueeze</h4>
<ul>
<li><code>squeeze</code>
去除所有维度为1的多于维度。dim用于指定哪些维度可以被操作。
<ul>
<li>squeeze返回一个与原矩阵共享内存的矩阵（相当于一个ref）</li>
<li>squeeze可能会在batch训练中，将batch_size =
1造成的第四维将为三维。</li>
</ul></li>
<li><code>unsqueeze</code>
就是增加一个维度（为1）。参数与squeeze一致。</li>
</ul>
<h4 id="的作用">“-1”的作用</h4>
<p>​
与矩阵乘法中使用None做索引类似，-1在torch中也有很多作用。比如最常用的：</p>
<ul>
<li>a.view(1, -1)与a.view(-1,
1)。此处-1表示，由系统自主确定此处的值，-1称为推测。但是只有一维可以被推测，高于1维没办法确定性推测。但-1还是有一些奇怪的使用：</li>
<li>sum(dim = -1)
此处是什么意思？这与-1作为索引一致。-1为最后一个，则选择最后一维进行sum操作。通常为列操作。</li>
</ul>
<hr>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title>2D体积光绘制算法设计</title>
    <url>/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[<h1 id="volume2d">Volume2D</h1>
<hr>
<h2 id="preface">Preface</h2>
<p>​
最近玩Minecraft1.12时发现了一个极其棒的光影包，体积光（虚假的体积光，不是用光线追踪做的）做的极其漂亮，使我对这个游戏重新产生了兴趣。</p>
<p><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/mc.png"></p>
<center>
Figure 1. 我的世界光影
</center>
<p>​
实际上，个人之前就对体积光有很大的兴趣，拍照的时候也很喜欢寻找存在"Gods'
Ray"的场景，没有就将其强行用PS的径向模糊绘制出来。对于游戏内部的光影，我也很想自己实现一个光线效果（大一写的游戏<a href="https://github.com/Enigmatisms/Ethians-Alpha-1.1">Ethians alpha
1.1🔗</a>中有阴影计算的算法（FOV shadow
casting），但结果是基于栅格的，而不是基于像素的）。综合以上的想法 +
想精进一下C++ STL技术，我设计了一个这样的问题。</p>
<span id="more"></span>
<blockquote>
<p>假设有一个点光源，在一个只有矩形障碍物的2D平面空间中，如何高效渲染场景中的阴影？</p>
</blockquote>
<p>​ 这就是一个典型的渲染问题，我设计了一个渲染算法并采用C++ + OpenCV
4.5.1进行实现。</p>
<hr>
<h2 id="算法设计与实现">算法设计与实现</h2>
<h3 id="准备工作">准备工作</h3>
<p>​ 首先将整个地图进行栅格化。比如个人的实现中，一个1200 *
900的窗口，被栅格化为 40 * 30的地图，每个栅格大小为30
pixels。障碍物是基于栅格的（对于类似于Ethians Alpha
1.1这样的平面Roguelike
Game适用），栅格越精细，障碍物也可以更加精细，阴影计算对应的时间消耗越大。</p>
<hr>
<h3 id="边界确定与划分">边界确定与划分</h3>
<p>​
对于矩形的障碍物，一个很自然的想法就是：对其边界进行管理，阴影投射的产生是由于边界对光线的截断作用。但是对于一个w
*
h的栅格化地图，每一个栅格存在4条边界（不考虑共用边界时），直接对所有边界进行操作，时间复杂度将至少是<span class="math inline">\(O(n^2)\)</span>的。显然，在这个问题中，有些边界是完全不必要存在的，我们需要在此步内计算真正可能影响渲染的边界。关于边界我们还需要其他的信息：</p>
<ul>
<li>边界的两个端点位置</li>
<li>边界是垂直的还是水平的</li>
<li>边界是否被遮挡，是否被处理过</li>
<li>边界相对于光线的方向</li>
</ul>
<p>​ 后续的计算需要依赖于上述信息。</p>
<h4 id="边界的按栅格确定">边界的按栅格确定</h4>
<p>​ 刚开始时我的设计有些问题，我直接使用位置进行遍历（按照水平 /
竖直两个方向，并行），能够快速求出所有的边界。规则如下：</p>
<ol type="1">
<li>设置occupancy
map（栅格占用2D数组），为0则表示没有障碍物，为1表示有障碍物</li>
<li>边界所在的位置 水平边的上方一格与下方一格occupancy
map值不相等，竖直边则是左右块的值不相等</li>
<li>可以快速确定两个方向的所有边</li>
</ol>
<p>​
但是这样存在一个问题，我确实可以省略一些非边界位置，比如两个相邻障碍物块之间的边界或者两个空气方块之间的边界，仍然存在一些无用边界无法被剔除。如下图所示：</p>
<p><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/rays.JPG"></p>
<center>
Figure 2. 冗余边界示意图
</center>
<p>​
实际上背对光源的边界对投影毫无帮助，计算时可以忽略。这样既可以节省内存，也可以节省计算时间。而如开始的设计，按照边界的水平
/
竖直方向进行边界计算无法获知某一条边界在栅格上的位置，也就无法获知其是否能影响投影结果。</p>
<p>​
按照栅格进行确定，也就是遍历地图上所有的栅格，边界在栅格上是有其相对位置信息的，而栅格相对光源也是可以获知位置信息的，这样可以计算出边界是否会影响投影结果。具体的规则如下：</p>
<ul>
<li>在光源正上方的栅格，只有面朝光源的这一条边界是有意义的</li>
<li>在光源侧面的栅格，根据光源的相对位置，最多选择两条面朝光源的边界</li>
<li>首先计算栅格相对光源的位置：分为8种情况：</li>
</ul>
<table>
<thead>
<tr>
<th>enum名称</th>
<th>意义</th>
<th>二进制编码</th>
<th>16进制表示</th>
</tr>
</thead>
<tbody>
<tr>
<td>TL</td>
<td>左上</td>
<td>0000</td>
<td>0x00</td>
</tr>
<tr>
<td>DT</td>
<td>正上</td>
<td>0001</td>
<td>0x01</td>
</tr>
<tr>
<td>TR</td>
<td>右上</td>
<td>0010</td>
<td>0x02</td>
</tr>
<tr>
<td>DL</td>
<td>正左</td>
<td>0100</td>
<td>0x04</td>
</tr>
<tr>
<td>DR</td>
<td>正右</td>
<td>0110</td>
<td>0x06</td>
</tr>
<tr>
<td>BL</td>
<td>左下</td>
<td>1000</td>
<td>0x08</td>
</tr>
<tr>
<td>DB</td>
<td>正下</td>
<td>1001</td>
<td>0x09</td>
</tr>
<tr>
<td>BR</td>
<td>右下</td>
<td>1010</td>
<td>0x0a</td>
</tr>
</tbody>
</table>
<p>​
设置编码的原因是，可以根据逻辑运算快速求出栅格或者边界是否属于某个方向（例如上方
包括左上 正上和右上，或者正方向，包括四个正向）。</p>
<ul>
<li>只有正方向的栅格存在一条有效边界，其余栅格均存在两条有效边界，如下图所示：</li>
</ul>
<p><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/block.JPG"></p>
<center>
Figure 3. 有效边界示意图
</center>
<p>​
根据边中点与光源的相对位置可以计算出边的方向（orient），边的orient图：</p>
<p><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/orient.png"></p>
<center>
Figure 4. 边方向计算图，中部灰色方块是光源
</center>
<p>​
边界计算是分块并行的。由于我使用的机器为4核的，使用了4个线程（也就是依图像中心划分为四个象限，并行计算，最后合并到一个vector内）</p>
<hr>
<h3 id="边界重新计算">边界重新计算</h3>
<p>​
光有边界是没有用的，我们需要通过边界来计算渲染问题，前面的步骤只是在减少不必要的边界计算以及渲染框计算。关于阴影区域的一个简单想法是：投影是存在先后顺序的，距离光源近的边界必然是需要被预先处理的，并且在距离近的边界投影完成之后，可能导致其他边界被遮挡。被完全遮挡的边界是不需要参与后续计算的，这是因为更远的边界被完全遮挡后，其投影的阴影部分必然小于遮挡此边的边界的投影阴影区域（很绕？）。</p>
<p>​
既然存在先后顺序，就必然涉及到排序。为了避免进行排序，实现中直接用了一个小顶堆（C++
<code>&lt;queue&gt;</code> 头文件中的
priority_queue）。可惜的是，priority_queue的特性与queue相似，没有迭代器，无法遍历，所以priority_queue存放的是边界类的指针，指向vector中的某个边界类。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">EdgeCompFunctor</span>&#123;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">operator</span><span class="params">()</span> <span class="params">(<span class="type">const</span> Edge* <span class="type">const</span> e1, <span class="type">const</span> Edge* <span class="type">const</span> e2)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> e1-&gt;<span class="built_in">getDistance</span>() &gt; e2-&gt;<span class="built_in">getDistance</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">std::priority_queue&lt;Edge*, std::vector&lt;Edge*&gt;, EdgeCompFunctor&gt; edges;</span><br></pre></td></tr></table></figure>
<p>​
边界到光源的距离在计算边界的时候，按照中点到光源的欧式距离已经计算过了。</p>
<p>​ 边界重新计算主要解决两个问题：</p>
<ul>
<li>完全被遮挡的边界，设置其内部的valid
flag为false，之后出队时如果遇到标签无效的边界直接跳过。</li>
<li>部分被遮挡的边界，<strong><u>需要重新计算其端点</u></strong>。这个才是最重要的部分。</li>
</ul>
<p>​
如何判定一个Edge在某个距离更近的边界产生的阴影内部呢？可以使用相对角度进行判定：绝对角度坐标（比如极坐标）是不好的，不管使用什么表征（除非四元数），都会存在奇异性，比如极坐标的x正向实际分割了0°与360°，这会让角度大小判定变得复杂。</p>
<p><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/calc2.JPG"></p>
<center>
Figure 5. 遮挡性计算
</center>
<p>​
如上图所示，假设我们看左上角那条边界。首先对于正在投影的边界（Projecting
edge），其遮挡范围有个角度θ。那么有如下规则，假设一条需要判断的边界到到两条边界的角度为<span class="math inline">\(\theta_{ij},i,j=1,2\)</span>。其中 <span class="math inline">\(\theta{ij}\)</span>表示边界端点i到光线j的夹角：</p>
<ul>
<li>某端点与光源连线到两束光线的角度均小于光线夹角θ：说明这个端点在不可视范围内</li>
<li>某端点到光源连线到两束光线的角度中，至少有一个角度大于θ，说明这个端点在可视范围内。</li>
</ul>
<p>​
如果我们通过计算方向向量，使用方向向量进行内积的计算，内积的结果就是端点和光线夹角的cos值，显然，cos值越接近1（越大），对应端点连线
/ 光线的夹角越小。（<strong><u>注意这内积值是cos值，cos在0-<span class="math inline">\(\pi\)</span>是减函数，开始忽略了这一点，直接“越小越好”导致了爆炸</u></strong>）。</p>
<p>​ 得到了夹角之后有如下规则：</p>
<ul>
<li>两个端点均在不可视范围内的直接设置valid = false，之后不再处理</li>
<li>其中一个端点在不可视范围内的，计算此端点的更新值（恰好在光线上的点）。</li>
</ul>
<p>​
关于端点更新到什么位置：简单的想法是，端点更新到离他近的光线上（夹角小的光线上）。我之前这样做的时候引起了问题：假如夹角小的那条光线对应的位置在障碍物内部或者在空气方块内部（总之不在边界上），就会出现问题。所以需要判定：优先投影到夹角小的光线对应的更新位置上，如果occupancy
map指示对应位置不是边界，则投影到另一条光线位置。</p>
<p>​ 那么整个流程应该是：</p>
<ul>
<li>取堆顶，堆顶指针指向的边界为当前投影边，计算光线方向向量，pop</li>
<li>“八叉”搜索（个人叫法，现在没有用八叉树实现，但是实际应该是可以用类似结构实现的），搜索需要更新的边，进行更新</li>
<li>更新就是判定是否要更新端点或者valid flag值，此处可以并行</li>
<li>所有需要更新的边更新之后，确定渲染框</li>
</ul>
<h4 id="八叉搜索">八叉搜索</h4>
<p>​
由于每条边都包含方向信息，而在某条边投影时，并非整张地图上的边都有可能更新。更新只发生在与投影边相同方向（或是相近方向）的边中。规则是：</p>
<ul>
<li>如果是正方向上的边，比如投影边是正上方的，由于正方向障碍物的阴影覆盖面广，需要搜索正上方，左上方，右上方的所有边。也就是说，正方向的投影边需要搜索一个大方向（包含3个小的方向）</li>
<li>如果不是正方向上的边，只需要搜索边集合（vector）中与投影边相同方向的边即可。</li>
</ul>
<p>​
这种方法还只是基于一维vector的全遍历，实际可以使用unordered_map，以方向编码为key，value为vector，只搜索部分vector。</p>
<hr>
<h3 id="渲染框确定">渲染框确定</h3>
<p>​
个人认为，本投影问题实际上是：每一条边投影时产生图像上的一部分阴影部分，每投影一条边时就可以计算一个渲染框，只需要将此渲染框内填充满阴影（的颜色）即可。如下图所示，给定一条边界，需要计算此边界产生的阴影区域，也就是需要获得光线（或者阴影边界线）与地图边界的交点。如果得到交点，经过排序之后，可以直接使用OpenCV提供的fillConvexPoly进行凸多边形的颜色填充。</p>
<p><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/render.JPG"></p>
<center>
Figure 6. 渲染框计算示意图
</center>
<p>​ 如果需要解边界上的点位置，我们需要如下信息：光源位置<span class="math inline">\((x_c, y_c)\)</span>，光线向量<span class="math inline">\((v_x,v_y), (u_x,u_y)\)</span>，边界：<span class="math inline">\(x=0,y=0,x=x_M,y=y_M\)</span>，并设对应边界为：<span class="math inline">\((x_b,y_b)\)</span>那么可以根据： <span class="math display">\[
(x_c,y_c)+t(v_x,v_y)=(x_b,y_b)
\]</span> ​ 在边界上<span class="math inline">\(x_b,y_b\)</span>中必然有一个是已知的，可以解出t，得到未知的边界坐标分量。实际上，一条射线（一个向量）可能与两个边界（相邻的x
/
y方向边界）相交，得到两个解，从两个解中选择合理值（两个分量均在边界范围内）作为解。</p>
<p>​
此外，得到了边界交点并不代表着渲染框完全选取好了，由于边界交点并不一定在同一条地图边界上，可能需要增加额外的地图corner为渲染框角点。有如下三种情况：</p>
<p><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/cond.JPG"></p>
<center>
Figure 7. 渲染框增加地图边界点的三种情况
</center>
<p>​
在出现需要增加点的情况下，需要人为设计一些规则，讨论如何判定进入这三种情况中的哪一种情况：</p>
<ul>
<li>加入两个点的情况出现时，特征的表现是：两个解的某个分量差的绝对值等于地图某个方向的长度。</li>
<li>加入一个点的情况出现时，特征的表现是：两个解的对应分量不会相等。</li>
</ul>
<p>​
渲染框需要emplace到某个二维vector中。此后使用4个线程同时绘制渲染框即可（地图内100个随机障碍块时，绘制时间大概是1.5ms）。结果如下图所示：</p>
<table>
<thead>
<tr>
<th style="text-align: center;"><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/direct.png"></th>
<th style="text-align: center;"><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/direct2.png"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">随机地图渲染框绘制</td>
<td style="text-align: center;">非随机地图渲染框绘制</td>
</tr>
</tbody>
</table>
<hr>
<h3 id="美化">美化</h3>
<p>​ 美化主要做了两个事情：可视范围确定 +
光强衰减。这两个事情可以合并起来处理。开始我使用线性衰减，设置阴影的色彩为(20,
20, 20)： <span class="math display">\[
max(255-\frac{255-20}{R_{max}}R,20)
\]</span> ​ 此式说明，光强度线性衰减到<span class="math inline">\(R_{max}\)</span>后，维持在最低光强值处。线性衰减的效果并不好，可见范围内较亮位置比较小。而改换成较为符合物理学的光强衰减公式（平方反比）后，效果较好：
<span class="math display">\[
max(\frac{255}{(aR+1)^2},20),where\;a=\frac{\sqrt\frac{255}{20}-1}{R_{max}}
\]</span> ​ 美化后的结果如下两张图所示：</p>
<table>
<thead>
<tr>
<th style="text-align: center;"><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/beauty1.png"></th>
<th style="text-align: center;"><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/beauty2.png"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">随机地图渲染框绘制</td>
<td style="text-align: center;">非随机地图渲染框绘制</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="结果与代码">结果与代码</h2>
<p>​ 代码见<a href="https://github.com/Enigmatisms/Algorithms-Plus/tree/master/cpp/volume">[Github🔗Algorithm
Plus/cpp/volume]</a>，代码依赖：OpenCV 4.5.1，OpenMP，C++
11（或以上），CMake。</p>
<p>​
加入了平滑运动：光源的运动不是按照栅格进行的，而是按照像素进行的，运动过程比较平滑，可以通过键盘操控光源的移动。输出的gif如下：</p>
<p><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/volume.gif"></p>
<p><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/volume2.gif"></p>
<center>
Figure 8. 体积光与光源运动
</center>
<hr>
<br>
<center>
Do you like what you♂see ?
</center>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>algos</tag>
      </tags>
  </entry>
  <entry>
    <title>CycleGAN Paper Summary</title>
    <url>/2021/02/10/CycleGAN-Paper-Summary/</url>
    <content><![CDATA[<h1 id="cyclegan">CycleGAN</h1>
<hr>
<h2 id="preface">Preface</h2>
<p>​ GAN常用作风格迁移或者是object
transfiguration，但是普通的GAN实际上并不能很好地胜任这些任务。原始的GAN是从一个隐含向量z（常服从一个简单的多维分布）映射到一个具有丰富信息的更高维空间的过程，而这种映射往往“arbitrary”，它可以乱射（随机性的生成）。比如在object
transfiguration中，A-&gt;B集合映射过程可以通过此网络实现，但B集合进入网络后，生成出来的（例应是原始的B）却与原始B相差很远。当然，在object
transfiguration中，更加有挑战性的问题是，对于pix2pix论文提出的成对图像转换而言，成对图像一般很难获得。如果只有两个集合A
/ B，A / B内的对象为不同属性的，那么在没有预先产生匹配关系的情况如何将A
/ B集合内的物体互相映射呢？</p>
<span id="more"></span>
<p>​ 在论文 <em>Unpaired Image-to-Image Translation using
Cycle-Consistent Adversarial Networks</em> （arXiv链接：<a href="https://arxiv.org/abs/1703.10593">【arXiv
Preview】🔗</a>）中，作者提出了：Cycle
Consistancy的思想（好了，xxx一致性，听多了）（循环一致性），在误差函数中添加了两项：</p>
<ul>
<li>循环一致误差（CCL），用于控制一致性（显然）</li>
<li>本征一致性，感觉作者没有提。但是我觉得可以通过CCL推导出来。</li>
</ul>
<h3 id="复现的结果">复现的结果</h3>
<p>​ 由于受到设备的限制（GeForce
MX150，三年的i5小米Air轻薄本的渣显卡）网络只训练了25个迭代（原文使用了50个学习率恒定迭代，此后50个迭代学习率线性递减至0），也没有修改学习率设置。一张图片大概需要计算1s，995张图片需要15min+才能完成一轮迭代。结果如图：</p>
<p><img src="/2021/02/10/CycleGAN-Paper-Summary/result.JPG"></p>
<center>
Figure 1. 训练结果
</center>
<p>​
两行为一组，一共六行。前两行是橙子-&gt;苹果，中间两行是苹果-&gt;橙子，后两行是初始情况（欠训练时的结果）。</p>
<hr>
<h2 id="论文的细节">论文的细节</h2>
<h3 id="ccl的定义">CCL的定义</h3>
<p>​ 在【3. Formulation】中，作者提到：循环一致性就是：假设集合<span class="math inline">\(X\)</span>与<span class="math inline">\(Y\)</span>分别包含两种类型物体，<span class="math inline">\(G\)</span>与<span class="math inline">\(F\)</span>分别是两个生成器，其中<span class="math inline">\(G\)</span>用于利用集合<span class="math inline">\(X\)</span>对象生成集合<span class="math inline">\(Y\)</span>的对象，<span class="math inline">\(F\)</span>则正好相反。也就是： <span class="math display">\[
G: X\rightarrow Y,G(x)\rightarrow Y,\text{for each }x\in X \\
F: Y\rightarrow X,F(y)\rightarrow X,\text{for each }y\in Y
\]</span> ​ 那么对于这样的映射，应该有：<span class="math inline">\(F(G(x))\approx
x\)</span>（也就是经过两个生成网络后，<span class="math inline">\(X\rightarrow Y\rightarrow
X\)</span>），数据应该和初始输入保持一致。在object
transfiguration或是style
transfer中，我觉得这种想法十分自然，并且很妙。由于在这两个问题中，图像本身的形状特征并不会发生巨大的变化，变化的只是颜色
/ 纹理属性，在object
transfiguration中，从物体A变成物体B以及其反过程是对称的，风格迁移中，风格的加入和消除也是对称的（可以将原图看成另一种风格），那么由反函数的性质，应该存在上式的结果。于是，作者定义了一个Cycle
Consistancy Loss： <span class="math display">\[
L_{cyc}(G,F,x,y)=\Vert G(F(y))-y\Vert_1+\Vert F(G(x))-x\Vert_1
\]</span> ​
也就是用（理论上的identity变换）变换前后的图像的1-范数进行比较。显然是越小越好，希望这种identity映射前后基本不变。</p>
<p>​
但其实整篇论文传达的意思就那么简单，18页的论文，放了一半页数的图，但是做的事情却牛大了（虽然已经是4年前的论文了）。不得不吐槽一下，原论文中提到的信息不太多（可能是因为这些基本的问题作者认为大家都应该明白所以不说了？），所以这篇文章非常好懂，复现起来也相对简单（但是我太菜了，遇到了一些坑）。</p>
<hr>
<h3 id="ccl可以推出什么">CCL可以推出什么</h3>
<p>​ 个人认为，既然存在CCL（<span class="math inline">\(X\rightarrow
Y\rightarrow
X\)</span>循环映射不变），那么以下想法也是自然应该成立的：设<span class="math inline">\(x\in X, y \in Y\)</span>，那么应该存在： <span class="math display">\[
\begin{equation}
G:X\rightarrow Y, G(y)\approx y\\
F:Y\rightarrow X, F(x)\approx x
\end{equation}
\]</span> ​ 也就是说，由于G的输出空间为<span class="math inline">\(Y\)</span>（期望），所以对于已经在y空间里的数据而言，生成网络不应该改变其特征。所以可以定义本征一致性loss：
<span class="math display">\[
\begin{equation}\label{equ:ind}
L_{ind}=\mathbb E_{p\_data(y)} \Vert G(y)-y\Vert_1 + \mathbb
E_{p\_data(y)} \Vert F(x)-x\Vert_1
\end{equation}
\]</span> ​
可以认为这是循环的一半情况吧，但是确实是应该加入到loss项中的，既然存在循环一致性，那么本征一致性理论上来说也是存在的。</p>
<p>​ 于是，full objective应该是： <span class="math display">\[
\begin{equation}
L_{full}(X,Y,G,F)=L_{adv}(X,Y,G,F)+L_{cyc}(X,Y,G,F)+L_{ind}(X,Y,G,F)
\end{equation}
\]</span></p>
<hr>
<h3 id="网络结构">网络结构</h3>
<h4 id="生成器">生成器</h4>
<p><span id="generator"></span></p>
<p>​ 论文中的生成器采用了ResNet结构，首先图片都是256 * 256 *
3的图片，以6个Residual Block结构进行说明：</p>
<ul>
<li>输入层：输入3 输出64，<span class="math inline">\(7\times 7\)</span>
大小的卷积网络，使用ReLU激活函数，InstanceNorm
<ul>
<li>Reflection Padding</li>
</ul></li>
<li>输入64 输出128，<span class="math inline">\(3\times 3\)</span>
卷积网络，<strong><u>步长2</u></strong>，其余同上
<ul>
<li>Reflection Padding</li>
</ul></li>
<li>输入128 输出256，<span class="math inline">\(3\times 3\)</span>
卷积网络，<strong><u>步长2</u></strong>，其余同上</li>
<li>Residual Block 1，256-&gt;256，<span class="math inline">\(3\times
3\)</span>
卷积网络，<strong><u>步长2</u></strong>，其余同上，个人使用了ZeroPadding</li>
<li>Residual Block 2，Residual Block 3，Residual Block 4，Residual Block
5，Residual Block 6</li>
<li>非整数步长的卷积（ConvTranspose，反卷操作）， <span class="math inline">\(3\times 3\)</span> ，步长1/2，256-&gt;128</li>
<li>非整数步长的卷积， <span class="math inline">\(3\times 3\)</span>
，步长1/2，128-&gt;64</li>
<li>输出层，（64-&gt;3）其余同输入层，Tanh激活</li>
</ul>
<p></p>
<h4 id="判别器">判别器</h4>
<p><span id="clf"></span></p>
<p>​
判别器使用PatchGAN结构，也就是说不只输出一个值（比如过卷积后再过全连接输出1）。输出的是一个super
image，super
image是一张size更小的单通道图，每个像素表示的是：<strong><u>判别器输出的结果，图像上每小块为real的概率（重新组织的特征图）</u></strong>。也就是说，输出层只需要卷积，输出卷积结果。</p>
<ul>
<li><span class="math inline">\(4\times 4\)</span>
Convolution，64-&gt;128，很奇怪吧。偶数大小的kernel，所以anchor在哪？
LeakyReLU(0.2)
<ul>
<li>InstanceNorm</li>
</ul></li>
<li><span class="math inline">\(4\times 4\)</span>
Convolution，128-&gt;256 LeakyReLU(0.2)</li>
<li><span class="math inline">\(4\times 4\)</span>
Convolution，256-&gt;512 LeakyReLU(0.2)</li>
<li><span class="math inline">\(4\times 4\)</span>
Convolution，512-&gt;1，直接输出</li>
</ul>
<p>额，不讲武德。为什么网络结构细节放在Appendix？搞得我以为我读完了，最后一乱翻发现了更重要的东西。</p>
<p></p>
<hr>
<h3 id="原始gan模式崩塌">原始GAN模式崩塌?</h3>
<h4 id="模式崩塌的定义">模式崩塌的定义</h4>
<p>​
模式崩塌也就是多个输入映射到同一个输出上的情况。这通常出现在输出模式具有多峰分布的情况。通常我们希望，在目标分布（不可知，但是可以通过采样学习近似）多峰的情况下，拟合的近似分布也应该是多峰的。但如果出现了生成器过强的情况，直接导致生成器每次都拟合到其中一个峰上，就很可能导致模式崩塌。</p>
<p><img src="/2021/02/10/CycleGAN-Paper-Summary/adver.JPG"></p>
<center>
Figure 2. 图片来自Goodfellow著名论文 GAN[1]
</center>
<p>​
上图说明的是，多峰分布时，每一次训练生成器后的生成分布。训练造成了模式崩塌，也就是输出的低丰富性，这就失去了GAN本身的意义。</p>
<p>​ Goodfellow在论文中提到两种可能产生模式崩塌的原因：</p>
<h5 id="jskl散度的使用导致模式崩塌">JS/KL散度的使用导致模式崩塌</h5>
<p>​ JS散度： <span class="math display">\[
\begin{equation}\label{equ:js}
2D_{JS}(P_R|P_G)=\int_xP_R(x)log(\frac{P_R(x)}{\frac{P_R(x) +
P_G(x)}{2}})dx + \int_xP_G(x) log(\frac{P_G(x)}{\frac{P_R(x) +
P_G(x)}{2}})dx
\end{equation}
\]</span> ​ KL散度： <span class="math display">\[
\begin{equation}
D_{KL}(P|Q)=\int_xP(x)log(\frac{P(x)}{Q(x)})dx
\end{equation}
\]</span> ​
KL散度能造成更加恐怖的模式崩塌。由于KL散度的非对称性，每次求导都会往特定方向逼近。求导时往特定方向趋近的问题导致了模式崩塌？为什么会这样？KL散度的不对称性决定了其可以从两个方向进行观察，两个方向上的KL散度不是相同的，Goodfellow称<span class="math inline">\(D_{KL}(p_{data}\Vert
p_{model})\)</span>（以data分布为主导的KL散度）为正KL散度，<span class="math inline">\(D_{KL}(p_{model}\Vert
p_{data})\)</span>为逆KL散度。正KL散度和逆KL散度在优化上的表现是有所不同的。可以从直观上理解，前者是给定数据分布（的计算
/ 估计）时，模型分布于数据分布的差别，那么此时模型分布
<strong><u>将会是被动的</u></strong>，只要能达到最小拟合的情况，模型分布怎么样都可以。</p>
<p><img src="/2021/02/10/CycleGAN-Paper-Summary/collapse.JPG"></p>
<center>
Figure 3. 模式崩塌问题中的两种KL散度[1]
</center>
<p>​
如上图左图，由于原始（数据）分布已知，模型分布为了产生最小散度，形状可以很奇怪。而在逆KL散度中，已经知道的是模型分布，也就是说：已经出现在模型中的模式<strong><u>概率分布大</u></strong>，尚未出现的模式概率分布小。这样一加权，就会让已经生成的模式被强化，造成单峰性（如上图右）。</p>
<p>​ 这两种KL散度倾向性不同：</p>
<ul>
<li>正KL散度倾向于满足数据分布，不考虑模型已经有的分布，所以很可能生成一些奇怪的模式（比如上图中概率分布大的部分在两峰中间，这是不合理的），但是理论上其多样性更佳</li>
<li>逆KL散度倾向于生成已经存在的模式，不习惯于跳出圈子。显然这样做会产生更多我们熟悉的模式，更少奇怪的新模式，但是容易引起模式崩塌。</li>
</ul>
<p>​ 关于这点，Goodfellow这样说到：</p>
<blockquote>
<p>We can think of <span class="math inline">\(D_{KL}(p_{data}\Vert
p_{model})\)</span> as preferring to place high probability everywhere
that the</p>
<p>data occurs, and <span class="math inline">\(D_{KL}(p_{model}\Vert
p_{data})\)</span> as preferrring to place low probability wherever the
data does not occur.</p>
</blockquote>
<h5 id="minmax顺序问题">min/max顺序问题</h5>
<p>​ Goodfellow在GAN论文中也提到，GAN的原理（min
max）可能会引起模式崩塌。通常我们说，GAN是：minmax结构的，也就是： <span class="math display">\[
\begin{equation}\label{equ:minmax}
G^*=\mathop{argmin}_{G} \mathop{max}_{D}L(G,D)
\end{equation}
\]</span> ​
其意义也就是（在前某篇文章中提到过）：在判别器最优的情况下进行生成器的最优化。我们希望在一个十分强的判别器存在的情况下仍然能尽可能优化生成器，直到生成器骗过判别器。而Goodfellow说到：</p>
<blockquote>
<p>We use it in the hope that it will behave like min max but it often
behaves like max min.</p>
</blockquote>
<p>​ max min也就是公式<span class="math inline">\(\eqref{equ:minmax}\)</span>对于min /
max的取反结果。个人认为可以这样理解：max
min结构也就是：训练生成器在内循环，训练判别器在外循环。直观上看也就是每一次训练判别器，可能会训练多次生成器。这样是不好的。判别器训练一次之后，生成器会有过拟合到<strong><u>判别器认为最像real
data的一种（或少数几种）模式上</u></strong>的趋势（由于生成器要训练多次）。这就导致了模式崩塌。关于这个理解，原文是这样写的：</p>
<blockquote>
<p>The generator is thus asked to map every <strong>z</strong> value to
the single <strong>x</strong> coordinate that the discriminator believes
is most likely to be real rather than fake.</p>
</blockquote>
<p>​ 有些情况下可能会导致GAN的行为更像max min而非min
max。个人认为：训练一次判别器后训练多次分类器可能造成此情况（我之前也这么写过，效果是好的，毕竟生成出来的图片最像真的，但是多样性变差了）。</p>
<hr>
<h2 id="复现的细节">复现的细节</h2>
<h3 id="反卷积过程">反卷积过程</h3>
<p>​ 在CycleGAN<a href="#generator">[网络结构细节]</a>中，作者使用了这样的一个结构：非整数步长的卷积（ConvTranspose，反卷操作），
<span class="math inline">\(3\times 3\)</span>
，步长1/2，256-&gt;128。反卷积之前试着使用过，但是由于（当时我以为）1/2步长时其输出只能为奇数，就没有深入了解了。结果此处碰上了，为了尽可能按照论文复现，重新了解了一下这个玩意。</p>
<p>​
ConvTranspose就是卷积的逆过程，在有步长的情况下更为明显。常用于上采样放大。但实际上，即使步长为1，“放大”也是做不到的。由于ConvTranspose实际上也是用卷积核生成输出，卷积核必然导致输出小于输入，所以需要加入padding。padding让我感觉反卷积在放大过程中需要加入太多无效的信息（即使reflection
padding也是一样的），毕竟是上采样过程（信息
少-&gt;多）。这种“无效信息的加入”在步长不为1的1时候更能体现出来（如下图片列表）</p>
<table>
<thead>
<tr>
<th style="text-align: center;"><img src="/2021/02/10/CycleGAN-Paper-Summary/pad.gif"></th>
<th><img src="/2021/02/10/CycleGAN-Paper-Summary/nopad2.gif"></th>
<th><img src="/2021/02/10/CycleGAN-Paper-Summary/nopad3.gif"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">padding放大</td>
<td>stride放大（奇数）</td>
<td>stride放大（偶数）</td>
</tr>
</tbody>
</table>
<p>​
分数步长的卷积就是需要上采样的卷积。整数步长将会使卷积核跳过一些位点，而分数（小于1）则是需要在位点之间进行padding的。非1步长
/ 有padding的卷积计算就不再赘述了。</p>
<p>​ 值得注意的是分数步长的卷积，当步长不为1时（比如stride =
2），两个原始位点之间会填充一个位点。这样导致了：当stride =
2时，不管原来的输入size为奇数还是偶数，输出一定是奇数size的（<strong><u>此处说的是kernel
size为奇数，个人感觉偶数的kernel
size不够自然，需要讨论anchor</u></strong>）（偶数kernel
size可以让输出为偶数，比如ConvTranspose2d(n, n, 4, 2, 1)
就是放大size为原来的两倍）。我实现的第一版CycleGAN使用的是ConvTranspose，附带了一个output_padding
(由于当时使用奇数核)，正如图三所示，感觉其结果十分不自然，但效率上并没有太大的区别。对于偶数kernel，其anchor默认在最左上方。</p>
<p>​
然而在第二版CycleGAN中我就把反卷积换成了卷积+上采样了，网络看起来更正常一些。</p>
<hr>
<h3 id="patchgan">PatchGAN</h3>
<p>​
这里指的是分类器设计，CycleGAN作者在其论文中采用了CycleGAN的结构，也就是分类器不输出二分类概率值，而是直接输出一个channel-1的卷积结果。例如，一个256*256的图像可以被一个70*70的特征图给表达，这70*70个元素，每个元素代表着图上的某个区域的真实性。自然我们希望，在判定为真实时这个输出接近ones(70,
70)，反之接近zeros(70,
70)。论文中使用了70*70，我的实现中并没有这么做。我写的判别器结构：</p>
<ul>
<li>(256, 256, 3) -&gt; (128, 128, 8) kernel size = 4，stride =
2，padding = 1，no norm</li>
<li>(128, 128, 8) -&gt; (64, 64, 16) kernel size = 4，stride =
2，padding = 1，instance norm</li>
<li>(64, 64, 16) -&gt; (32, 32, 32) kernel size = 4，stride = 2，padding
= 1，instance norm</li>
<li>(32, 32, 32) -&gt; (16, 16, 1) kernel size = 4，stride = 2，padding
= 1，no activation, no norm.</li>
</ul>
<p>​ 当然，如果要说的话，个人还有几个没有复现的部分：</p>
<ul>
<li>ResNet residual
block我只用了两个。在论文中，128*128使用了6个resBlock，256*256则使用了9个。</li>
<li>没有避免model
oscillation的trick（使用历史生成的图片而非当前最新生成的图片进行训练）</li>
<li>可能本征Loss是我加进去的东西，我在原文中并没有读出这样的意思来。（<strong><u>张麻子：这tm是复现？</u></strong>）</li>
</ul>
<hr>
<h3 id="normalization谈">Normalization谈</h3>
<p>​ 首先看一张图（来自西交袁泽剑老师的CVPR课PPT，而PPT上的图又是来自<a href="https://arxiv.org/abs/1803.08494">【Wu and He, “Group
Normalization”, ECCV 2018🔗】</a></p>
<p><img src="/2021/02/10/CycleGAN-Paper-Summary/norm.JPG"></p>
<center>
Figure 4. 4种normalization
</center>
<p>​
上图描述了常用的（第四种我在写这篇文章之前也不知道是啥）4种norm（我目前见过用的只有BN与IN）。Normalization的作用就是神经网络的“白化操作”，将NN的输出固定于Norm(0,
1)，可以稳定训练。</p>
<h4 id="bn">BN</h4>
<p>​
BatchNorm看名字就应该能知道，这种Normalization与batch有关。看第一张图，当Batch
size为N时，将会对某个channel做batch内的norm操作（也就是一个batch里的所有训练用例
+ 一个channel的特征）。显然这个操作在batch
size为1时意义不大（退化成了instance
norm？）。类似于多张图片训练的（判别模型）常用这个。</p>
<h4 id="in">IN</h4>
<p>​ 显然instance
norm与batch没有关系，它是对单张图片意义上的norm。图片每个通道进行normalization。通道数对应了filter数，filter对应了生成的特征。实际上instance
norm就是对不同的特征进行normalization。instance
norm由于针对单张图片的不同通道，常用于生成式技术比如style transfer。</p>
<h4 id="layernorm-groupnorm">LayerNorm &amp; GroupNorm</h4>
<p>​ Laynorm
是一张图的所有通道做normalization。网上说是对RNN明显的，至于为什么，我没有深入了解过。而GroupNorm相当于是多个通道的Instance
Norm，选取的通道数是可变的。</p>
<hr>
<h3 id="resnet相关">ResNet相关</h3>
<p>​
ResNet专注于学习输入输出残差的表示，而不是学习简单的输入输出关系。为什么说学习残差？普通的CNN网络输入输出结构是这样的：
<span class="math display">\[
x\mathop{\rightarrow}^F F(x)\rightarrow y
\]</span> ​ 学习的是x与y之间的映射关系，而在res net种，增加了一个identity
mapping的合并： <span class="math display">\[
x\mathop{\rightarrow}^F F(x)\rightarrow x&#39;,y=x+x&#39;
\]</span> ​
那么，真正的输出是y，但是存在参数的部分输入输出只有x'，也就是说学习的实际上只是y-x（输出
-
输入），也就是说：学习的是残差，残差表示将可以使深层网络收敛速度加快，并且网络过深时模型准确率并不会有太大的损失。实际上ResNet的
residual block结构也就是一个identical
mapping和卷积的并联，个人在刚开始什么都不懂的时候，曾经将两个不同kernel
size的卷积层并联在一起，觉得这会提高网络的表达能力（虽然不知道为什么，只是一种感觉）。所以CycleGAN为什么要使用ResNet结构？</p>
<p>​
个人的理解是：网络层数加深时，原始图的信息会在经过卷积发生损失，层数越深，积累的损失越大。加入直接的信息通道（shortcut）可以减少这样的信息损失。（可能个人原来使用不同的kernel
size核并联时觉得，这样可以在同一层聚合不同大小的特征）。CSDN上有一篇文章说的很好（总结起来就是如下观点）[2]:</p>
<ul>
<li><p>孙剑（？是我们学校的孙剑老师吗）认为ResNet可以避免梯度弥散问题（过深的网络优化时梯度不明显）</p></li>
<li><p>特征冗余可以被削弱：减少信息损失问题（和我的想法有点类似）</p></li>
<li><p>ensemble
特征融合：实际的网络层数由于shortcut的加入变得并不太深</p></li>
<li><p>层次性：shortcut保留了简单的特征，与复杂的特征（参数卷积部分）融合</p></li>
<li><p>凸函数性：层数越深，函数非凸性越严重，找不到全局最优，ResNet结构可以优化函数非凸性</p></li>
</ul>
<hr>
<h3 id="一些细节问题">一些细节问题</h3>
<ul>
<li>关于激活函数：Sigmoid通常用于概率映射，Tanh通常用于图像输出层，而ReLU和LeakyReLU通常作为中间层的输出函数。注意不要乱加。</li>
<li>为什么有的时候输入层会倾向于不进行normalization？很显然，输入的数据会进行预处理，通常都在DataLoader的transform中。比如说使用normalize，以及shuffle，就已经可以保证数据的标准高斯分布。这种情况下，第一层是不需要进行normalize的。</li>
<li>Conv2D不提供padding的模式变换（same和circular选项不算），需要在nn模块下使用ReflectionPad
/ ZeroPad 等等Padding方式。</li>
</ul>
<hr>
<h2 id="参考文献">参考文献</h2>
<p>[1] Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros
Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial
Networks.</p>
<p>[2] Ian J. Goodfellow, Jean Pouget-Abadie∗ , Mehdi Mirza, Bing Xu,
David Warde-Farley, Generative Adversarial Nets</p>
<p>[3]
《ResNet个人理解》https://blog.csdn.net/nini_coded/article/details/79582902</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title>Typora &amp; Markdown Intros</title>
    <url>/2021/02/09/Typora-Markdown-Intros/</url>
    <content><![CDATA[<h1 id="typora-markdown">Typora &amp; Markdown</h1>
<hr>
<h2 id="why">Why?</h2>
<p><span id="start"></span></p>
<p>​ 此文撰写的目的是：</p>
<ul>
<li>归纳Typora（Markdown编辑器） 的基本使用（常用的都能找到）</li>
<li>给我Raven的安利。</li>
</ul>
<center>
效率工具，绝不白启
</center>
<p></p>
<span id="more"></span>
<h3 id="why-markdown">Why Markdown?</h3>
<p>​ 虽说markdown实际是给
不爱使用鼠标在word上点来点去的人使用的（并且面向的人群一般是对敲代码有兴趣的人），但由于Markdown上手极其简单，并且使用效率极高，<strong><u>极其适合：</u></strong></p>
<ul>
<li>撰写ReadMe，帮助他人理解某个程序 / 文件包 / 压缩包文件 / 文档 / 代码
如何使用。</li>
<li>写一些风格简约而又好看的文档，方便撰写 tutorials / ideas / agenda /
会议记录 / <strong><u>学习笔记</u></strong> /
<strong><u>实验报告</u></strong> /
等等，<strong><u>并快速生成PDF文件</u></strong>。</li>
<li>【Event Horizon】上的所有博文，均是markdown渲染出来的。</li>
</ul>
<h3 id="why-typora">Why Typora?</h3>
<p><img src="/2021/02/09/Typora-Markdown-Intros/from_site.png"></p>
<center>
Figure 1. 来自官网的图片
</center>
<p>​ Typora
是一款极其轻量级的Markdown语法编辑器，其界面就像windows自带的记事本。并且，对于markdown语法支持实时渲染（直接显示效果）。易用性与美观性（尤其是其自带的Pixyll主题，中英文都极其美观）是其另外两个优点。Typora支持：</p>
<ul>
<li>Markdown所有语法</li>
<li>LaTex数学公式渲染</li>
<li>html支持（网页前端语言，markdown进阶中用于美化，本文会提几个常用栗子）</li>
</ul>
<hr>
<h2 id="level-1-skills">Level 1 Skills</h2>
<p>​
本节将会介绍基础的markdown语法。记忆这些语法是非常容易的，因为都很简单。</p>
<h3 id="无序-有序items">无序 &amp; 有序items</h3>
<h4 id="无序items">无序items</h4>
<p>​ 在分点操作时，常常会使用 (1) 分点内容前面加上一个黑色圆点 (2)
使用编号（有序排列），在markdown中，无需进行鼠标点击（鼠标 / 触控板 /
触屏 在文档撰写的时候真的累赘）。对于
<strong>无序分点，可以如下输入：</strong></p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> Markdown is easy to use.</span><br><span class="line"><span class="bullet">-</span> Markdown is so goodlooking.</span><br><span class="line"><span class="bullet">-</span> Simplicity is the basic traits.</span><br></pre></td></tr></table></figure>
<p>​ （前面的- 就是减号，当然 “*” 号也是可以替换“-”
号的），在Typora页面上实时显示的结果是：</p>
<ul>
<li>Markdown is easy to use.</li>
<li>Markdown is so goodlooking.</li>
<li>Simplicity is the basic traits.</li>
</ul>
<p>​
当然，不同级别的items（分级）也是支持的，只需要通过缩进的方式（比如TAB缩进，或是Typora提供的
<code>Ctrl + ]</code>
增加缩进（级别减小（子item）），<code>Ctrl + [</code>
减少缩进（或者说：级别增大））：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> Markdown is easy to use.</span><br><span class="line"><span class="bullet">	-</span> Gramma is easy to remember.</span><br><span class="line"><span class="bullet">		-</span> &quot;- + indent&quot; is unordered item.</span><br><span class="line"><span class="bullet">    -</span> Then What?</span><br></pre></td></tr></table></figure>
<p>​ 在Typora页面上实时显示的结果是：</p>
<ul>
<li>Markdown is easy to use.
<ul>
<li>Gramma is easy to remember.
<ul>
<li>"- + indent" is unordered item.</li>
</ul></li>
<li>Then What?</li>
</ul></li>
</ul>
<h4 id="有序items">有序items</h4>
<p>​ 需要按照编号排列时，可以输入以下语句：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> Open the gate.</span><br><span class="line"><span class="bullet">2.</span> Let the army in.</span><br><span class="line"><span class="bullet">3.</span> Close the gate.</span><br></pre></td></tr></table></figure>
<p>​
这个其实有点鸡肋了，markdown会自动帮你调整编号的位置。Typora则会帮你自动添加编号，也即：输入一个
1. 再换行，会自动出现 2. 3. 等等。以上的输出结果是：</p>
<ol type="1">
<li>Open the gate.</li>
<li>Let the army in.</li>
<li>Close the gate.</li>
</ol>
<p>​ 当然，有序items也是可以分级的。同样使用缩进的方法可以达到目的。</p>
<h4 id="typora-items使用的一个坑">Typora items使用的一个坑</h4>
<ul>
<li><p>随便写的一句话。</p>
<p>随便写的第二句话。</p></li>
<li><p>随便写的一句话</p></li>
</ul>
<p>​ 随便写的第二句话。</p>
<p>​ 在写完items后，不想要分下一个点了，想要开始另一端正文，但是无论使用
backspace 删除 还是使用 <code>Ctrl + [</code>
删去自动添加的分点，都会让下一行的首行缩进变得很奇怪，主要体现在：按下TAB之后，正常情况下只会缩进一个字符，但是此情况下，缩进了不止一个字符，并且出现了错位的情况。</p>
<table>
<colgroup>
<col style="width: 19%">
<col style="width: 80%">
</colgroup>
<thead>
<tr>
<th><img src="/2021/02/09/Typora-Markdown-Intros/ind_1.JPG"></th>
<th>错误情况，正文与item文字对齐了。并且一个tab就能缩进到此情况</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="/2021/02/09/Typora-Markdown-Intros/ind_2.JPG"></td>
<td>正确情况，需要两个tab才能达到首行缩进两个字符的情况</td>
</tr>
</tbody>
</table>
<p>​ 对于强迫症患者而言（如作者），这是不能被接受的。解决方法是：</p>
<ul>
<li>在错误情况的行首 两次tab键，先进行一次首行两字符缩进。</li>
<li>再使用<code>Ctrl + [</code>
取消Typora自动设置的item缩进，即可。</li>
</ul>
<hr>
<h3 id="字体变换">字体变换</h3>
<p>​ Markdown
如何打出：<em>斜体（Italic）</em>，<strong>加粗（Bold）</strong>，<strong><em>斜体加粗（Combined）</em></strong>，<u>下划线</u>，<del>删除线</del>呢？</p>
<ul>
<li><p>斜体使用：<code>*斜体*</code>，输入两个<code>**</code>
在<code>*</code>包括的部分内部内输入需要斜体的文字即可。当然，不管是word，OneNote还是Typora，快捷键都是<code>Ctrl+I</code></p></li>
<li><p>加粗：<code>**加粗**</code>，需要加粗的文字需要左右各两个<code>*</code>。不管是word，OneNote还是Typora，快捷键都是<code>Ctrl+B</code></p></li>
<li><p>斜体加粗：<code>***斜体加粗***</code>，也就是需要加粗的部分左右各3星。不管是word，OneNote还是Typora，快捷键都是<code>Ctrl+I+B</code></p></li>
<li><p>下划线：<font color="blue">这是第一个HTML语法的小栗子，不过很简单</font>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;u&gt;需要下划线的部分&lt;/u&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>&lt;u&gt;</code>表示起始（underline），<code>&lt;/u&gt;</code>前的<code>/</code>表示结束。</li>
<li>不管是word，OneNote还是Typora，快捷键都是<code>Ctrl+U</code></li>
</ul></li>
<li><p>删除线：<code>~~需要删除的部分~~</code>，也就是左右各两个<code>~</code>。Typora中，默认快捷键是：<code>Alt+Shift+5</code>。</p></li>
</ul>
<p>​ 给出一个实际的例子，输入如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">开始：*这是文中需要倾斜的部分*，这是正常的部分，这是**需要加粗的部分**，而这是***综合部分***。下划线可以&lt;u&gt;这么加&lt;/u&gt;，而下划线+加粗可以这样，&lt;u&gt;**虽然Ctrl+B+U快捷键完全可以解决**&lt;/u&gt;。删除线则是~~这样使用的~~。</span><br></pre></td></tr></table></figure>
<p>​ 实际输出如下：</p>
<p>​
开始：<em>这是文中需要倾斜的部分</em>，这是正常的部分，这是<strong>需要加粗的部分</strong>，而这是<strong><em>综合部分</em></strong>。下划线可以<u>这么加</u>，而下划线+加粗可以这样，<u><strong>虽然Ctrl+B+U快捷键完全可以解决</strong></u>。删除线则是<del>这样使用的</del>。</p>
<hr>
<h3 id="标题与分割线">标题与分割线</h3>
<p><span id="caption"></span></p>
<p>​
Markdown中的标题是格式化的。不需要设置大小与格式（不过正常情况下标题是左对齐的）。标题使用
<code>#</code> + 空格来表示。</p>
<p></p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="section"># 一级标题</span></span><br><span class="line"><span class="section">## 二级标题</span></span><br><span class="line"><span class="section">### 三级标题</span></span><br><span class="line"><span class="section">#### 四级标题</span></span><br><span class="line"><span class="section">##### 五级标题</span></span><br></pre></td></tr></table></figure>
<p>​ 输出结果是长这样的：</p>
<p><img src="/2021/02/09/Typora-Markdown-Intros/caption.png"></p>
<center>
Figure 2. 标题样式
</center>
<p>​ 注意，<code>#</code>之后一定要跟上空格，再输入标题内容。</p>
<p>​
分割线：只需要在需要分割的位置，加入<code>---</code>即可进行分割（注意<code>---</code>一定要另起一行，分割线行中只能写这一个内容）。比如文中的分割线，都是<code>---</code>的渲染结果，例子：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Contents I</span><br><span class="line">---</span><br><span class="line">Contents II</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="超链接的两种常见方式">超链接的两种常见方式</h3>
<p>​ HyperLink （超链接）最常见的使用方式就是
<strong><u>网页跳转</u></strong>。当然，markdown中存在另一种页内跳转的方式。假设我们希望读者在读到这段文字的时候，去查看本文其他位置的内容，比如
<a href="#start">【点我查看文章开头】</a>，确实也是可以做到的。</p>
<h4 id="网页跳转">网页跳转</h4>
<p>​
reference编写时，可能我们希望读者可以通过点击直接跳转到某个位置，可以使用以下方式进行编写：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[跳转链接](https://www.baidu.com/)</span><br></pre></td></tr></table></figure>
<p>​
<code>[]</code>内部指定：超链接嵌入在<code>[]</code>包括的文字内部，也就是说，点击此段被包括的部分，可以进行跳转。<code>()</code>内部则是网址了，网址只需要在浏览器上复制后粘贴于此处即可。上述渲染结果如下：</p>
<p>​ <a href="https://www.baidu.com/">跳转链接</a></p>
<h4 id="页内跳转">页内跳转</h4>
<p>​
如果是PDF文件，需要读者可以方便地随着作者的思路走，可以使用如下方式。</p>
<ol type="1">
<li><p>在需要跳转到的位置插入：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;span id=&#x27;name&#x27;&gt;</span><br><span class="line">需要跳转的位置，比如上个&quot;超链接的两种常见方式&quot;开头部分跳转到文章开头，则将此块插入到文章开头</span><br><span class="line">&lt;/span&gt;</span><br><span class="line">例如：</span><br><span class="line">&lt;span id=&#x27;start&#x27;&gt;</span><br><span class="line">	此文撰写的目的是：</span><br><span class="line">- 归纳Typora（Markdown编辑器） 的基本使用（常用的都能找到）</span><br><span class="line">- 给我Raven的安利。</span><br><span class="line">&lt;/span&gt;</span><br></pre></td></tr></table></figure>
<p>​ 需要说明的是，id='name'
在这里设置了一个标签，name是标签的名字。比如一篇文章内部可能有很多跳转，为了不混淆目的地，需要标记不同的目的地的名称。比如开头标记为<code>span id='start'</code>，而结尾标记为<code>span id='ending'</code>。此后就根据标记跳转到需要的地方。</p></li>
<li><p>在开始跳转位置处写：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[点我跳转](#name)</span><br></pre></td></tr></table></figure>
<p>​
由于作者在文章开头处设置了一个跳转目的地，写的是<code>&lt;span id='start'&gt;</code>，也就是目的地被称为了<code>start</code>，上面这个例子的name
如果设置成start，则结果是这样的：</p>
<p>​ <a href="#start">点我跳转</a>。当然一般为了美观，可以在<code>[]</code>内再加上一个<code>[]</code>，就会变成<a href="#name">[点我跳转]</a>。注意在<code>()</code>内，需要一个<code>#</code>，此处不表示一级标题。</p></li>
<li><p>查看结果。</p></li>
</ol>
<hr>
<h3 id="图片与表格插入">图片与表格插入</h3>
<h4 id="图片插入">图片插入</h4>
<p>​ Markdown的图片插入语法如下图所示：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">![<span class="string">文章中给图片起的别名</span>](<span class="link">图片所在位置</span>)</span><br></pre></td></tr></table></figure>
<p>​
<code>[]</code>中的内容可以不填写，但是图片位置必须要指定。在Typora中，有两种方式可以快速插入图片：(1)
右键-&gt;插入-&gt;图片。(2) 快捷键<code>Ctrl+Shift+I</code>。</p>
<table>
<colgroup>
<col style="width: 21%">
<col style="width: 78%">
</colgroup>
<thead>
<tr>
<th><img src="/2021/02/09/Typora-Markdown-Intros/insert1.JPG"></th>
<th>可以点击文件夹图标进行图片插入</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="/2021/02/09/Typora-Markdown-Intros/insert2.JPG"></td>
<td>也可以手动输入，默认是绝对路径（就是要输入从盘位置开始的路径）</td>
</tr>
</tbody>
</table>
<p>​
注意，与word不同：word插入图片后，修改文件夹中的图片，不会对已经在文章里的内容产生影响（比如更改大小
/
删除等等，文中的图片保持不变），因为word中的图片是一份copy。而Markdown中的图片，只是原图片的<strong><u>链接</u></strong>，任何对源文件的修改都将影响文中的图片。其好处是：更改图片的细节很容易，无需重新插入。但是，在完成文章，输出成pdf前一定要确保对应名字的图片能够被找到。</p>
<p>​
<code>()</code>中，除了可以填写本地图片（插入本地图片），也可以插入网络上的图片。浏览器一般会提供<strong>复制图片链接</strong>选项，只需要将链接填写在<code>()中即可</code>。比如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">![起子](https://bkimg.cdn.bcebos.com/pic/bba1cd11728b4710dac3926bc9cec3fdfd0323ac?x-bce-process=image/watermark,image_d2F0ZXIvYmFpa2U4MA==,g_7,xp_5,yp_5/format,f_auto)</span><br></pre></td></tr></table></figure>
<p>​ 输出结果如下：</p>
<p><img src="https://bkimg.cdn.bcebos.com/pic/bba1cd11728b4710dac3926bc9cec3fdfd0323ac?x-bce-process=image/watermark,image_d2F0ZXIvYmFpa2U4MA==,g_7,xp_5,yp_5/format,f_auto" alt="起子" style="zoom:50%;"></p>
<center>
Figure 3. 起子的百度百科上复制的图片
</center>
<p>​
Typora提供了图片大小缩放的快捷选项，只需要对插入的图片按右键，找到<code>【缩放图片到】</code>即可。缩放后，图片的源码栏
<strong><u>不再是markdown语法</u></strong>，而变成了
<strong><u>HTML语法</u></strong>，因为原生markdown不支持缩放，但是与使用者无关，其插入路径还是可以随意更改，这个特性对本地图片也是适用的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;img src=&quot;https://bkimg.cdn.bcebos.com/pic/bba1cd11728b4710dac3926bc9cec3fdfd0323ac?x-bce-process=image/watermark,image_d2F0ZXIvYmFpa2U4MA==,g_7,xp_5,yp_5/format,f_auto&quot; alt=&quot;起子&quot; style=&quot;zoom:50%;&quot; /&gt;</span><br></pre></td></tr></table></figure>
<p>​
注意到上述代码中有一项：<code>style="zoom:50%;"</code>，表明缩放的大小。Typora只提供了默认的几个缩放等级，如果要更灵活的缩放可以直接更改<code>50%</code>为其他数值。</p>
<h4 id="表格插入">表格插入</h4>
<p>​
原生Markdown支持表格，但是表格的输入有点麻烦（Typora提供了更快捷的插入方式），可以先看原生语法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">|姓名|班级|学号|成绩|</span><br><span class="line">|:-|:-:|-:|:-:|</span><br><span class="line">|A|1|001|59|</span><br><span class="line">|B|1|002|58|</span><br><span class="line">|C|1|003|57|</span><br></pre></td></tr></table></figure>
<p>​ 输出的结果如图（Pixyll主题下的图表，最美观的那种）：</p>
<p><img src="/2021/02/09/Typora-Markdown-Intros/table.png"></p>
<center>
Figure 4. Typora Pixyll主题表格
</center>
<p>​ 注意到其中有些奇怪的东西：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">|:-|:-:|-:|:-:|</span><br></pre></td></tr></table></figure>
<p>​
这是什么？此处表示图表的对齐方式：<code>:-</code>冒号在左边表示左对齐。<code>:-:</code>两边有冒号表示居中，<code>-:</code>右边冒号表示右对齐。原生语法下，不写对齐方式是不会渲染表格的，出来的就是这一堆神秘代码。</p>
<p>​ Typora右键可以插入表格，在插入的表格左上方可以选择对齐方式 /
表格size（列 *
行）。但是表格的大小（每个cell的长宽）根据所在列和行的内容自动调整。注意，表格内也可以使用markdown
/ HTML / LaTex语法。</p>
<hr>
<h3 id="todos与引用">TODOs与引用</h3>
<p>​ 代办项 / 引用 是markdown提供的另外两种输出样式：如图所示</p>
<p><img src="/2021/02/09/Typora-Markdown-Intros/todos.png"></p>
<center>
Figure 5. 引用与待办项输出示例
</center>
<h4 id="引用">引用</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; 一级引用</span><br><span class="line">&gt;&gt; 二级引用</span><br><span class="line">&gt;&gt;&gt; 三级引用</span><br></pre></td></tr></table></figure>
<p>​ 注意&gt;号后面要加空格。引用可以一直套娃下去。</p>
<p>​
有的时候可能卡在引用语法里出不来（输入不了正常的文字，换行之后仍然是引用区内），只需要使用<code>Ctrl+[</code>减少缩进即可退出引用。</p>
<h4 id="todos">TODOs</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- [x] 14:00-16:00</span><br><span class="line">- [ ] 16:00-18:00</span><br></pre></td></tr></table></figure>
<p>​
注意：首先是<code>-</code>号，<strong>空格</strong>后，再输入<code>[ ]</code>（中有空格），再空格输入文字。其中输入有x的表明已经完成的，原生markdown中需要输入x，但Typora中可以直接点击，自动输入x。</p>
<hr>
<h3 id="代码片段与代码块">代码片段与代码块</h3>
<p>​
一般会给程序员使用，比如要强调一块代码的时候。Markdown是可以根据选择的语言进行语法高亮(Syntax
Highlights) 以及自动标注行号的，以下是C++代码的一个实例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>** argv)</span></span>&#123;</span><br><span class="line">	std::cout &lt;&lt; <span class="string">&quot;Hello Markdown!\n&quot;</span>;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
实际上，所有需要强调的非文章内容都可以放在代码块中。原生markdown语法是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">```</span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line">...</span><br><span class="line">​```</span><br></pre></td></tr></table></figure>
<p>​
需要指定语言时，Typora在代码块右下角可以输入语言（点击代码块后右下角会出现），原生语法是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">```语言名称</span><br><span class="line"></span><br><span class="line">​```</span><br><span class="line">例如</span><br><span class="line">​```python</span><br><span class="line">print(&quot;Hello markdown.&quot;)</span><br><span class="line">​```</span><br></pre></td></tr></table></figure>
<p>​
如果不需要整段的代码，而是需要强调某些小部分的话，可以使用“`”符号。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">插入图片的快捷键是`Ctrl+Shift+I`</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="emoji">Emoji</h3>
<p>​
这个好像是Typora提供的（原生markdown好像也有，但是emoji的名称要去记，很不方便）。比如我要输入一个微笑：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">:smile:</span><br></pre></td></tr></table></figure>
<p>​
微笑将会按照上面的语法显示出来：:smile:。对Typora而言，输入英文冒号后，随便输入一个字母都可能有对应的emoji，比如：</p>
<p><img src="/2021/02/09/Typora-Markdown-Intros/emoji.png"></p>
<center>
Figure 6. Markdown自带的emoji
</center>
<hr>
<h3 id="typora的一些设置与功能">Typora的一些设置与功能</h3>
<p><span id="setting"></span></p>
<p>​
Typora个性化设置可以帮助用户更好地使用其携带的一些功能：右上角<code>[文件]</code>-&gt;<code>[偏好设置]</code>-&gt;<code>[Markdown]</code>中（markdown设置更为常用）：</p>
<p></p>
<p><img src="/2021/02/09/Typora-Markdown-Intros/setting1.png"></p>
<center>
Figure 7. 常用设置1
</center>
<p><img src="/2021/02/09/Typora-Markdown-Intros/setting2.png"></p>
<center>
Figure 8. 常用设置2
</center>
<p>​ 在Typora中还有两种模式可以设置：</p>
<ul>
<li>打字机模式（页面自动定位到当前行所在位置，无需滚轮滚动）（可以自己试试看：快捷键<code>F8</code>）</li>
<li>专注模式（其他内容的可见性会变低（加雾），当前书写内容正常显示）（可以自己试试看：快捷键<code>F9</code>）
<ul>
<li>左上角：视图中可以进行设置</li>
</ul></li>
</ul>
<h4 id="目录组织">目录组织</h4>
<p>​ 如果需要快速建立目录，可以直接在文章开头输入:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[toc]</span><br></pre></td></tr></table></figure>
<p>​ 表示（table of contents），这个目录的建立是根据<a href="#caption">【标题与分割线】</a>中的标题级数来组织的。目录可以用在：</p>
<ul>
<li>实验报告 / 长文 中</li>
<li>并且，生成pdf时，会自动插入书签（每个标题都会有书签，书签下根据标题级数还会有子书签）</li>
</ul>
<hr>
<h2 id="level-2-skills">Level 2 Skills</h2>
<p>​ 此部分内容较为进阶，但是如1 /
3节而言，对于大多数人来说都很实用（第三节难记），包括：</p>
<ul>
<li>实用的HTML命令（简单可复制）</li>
<li>LaTex数学公式输入</li>
<li>mermaid（块状流程图） / flow（标准流程图） /
gantt（甘特图）绘制</li>
</ul>
<hr>
<h3 id="实用html命令">实用HTML命令</h3>
<blockquote>
<p><em>HTML</em>称为超文本标记语言，是一种标记语言。它包括一系列标签．通过这些标签可以将网络上的文档格式统一，使分散的Internet资源连接为一个逻辑整体。<a href="https://baike.baidu.com/item/HTML/97049?fr=aladdin">HTML
百度百科</a></p>
</blockquote>
<p>​
本文不教HTML怎么写（不是本文的目的），并且HTML也不像原生markdown那么简洁，但是有些非常实用的编辑命令不得不提。</p>
<h4 id="文字的居中与修改">文字的居中与修改</h4>
<p>​
原生markdown貌似不支持直接居中，作为使用者，我也不可能直接就用空格手动居中了。居中
/ 字体调整等方面相对麻烦（虽然无需鼠标点击）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;center&gt;需要居中的部分&lt;/center&gt;</span><br></pre></td></tr></table></figure>
<p>​ 显示的结果是：</p>
<center>
需要居中的部分
</center>
<p>​ 而字体大小 / 颜色 /
字型调整，需要应用<code>&lt;font&gt;</code>语法：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">font</span> <span class="attr">size</span>=<span class="string">3</span> <span class="attr">color</span>=<span class="string">&#x27;blue&#x27;</span> <span class="attr">face</span>=<span class="string">&#x27;黑体&#x27;</span>&gt;</span>黑体，size=3的蓝色字<span class="tag">&lt;/<span class="name">font</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">font</span> <span class="attr">size</span>=<span class="string">4</span> <span class="attr">color</span>=<span class="string">&#x27;red&#x27;</span> <span class="attr">face</span>=<span class="string">&#x27;微软雅黑&#x27;</span>&gt;</span>微黑，size=4的红色字<span class="tag">&lt;/<span class="name">font</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">font</span> <span class="attr">size</span>=<span class="string">5</span> <span class="attr">color</span>=<span class="string">&#x27;green&#x27;</span> <span class="attr">face</span>=<span class="string">&#x27;Arial&#x27;</span>&gt;</span> Arial字体，size=5的绿色字<span class="tag">&lt;/<span class="name">font</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><font size="3" color="blue" face="黑体">黑体，size=3的蓝色字</font>
<font size="4" color="red" face="微软雅黑">微黑，size=4的红色字</font>
<font size="5" color="green" face="Arial">
Arial字体，size=5的绿色字</font></p>
<p>​ 多重特性叠加也是可以的：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;center&gt;&lt;font size=3 color=&#x27;blue&#x27; face=&#x27;黑体&#x27;&gt;居中黑体size3蓝色字/font&gt;&lt;/center&gt;</span><br></pre></td></tr></table></figure>
<center>
<font size="3" color="blue" face="黑体">居中黑体size3蓝色字/font&gt;
</font></center>
<hr>
<h4 id="分页-高级表格">分页 / 高级表格</h4>
<p>​
假如我们希望某处文字后，另起一页，直接打换行太不方便了（并且markdown中没有页数这个概念，转为pdf后才能看到分页效果）。可以复制以下代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;div style=&quot;page-break-after: always;&quot;&gt;&lt;/div&gt;</span><br></pre></td></tr></table></figure>
<p>​ 表示此处之后，进行新加一页的操作。通常用于：abstract与下文的分割 /
目录与下文的分割 / 正文与reference的分割。</p>
<p>​
<strong><u>高级表格</u></strong>：原生markdown不支持单元格合并，需要使用HTML的<code>&lt;table&gt;</code>标签才能得到扩展。具体方法十分复杂，不作为重点，只是提一下，有兴趣者参看：</p>
<ul>
<li><a href="https://www.runoob.com/html/html-tables.html">【HTML 表格 |
菜鸟教程🔗】</a></li>
<li><a href="https://blog.csdn.net/lhrdlp/article/details/100861546">【CSDN
HTML表格 单元格合并🔗】</a></li>
</ul>
<hr>
<h4 id="之前讲过的html">之前讲过的HTML</h4>
<ul>
<li><code>&lt;u&gt;...&lt;/u&gt;</code> 下划线语法</li>
<li><code>&lt;span id='name'&gt;...&lt;/span&gt;</code>，设置跳转位置标记语法</li>
</ul>
<hr>
<h3 id="latex-数学公式渲染">LaTex 数学公式渲染</h3>
<p>​ 什么是<a href="https://baike.baidu.com/item/LaTeX/1212106?fr=aladdin">[<span class="math inline">\(\LaTeX\)</span>百度百科🔗]</a>，<a href="(https://www.latex-project.org/)">[<span class="math inline">\(\LaTeX\)</span>官网]</a></p>
<p>​ 原生的markdown不支持（Github上的readme就不直接支持<span class="math inline">\(\LaTeX\)</span>语法），但是Typora支持。有数学公式输入需要的朋友可以使用内置的功能。注意可能需要在设置中打开LaTex支持，详见<a href="#setting">【Typora的一些设置与功能】</a>。</p>
<h4 id="内联公式">内联公式</h4>
<p>​ 就是行内嵌入公式，比如：<span class="math inline">\(P(x|y)=\frac{P(x,y)}{P(y)}\)</span>或是：<span class="math inline">\(f:D \subset \mathbb R^n\rightarrow \mathbb
R\)</span>。只需要使用：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">比如：$P(x|y)=\frac&#123;P(x,y)&#125;&#123;P(y)&#125;$</span><br></pre></td></tr></table></figure>
<p>​ 也就是LaTex语法是被$符号（左右各一个）包围的。</p>
<h4 id="公式块">公式块</h4>
<p><span class="math display">\[
2D_{JS}(P_R|P_G)=\int_xP_R(x)log(\frac{P_R(x)}{\frac{P_R(x) +
P_G(x)}{2}})dx + \int_xP_G(x) log(\frac{P_G(x)}{\frac{P_R(x) +
P_G(x)}{2}})dx
\]</span></p>
<p>​
还没有接触过LaTex的朋友，就不指望你立马写出以上的公式来了。上面公式的代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$$</span><br><span class="line">2D_&#123;JS&#125;(P_R|P_G)=\int_xP_R(x)log(\frac&#123;P_R(x)&#125;&#123;\frac&#123;P_R(x) + P_G(x)&#125;&#123;2&#125;&#125;)dx + \int_xP_G(x) log(\frac&#123;P_G(x)&#125;&#123;\frac&#123;P_R(x) + P_G(x)&#125;&#123;2&#125;&#125;)dx</span><br><span class="line">$$</span><br></pre></td></tr></table></figure>
<p>​ 重点就是开头和结尾插入两个<code>$$</code>。</p>
<h4 id="常用latex语法">常用<span class="math inline">\(\LaTeX\)</span>语法</h4>
<p><img src="/2021/02/09/Typora-Markdown-Intros/latex1.png"></p>
<center>
Figure 9. LaTex常用语法
</center>
<p>​
公式块语法（多行公式，<strong><u>左对齐</u></strong>，每个公式<strong><u>独立标号</u></strong>）</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;align&#125;</span><br><span class="line"><span class="built_in">&amp;</span> x = a + b 	<span class="keyword">\\</span> <span class="comment">% \\为换行</span></span><br><span class="line"><span class="built_in">&amp;</span> x = c + d</span><br><span class="line"><span class="keyword">\end</span>&#123;align&#125;</span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
\begin{align}
&amp; x = a + b     \\ % \\为换行
&amp; x = c + d
\end{align}
\]</span></p>
<p>​ 多行公式，所有公式标号只有一个:</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;equation&#125;</span><br><span class="line">x = a + b 	<span class="keyword">\\</span> <span class="comment">% \\为换行</span></span><br><span class="line">x = c + d</span><br><span class="line"><span class="keyword">\end</span>&#123;equation&#125;</span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
\begin{equation}
x = a + b   \\ % \\为换行
x = c + d
\end{equation}
\]</span></p>
<p>​ 其他的语法可以见上一篇博文<a href="https://enigmatisms.github.io/2021/02/05/LaTex%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E8%AE%B0%E5%BD%95/">[LaTex基础语法记录]</a>。有些语法支持（比如矩阵
/ 大花括号 / 公式lable添加），有些不支持（图片操作 / 分节）</p>
<hr>
<h3 id="mermaid-flow-gantt">Mermaid / Flow / Gantt</h3>
<p>​
这三种是常见的图表（块状逻辑图）（流程图）（甘特图（多用于项目管理）），这些图表都是基于三个“`”符号的代码块：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">```mermaid</span><br><span class="line">...</span><br><span class="line">​```</span><br><span class="line"></span><br><span class="line">​```flow</span><br><span class="line">...</span><br><span class="line">​```</span><br><span class="line"></span><br><span class="line">​```gantt</span><br><span class="line">...</span><br><span class="line">​```</span><br></pre></td></tr></table></figure>
<h4 id="mermaid">Mermaid</h4>
<p>​ 只提供简单的示例：mermaid图表通常的输出如下：</p>
<p><img src="/2021/02/09/Typora-Markdown-Intros/mermaid2.png"></p>
<center>
Figure 10. TB与LR两种空间排布的输出
</center>
<p>​
左图是上下式排列（<code>graph TB</code>）右图是左右式排列（<code>graph LR</code>）。</p>
<p>​ mermaid图提供了几种
<strong>【线型】</strong>，【<strong>框型</strong>】。比如：</p>
<ul>
<li>细直线（无向<code>---</code>），细箭头（有向<code>--&gt;</code>），粗直线（<code>===</code>），粗箭头（<code>==&gt;</code>）</li>
<li>直角框（A[内容]），圆角框（ A(内容) ），圆形框（ A((内容))
），如下代码所示。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph LR</span><br><span class="line">A((A))--&gt;B[B]</span><br><span class="line">B--&gt;C((C))</span><br><span class="line">B---D(D)</span><br><span class="line">C===E(E)</span><br><span class="line">D==&gt;E((E))</span><br></pre></td></tr></table></figure>
<p>​ 输出的结果为：</p>
<p><img src="/2021/02/09/Typora-Markdown-Intros/mermaid3.png"></p>
<center>
Figure 11. 不同线型与框型的输出
</center>
<h4 id="flow流程图">Flow流程图</h4>
<p>​ 流程图中有五个主要结构：其书写如表所示：</p>
<table>
<thead>
<tr>
<th>结构</th>
<th>书写方式</th>
</tr>
</thead>
<tbody>
<tr>
<td>开始框（圆角框）</td>
<td>start</td>
</tr>
<tr>
<td>输入输出框（平行四边形）</td>
<td>inputoutput</td>
</tr>
<tr>
<td>流程框（直角框）</td>
<td>operation</td>
</tr>
<tr>
<td>条件判定（菱形框）</td>
<td>condition</td>
</tr>
<tr>
<td>结束框（圆角框）</td>
<td>end</td>
</tr>
</tbody>
</table>
<p>​ 一个书写示例如下图所示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">start=&gt;start: Program starts</span><br><span class="line">input=&gt;inputoutput: Input</span><br><span class="line">operation=&gt;operation: System checking</span><br><span class="line">condition=&gt;condition: System failed?</span><br><span class="line">output=&gt;inputoutput: Output</span><br><span class="line">error=&gt;operation: Error</span><br><span class="line">end=&gt;end: Shutdown</span><br><span class="line"></span><br><span class="line">start(right)-&gt;input</span><br><span class="line">input(right)-&gt;operation</span><br><span class="line">operation(right)-&gt;condition</span><br><span class="line">condition(no,right)-&gt;output</span><br><span class="line">condition(yes,bottom)-&gt;error(right)-&gt;output</span><br><span class="line">output(right)-&gt;end</span><br></pre></td></tr></table></figure>
<p>​
对于<code>=&gt;</code>左边的部分，其实是每个框的名称，比如定义一个operation框叫做error。<code>=&gt;</code>右边则是框类型。上半部分中，所有的框被定义了，包括其类型以及内容（类型后冒号
+ 空格
输入内容），下半部分则是其中的流程转换关系（<code>-&gt;</code>表示
flow的方向）</p>
<p>​ 注意 condition可多分支，所以会有(no) / (yes)标签，其他的(right /
bottom)都指的是箭头的空间方向。事实上，flow只能画一些简单的流程图，复杂的流程图中各个框的位置极其难编排。输出结果如下：</p>
<p><img src="/2021/02/09/Typora-Markdown-Intros/flow.JPG"></p>
<center>
Figure 12. flow流程图输出的结果
</center>
<h4 id="gantt时间图">Gantt时间图</h4>
<p>​ 给一个例子吧，from <a href="https://blog.csdn.net/zyxhangiian123456789/article/details/102479437">[CSDN
Gantt Graph]</a>。个人其实没有使用在这个的需求。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gantt</span><br><span class="line">dateformat YYYY-MM-DD</span><br><span class="line">Title The expected refining schedule</span><br><span class="line">section DS1</span><br><span class="line">Oil 3 (25,000): done, 0h, 100h</span><br><span class="line">Oil 4 (24,000): crit, 96h</span><br><span class="line">Oil 8 (24,000): crit, 176h</span><br><span class="line">section DS2</span><br><span class="line">Oil 1 (16,000): done, 0h, 48h</span><br><span class="line">Oil 2 (26,000): done, 78h</span><br><span class="line">oil 11 (82,300): crit, 246h</span><br><span class="line">section DS3</span><br><span class="line">Oil 5 (15,000): done, 0h, 60h</span><br><span class="line">Oil 4 (17,000): done, 68h</span><br><span class="line">oil 6 (18,000): done, 72h</span><br><span class="line">oil 10 (43,055): crit, 172h</span><br><span class="line">section DS4</span><br><span class="line">Oil 7 (22,000): done, 0h, 35h</span><br><span class="line">Oil 8 (103,000): active, 165h</span><br><span class="line">oil 9 (107,638): crit, 172h</span><br></pre></td></tr></table></figure>
<p><img src="/2021/02/09/Typora-Markdown-Intros/gantt.JPG"></p>
<center>
Figure 13. Gantt图绘制结果
</center>
<hr>
<h2 id="实践练习">实践练习！</h2>
<ul>
<li>一句话：尝试-&gt;熟练 就能发现word / WPS 有多难以使用。</li>
<li>读者可以尝试使用Markdown写一份笔记。要求包含：
<ul>
<li>封面的设计（比如居中 / 强制分页 / 字体变换 / 图片插入）</li>
<li>目录（toc插入 / 强制分页）</li>
<li>正文（标题 / 强调 / 分点 / 超链接 / 引用 / 表格 / 代码块(optional) /
LaTeX(optional) ）</li>
</ul></li>
</ul>
<center>
<font size="5"> Amat Victoria Curam. 2021.2.10</font>
</center>
<p>​</p>
]]></content>
      <categories>
        <category>tutorial</category>
      </categories>
      <tags>
        <tag>typesetting</tag>
      </tags>
  </entry>
  <entry>
    <title>LaTex基础语法记录</title>
    <url>/2021/02/05/LaTex%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<h1 id="latex基础语法记录"><span class="math inline">\(\LaTeX{}\)</span>基础语法记录</h1>
<hr>
<h2 id="一些关键词">一些关键词</h2>
<p><strong><code>\lipsum</code></strong></p>
<p>​
<code>\lipsum</code>是宏包<code>&#123;lipsum&#125;</code>中的命令，用于生成随机的文本。一般用于模板的演示。</p>
<p>​ 对于宏包而言，可以使用<code>\usepackage</code>调用</p>
<p><strong>倾斜与加粗</strong></p>
<p>​
<code>\emph&#123;% text %&#125;</code>是将text变为斜体，但是<code>\emph&#123;&#125;</code>适合单行，<code>\em ... \em</code>回对两个成对的<code>\em</code>之间的所有字体（包括标题）进行斜体化。</p>
<p>​ <code>\textbf</code>是 文字粗体（text bold font）<span class="math inline">\(\textbf{Like: Test}\)</span> &lt;-&gt; <span class="math inline">\(\text{Like: test}\)</span>。</p>
<p>​ <code>\mathbf</code> 是tex中的数学粗体，<span class="math inline">\(\text{vector }\mathbf{a,b,A}\)</span></p>
<p>​ <code>\pmb</code> 是粗斜体：<span class="math inline">\(\pmb{b}=\pmb{Ax}\)</span></p>
<p><strong>其他常用操作</strong></p>
<p>（1）字体大小更换 (定性) <span class="math display">\[
\begin{align}
&amp;\tiny \text{\tiny font for the things I have written. 1234567890}\\
&amp;\scriptsize  \text{\scriptsize font for the things I have written.
1234567890}\\
&amp;\small \text{\small font for the things I have written.
1234567890}\\
&amp;\normalsize  \text{\normalsize font for the things I have written.
1234567890}\\
&amp;\large \text{\large font for the things I have written.
1234567890}\\
&amp;\Large \text{\Large font for the things I have written.
1234567890}\\
&amp;\LARGE \text{\LARGE font for the things I have written.
1234567890}\\
&amp;\huge \text{\huge font. 1234567890}\\
&amp;\Huge \text{\Huge font. 1234567890}\\
\end{align}
\]</span> ​ 使用一些常用的大小描述词即可。</p>
<p>（2）字体大小更换（定量）</p>
<p>​
<code>\fontsize</code>是可以调整字体大小的，但貌似不是很好用。对于公式<code>\begin&#123;align&#125;</code>以及<code>\emph</code>中的字体大小可以进行更改，但是对于<code>\text</code>内部的字体，无法很好地修改。</p>
<p>（3）字体切换： <span class="math display">\[
\begin{align}
\sf {\text{That is the most wonderful thing I know. \sf} } \\
\tt {\text{That is the most wonderful thing I know. \tt}} \\
\rm {\text{That is the most wonderful thing I know. \rm}}
\end{align}
\]</span> ​ <code>\sf</code>
为sans-serif字体集合，<code>\tt</code>为typewriter字体，<code>\rm</code>为罗马字体集。</p>
<p>（4）矩阵的书写</p>
<ul>
<li><code>matrix</code>: 无框matrix</li>
<li><code>pmatrix</code>: 圆括号matrix</li>
<li><code>vmatrix</code>: 行列式matrix</li>
<li><code>bmatrix</code>与<code>Bmatrix</code>:
中括号matrix与大括号matrix</li>
</ul>
<p><span class="math display">\[
\begin{pmatrix}\label{mats}
1,0,0\\
0,1,0\\
0,0,1
\end{pmatrix},
\begin{pmatrix}
1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 1
\end{pmatrix},
\begin{matrix}
1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 1
\end{matrix},
\begin{bmatrix}
1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 1
\end{bmatrix},
\begin{vmatrix}
1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 1
\end{vmatrix},
\begin{Bmatrix}
1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 1
\end{Bmatrix}
\]</span></p>
<p>（5）其他常用命令</p>
<table>
<colgroup>
<col style="width: 20%">
<col style="width: 29%">
<col style="width: 50%">
</colgroup>
<thead>
<tr>
<th>命令</th>
<th>作用</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>\newpage</code></td>
<td>直接换页（相当于html的 div always）</td>
<td>markdown不支持</td>
</tr>
<tr>
<td><code>\item</code></td>
<td>分点，加小圆点</td>
<td><code>\begin&#123;itemize&#125; \item ... \item ...  \end&#123;itemize&#125;</code></td>
</tr>
<tr>
<td><code>\section&#123;name&#125;</code></td>
<td>一级标题（1. ）</td>
<td><code>\section&#123;Header&#125;</code></td>
</tr>
<tr>
<td><code>\subsection&#123;name&#125;</code></td>
<td>二级标题（1.1.）</td>
<td><code>\subsection&#123;Header&#125;</code></td>
</tr>
<tr>
<td><code>\subsubsection&#123;n&#125;</code></td>
<td>三级标题（1.1.1.）</td>
<td><code>\subsubsection&#123;Header&#125;</code></td>
</tr>
<tr>
<td><code>\begin&#123;Lemma&#125;</code></td>
<td>引理开始</td>
<td><code>\begin&#123;Lemma&#125; \label&#123;name&#125;... \end&#123;Lemma&#125;</code></td>
</tr>
<tr>
<td><code>\begin&#123;Theorem&#125;</code></td>
<td>定理开始</td>
<td><code>\begin&#123;Theorem&#125; \label&#123;name&#125;... \end&#123;Theorem&#125;</code></td>
</tr>
<tr>
<td><code>\eqref</code></td>
<td>公式引用，相当于设置内部链接</td>
<td><span class="math inline">\(\eqref{mats}\)</span>，<code>\eqref&#123;mats&#125;</code></td>
</tr>
<tr>
<td><code>\ref</code></td>
<td>非公式引用</td>
<td><span class="math inline">\(\ref{mats}\)</span>，<code>\ref&#123;mats&#125;</code></td>
</tr>
<tr>
<td><code>\url</code></td>
<td>链接</td>
<td><code>\url&#123;http://www.latexstudio.net/&#125;</code></td>
</tr>
<tr>
<td><code>\eqno</code></td>
<td>在非编号模式下，可以进行编号</td>
<td><code>\eqno&#123;(1)&#125;</code>，<code>\eqno</code>可以无视原有的标号，并且支持字符串</td>
</tr>
<tr>
<td><code>\vspace&#123;&#125;</code></td>
<td>插入竖直方向的空行</td>
<td>比如<code>\vspace&#123;\parskip&#125;</code>，跳过的距离相当于两个段落之间的距离</td>
</tr>
<tr>
<td><code>\textcolor[rgb]&#123;r,g,b&#125;</code></td>
<td>修改字体颜色</td>
<td><span class="math inline">\(\textcolor[rgb]{0,0,1}{1,2,3}\)</span>.<code>$\textcolor[rgb]&#123;0,0,1&#125;&#123;1,2,3&#125;$</code></td>
</tr>
</tbody>
</table>
<ul>
<li>对于引用而言，提到公式就需要进行<code>\eqref</code>，其他的如见figure
x，也需要用到<code>\ref</code></li>
</ul>
<hr>
<h2 id="图片操作">图片操作</h2>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;figure&#125;[h]		<span class="comment">% 如果没有[h] LaTex可能会自动排版</span></span><br><span class="line"><span class="keyword">\centering</span>				<span class="comment">% 一般都是需要居中的</span></span><br><span class="line"><span class="keyword">\includegrahics</span>[width=xxcm]&#123;name<span class="built_in">_</span>of<span class="built_in">_</span>the<span class="built_in">_</span>pic.jpg&#125;</span><br><span class="line"><span class="keyword">\caption</span>&#123;test the fig&#125; <span class="keyword">\label</span>&#123;fig:test1&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;figure&#125;</span><br></pre></td></tr></table></figure>
<p>​ 按照以上语法可以插入一张图片，并且，对于第三行的include
graphics，会按照宽度自动横向，竖向编排。如果需要多图，可以多个<code>\includegraphics</code>，当然也可以使用子图：主要是minipage的使用与subfigure</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="comment">% latex 竖排操作</span></span><br><span class="line"><span class="keyword">\begin</span>&#123;figure&#125;[h]</span><br><span class="line"><span class="keyword">\centering</span></span><br><span class="line"><span class="keyword">\subfigure</span>[line1]&#123;</span><br><span class="line"><span class="keyword">\begin</span>&#123;minipage&#125;[b]&#123;0.23<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;minipage&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">\subfigure</span>[line2]&#123;</span><br><span class="line"><span class="keyword">\begin</span>&#123;minipage&#125;[b]&#123;0.23<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;minipage&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">\subfigure</span>[line3]&#123;</span><br><span class="line"><span class="keyword">\begin</span>&#123;minipage&#125;[b]&#123;0.23<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;minipage&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">\subfigure</span>[line4]&#123;</span><br><span class="line"><span class="keyword">\begin</span>&#123;minipage&#125;[b]&#123;0.23<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;minipage&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">\caption</span>&#123;multiple dogs&#125; <span class="keyword">\label</span>&#123;fig:dogs&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;figure&#125;</span><br></pre></td></tr></table></figure>
<p>显示的结果如下：</p>
<p><img src="/2021/02/05/LaTex%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E8%AE%B0%E5%BD%95/dogs.JPG"></p>
<h3 id="相关代码理解">相关代码理解</h3>
<p>​ <code>\subfigure[name]&#123;&#125;</code>
花括号内的内容与普通的<code>\begin&#123;figure&#125;[xxx]</code>内部的内容极其相似，甚至可以一样。比如说我不需要多图（上述代码是4*4
多图显示的情况），我只需要每列一张图片，那么minipage完全不需要使用（<code>\minipage</code>相当于将页面分割为更小的页面）。只需按照如下方式书写即可：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\subfigure</span>[name]&#123;</span><br><span class="line">	<span class="keyword">\includegraphics</span>[width=xxxcm]&#123;name.jpg&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​
对于<code>\minipage</code>的设置，<code>\begin&#123;minipage&#125;[b]&#123;0.23\linewidth&#125;</code>其中<code>[b]</code>可能与位置设置有关，只要所有minipage的设置一致就不会出现图片错位的问题。而<code>&#123;0.23\linewidth&#125;</code>表示的是当前的【正文的，原page的】linewidth（行的宽度（跨度））的0.23倍。也就是设置这个minipage的宽度大小。由于4
* 4，所以设置约1/4，需要留一定余量。</p>
<p>​
而由于在<code>\minipage</code>花括号之内，<code>\linewidth</code>将与定义的minipage一致，那么可以简单地写为：插入图片的宽度就为<code>\linewidth</code>，占满整个minipage行宽即可。</p>
<p>​
图片的插入并非什么困难的问题，主要是图片的排版。排版的话，传统的<code>\begin&#123;figure&#125;[htbp]</code>用处不大，可以考虑：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\usepackage</span>&#123;float&#125;		<span class="comment">% 图片浮动宏包</span></span><br><span class="line"><span class="keyword">\begin</span>&#123;figure&#125;[H]		<span class="comment">% 图片定位在当前位置</span></span><br></pre></td></tr></table></figure>
<p>显示效果如图所示：</p>
<p><img src="/2021/02/05/LaTex%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E8%AE%B0%E5%BD%95/float.JPG"></p>
<hr>
<h2 id="表格的插入">表格的插入</h2>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;table&#125;  </span><br><span class="line"><span class="keyword">\centering</span></span><br><span class="line"><span class="keyword">\caption</span>&#123;table&#125; <span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line"><span class="keyword">\begin</span>&#123;tabular*&#125;&#123;12cm&#125;&#123;cccc&#125;</span><br><span class="line"><span class="keyword">\hline</span><span class="keyword">\vspace</span>&#123;1pt&#125;</span><br><span class="line"><span class="keyword">\textbf</span>&#123;Name&#125; <span class="built_in">&amp;</span> <span class="keyword">\textbf</span>&#123;Gender&#125;  <span class="built_in">&amp;</span> <span class="keyword">\textbf</span>&#123;Current Address&#125; <span class="built_in">&amp;</span> <span class="keyword">\textbf</span>&#123;Score&#125;<span class="keyword">\vspace</span>&#123;1pt&#125;<span class="keyword">\\</span>  </span><br><span class="line"><span class="keyword">\hline</span><span class="keyword">\vspace</span>&#123;1pt&#125;</span><br><span class="line">Tobby  <span class="built_in">&amp;</span> Male <span class="built_in">&amp;</span> 4 Avenue, Chicago, Illinois <span class="built_in">&amp;</span> 99<span class="keyword">\vspace</span>&#123;1pt&#125;<span class="keyword">\\</span>  </span><br><span class="line">Laura  <span class="built_in">&amp;</span> Female <span class="built_in">&amp;</span> unknown town, Atlanta, Georgia <span class="built_in">&amp;</span> 98<span class="keyword">\vspace</span>&#123;1pt&#125;<span class="keyword">\\</span>  </span><br><span class="line"><span class="keyword">\hline</span><span class="keyword">\vspace</span>&#123;1pt&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;tabular*&#125;  </span><br><span class="line"><span class="keyword">\end</span>&#123;table&#125; </span><br></pre></td></tr></table></figure>
<p>输出的结果如下图所示：</p>
<p><img src="/2021/02/05/LaTex%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E8%AE%B0%E5%BD%95/table.JPG"></p>
<h3 id="相关代码理解-1">相关代码理解</h3>
<p><strong>- 为什么要用<code>&#123;tabular\*&#125;</code>?</strong></p>
<p>​
<code>&#123;tabular\*&#125;</code>是可以进行线表宽度调整的，比如表格太小了，希望宽度方向能占更大的空间，需要使用语法：<code>\begin&#123;tabular*&#125;&#123;宽度&#125;[位置]&#123;对齐样式与列数&#125;</code></p>
<p>​
普通的<code>&#123;tabular&#125;</code>只需要：<code>\begin&#123;tabular&#125;[位置]&#123;对齐样式与列数&#125;</code>。这样的表格是根据内容自适应调整大小的。</p>
<p>​
其中<code>&#123;cccc&#125;</code>表示4列，每列都是举中对齐。如果需要左边对齐，使用llll。</p>
<p><strong>- 线表样式</strong></p>
<p>​
<code>\hline</code>表示插入一根横向线，<code>\vline</code>可以在cell元素值内部使用，相当于竖线。</p>
<p>​ <code>\vspace</code>一般用于调整间距，<code>&amp;</code>
用于分割。</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>typesetting</tag>
      </tags>
  </entry>
  <entry>
    <title>GAN原理与实现</title>
    <url>/2021/02/02/GAN%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="gan-生成对抗网络">GAN 生成对抗网络</h1>
<hr>
<h2 id="编码器原理">编码器原理</h2>
<h3 id="自动编码器">自动编码器</h3>
<p>​ 自动编码器，简单地说就是以下结构：</p>
<p><img src="/2021/02/02/GAN%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0/GAN_1.JPG"></p>
<p>​
从原始输入，对其进行编码（编码过程可以使用感知机（前馈，无BP操作）或者神经网络（现在的架构一般是BP式的优化）），生成
<strong><u>压缩后的编码数据</u></strong>。再想办法从编码中（必然存在信息损失）恢复原来的图片。但是一般而言，自动编码器（AE）都是确定输入输出的，每一种编码会由训练得到唯一的输出。</p>
<p>​ 我们希望生成更多的数据或者达到人工智能创作 /
想象的目的，需要随机的输出。我们希望可以加入编码的扰动（Perturbance）或者人工的干预（Intervention），让编码更加多样化
/
随机化，而且Decoder可以对这种加入的噪声鲁棒。这就得到了VAE（Variational
Auto Encoder）变分自动编码器。</p>
<h3 id="变分自动编码器">变分自动编码器</h3>
<p>​
一个想法：首先一个随机的编码器在数学上的表现应该是给定一个向量（比如编码）Z，从Z中恢复X（训练集的分布）。那么就是从<span class="math inline">\(P_Z(x)\)</span>到<span class="math inline">\(P_X(x)\)</span>的映射（编码分布空间到样本空间的映射），得到新的分布<span class="math inline">\(P_{\hat
X}(x)\)</span>。那么根据贝叶斯的想法，可以表示分布<span class="math inline">\(P_X(x)\)</span>为： <span class="math display">\[
\begin{equation}
P_X(x)=\sum_kP(X|Z_k)P(Z_k)\label{YY}
\end{equation}
\]</span> ​ 意思是：不同编码的分布 与 给定编码下，输出数据为对应类型X
两者的条件概率结合。那么数据生成和分布之间的关系又是什么呢?直观地理解一下：</p>
<p>​
世界上有几乎无数种猫，猫产生的后代也不是和其父母一致的。那么我们如果想从数据层面【生成猫】，应该首先知道
<strong>不同表现型的猫的【总体分布】</strong>，如果知道这个分布，显然只需要从这个分布中随机采样就可以得到任意新性状的猫。但是这个分布基本是不可知的，即使存在海量数据我们也没办法得到这个分布的表达式。所以我们希望通过别的方式来近似表达这个分布，比如使用式(1)。</p>
<p>​
假设Z不是编码而是不同的形状，那么可以建立一个性状以及含有对应组合表现型的猫的概率映射，通过贝叶斯全概率公式获得。而把Z换为编码（<strong>更加抽象的形状表示</strong>），也是一样的，编码存在分布（正如不同性状如黑白存在一定分布），而给定编码（给定形状）时也存在其他的分布（Z=公猫，公猫中的白猫
/ 花猫分布等等）。</p>
<p>​ VAE中，<span class="math inline">\(P(Z)\)</span>被建模成了标准正态分布（其他分布也可），原因有以下两点：</p>
<ul>
<li>标准正态分布常见，并且方便进行熵计算（<strong><u>或者说，KL散度计算时不会出现问题（比如均匀分布会存在概率密度为0导致奇异性的现象）</u></strong>）</li>
<li>天然的exp性质，并且表示容易，只需要对<span class="math inline">\(\mu,\sigma\)</span>进行建模表示即可。</li>
</ul>
<hr>
<h2 id="gan原理">GAN原理</h2>
<ul>
<li>GAN需要构建一个生成器和一个判别器，生成器需要生成能够以假乱真的数据。生成出的数据需要输入到判别器中，由判别器进行判定：此数据是真的（非生成的）还是假的（生成的）。<strong><u>固定判别器的参数，训练生成器参数，</u></strong>使得生成器生成的结果输入到判别器中，二分类（真假判定）得到结果尽可能接近1.</li>
<li>判别器的训练：我们希望我们的判别网络尽可能强大，能够区分真假数据，这样再进行生成器训练时，生成器训练会有更加严格的监督。判别器训练时，固定生成器网络参数，生成器生成的数据需要使label尽可能为false。</li>
</ul>
<p><img src="/2021/02/02/GAN%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0/GAN_2.JPG"></p>
<ul>
<li>并且，分类器不仅能正确处理生成器生成的数据（正确地label成false类）（True
Positive），还需要有处理True
Negative的能力，对于真实的数据，需要正确分类为真。</li>
</ul>
<hr>
<h2 id="gan的数学原理">GAN的数学原理</h2>
<h3 id="kl散度">KL散度</h3>
<p>​
需要回忆一下KL散度的定义，KL散度描述的是两个概率分布的相似程度，又称为相对熵。既然是“熵”，那么相对熵就与绝对熵（信息熵）存在关系。信息熵是信息不确定程度的度量。而信息量的度量是：
<span class="math display">\[
I(x_i)=-log(p(x_i))
\]</span> ​
也就是说：事件发生的概率越小，若发生，携带的信息量是越大的。对于一个具有一定不确定度的信息源，一个事件<span class="math inline">\(x_i\)</span>发生的概率若是<span class="math inline">\(P(x_i)\)</span>，那么信息熵为： <span class="math display">\[
H(x_i)=-p(x_i)log(p(x_i))
\]</span> ​
如果信息源发送的“事件”存在n个不同的取值，每个事件的概率为<span class="math inline">\(p(x_i)\)</span>，那么，信息源熵为： <span class="math display">\[
H(U)=-\sum_{i=1}^np(x_i)log(p(x_i))
\]</span> ​
可以看出，信息熵是系统信息量根据概率分布的加权，是一个系统的平均（期望）信息量。</p>
<h3 id="kl散度的由来">KL散度的由来</h3>
<p>​
对于一个字符集（比如26字母，需要进行不等长编码），假设每个字符X出现的概率是<span class="math inline">\(P(x)\)</span>，那么可以知道，一个字符需要编码的字节数（或者位数）会对等于信息量<span class="math inline">\(I(x)\)</span>，那么一个字符集编码的平均字节数等于信息熵<span class="math inline">\(H(U)\)</span>。假设，这个字符集的真实概率分布为<span class="math inline">\(P(x_i)\)</span>，那么其平均编码数为 <span class="math display">\[
H(X)=\sum_{i=1}^n p(x_i)log(\frac{1}{p(x_i)})
\]</span> ​ 由于，<span class="math inline">\(P(x_i)\)</span>是字符集X的真实概率分布，对于X是最优的（对应的编码方式是最优的）。如果需要以这种编码方式对字符集Y（对应的概率分布为<span class="math inline">\(Q(x_i)\)</span>）进行编码，编码平均字节数必然是更多的（因为不是最优的），那么这种编码下存在的差异是：
<span class="math display">\[
D_{KL}(P||Q)=\sum P(x)log(\frac{1}{Q(x)}) - \sum
P(x)log(\frac{1}{P(x)})=\sum P(x)\frac{P(x)}{Q(x)}
\]</span> ​ 理解了编码的物理意义就知道，为什么是<span class="math inline">\(\frac {P(x)}{Q(x)}\)</span>了，因为<span class="math inline">\(Q(x)\)</span>并非最优分布，需要的编码量更大。而我们不喜欢负数，为了让KL散度为正，故这样定义。</p>
<p>​ 穿插一点优化原理的知识：为什么使用交叉熵作为很多网络的损失函数？</p>
<h3 id="交叉熵与kl散度的关系">交叉熵与KL散度的关系</h3>
<p>​ 交叉熵的定义： <span class="math display">\[
H_c(x)=-\sum_{i=1}^np(x_i)log(q(x_i))=\sum P(x)log(\frac{1}{Q(x)})
\]</span> ​ 与KL散度的公式进行对比，可以发现： <span class="math display">\[
D_{KL}(P||Q)=H_c(x)-\sum P(x)log(P(x))
\]</span> ​ 其中：<span class="math inline">\(\sum
P(x)log(P(x))\)</span>表征的是原始分布。在训练过程中（比如典型的分类器训练），<span class="math inline">\(P(x)\)</span>一般是给定的：比如我们给定数据的原始label就是给定了一个原始分布，我们希望网络学习到的分布参数能够尽可能与原始分布接近。而由于<span class="math inline">\(\sum
P(x)log(P(x))\)</span>是常数（给定的原始分布是常的），优化交叉熵就相当于优化训练集与输出的KL散度。</p>
<h3 id="gan在优化什么">GAN在优化什么</h3>
<p>​
GAN的训练过程本质上就是构造一个近似的原始分布。由于我们只有原始分布的采样（比如MNIST手写数据集，是手写数字的采样），我们希望得到采样外的数据，那就需要原始分布。那么构建原始分布，可以看作是：构建一个带有参数集合<span class="math inline">\(\{\theta\}\)</span>的分布<span class="math inline">\(P_G\)</span>，使得，从<span class="math inline">\(P_G\)</span>中采样得到的原始分布的采样（给定的数据集）的概率尽可能大（个人理解）。</p>
<p>​
什么意思？我们认为：在极大似然的思想下，参数应该尽可能反映采样的结果，也就是给定真实分布<span class="math inline">\(P_R\)</span>的抽样集合<span class="math inline">\(d = \{x_1, x_2, ...
x_n\}\)</span>，应该使下式最大（极大似然）。 <span class="math display">\[
\begin{align}
&amp;L(\theta)=\prod_{i=1}^n P_G(x_i|\theta) \\
&amp;\theta^*=\mathop{argmax}_{\theta}\prod_{i=1}^n P_G(x_i|\theta)
\end{align}
\]</span> ​ 接下来我们对公式(10)进行一些数学上的变换：</p>
<ol type="1">
<li>log化：由于log是严格增的，加log将不影响结果</li>
</ol>
<p><span class="math display">\[
\theta^*=\mathop{argmax}_{\theta}\;log(\prod_{i=1}^n
P_G(x_i|\theta))=\mathop{argmax}_{\theta}\;\sum_{i=1}^nlog(P_G(x_i|\theta))
\]</span></p>
<ol start="2" type="1">
<li>与真实分布进行关联：在生成器对应的生成分布近似于原始分布的情况下，生成分布下讨论最优参数<span class="math inline">\(\theta^*\)</span>对应的似然，就等价于讨论原始分布采样得到结果概率。</li>
</ol>
<p><span class="math display">\[
\theta^* \approx \mathop{argmax}_{\theta}\;S_x\{P_R|log(P_G(x|\theta))\}
\]</span></p>
<p>​ 上式的意义是：<span class="math inline">\(\sum_{i=1}^nlog(P_G(x_i|\theta))\)</span>-&gt;中的<span class="math inline">\(x_i\)</span>相当于从真实分布<span class="math inline">\(P_R\)</span>中抽样得到，隐含了抽样概率（得到<span class="math inline">\(x_i\)</span>的概率被隐含了），如果抽样次数接近无穷大，相当于对全空间进行抽样，可以连续化为：
<span class="math display">\[
\theta^*=\mathop{argmax}_{\theta}\;\int_x P_R(x)log(P_G(x|\theta))dx
\]</span></p>
<ol start="3" type="1">
<li>转化为KL散度：实际上(13)已经有KL散度的影子了，KL散度的连续形式为：</li>
</ol>
<p><span class="math display">\[
D_{KL}(P||Q)=\int_x P(x)log(\frac{P(x)}{Q(x)})dx
\]</span></p>
<p>​ 则，由于在argmax过程中引入与<span class="math inline">\(\theta\)</span>无关的常数因子，不影响结果，那么(13)可以写为：
<span class="math display">\[
\theta^*=\mathop{argmax}_{\theta}\;\int_x
P_R(x)log(P_G(x|\theta))dx-\int_x P_R(x)log(P_R(x))dx
\]</span> ​ 与(14)对比，发现，后端需要优化的式子就是对应的KL散度： <span class="math display">\[
\int_x P_R(x)log(P_G(x|\theta))dx-\int_x P_R(x)log(P_R(x))=\int_x
P_R(x)log(\frac{P_G(x)}{P_R(x)})dx=D_{KL}(P_R||P_G)
\]</span> ​ 也就是说：得到最优生成分布的参数<span class="math inline">\(\theta\)</span>的过程就是在优化原始分布（未知，但是采样已知）与最优生成分布的KL散度。</p>
<h3 id="生成分布的计算">生成分布的计算</h3>
<p>​ 那么，为什么GAN要在高斯中采样？原来的latent
vector(z)又是如何一步步变到生成数据的？我们已经通过近似证明了（其中一个巧妙的思想就是：采样得到的样本隐含了其概率分布）优化GAN生成器与优化生成分布/原始分布KL散度的等价性。</p>
<p>​ 在公式(16)中，存在<span class="math inline">\(P_G(x|\theta)\)</span>，这是之前从未出现过的。我们通过latent
vector
z（从多维高斯中采样的随机向量）构造了一个从多维高斯分布经非线性映射得到的生成分布。那么<span class="math inline">\(P_G(x|\theta)\)</span>自然与高斯分布有关。那么<span class="math inline">\(P_G(x|\theta)\)</span>可以被表示为：</p>
<p><span class="math display">\[
P_G(x|\theta)=\int_zP_{prior}(z)I_G(z)dz \\
I_G(z)=
\left\{
    \begin{array}{**lr**}
        1,\;if\;G(z)=x,\\
        0,\;if\;G(z)\neq x
    \end{array}
\right.
\]</span></p>
<p>​
也就是说此处使用了一个类似边缘分布的求取的方法，将所有可以生成x的z找到，求取其概率。其中<span class="math inline">\(P_{prior}\)</span>是先验分布，在此处是多维高斯。以上只是理论推导，实际上，指示函数<span class="math inline">\(I_G(z)\)</span>是不可知的，那么使用公式(17)是无法计算<span class="math inline">\(P_G(x|\theta)\)</span>的。此时我们引入了判别器
Discriminator，用以取代MLE的指示函数处理。</p>
<h3 id="判别器与js散度的导出">判别器与JS散度的导出</h3>
<p>​
每次生成器G训练时，我们都希望，在给定的判别器D较优时，生成器G仍然能骗过D。首先，根据简单的BCELoss，我们定义需要优化的score（最大化）：
<span class="math display">\[
S(G, D)=S_{x\{P_R\}}\;log(D(x))+S_{x\{P_G\}}\;log(1-D(X))
\]</span> ​
上式也就是D训练时，希望能最优地区分原始数据与生成数据所定义的Score。那么采样<span class="math inline">\(S_{x\{dist\}}\)</span>可以展开为定积分： <span class="math display">\[
S(G,D)=\int_xP_R(x)log(D(x))dx+\int_x P_G(x) log(1-D(x))dx
\]</span> ​
判别器训练时，G的参数不变，原始分布参数也不变，那么公式(19)中的可变量就是D的参数。我们需要求到一个最优的D（<span class="math inline">\(D^*\)</span>）以最终求得G：也即最优判别器下对应的最优生成器。
<span class="math display">\[
G^*=\mathop{argmin}_{G}\;\mathop{argmax}_{D}\;S(G,D)
\]</span> ​ 可以将(19)式合并积分内式子，并且进行求导（对D）： <span class="math display">\[
\begin{align}
    &amp;S_n(D)=P_R(x)log(D(x))+P_G(x) log(1-D(x))\\
    let:\;&amp;\frac{\partial S_n}{\partial
D}=\frac{P_R(x)}{D}-\frac{P_G(x)}{1-D}=0
\end{align}
\]</span></p>
<p>​ 可以得到最优判别器的参数D为： <span class="math display">\[
D(x)=\frac{P_R(x)}{P_R(x) + P_G(x)}
\]</span></p>
<p>​ 那么公式(19)的D(X)表达式已经知道了，带入得到： <span class="math display">\[
S(G,D)=\int_x
\left\{
    P_R(x)log(\frac{P_R(x)}{P_R(x) + P_G(x)}) + P_G(x)
log(\frac{P_G(x)}{P_R(x) + P_G(x)})
\right\}
dx
\]</span></p>
<p>​ 单独讨论(24)积分内部的式子，可以发现，当我们进行如下处理后： <span class="math display">\[
\begin{equation}
\int_x P_R(x) log(\frac{P_R(x)}{\frac{P_R(x) + P_G(x)}{2}})dx + \int_x
P_G(x) log(\frac{P_G(x)}{\frac{P_R(x) + P_G(x)}{2}})dx-2log2\\
=D_{KL}(P_R|{\frac{P_R(x) + P_G(x)}{2}})+D_{KL}(P_G|{\frac{P_R(x) +
P_G(x)}{2}})-2log2\\
=2D_{JS}(P_R|P_G)-2log2
\end{equation}
\]</span> ​ 我们将式(25)化简结果的部分进行定义： <span class="math display">\[
D_{JS}(P|Q)\overset{\Delta}{=}{\frac12}D_{KL}(P|M)+{\frac12}D_{KL}(Q|M),\\
where\;\;M=\frac{P+Q}2
\]</span> ​
可以看出，JS散度相比于KL散度而言，其是对称的。我们优化的是关于
{生成分布}{原始分布}的JS散度，其中借助了判别器，判别器将复杂的MLE指示函数（形式不负责，但是难算）转化为了易于计算的JS散度，以优化两个分布的差异。</p>
<hr>
<h2 id="原始gan为什么难以训练">原始GAN为什么难以训练</h2>
<p>​ 原始GAN实际在优化(25)式对应的JS散度。<span class="math inline">\(P_G\)</span>与<span class="math inline">\(P_R\)</span>可以互相接近（<span class="math inline">\(P_G\)</span>通过梯度来调整）。而如果，这两个分布本身就几乎不重合（什么叫不重合？），会怎么样？</p>
<p>​
不重合的定义很简单，概率密度不为0的位置错开了（或概率密度较大的位置错开了）。那么假设<span class="math inline">\(P_G\)</span>与<span class="math inline">\(P_R\)</span>的关系是任意的，那么会有如下四种关系：</p>
<ul>
<li><span class="math inline">\(P_G(x)\approx
0,P_R(x)&gt;&gt;0\)</span></li>
<li><span class="math inline">\(P_G(x)&gt;&gt; 0,P_R(x)\approx
0\)</span></li>
<li><span class="math inline">\(P_G(x)&gt;&gt;
0,P_R(x)&gt;&gt;0\)</span></li>
<li><span class="math inline">\(P_G(x)\approx 0,P_R(x)\approx
0\)</span></li>
</ul>
<p>​
在前两种情况成立时，不重合（一个分布有值的地方，另一个分布基本上没有值）。那么在不重合情况下，我们重新看一下公式(25):
<span class="math display">\[
2D_{JS}(P_R|P_G)=\int_xP_R(x)log(\frac{P_R(x)}{\frac{P_R(x) +
P_G(x)}{2}})dx + \int_xP_G(x) log(\frac{P_G(x)}{\frac{P_R(x) +
P_G(x)}{2}})dx
\]</span> ​ 当<span class="math inline">\(P_G\)</span>不为0的位置，<span class="math inline">\(P_R\)</span>接近0，那么可以知道，(27)的计算结果为log2，对于第二种情况，计算结果也是log2（或与x有关，但是x的影响极其小）。可以知道，在这种情况下，需要优化的<span class="math inline">\(D_{JS}\)</span>已经不具备指导意义了，梯度已经消失了。生成器无法得到有用的信息。</p>
<blockquote>
<p><span class="math inline">\(P_R\)</span>与<span class="math inline">\(P_G\)</span>不重叠或重叠部分可忽略的可能性有多大？不严谨的答案是：非常大。比较严谨的答案是：当<span class="math inline">\(P_R\)</span>与<span class="math inline">\(P_G\)</span>的支撑集（support）是高维空间中的低维流形（manifold）时，<span class="math inline">\(P_R\)</span>与<span class="math inline">\(P_G\)</span>重叠部分测度（measure）为0的概率为1。</p>
</blockquote>
<ul>
<li>其中，支撑集就是（1）函数的非零部分集合（2）概率分布的非0部分集合。</li>
<li>流形：就是高维空间中的，拥有实质更低自由度的形体。</li>
</ul>
<p>​ 那么可知：<span class="math inline">\(P_G\)</span>的支撑集恰好就是高维空间中的低维流形。由于我们使用的latent
vector比原图片flatten之后的大小小得多：比如196 dims的z，全连接至56 * 56
* 2 再卷积到56 * 56，<span class="math inline">\(P_G\)</span>就是低维空间的流形。</p>
<hr>
<h2 id="介绍wasserstein距离的一些数学准备">介绍Wasserstein距离的一些数学准备</h2>
<h3 id="lipschitz-条件">Lipschitz 条件</h3>
<p>​ 这个是高等数学中没有要求掌握的部分，但是在此处又提到了。</p>
<p>​ 若x为有界空间<span class="math inline">\(\mathbb
R^n\)</span>中的一个向量，定义在<span class="math inline">\(\mathbb
R\)</span>上的函数<span class="math inline">\(f(x)\)</span>有界的<strong><u>充分</u></strong>条件是：<span class="math inline">\(f(x)\)</span>满足Lipschitz连续性条件： <span class="math display">\[
f:D \subset \mathbb R^n\rightarrow \mathbb R,\;\exists
K,\;|f(a)-f(b)|\leq K|a-b|,\; a,b \in D
\]</span> ​ 函数值的距离与函数变量的距离存在一个上界关系。所以<span class="math inline">\(f\)</span>又称为收缩映射，K（若&lt;1）称为Lipschitz常数。而Lipschitz连续性如果存在，训练时将将不会出现梯度爆炸的情况，由于Lipschitz连续性可以限制梯度，防止梯度爆炸。而WGAN使用的是剪裁的方法，权值剪裁可以保证1-Lipschitz连续性，但是效果不太好。权值剪裁可能导致权值的集中化。</p>
<hr>
<h2 id="gan实现过程中的一些问题">GAN实现过程中的一些问题</h2>
<ul>
<li>分类器过强导致gan_v2在无法判断终止的情况下，分类器一直进行训练，导致分类器的loss减到0.0001左右，而生成器的loss上涨到10左右。这样导致了生成器生成的图片完全为黑色图。</li>
<li>之前WGAN的训练效果并不好，没有直接GAN的训练效果好。
<ul>
<li>原因是：使用的网络结构根本不需要那么复杂。之前使用了奇怪的：卷积 +
upsample结构。最后一层输出还使用了并联两个大小卷积核输出结果的方法，导致训练慢。</li>
</ul></li>
<li>将网络全部替换成全连接层，训练600个Batch之后就已经可以看出数字的形状了，但训练batch增加并没有显著导致外围的高斯噪声减少，个人认为这是由于全连接层特性决定的。</li>
<li>于是我尝试将全连接层的输出层替换为3 *
3的卷积网络。卷积输出会导致模糊，3 *
3卷积网络模糊减退十分慢。在参考了GAN training tricks之后，将3 * 3
kernel替换为 5 * 5
kernel，最后得到了平滑结果，外围噪声可以完全消除，网络输出具有平滑度。</li>
<li>WGAN 的 <strong>clipping
parameter</strong>对输出的影响也比较大，当clipping
parameter比较大的时候输出直接变成了奇怪的浮雕。</li>
</ul>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title>Enigma&#39;s First Blog</title>
    <url>/2021/01/29/Enigma&#39;s-First-Blog/</url>
    <content><![CDATA[<p>​ This post is for testing all the configurations and settings are
good to go.</p>
<p>​ I decided to start my own blog, for keeping track of the knowledge
and skills I have learned. This blog site may well be known to others
one day, and there is nothing to lose for me if otherwise. (Self
pleasuring, I like to see things organized.)</p>
<ul>
<li><p>A lot of markdown notes of mine are poor-organized for the lack
of a good platform in which those notes can be published.</p></li>
<li><p>A blogging website might motivate me to interpret the essence of
knowledge learned in my own language, moving from 'self teaching' to
teaching others (Deeper understanding is established on the ability to
teach others).</p></li>
<li><p>"Open source in Knowledge" is another reason, for there were many
times at which I can read blogs of others when I need help. Thereby,
publishing what you know might, in turn, help others.</p></li>
<li><p>Unfortunately, I found my words messy, ambiguous and sometimes
unorganized, making practices demanded increasingly.</p></li>
<li><p>3-2 term in XJTU, I have a computer network related course
incoming. I think I can learn something from maintaining my own blog
pages.</p></li>
</ul>
<p>​ This blog might be written in both English and Chinese, which
depends on the depth of contents. The page is also deployed to
<code>enigmatisms.github.io</code>.</p>
<center>
<i>Amat Victoria Curam.</i>
</center>
]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>English</tag>
        <tag>personal</tag>
        <tag>life</tag>
      </tags>
  </entry>
</search>
