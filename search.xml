<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2D LiDAR Simulator Release Notice</title>
    <url>/2021/08/28/2D-LiDAR-Simulator-Release-Notice/</url>
    <content><![CDATA[<h1 id="d-lidar-simulator-v-1.0">2D LiDAR Simulator V 1.0</h1>
<hr>
<p>2D LiDAR Simulator V 1.0🎇 is built upon the repository🎉🎉: <a href>Github🔗: Enigamtisms/Volume2D</a>, which is, recently, updated. This simulator contains:</p>
<ul>
<li><strong><u>map editor</u></strong>🎛 (with which you can build your own map),</li>
<li><strong><u>ROS integration</u></strong>🚀:
<ul>
<li>rosbag generation without publishing</li>
<li>rviz visualization for LaserScan, tf, Odometry (perturbed)</li>
<li>Direct message publishing</li>
</ul></li>
<li><strong><u>Easy-to-use</u></strong>👌 roslaunch <strong><u>parameter setting</u></strong>🗝 for simulated LiDAR and other perimeter settings.</li>
<li>Fluent opencv-based k<strong><u>eyboard / mouse control</u></strong>⌨🖱 with <strong><u>high FPS</u></strong>⏲, visualizing free space and scan.</li>
</ul>
<p>Some demo pictures are shown as follows:</p>
<p><img src="/2021/08/28/2D-LiDAR-Simulator-Release-Notice/1.png"></p>
<p><img src="/2021/08/28/2D-LiDAR-Simulator-Release-Notice/2.png"></p>
<span id="more"></span>
<hr>
<h2 id="dependencies">Dependencies</h2>
<p>The implementations are done in Ubuntu 18.04, under some of the key libraries:</p>
<table>
<thead>
<tr class="header">
<th>Library name</th>
<th>Version</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ROS</td>
<td>Melodic (for Ubuntu 18.04)</td>
</tr>
<tr class="even">
<td>OpenCV</td>
<td>3.x.x or above</td>
</tr>
<tr class="odd">
<td>Eigen</td>
<td>Usually bond with ROS</td>
</tr>
</tbody>
</table>
<p>For compilation, C++ 17 standards are recommended.</p>
<hr>
<h2 id="download-compile">Download &amp; Compile</h2>
<p>In the repository <a href="https://github.com/Enigmatisms/LiDARSim2D">Enigmatisms/LiDAR2DSim</a>, click clone would suffice.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone git@github.com:Enigmatisms/LiDARSim2D.git</span><br><span class="line">cd LiDARSim2D</span><br></pre></td></tr></table></figure>
<p>Usually, for a ROS package we can compile the code via <code>catkin_make</code>. Yet, sometimes we want to compile A debug version, i.e. <code>-DCMAKE_BUILD_TYPE=DEBUG</code> and a release version at the same time for debugging convenience, therefore, <code>catkin_make</code> might not be quick to use. I have written a shell script named <code>make.sh</code> in the root directory, you can thereby run:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo chmod 777 ./make.sh</span><br><span class="line">./make.sh &lt;thread num for compilation&gt; &lt;if not empty, DCMAKE_BUILD_TYPE=DEBUG&gt;</span><br></pre></td></tr></table></figure>
<p>This script receives two params (the second one is optional). The former one declares the number of thread for compilation and the latter one is for debug mode specification. <code>make.sh</code> is simply an encapsulation of <code>catkin_make</code>.</p>
<p>Notice that if debug mode is on, cmake files will be output to folder <code>build_debug</code>, <code>devel</code> thereby contains the executable file of the most recent compilation (regardless of compilation mode <code>DCMAKE_BUILD_TYPE</code>)</p>
<hr>
<h2 id="run">Run</h2>
<p>Before run any of the code, make sure to:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$ </span><span class="language-bash">~/LiDAR2DSim: <span class="built_in">source</span> devel/setup.bash</span></span><br></pre></td></tr></table></figure>
<p>Otherwise, ROS package <code>lidar_sim</code> will not be found.</p>
<h3 id="the-editor">1. The Editor</h3>
<p>​ Map editor is for the people who want to create their own maps. Run:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">roslaunch lidar_sim editor.launch</span><br></pre></td></tr></table></figure>
<p>​ You can find the param settings in <code>src/lidar_sim/launch/editor.launch</code></p>
<ul>
<li>map_name: specified output file name in folder <code>maps</code> ( <code>maps</code> is in the root directory)</li>
</ul>
<p>​ There are some other things to be noticed:</p>
<ul>
<li>The outer boundaries are given (30-pixel-thin), therefore don't draw anything in the border.</li>
<li>Objects (Obstacles) are <strong>directional</strong> (all the points of each any one of the obstacles should be drawn in a anti-clockwise way)</li>
<li><strong><u>Press left button of the mouse</u></strong> to add a new point.</li>
<li><strong><u>Press <code>E</code></u></strong> if one obstacle is drawn, and it will automatically enclose itself.</li>
<li><strong><u>Press <code>S</code></u></strong> to save the map and quit.</li>
<li><strong><u>Press <code>P</code></u></strong> to pop the points added, if the new points are empty, the enclosed objects will be popped.</li>
<li><strong><u>Press <code>ESC</code></u></strong> to exit without saving the map.</li>
</ul>
<h3 id="particle-filter">2. Particle filter</h3>
<p>This repository is once a repo for <strong><u>Particle filter</u></strong>, I implemented one simple particle filter for localization purposes. Therefore you can play with it.</p>
<p>This particle filter includes a <strong>2D LiDAR simulator</strong>, which is based on the <strong>Volume2D Shader of mine</strong>[<a href="https://github.com/Enigmatisms/Volume">Github Repo: Enigmatisms/Volume]</a>. Using this LiDAR simulator, I implemented an interesting little localization program via <strong>Particle Filter</strong>. The localization experiments are only done in a 2D-2DoF (translation position x and y) problem.</p>
<p>Under the condition of 2000 particles, the FPS of this algorithm is about 16-50 hz, and the convergence is fast and accurate. Run:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">roslaunch lidar_sim filter.launch</span><br></pre></td></tr></table></figure>
<p>To find out.</p>
<h3 id="scan-simulator">3. Scan simulator</h3>
<p>The main content of this repo. Run:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">roslaunch lidar_sim scan.launch</span><br></pre></td></tr></table></figure>
<p>On initialization, two new windows will pop up:</p>
<ul>
<li>An opencv window for free space, LiDAR scan visualization and scanner controlling.</li>
<li>An rviz window for sensor_msgs / nav_msgs visualization</li>
</ul>
<p>Check the launch file, you can find <strong><u>a lot of</u></strong> params.</p>
<ul>
<li>Controller settings:
<ul>
<li>trans_speed: translation speed (pixel per move, which is 2cm per move)</li>
<li>rot_vel: rotation velocity, in degree, which is only available in keyboard control</li>
<li>init_x, init_y: initial position of the scanner</li>
<li>kp, ki, kd: PID parameters for mouse controller, which allows smooth control.</li>
</ul></li>
<li>LiDAR settings
<ul>
<li>angle_min, angle_max: angle range in rad</li>
<li>angle_incre: angle resolution (increment) in rad</li>
<li>lidar_noise: noise level (gaussian sigma) for the noise in <strong><u>range.</u></strong></li>
<li>lidar_fps: frame rate of LiDAR</li>
</ul></li>
<li>Odometry settings: for nav_msgs::Odometry publishing
<ul>
<li>translation_noise: translation noise level</li>
<li>rotation_noise: rotation noise level (both gaussian)</li>
</ul></li>
<li>other settings:
<ul>
<li>map_name: which map to run</li>
<li>bag_name: the name of output rosbag</li>
<li>skip_selection: if true, the program will not ask you to select the initial position of the scanner, (init_x, init_y) will come into use.</li>
<li>direct_pub: publish the ROS messages in the program</li>
</ul></li>
</ul>
<hr>
<h2 id="demo">Demo</h2>
<video src="scan.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>release</tag>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title>2D体积光绘制算法设计</title>
    <url>/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[<h1 id="volume2d">Volume2D</h1>
<hr>
<h2 id="preface">Preface</h2>
<p>​ 最近玩Minecraft1.12时发现了一个极其棒的光影包，体积光（虚假的体积光，不是用光线追踪做的）做的极其漂亮，使我对这个游戏重新产生了兴趣。</p>
<p><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/mc.png"></p>
<center>
Figure 1. 我的世界光影
</center>
<p>​ 实际上，个人之前就对体积光有很大的兴趣，拍照的时候也很喜欢寻找存在"Gods' Ray"的场景，没有就将其强行用PS的径向模糊绘制出来。对于游戏内部的光影，我也很想自己实现一个光线效果（大一写的游戏<a href="https://github.com/Enigmatisms/Ethians-Alpha-1.1">Ethians alpha 1.1🔗</a>中有阴影计算的算法（FOV shadow casting），但结果是基于栅格的，而不是基于像素的）。综合以上的想法 + 想精进一下C++ STL技术，我设计了一个这样的问题。</p>
<span id="more"></span>
<blockquote>
<p>假设有一个点光源，在一个只有矩形障碍物的2D平面空间中，如何高效渲染场景中的阴影？</p>
</blockquote>
<p>​ 这就是一个典型的渲染问题，我设计了一个渲染算法并采用C++ + OpenCV 4.5.1进行实现。</p>
<hr>
<h2 id="算法设计与实现">算法设计与实现</h2>
<h3 id="准备工作">准备工作</h3>
<p>​ 首先将整个地图进行栅格化。比如个人的实现中，一个1200 * 900的窗口，被栅格化为 40 * 30的地图，每个栅格大小为30 pixels。障碍物是基于栅格的（对于类似于Ethians Alpha 1.1这样的平面Roguelike Game适用），栅格越精细，障碍物也可以更加精细，阴影计算对应的时间消耗越大。</p>
<hr>
<h3 id="边界确定与划分">边界确定与划分</h3>
<p>​ 对于矩形的障碍物，一个很自然的想法就是：对其边界进行管理，阴影投射的产生是由于边界对光线的截断作用。但是对于一个w * h的栅格化地图，每一个栅格存在4条边界（不考虑共用边界时），直接对所有边界进行操作，时间复杂度将至少是<span class="math inline">\(O(n^2)\)</span>的。显然，在这个问题中，有些边界是完全不必要存在的，我们需要在此步内计算真正可能影响渲染的边界。关于边界我们还需要其他的信息：</p>
<ul>
<li>边界的两个端点位置</li>
<li>边界是垂直的还是水平的</li>
<li>边界是否被遮挡，是否被处理过</li>
<li>边界相对于光线的方向</li>
</ul>
<p>​ 后续的计算需要依赖于上述信息。</p>
<h4 id="边界的按栅格确定">边界的按栅格确定</h4>
<p>​ 刚开始时我的设计有些问题，我直接使用位置进行遍历（按照水平 / 竖直两个方向，并行），能够快速求出所有的边界。规则如下：</p>
<ol type="1">
<li>设置occupancy map（栅格占用2D数组），为0则表示没有障碍物，为1表示有障碍物</li>
<li>边界所在的位置 水平边的上方一格与下方一格occupancy map值不相等，竖直边则是左右块的值不相等</li>
<li>可以快速确定两个方向的所有边</li>
</ol>
<p>​ 但是这样存在一个问题，我确实可以省略一些非边界位置，比如两个相邻障碍物块之间的边界或者两个空气方块之间的边界，仍然存在一些无用边界无法被剔除。如下图所示：</p>
<p><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/rays.JPG"></p>
<center>
Figure 2. 冗余边界示意图
</center>
<p>​ 实际上背对光源的边界对投影毫无帮助，计算时可以忽略。这样既可以节省内存，也可以节省计算时间。而如开始的设计，按照边界的水平 / 竖直方向进行边界计算无法获知某一条边界在栅格上的位置，也就无法获知其是否能影响投影结果。</p>
<p>​ 按照栅格进行确定，也就是遍历地图上所有的栅格，边界在栅格上是有其相对位置信息的，而栅格相对光源也是可以获知位置信息的，这样可以计算出边界是否会影响投影结果。具体的规则如下：</p>
<ul>
<li>在光源正上方的栅格，只有面朝光源的这一条边界是有意义的</li>
<li>在光源侧面的栅格，根据光源的相对位置，最多选择两条面朝光源的边界</li>
<li>首先计算栅格相对光源的位置：分为8种情况：</li>
</ul>
<table>
<thead>
<tr class="header">
<th>enum名称</th>
<th>意义</th>
<th>二进制编码</th>
<th>16进制表示</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>TL</td>
<td>左上</td>
<td>0000</td>
<td>0x00</td>
</tr>
<tr class="even">
<td>DT</td>
<td>正上</td>
<td>0001</td>
<td>0x01</td>
</tr>
<tr class="odd">
<td>TR</td>
<td>右上</td>
<td>0010</td>
<td>0x02</td>
</tr>
<tr class="even">
<td>DL</td>
<td>正左</td>
<td>0100</td>
<td>0x04</td>
</tr>
<tr class="odd">
<td>DR</td>
<td>正右</td>
<td>0110</td>
<td>0x06</td>
</tr>
<tr class="even">
<td>BL</td>
<td>左下</td>
<td>1000</td>
<td>0x08</td>
</tr>
<tr class="odd">
<td>DB</td>
<td>正下</td>
<td>1001</td>
<td>0x09</td>
</tr>
<tr class="even">
<td>BR</td>
<td>右下</td>
<td>1010</td>
<td>0x0a</td>
</tr>
</tbody>
</table>
<p>​ 设置编码的原因是，可以根据逻辑运算快速求出栅格或者边界是否属于某个方向（例如上方 包括左上 正上和右上，或者正方向，包括四个正向）。</p>
<ul>
<li>只有正方向的栅格存在一条有效边界，其余栅格均存在两条有效边界，如下图所示：</li>
</ul>
<p><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/block.JPG"></p>
<center>
Figure 3. 有效边界示意图
</center>
<p>​ 根据边中点与光源的相对位置可以计算出边的方向（orient），边的orient图：</p>
<p><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/orient.png"></p>
<center>
Figure 4. 边方向计算图，中部灰色方块是光源
</center>
<p>​ 边界计算是分块并行的。由于我使用的机器为4核的，使用了4个线程（也就是依图像中心划分为四个象限，并行计算，最后合并到一个vector内）</p>
<hr>
<h3 id="边界重新计算">边界重新计算</h3>
<p>​ 光有边界是没有用的，我们需要通过边界来计算渲染问题，前面的步骤只是在减少不必要的边界计算以及渲染框计算。关于阴影区域的一个简单想法是：投影是存在先后顺序的，距离光源近的边界必然是需要被预先处理的，并且在距离近的边界投影完成之后，可能导致其他边界被遮挡。被完全遮挡的边界是不需要参与后续计算的，这是因为更远的边界被完全遮挡后，其投影的阴影部分必然小于遮挡此边的边界的投影阴影区域（很绕？）。</p>
<p>​ 既然存在先后顺序，就必然涉及到排序。为了避免进行排序，实现中直接用了一个小顶堆（C++ <code>&lt;queue&gt;</code> 头文件中的 priority_queue）。可惜的是，priority_queue的特性与queue相似，没有迭代器，无法遍历，所以priority_queue存放的是边界类的指针，指向vector中的某个边界类。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">EdgeCompFunctor</span>&#123;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">operator</span><span class="params">()</span> <span class="params">(<span class="type">const</span> Edge* <span class="type">const</span> e1, <span class="type">const</span> Edge* <span class="type">const</span> e2)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> e1-&gt;<span class="built_in">getDistance</span>() &gt; e2-&gt;<span class="built_in">getDistance</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">std::priority_queue&lt;Edge*, std::vector&lt;Edge*&gt;, EdgeCompFunctor&gt; edges;</span><br></pre></td></tr></table></figure>
<p>​ 边界到光源的距离在计算边界的时候，按照中点到光源的欧式距离已经计算过了。</p>
<p>​ 边界重新计算主要解决两个问题：</p>
<ul>
<li>完全被遮挡的边界，设置其内部的valid flag为false，之后出队时如果遇到标签无效的边界直接跳过。</li>
<li>部分被遮挡的边界，<strong><u>需要重新计算其端点</u></strong>。这个才是最重要的部分。</li>
</ul>
<p>​ 如何判定一个Edge在某个距离更近的边界产生的阴影内部呢？可以使用相对角度进行判定：绝对角度坐标（比如极坐标）是不好的，不管使用什么表征（除非四元数），都会存在奇异性，比如极坐标的x正向实际分割了0°与360°，这会让角度大小判定变得复杂。</p>
<p><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/calc2.JPG"></p>
<center>
Figure 5. 遮挡性计算
</center>
<p>​ 如上图所示，假设我们看左上角那条边界。首先对于正在投影的边界（Projecting edge），其遮挡范围有个角度θ。那么有如下规则，假设一条需要判断的边界到到两条边界的角度为<span class="math inline">\(\theta_{ij},i,j=1,2\)</span>。其中 <span class="math inline">\(\theta{ij}\)</span>表示边界端点i到光线j的夹角：</p>
<ul>
<li>某端点与光源连线到两束光线的角度均小于光线夹角θ：说明这个端点在不可视范围内</li>
<li>某端点到光源连线到两束光线的角度中，至少有一个角度大于θ，说明这个端点在可视范围内。</li>
</ul>
<p>​ 如果我们通过计算方向向量，使用方向向量进行内积的计算，内积的结果就是端点和光线夹角的cos值，显然，cos值越接近1（越大），对应端点连线 / 光线的夹角越小。（<strong><u>注意这内积值是cos值，cos在0-<span class="math inline">\(\pi\)</span>是减函数，开始忽略了这一点，直接“越小越好”导致了爆炸</u></strong>）。</p>
<p>​ 得到了夹角之后有如下规则：</p>
<ul>
<li>两个端点均在不可视范围内的直接设置valid = false，之后不再处理</li>
<li>其中一个端点在不可视范围内的，计算此端点的更新值（恰好在光线上的点）。</li>
</ul>
<p>​ 关于端点更新到什么位置：简单的想法是，端点更新到离他近的光线上（夹角小的光线上）。我之前这样做的时候引起了问题：假如夹角小的那条光线对应的位置在障碍物内部或者在空气方块内部（总之不在边界上），就会出现问题。所以需要判定：优先投影到夹角小的光线对应的更新位置上，如果occupancy map指示对应位置不是边界，则投影到另一条光线位置。</p>
<p>​ 那么整个流程应该是：</p>
<ul>
<li>取堆顶，堆顶指针指向的边界为当前投影边，计算光线方向向量，pop</li>
<li>“八叉”搜索（个人叫法，现在没有用八叉树实现，但是实际应该是可以用类似结构实现的），搜索需要更新的边，进行更新</li>
<li>更新就是判定是否要更新端点或者valid flag值，此处可以并行</li>
<li>所有需要更新的边更新之后，确定渲染框</li>
</ul>
<h4 id="八叉搜索">八叉搜索</h4>
<p>​ 由于每条边都包含方向信息，而在某条边投影时，并非整张地图上的边都有可能更新。更新只发生在与投影边相同方向（或是相近方向）的边中。规则是：</p>
<ul>
<li>如果是正方向上的边，比如投影边是正上方的，由于正方向障碍物的阴影覆盖面广，需要搜索正上方，左上方，右上方的所有边。也就是说，正方向的投影边需要搜索一个大方向（包含3个小的方向）</li>
<li>如果不是正方向上的边，只需要搜索边集合（vector）中与投影边相同方向的边即可。</li>
</ul>
<p>​ 这种方法还只是基于一维vector的全遍历，实际可以使用unordered_map，以方向编码为key，value为vector，只搜索部分vector。</p>
<hr>
<h3 id="渲染框确定">渲染框确定</h3>
<p>​ 个人认为，本投影问题实际上是：每一条边投影时产生图像上的一部分阴影部分，每投影一条边时就可以计算一个渲染框，只需要将此渲染框内填充满阴影（的颜色）即可。如下图所示，给定一条边界，需要计算此边界产生的阴影区域，也就是需要获得光线（或者阴影边界线）与地图边界的交点。如果得到交点，经过排序之后，可以直接使用OpenCV提供的fillConvexPoly进行凸多边形的颜色填充。</p>
<p><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/render.JPG"></p>
<center>
Figure 6. 渲染框计算示意图
</center>
<p>​ 如果需要解边界上的点位置，我们需要如下信息：光源位置<span class="math inline">\((x_c, y_c)\)</span>，光线向量<span class="math inline">\((v_x,v_y), (u_x,u_y)\)</span>，边界：<span class="math inline">\(x=0,y=0,x=x_M,y=y_M\)</span>，并设对应边界为：<span class="math inline">\((x_b,y_b)\)</span>那么可以根据： <span class="math display">\[
(x_c,y_c)+t(v_x,v_y)=(x_b,y_b)
\]</span> ​ 在边界上<span class="math inline">\(x_b,y_b\)</span>中必然有一个是已知的，可以解出t，得到未知的边界坐标分量。实际上，一条射线（一个向量）可能与两个边界（相邻的x / y方向边界）相交，得到两个解，从两个解中选择合理值（两个分量均在边界范围内）作为解。</p>
<p>​ 此外，得到了边界交点并不代表着渲染框完全选取好了，由于边界交点并不一定在同一条地图边界上，可能需要增加额外的地图corner为渲染框角点。有如下三种情况：</p>
<p><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/cond.JPG"></p>
<center>
Figure 7. 渲染框增加地图边界点的三种情况
</center>
<p>​ 在出现需要增加点的情况下，需要人为设计一些规则，讨论如何判定进入这三种情况中的哪一种情况：</p>
<ul>
<li>加入两个点的情况出现时，特征的表现是：两个解的某个分量差的绝对值等于地图某个方向的长度。</li>
<li>加入一个点的情况出现时，特征的表现是：两个解的对应分量不会相等。</li>
</ul>
<p>​ 渲染框需要emplace到某个二维vector中。此后使用4个线程同时绘制渲染框即可（地图内100个随机障碍块时，绘制时间大概是1.5ms）。结果如下图所示：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/direct.png"></th>
<th style="text-align: center;"><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/direct2.png"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">随机地图渲染框绘制</td>
<td style="text-align: center;">非随机地图渲染框绘制</td>
</tr>
</tbody>
</table>
<hr>
<h3 id="美化">美化</h3>
<p>​ 美化主要做了两个事情：可视范围确定 + 光强衰减。这两个事情可以合并起来处理。开始我使用线性衰减，设置阴影的色彩为(20, 20, 20)： <span class="math display">\[
max(255-\frac{255-20}{R_{max}}R,20)
\]</span> ​ 此式说明，光强度线性衰减到<span class="math inline">\(R_{max}\)</span>后，维持在最低光强值处。线性衰减的效果并不好，可见范围内较亮位置比较小。而改换成较为符合物理学的光强衰减公式（平方反比）后，效果较好： <span class="math display">\[
max(\frac{255}{(aR+1)^2},20),where\;a=\frac{\sqrt\frac{255}{20}-1}{R_{max}}
\]</span> ​ 美化后的结果如下两张图所示：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/beauty1.png"></th>
<th style="text-align: center;"><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/beauty2.png"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">随机地图渲染框绘制</td>
<td style="text-align: center;">非随机地图渲染框绘制</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="结果与代码">结果与代码</h2>
<p>​ 代码见<a href="https://github.com/Enigmatisms/Algorithms-Plus/tree/master/cpp/volume">[Github🔗Algorithm Plus/cpp/volume]</a>，代码依赖：OpenCV 4.5.1，OpenMP，C++ 11（或以上），CMake。</p>
<p>​ 加入了平滑运动：光源的运动不是按照栅格进行的，而是按照像素进行的，运动过程比较平滑，可以通过键盘操控光源的移动。输出的gif如下：</p>
<p><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/volume.gif"></p>
<p><img src="/2021/02/18/2D%E4%BD%93%E7%A7%AF%E5%85%89%E7%BB%98%E5%88%B6%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/volume2.gif"></p>
<center>
Figure 8. 体积光与光源运动
</center>
<hr>
<br>
<center>
Do you like what you♂see ?
</center>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>algos</tag>
      </tags>
  </entry>
  <entry>
    <title>3D Reconstruction with Posed Mono-cam Images</title>
    <url>/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/</url>
    <content><![CDATA[<h1 id="re3d">Re3D</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​ 电脑还没到，我[#]。不得不说京东有些店是真的脑瘫，买RTX发AMD，AMD yes也别这样啊。没办法工作的情况下只能看论文，继续3D重建。3D重建有些部分与我当前工作有重合之处，我也想从中获得一些启发。本文是两篇小论文以及一本书（这本书的其中一卷）的一个小理解：</p>
<ul>
<li><a href="https://arxiv.org/pdf/2003.10432.pdf?ref=https://githubhelp.com">Murez, Zak, et al. "Atlas: End-to-end 3d scene reconstruction from posed images." <em>European Conference on Computer Vision</em>. Springer, Cham, 2020.</a></li>
<li><a href="https://proceedings.neurips.cc/paper/2021/file/0a87257e5308197df43230edf4ad1dae-Paper.pdf">Bozic, Aljaz, et al. "Transformerfusion: Monocular rgb scene reconstruction using transformers." <em>Advances in Neural Information Processing Systems</em> 34 (2021)</a></li>
<li>书（不得不说这本... 期刊？写得真不错，CV方向的基础以及前瞻，不过是当时的前瞻了，可能也比较老）: <a href="https://www.nowpublishers.com/CGV">Foundations and Trends® in Computer Graphics and Vision</a></li>
</ul>
<p>​ 附注：不让我工作我就打原神。</p>
<span id="more"></span>
<hr>
<h2 id="ii.-基本概念">II. 基本概念</h2>
<p>​ 以下内容很多都来自于[1]，个人觉得此文写得很不错，逻辑清晰，易读性强。</p>
<h3 id="d重建概述">2.1 3D重建概述</h3>
<h4 id="d重建的基本方法">2.1.1 3D重建的基本方法</h4>
<p>​ 笔者认为，3D重建行业发展的理想道路应该是：</p>
<ul>
<li>单目RGB-已知图像位姿的3D重建</li>
<li>双目RGB 图像位姿可以未知</li>
</ul>
<p>​ 实际上，可以将第二种情况视作第一种情况的特例。第二种情况只不过是将一半的图像用于双目深度计算了。在[1]中，作者认为：</p>
<blockquote>
<p>The 3D reconstruction of shapes from <strong><u>multiple</u></strong>, <strong><u>uncalibrated</u></strong> images is one of the most promising 3D acquisition techniques.</p>
</blockquote>
<p>​ 但“uncalibrated mono-cam”应该说是最困难的一种，当然如果做出来了，意义也是最大的一种（用最少的先验知识以及辅助工具获得了想要的信息，这就是优雅的、低成本的好方法）。</p>
<p>​ 关于视觉3D重建，[1]中提到了两种主要的方向：</p>
<pre class="mermaid">
graph TB
A(3D Shape Extraction)
B(Passive)
C(Active)
D(Single vantage point)
E(Single vantage point)
F(Multiple vantage points)
G(Multiple vantage points)
A--&gt;B
A--&gt;C
B--&gt;D
B--&gt;F
C--&gt;E
C--&gt;G
H(Shape from texture&lt;br&gt;Shape from occlusion&lt;br&gt;Shape from defocus&lt;br&gt;Shape from contour&lt;br&gt;Time to contact)
I(Passive stereo&lt;br&gt;SfM&lt;br&gt;Shape from sillhouttes)
J(Time of Flight&lt;br&gt;Shape from texture)
K(Structed light&lt;br&gt;Active stereo&lt;br&gt;Photometric stereo)
D--&gt;H
F--&gt;I
E--&gt;J
G--&gt;K
</pre>
<center>
Figure 1. 3D重建方法分类
</center>
<div class="tabs" id="span-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#span-unique-name-1">Active</a></li><li class="tab"><a href="#span-unique-name-2">Passive</a></li></ul><div class="tab-content"><div class="tab-pane active" id="span-unique-name-1"><p>​ 可以认为，active方法是一种通过一些处理使得后续的复杂计算（比如correspondence search）变简单的方法。比如使用光斑进行“制导”：一个长波光源发射不可见光，另一个接收器（相当于相机）接收光。假设我们认为发射的是可见光，接收器也是一台相机，那么相当于是：相机拍摄到一个亮斑，而发射器可以认为是相机的反向模型，则“发射器-接收器”可被视作是两台相机组成的双目系统，而亮斑的存在已经帮我们标注好了correspondence。</p>
<center>
<img src="/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/active.png" style="zoom:50%;">
</center>
<center>
Figure 2. Active 方法图示[1]
</center>
<p>​ 当然，单点没什么卵用。我们希望可以获得整个面的correspondences关系，是否仍然可以使用active光斑法？当然也是可行的，不过由于我们在使用单点光斑时，基于的想法是“<strong><u>唯一性</u></strong> 以及 <strong><u>容易查找性</u></strong>，直接使用单点法中光斑的2D复制显然是不行的（emmm，事实上也可以，基于红外光斑阵列的深度相机也有的，但是这种方法除了保证了极线上的全局最优性，并没有实际解决correspondence search很棘手的问题）。</p>
<p>​ [1]中作者介绍了一些对光斑进行“positional embed”的方法。比如，我就使用 <strong>Attention is all you need</strong> 中的sinusoidal positional encodings思想，用多组不同频率或者相位的正弦波来唯一地表征一个位置，这样方便我们进行查找。</p></div><div class="tab-pane" id="span-unique-name-2"><p>​ 本方法不使用其他辅助手段，一般来说都是直接靠算法算出结果来的。比如说：passive triangulation。通过预先计算的correspondences，解出在某一个相机坐标系下的坐标。但作者自己也说：</p>
<blockquote>
<p>Correspondence search actually is the <strong><u>hardest</u></strong> part of stereo, and one would typically have to solve it for many points.</p>
</blockquote>
<p>​ 这我也没啥好说的，只能说（1）确实。（2）考虑一下CVPR 2021最新工作（好吧已经不是最新了） PointDSC？（好吧*2，作者这篇文章是2010年的）。</p>
<p>​ 虽然如此，passive方法更加优雅，不依赖发射器件，只进行接收符合大多数生物的特性，并且这样的方法适用性更广，active方法对应的什么结构光、ToF一到室外场景可能就直接寄了。</p></div></div></div>
<h4 id="d重建面临的挑战">2.1.2 3D重建面临的挑战</h4>
<ul>
<li>复杂物体形状：自遮挡 (self-occlusion)，视角不全，表面细节丰富等等</li>
<li>一些奇怪的纹理：反射、透射，万花筒式（比如钻石），半透明物体</li>
<li>Scalability：既要能够重建小物体，也要能够重建大物体。（从家具到城市）</li>
<li>数据量大、处理维度高（3D表征比2D高）：自、弱、无监督</li>
<li>精度：这个不用讲，高精度鲁棒实时不仅仅是2D SLAM的追求</li>
<li>Semantic 3D与Opportunistic scanning，说的是两个对偶：
<ul>
<li>前者指重建的<strong><u>算法过程基于内容</u></strong>，假设我知道我需要重建的是一辆车，那么知道“车”的先验信息或许对我进行重建有很大帮助。那么重建过程就需要对待重建的场景有一定理解，至少是语义级别的。这其中包含了一定的 High level task 帮助 low level task的意思。</li>
<li>后者指重建的<strong><u>数据获取过程基于内容</u></strong>，假设我知道当前场景大量存在无纹理区域（对passive方法不友好），我是否可以自适应更换到active方法（比如结构光）？</li>
</ul></li>
</ul>
<h3 id="相机模型回顾">2.2 相机模型回顾</h3>
<p>​ 之前其实没有仔细推过这部分的内容，现在权当补个票。首先，我们明确一下符号：</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(R\)</span></th>
<th><span class="math inline">\(C\)</span></th>
<th><span class="math inline">\(K\)</span></th>
<th><span class="math inline">\(p\)</span></th>
<th><span class="math inline">\(z\)</span></th>
<th><span class="math inline">\(P\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>外参：旋转</td>
<td>世界坐标系下相机光心</td>
<td>内参矩阵</td>
<td>图像位置</td>
<td>深度</td>
<td>世界坐标系位置</td>
</tr>
</tbody>
</table>
<p>​ 则若已知相机在世界系下的旋转与平移（<span class="math inline">\(R,C\)</span>），内参矩阵已知的情况下，有如下关系： <span class="math display">\[
\begin{equation}
zp=KR^T(P-C)
\end{equation}
\]</span> ​ 实际上<span class="math inline">\(R^T(P-C)\)</span>只不过做了一个世界系-&gt;相机系的坐标变换。此公式应当非常熟悉。</p>
<p>​ 我们考虑单目已知相机位姿与参数时的情况，并且我们假设已经获得了两张图片中的correspondences（我一句话，就搞完了SLAM和correspondence search）。那么显然，对于世界坐标系下同一点： <span class="math display">\[
\begin{align}
&amp;z_1p_1=K_1R_1^T(P-C_1)\label{first}\\
&amp;z_2p_2=K_2R_2^T(P-C_2)\label{second}
\end{align}
\]</span> ​ 则可以通过公式<span class="math inline">\(\eqref{first}\)</span>反求P： <span class="math display">\[
\begin{equation}
z_1R_1K_1^{-1}p_1+C_1=P
\end{equation}
\]</span> ​ 带入到公式<span class="math inline">\(\eqref{second}\)</span>中： <span class="math display">\[
\begin{align}
&amp;z_2p_2=K_2R_2^T(z_1R_1K_1^{-1}p_1+C_1-C_2)\rightarrow\\
&amp;z_2p_2=z_1K_2R_2^TR_1K_1^{-1}p_1+K_2R^T_2(C_1-C_2)\label{homo1}
\end{align}
\]</span> ​ 其中<span class="math inline">\(K_2R_2^TR_1K_1^{-1}:=A\)</span>被称为“Infinite Homography”，其物理意义有两种解释：</p>
<ul>
<li>图像i中一像素<span class="math inline">\(p_i\)</span>位置确定的光线，其灭点（vanishing point）在图像j下的投影矩阵：<span class="math inline">\(p_j=Ap_i\)</span></li>
<li>可以认为<span class="math inline">\(A\)</span>矩阵就是光线方向在两个相机之间的变换矩阵</li>
</ul>
<p>​ 我们暂且拿公式<span class="math inline">\(\eqref{homo1}\)</span>来玩一玩，看看它能推出一些什么有趣的理论。我们可以从理论上证明：</p>
<blockquote>
<p>双目匹配中，经过rectification的两张图像，correspondence search只需要在水平方向上进行。</p>
</blockquote>
<p>​ 看起来... 好无聊的理论。不过我仍然要来试一下：首先假设双目的相机内参一致，也即<span class="math inline">\(K_1=K_2\)</span>，并且若是经过校准（外参也经过标定）的双目相机，应有：<span class="math inline">\(R_1=R_2\)</span> 以及 <span class="math inline">\(C_1\)</span>与<span class="math inline">\(C_2\)</span>在相机z轴坐标上一致（其一的光心在另一相机的xy平面上），那么由公式<span class="math inline">\(\eqref{homo1}\)</span>，可以推出： <span class="math display">\[
\begin{equation}
z_2p_2=z_1(I)p_1+K_2R_2^T(C_1-C_2)
\end{equation}
\]</span> ​ 由于相机z轴坐标以及方向均一致，故对于同一个点，<span class="math inline">\(z_1=z_2\)</span>，而<span class="math inline">\(K_2R_2^T(C_1-C_2)\)</span>只有x轴方向不为0，故可以知道： <span class="math display">\[
\begin{equation}
p_2=p_1+\alpha v_x,\text{ in which }v_x \text{ only has x component}
\end{equation}
\]</span> ​ 这也就说明了标定后的双目只需水平进行correspondence search。</p>
<h3 id="对极约束与基础矩阵">2.3 对极约束与基础矩阵</h3>
<p>​ 2.2中实际上我们已经得到了一个重要的矩阵<span class="math inline">\(A\)</span>，用于进行灭点的映射。当然，这部分只是重要公式<span class="math inline">\(\eqref{homo1}\)</span>的一部分，观察公式<span class="math inline">\(\eqref{homo1}\)</span>的第二部分<span class="math inline">\(K_2R_2^T(C_1-C_2)\)</span>，不难发现，这部分是将世界坐标点<span class="math inline">\(P\)</span>用<span class="math inline">\(C_1\)</span>带入到公式<span class="math inline">\(\eqref{second}\)</span>中，也即<span class="math inline">\(C_1\)</span>在相机2下的投影。我们将这个投影点<span class="math inline">\(K_2R_2^T(C_1-C_2)\)</span>称为极点（epipole）</p>
<center>
<img src="/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/epi.png" style="zoom:70%;">
</center>
<center>
Figure 3. 相机关系与对极约束[1]
</center>
<p>​ 如图，<span class="math inline">\(e_2\)</span>就是<span class="math inline">\(C_1\)</span>对应相机的极点。而另一个点<span class="math inline">\(Am_1\)</span>（灭点的映射）。而由于公式<span class="math inline">\(\eqref{homo1}\)</span>对应了一个线性映射，并且有两个点已知：</p>
<div class="note "><h5 id="一个结论">一个结论</h5>
<p>我们可以知道，投影在相机1下，并且像素位置为图上<span class="math inline">\(m_1\)</span>位置的所有3D位置点，将会投影在相机2由<span class="math inline">\(e_2\)</span>以及<span class="math inline">\(Am_1\)</span>确定的直线上。</p>
</div>
<p>我们将这条线称为<span class="math inline">\(m_1\)</span>在相机2下的极线（epipolar line）。</p>
<p>​ 我们回过头来看2.2中的双目问题，由于未标定的相机（正如上图所示）是双目相机的一般化：</p>
<blockquote>
<p>Suppose we have two images, taken at the same time and from different viewpoints. Such setting is referred to as <strong><u>stereo</u></strong>.</p>
</blockquote>
<p>​ 在一般的两相机 (stereo) 情形下，进行correspondence search应该是在极线上进行，而标定后的简化双目模型，其极线就是特殊的水平线。由于：</p>
<ul>
<li>极点（如<span class="math inline">\(e_2\)</span>）根据定义，由于其在<span class="math inline">\(C_2\)</span>所在的X轴上，投影不存在，可以认为在无穷远处</li>
<li>对于相机1的任意一个位置，其投影灭点投影应该是存在的，但与一个X轴上无穷远点形成连线，可以（intuitively）认为形成的极线是水平的。</li>
</ul>
<p>​ 这也反过来说明了双目问题水平搜索的正确性。</p>
<p>​ 讨论完双目问题之后，再来细致地看一下“<strong><u>一个结论</u></strong>”中说的投影点必须在直线上这一结论。此时我们知道<span class="math inline">\(e_2\)</span>，<span class="math inline">\(m_2\)</span>，<span class="math inline">\(Am_1\)</span>在同一直线上。这能导出什么有用的信息？显然，三者线性相关，列向量组成的<span class="math inline">\(3\times 3\)</span>矩阵缺秩。 <span class="math display">\[
|\begin{pmatrix}
e_2 &amp; Am_1 &amp; m_2
\end{pmatrix}|=0, \text{ where |·| means determinant}
\]</span> ​ 注意上述矩阵<span class="math inline">\((e_2 \quad Am_1\quad m_2)\)</span>每一列的第三分量都是1，并不只是简单的一个二维矩阵。显然，<span class="math inline">\(e_2\)</span>与<span class="math inline">\(Am_1\)</span>确定的平面法线垂直于<span class="math inline">\(m_2\)</span>：</p>
<center>
<img src="/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/draw.jpg" style="zoom:45%;">
</center>
<center>
Figure 4. 外积与垂直关系
</center>
<p>​ 用goodnote随便涂了两笔，其中蓝色，红色以及黑色线才是真正的向量。由于外积可以写为反对称矩阵形式，也即： <span class="math display">\[
\begin{equation}
a\times b=[(a_1\quad a_2\quad a_3)^T]\times b=[a]_\times b=\begin{pmatrix}
0 &amp; -a_3 &amp; a_2 \\
a_3 &amp; 0 &amp; -a_1 \\
-a_2 &amp; a_1 &amp; 0
\end{pmatrix}b
\end{equation}
\]</span> ​ 则可以得到： <span class="math display">\[
\begin{equation}
|\begin{pmatrix}
e_2 &amp; Am_1 &amp; m_2
\end{pmatrix}|=0\iff m_2^T([e_2]_\times Am_1)=0\rightarrow m_2^T([e_2]_\times A)m_1=0
\end{equation}
\]</span> ​ 我们把矩阵<span class="math inline">\([e_2]_{\times}A\)</span>称为：基础矩阵（fundamental matrix）(<span class="math inline">\(F\)</span>)，其限定了由对极约束的两个图像点之间的关系。</p>
<hr>
<h2 id="iii.-eccv-2020-atlas">III. ECCV 2020: Atlas</h2>
<p>​ 最终重建基于TSDF (truncated-SDF)。网络主要结构：</p>
<p><img src="/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/atlas.png"></p>
<center>
Figure 5. 大力神的网络结构
</center>
<p>​ 经过流程主要是：</p>
<ul>
<li>2D特征提取，提取每张图像点的特征。</li>
<li>特征反投影，也就是由2D变为3D。这个反投影过程基于：
<ul>
<li>空间voxelize，作者称之为feature volume</li>
<li>相机模型，将一个点的特征投至与其关联光线穿过的所有voxel（如果我没理解错的话）</li>
</ul></li>
<li>增量融合：一张一张图像叠在一起，形成的feature volume <strong><u>变换到统一世界坐标系下</u></strong> 增量叠加。</li>
<li>形成一个dense的feature volume，这点我简单说一下：</li>
</ul>
<center>
<img src="/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/sketch.png" style="zoom:40%;">
</center>
<center>
Figure 6. 相机在volume中反投影示意图1（sketchup 2015）
</center>
<p>​ 由于每张图像都会形成一个volume，比如蓝色的为相机于位置1全局volume中得到的反投影，红色为相机在位置2下于全局volume中得到的反投影，为了方便观察，我将两者分开（实际上全局只存在一个灰色的volome），两者叠加：</p>
<center>
<img src="/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/sk2.png" style="zoom:50%;">
</center>
<center>
Figure 7. 相机在volume中反投影示意图2（sketchup 2015）
</center>
<p>​ 其中有些部分会有叠加，并且如果：某一部分在位姿1下观测到（在蓝色frustum内），并且也在位姿2下观测到（红色frustum内），由加权running average，特征会被保留，如果某些特征只在辆frustum的对称差集内（只有一个位姿有观测），那么加权平均将会弱化这些特征的存在性（毕竟如果在很多帧的情况下，某个位置都只被一个位姿观测到，那么大概率这个位置被遮挡了或者是一些不重要的角落）。根据加权平均（原文公式(3)(4)），观测点越少，特征越不显著（幅值越接近0）。</p>
<ul>
<li>下一步是3D encoder-decoder模型，使用了<span class="math inline">\(3\times3\times3\)</span>卷积以及<span class="math inline">\(1\times1\times 1\)</span>卷积（用于特征维度的变换），关于3D卷积的一点点分析，见此PDF：[TODO]
<ul>
<li>形状还是类似bottleneck</li>
</ul></li>
<li>作者在此处用了以下一些手段来保证训练的效果，因为这一部分直接回归TSDF（事关结果质量）：
<ul>
<li>encoder-decoder模型由于有bottleneck形状，上采样过程中每层都会输出TSDF，在不同精细度下与ground truth进行对比监督</li>
<li>TSDF中的“Focal loss”，由于3D重建中存在大量empty space，对训练其实没有帮助，TSDF距离大于0.99者被强制设为1，并且阻断反向的梯度流动，这样这些voxel对结果将不产生影响</li>
<li>惩罚墙中墙等现象，由于重力存在，3D重建简单场景时，竖直方向是可以整体来看的，比如对于一座简单的山（没有空洞，没有大于等于90度的峭壁），一整个voxel volume中，对于平面上任意竖列voxel，一定是下部存在voxels（山），上部不存在（空气）。并且由于TSDF重建是用marching cubes寻找等势面，重建的voxels只存在于表面，内部应该也不会有。故在这种简单情形下，我们可以认为，每一列就仅应该存在一个点（表示简单山表面）。</li>
<li>上面的意思就是说：如果在这座假想的简单山<strong><u>内部</u></strong>进行采样，由于内部是不存在表面重建的voxel的（空的），我们的重建不应该在对应位置增加一个 墙中点。</li>
</ul></li>
</ul>
<blockquote>
<p>However, to prevent the network from hallucinating artifacts behind walls, outside the room, we also mark all the voxels where their entire vertical column is equal to 1 and penalize in these areas too. The intuition for this is that if the entire vertical column was not observed it was probably not within the room.</p>
</blockquote>
<p>​ 不过笔者认为，关于“artifacts behind walls”这一部分，个人的解释还有一定问题（感觉有点强行解释），而网络上也无法找到对应的资料，如有人刚好读到此处并且有自己的理解，还望不吝赐教。</p>
<p>​ 所以其中重要的部分是？个人认为是这么两部分：</p>
<ul>
<li>2D特征反投影及加权平均融合：这一步真正生成了可用的feature volume</li>
<li>3D特征encoder-decoder：对于feature volume的重映射，并生成多尺度信息</li>
</ul>
<p>​ 其中feature volume生成有点意思，但个人认为可能这种正向的（2D-&gt;3D）资源消耗更大，毕竟每张图像都对应了一个feature volume（虽然是增量的叠加）。</p>
<hr>
<h2 id="iv.-nips-2021-transformerfusion">IV. NIPS 2021: TransformerFusion</h2>
<p>​ 在上一小节末，我提到：<strong><u>正向的</u></strong>方法，其实我个人并没有看多少篇多视角3D重建的文章，也不知道是否有对应方法的分类。此文的特点就是：使用了反向的方法（3D-&gt;2D），并且使用了transformer（但个人感觉这里用transformer可能有些缺点，之后再说）。</p>
<p><img src="/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/trans.png"></p>
<center>
Figure 8. TransformerFusion主要结构
</center>
<p>​ 基于DL的方法开始总是离不开特征学习，至于怎么使用，这是不同的网络架构需要考虑的事情。</p>
<p>​ 此文并没有使用层级，只是分成了coarse以及fine两部分，层与层之间在处理的较后部分才存在联系。其中要说的是transformer的 <strong><u>反向法</u></strong>。关于本文使用的tricks，个人不想再多说，什么free-space filtering（用类似于第三节说的“Focal loss”）以及refinement network，感觉大多数工作都会有。本节只想着重讨论此文方法与ECCV 2020方法的区别，以及其transformer的使用优劣之处。</p>
<p>​ 与正向法相对，反向法对于每张图像上的特征并不直接反投影到全局的feature volume再进行求和（平均），反向法处理的视点是每一个3D voxel。在一个全局volume中，对于一个特定的voxel <span class="math inline">\(v\)</span>，我在不同的图像中查找：</p>
<ul>
<li>此voxel在经过投影后，是否落在图像中？如果不再就跳过，如果在，将会选取本图像投影点附近的特征（根据线性插值）</li>
</ul>
<p>​ 正向法中是2D-&gt;3D信息流，使用反投影正向计算。而反向法是3D-&gt;2D的 <strong><u>查找</u></strong> 方式。从个人的感受上而言，笔者认为反向法更加优雅。</p>
<p>​ 另一方面，transformer具体做了什么？对于任意一个重建voxel，不同图像拍摄得到的信息对此voxel的贡献肯定是不一样的，比如我要重建你的鼻子，那么距离近并且角度合适的图像学习的特征大概率比距离远或角度不合适图像产生的特征更加有价值。<strong><u>不同图像对某一点特征的贡献度</u></strong> 将由transformer来评定。</p>
<p>​ transformer不仅仅输出【经过attention机制评定贡献度】融合的多张图像特征，还输出softmax时的概率（也就是每张图像的贡献weight），这是为了进行 <strong><u>视角选择（view selection）</u></strong>。看到这里，我感觉到一阵莫名的亲切，这不就是2D SLAM里的点云融合吗？所以这也成了我认为本文存在的不足之处。</p>
<h5 id="transformer-pros-cons">Transformer Pros &amp; Cons</h5>
<div class="tabs" id="span-unique"><ul class="nav-tabs"><li class="tab active"><a href="#span-unique-1">Pros</a></li><li class="tab"><a href="#span-unique-2">Cons</a></li></ul><div class="tab-content"><div class="tab-pane active" id="span-unique-1"><p>​ Transformer确实应该用，【贡献不同】这点从直觉上就很正确，与其使用别的方法进行学习，不如直接加attention，此处也非常适合attention操作。ECCV 2020一文中，对于不同视角下的特征，并没有明显的区分性，可以说是一视同仁，如果要说3D CNN进行了一些取舍，未免有些牵强。ECCV 2020中，如何区分significance，成了非常魔法的一部分。</p></div><div class="tab-pane" id="span-unique-2"><p>​ Transformer是<span class="math inline">\(O(n^2)\)</span>的，并且如果要深究，此处应该用Set Transformer这样置换不变的网络（并且人家Set Transformer至少还用induced point方法降低了复杂度）。而若要限制复杂度，就可以用 <u><strong>队列</strong></u> 的方式，我只需要保存不超过<span class="math inline">\(N\)</span>张图片，算法就不会越跑越慢了。但这其实也不太爽，对于每一个voxel，我需要维护的是一个小顶堆。由于本网络输出每张图像的weight，根据weight选择，超出堆大小就drop堆顶weight最小的图像特征。这样的话，烦人的就是管理的复杂度了，相比之下attention复杂度可能还小些？如果考虑一整个feature volume，那么复杂度就是<span class="math inline">\(O(n^3N(C+1))\)</span>，其中n是volume大小，<span class="math inline">\(N\)</span>是堆大小，<span class="math inline">\(C\)</span>是特征维度，+1表示需要保存weight。</p></div></div></div>
<p>​ 综上，transformer的attention，个人觉得是一个可保留的点，但是transformer带来的overhead个人感觉又是一个不可忽视的问题。至于怎么解决，个人粗略一想只想到 对于feature volume进行pruning（使得feature volume不要是dense的），毕竟<strong><u>3D表面重建</u></strong>，<strong><u>表面表面</u></strong>，重建的是3D空间中的2D流形，存储复杂度在理想情况下应该是<span class="math inline">\(O(n^2)\)</span>的，那么多空区域扔一扔，都留下来的话，简直就是土匪，土匪都不如。</p>
<center>
<img src="/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/disgust.jpeg" style="zoom:80%;">
</center>
<center>
Figure 9. 反正钱肯定是挣不着啦
</center>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://www.nowpublishers.com/article/Details/CGV-007">Foundations and Trends® in Computer Graphics and Vision - Vol 4 - Issue 4: 3D Reconstruction from Multiple Images Part 1: Principles</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>3D重建</tag>
      </tags>
  </entry>
  <entry>
    <title>CNN - Capsule Neural Networks</title>
    <url>/2021/02/20/CNN-Capsule-Neural-Networks/</url>
    <content><![CDATA[<h1 id="capsule">Capsule</h1>
<hr>
<h2 id="preface">Preface</h2>
<p>​ Geoffrey Hinton (他的团队 ? 挂名论文 ? ) 在2017年提出了一种有别与传统深度网络结构的网络。相对于Convolution层纯参数卷积核表示，Capsule网络的基本结构是胶囊，每个胶囊都有表征一定的空间结构的能力。与其说是胶囊网络，个人对这种网络结构的理解是：向量神经网络。本文是对论文 <strong><em>Dynamic Routing Between Capsules</em></strong> <a href="https://arxiv.org/pdf/1710.09829.pdf">【arxiv链接🔗】</a> 的总结，也包含了复现论文中遇到过的问题的分析。</p>
<span id="more"></span>
<hr>
<h2 id="问题理解">问题理解</h2>
<p>​ Capsule网络与普通网络的区别在哪里？普通卷积网络（Convolution）最突出的特点就是，自动特征的提取。但是由于卷积操作的空间对称性，并且在多层卷积后，特征的空间位置信息发生损失，对于需要明确位置信息的特征无法很好地提取。比如说：给定一张人脸照片，如果人脸照片被PS了，五官的空间位置十分奇怪：</p>
<p><img src="/2021/02/20/CNN-Capsule-Neural-Networks/lena.png"></p>
<center>
Figure 1. 惊悚的Lena照片
</center>
<p>​ 对于第二张图像，网络有可能将其分类为“人”，但是实际上这是怪物。而第三章图像，只不过经过了一个旋转，最后的分类结果也可能并不是“人”。我们希望在卷积的处理过程中，仍然保留相对位置信息，但又不想让整个网络变成R-CNN一样的复杂object detection结构。</p>
<p>​ Capsule结构就是为了解决空间位置信息问题提出的。其基本思想是：Capsule结构可以将图像中的一个物体分解，分解成不同的子结构，而子结构又可以由更加低级的子特征通过空间变换组合得到。</p>
<p><img src="/2021/02/20/CNN-Capsule-Neural-Networks/comp.JPG"></p>
<center>
Figure 2. 特征组合
</center>
<p>​ 乍一看，和卷积网络貌似很类似，卷积也是低级特征融合到高级特征图中。但Capsule 特征组合依靠的并不是activation函数进行特征融合，其依靠的是“动态路由”方法。</p>
<hr>
<h2 id="为什么要使用capsule">为什么要使用Capsule</h2>
<h3 id="capsule解决的问题">Capsule解决的问题</h3>
<p>​ 作者在文章中提到：基于HMM-GMM的语音识别方法在神经网络普适之前一直是SOTA方法，但是其致命缺陷是需要的内存空间太大（内存开销是平方级别的复杂度）。RNN网络对于内存的开销则是线性增长级别的，结果会好很多。</p>
<p>​ CNN相对于全连接层也存在这样的内存开销优势：不同位置的参数是共享的。但是在处理存在有特征的空间变换（平移旋转）时，CNN需要有参数的平移副本，才能实现对不同位置的同一特征进行识别。这让我想起了KCF的平移样本生成。KCF在训练时，会将选中目标的部分进行大量平移，以获得足够的多的训练样本。也就是用内存换取训练结果了，也许这在训练样本极其多时不利于训练，并且随着问题规模的变大，这种方法也并不好。并且CNN这种采用参数平移副本识别不同位置的特征的方式，非常不符合生物视觉原理。作者在文中开始就提到：</p>
<blockquote>
<p>Human vision ignores irrelevant details by using a carefully determined sequence of fifixation points to ensure that only a tiny fraction of the optic array is ever processed at the highest resolution.</p>
</blockquote>
<p>​ 处理视觉特征的时候，应该使用一定的Attention机制，使用非复制的参数，获得图上的特征，并使用简单的位置表示，应该是<strong><u>获取特征的移动位置</u></strong>而非<strong><u>移动（式）获取特征的位置</u></strong>。这种复制方法，必然导致参数占用内存的增加。CNN能够很好地处理平移特征（因为卷积的滑动窗口特性），但是对于其他的Affine Transformation（仿射变换），处理能力较差。Capsule本身就是带有空间位姿表征的，这样可以防止指数性的参数内存消耗。</p>
<h3 id="capsule的处理原理">Capsule的处理原理</h3>
<p>​ 在Preface种说到，Capsule网络实际上是向量神经网络。与一般的标量网络不同，Capsule网络每个输出都是向量，并且向量存在其特定的意义：</p>
<ul>
<li>向量的方向代表了其属性。可以将属性空间每个单独的维度理解为一个坐标轴，在某个方向的分量大小代表了此属性的强度（比如反射率 / intensity / 斜度等等）。也即此向量代表了其在参数空间中的位置。</li>
<li>向量的模长代表了概率。反映的是沿着某一方向的特征向量存在的概率。一个Capsule层上的所有胶囊可能对某个特征产生不同的意见，组合特征时希望能让意见一致的概率最大（Routing by agreement）。</li>
</ul>
<p>​ 每个Capsule表示的向量都是一个个的“instantiated parameter”，表征了一个个小组件（也许这样的小组件没有CNN抽取出来的特征那么抽象）。由于特征是不断融合的，底层特征抽取将会抽取出极其多的小型特征。每一层Capsule网络都是对上一层capsule的融合，第k层的capsule输出需要经过一个投票机制，才能被融合到1第k+1层的网络中去。当第k+1层网络存在输出后，从第k层网络选取出与第k+1层某个capsule输出最类似的一个低层capsule，增大其对应权重。</p>
<hr>
<h2 id="网络结构与计算细节">网络结构与计算细节</h2>
<h3 id="向量处理---路由原理">向量处理 - 路由原理</h3>
<p>​ 激活函数并没有被大量使用在Capsule网络中，由于向量网络并不方便使用activation，而且一般激活函数并不能满足上一节提到的：模长的概率表征特性。在此处，作者设计了一个这样的归一化函数，被称作 “<strong><em>squash</em></strong>”： <span class="math display">\[
\begin{equation}\label{equ:squash}
\mathbf{v}_{j} = \frac{\Vert \mathbf{s}_j\Vert^2}{1 +\Vert \mathbf{s}_j\Vert^2}\frac{\mathbf{s}_j}{\Vert \mathbf{s}_j\Vert}
\end{equation}
\]</span> ​ 使用此归一化方法，不仅可以进行长度归一，实际对模长很短的向量存在更大的非线性惩罚。假设第k层网络存在n个capsule filter，第k+1层存在m个capsule filter。那么<span class="math inline">\(\mathbb{u_{i}}\)</span>就是第k层中第i个filter的输出向量，从第k层第i个结构到第k+1层第j个结构的输出可以使用weight matrix映射： <span class="math display">\[
\mathbf{\hat{u}}_{j|i}=\mathbf{W}_{ij}\mathbf{u}_i
\]</span> ​ <span class="math inline">\(\mathbf{W}_{ij}\)</span>用于维数变换，并且需要综合不同的输入得到下一层某个capsule的输入。比如本文中，<span class="math inline">\(\mathbf{W}_{ij}\)</span>就是8 * 16的矩阵。<span class="math inline">\(\mathbf{\hat{u}}_{j|i}\)</span>相当于计算出的先验（上层i送到本层j的一个特征向量）。那么： <span class="math display">\[
\begin{equation}\label{equ:possi}
\mathbf{s}_{j}=\sum_{i=1}^{n}c_{ij}\mathbf{\hat{u}}_{j|i}
\end{equation}
\]</span> ​ 就是综合所有上一层的输出，得到本层第j个capsule的输入，使用<span class="math inline">\(\eqref{equ:squash}\)</span>进行非线性归一化得到<span class="math inline">\(\mathbf{v}_{j}\)</span>。<span class="math inline">\(c_{ij}\)</span>是概率加权因子，是由<span class="math inline">\(b_{ij}\)</span>（一个logit值）经过softmax得到的概率。</p>
<h3 id="动态路由过程">动态路由过程</h3>
<h4 id="内积---投票agreement">内积 - 投票（Agreement）</h4>
<p>​ 动态路由部分包含了激活函数的作用，并且在此处取代了normalization的作用。动态路由主要是为了计算<span class="math inline">\(\mathbf{v}_{j}\)</span>，通过迭代的方式求出概率加权因子，本质上是一个数学性的投票过程。开始生成的<span class="math inline">\(b_{ij}\)</span>都是0，softmax后，所有的输出路径概率都是相同的（均匀分布）。每一个胶囊的输出都相当于是一个带概率（模长）的特征向量prediction。所有的（weight matrix映射的）的组合（概率加权）就是某个高层capsule的输入，高层输出一个归一化后的向量。这个向量只需要与低层的输出向量进行内积即可，内积结果大，表示低层的输出与高层的输出较为符合（两个输出向量的方向较为一致），将会响应增强对应的路由路径。</p>
<p><img src="/2021/02/20/CNN-Capsule-Neural-Networks/vote.JPG"></p>
<center>
Figure 3. 基于内积的投票
</center>
<p>​ 根据几次迭代就可以确定低层/高层的输出一致性关系。</p>
<h4 id="算法流程理解">算法流程理解</h4>
<p>​ 整个动态路由算法流程如下：</p>
<p><img src="/2021/02/20/CNN-Capsule-Neural-Networks/routing.JPG"></p>
<center>
Figure 4. 动态路由算法流程
</center>
<p><strong>翻译与理解：</strong></p>
<ul>
<li>初始化logit值 为0，使得初始的routing路径概率分布为均匀分布。默认已经获得了经过weight matrix变换的先验输出向量。</li>
<li>开始迭代（迭代次数为r，论文中r = 3）
<ul>
<li>softmax 将logit变换为：<span class="math inline">\(c_{i}\)</span>，转换成符合概率定义的值。</li>
<li>计算本层的加权输入：也就是公式<span class="math inline">\(\eqref{equ:possi}\)</span>。计算所有低层prediction对应的高层prediction。</li>
<li>squash操作，非线性归一化。由于内积需要转换成概率，需要squash让模长小于1。</li>
<li>根据两层的输出计算内积，得到logits更新值。</li>
</ul></li>
</ul>
<p>​ 注意，只有两个连续的capsule层才会存在动态路由。由于动态路由是对低层 / 高层capsule连接特性的建模，低层prediction与高层prediction相符时，低层capsule更有可能与相应高层capsule相连。</p>
<h3 id="loss设计">loss设计</h3>
<p>​ Capsule网络在设计时，设计者为了让其拥有同时区分图上多个数字的能力，数字label使用一个长度为10的向量表示（类似one-hot），prediction中，每个位置存分类为对应值的概率。使用的是margin loss（SVM多分类问题使用的就是margin loss），由于鼓励图像多分类输出，margin loss 鼓励输出在0.9（正类）以及0.1（负类）附近，分类使用的margin loss objective为： <span class="math display">\[
\begin{equation}\label{equ:margin}
L_k=T_k\;max(0, m^{+} - \Vert\mathbf{v}_k\Vert)^2+\lambda(1-T_k)min(0, m^{-} - \Vert\mathbf{v}_k\Vert)^2
\end{equation}
\]</span> ​ 提供label时，如果图像中的数字是对应class k，那么<span class="math inline">\(T_k = 1\)</span>，否则为0。可以看出，<span class="math inline">\(T_k\)</span>不同情况下：</p>
<ul>
<li><span class="math inline">\(T_k\)</span>为1时，<span class="math inline">\(L_k=T_k\;max(0, m^{+} - \Vert\mathbf{v}_k\Vert)^2\)</span>，需要让输出的概率大概为0.9（<span class="math inline">\(m^+\)</span>=0.9）</li>
<li>反之，<span class="math inline">\(L_k=\lambda(1-T_k)min(0, m^{-} - \Vert\mathbf{v}_k\Vert)^2\)</span>，负类并不要求概率完全为0。为了多数字判定。(<span class="math inline">\(m^{-}\)</span>=0.1)，λ=0.5（影响削弱）</li>
</ul>
<p>​ 由于这是一个特殊的分类问题，输出会用一个向量表征（长度为16）。那么作者希望，通过16维的特征向量可以重建出原来的数字。作者使用了全连接网络作为decoder：</p>
<p><img src="/2021/02/20/CNN-Capsule-Neural-Networks/fc.JPG"></p>
<center>
Figure 5. 文中使用的全连接decoder
</center>
<p>​ 输入层是160维的，但我对这个的理解是：digitCaps存在mask，非预测值的数字将会被乘以0。那么160维的输入意义在哪？为什么不使用16维作为输入呢？</p>
<p>​ 不讨论这个设计问题的情况下，reconstruction会引入loss（需要让），相当于capsuleNN提取了图像的主要特征（PCA类似，只用几个主要特征值恢复图像），但结果与原图应该尽量接近。（这在CycleGAN中也有类似的操作，不过对应的是Cycle Consistency Loss）。Full objective: <span class="math display">\[
L_{full}=\sum L_k+0.0005 \times L_{reconstruct}
\]</span> ​ 为了不让reconstruction loss造成的优化影响过大，需要将其scale到一个较小的值上。</p>
<hr>
<h2 id="复现-问题">复现 &amp; 问题</h2>
<p>​ 实现CapsNet遇到了比较大的困难，发现自己之前实现的那些网络都比较简单，不需要用到太多的Pytorch tensor特性或是torch的API。于是在本次复现论文时，发现在minibatch情形（高维矩阵计算）下，自己明白逻辑，但是不知如何使用Pytorch完成矩阵计算。显然，将sample一个个计算 / 一维一维计算是可以完成算法的逻辑的，但是这样存在问题：</p>
<ul>
<li>slice / index操作 / 分维度计算（小块矩阵运算）容易导致低下的效率以及内存的消耗</li>
<li>代码变得臃肿，不符合多维矩阵的API设计初衷</li>
</ul>
<p>​ 复现尝试了实现网络结构，但是比较失败（我太菜了）。最后我学习了一下别人的实现，对代码进行了细致的注释：<a href="https://github.com/gram-ai/capsule-networks">[Github Repository🔗:gram-ai/ capsule-networks]</a></p>
<h3 id="实现上的一些点">实现上的一些点</h3>
<p>​ 在实现过程中，主要是Capsule Layer的实现比较困难：</p>
<ul>
<li>nn.ModuleList保存胶囊层的结构，比如保存8个相同的Conv2d Filter。对同一输入处理8次，再使用cat方法连接，产生向量输出。</li>
<li>nn.Parameter 用于 weight matrix的实现。但我对这个环节产生了<a href="#thinking">一些看法</a>。
<ul>
<li>以上这两种方法都可以自动将参数加入继承了nn.Module的类的<code>.parameter()</code>中</li>
</ul></li>
<li>高维矩阵运算 不知如何进行（开始练运算规则都不知道）
<ul>
<li>输入卷积层的输出结果为：(n, 256, 20, 20)，n为batch size</li>
<li>PrimaryCaps每个胶囊输出的结果应该是：(n, 32, 6, 6, 1)。每个输出需要进行ravel（不同的通道，每个通道内的6 * 6输出），得到(n, 1152, 1) cat之后得到(n, 1152, 8)</li>
<li>PrimaryCaps 经过weight matrix之后，输出的prior应该是（shape）:(10, n, 1152, 1, 16):
<ul>
<li><code>x[None, :, :, None, :] @ self.route_weights[:, None, :, :, :]</code></li>
<li>x由(n, 1152, 8) 变为(<strong><u>10</u></strong>, n, 1152, <strong><u>1</u></strong>, 8)，weights(10, 1152, 8, 16)变为：(10, <strong><u>n</u></strong>, 1152, 1, 16)</li>
</ul></li>
</ul></li>
<li>剩下的主要问题就是：
<ul>
<li>一些基本API的使用不够熟练，不知道如何进行sum / transpose / max等等。</li>
<li>矩阵维度应该如何进行变换，才能让一个batch不被index / slice操作分割处理。何时加入一个维度，何时squeeze？应该是经验不足，API使用不熟练的问题。</li>
</ul></li>
</ul>
<hr>
<h2 id="个人看法">个人看法</h2>
<p><span id="thinking"></span></p>
<p>​ 关于CapsuleNet，个人有以下看法：</p>
<ul>
<li>MNIST数据集未免太简单了，这样的实验（虽然作者说，关于Capsule网络只进行浅层的分析）：</li>
</ul>
<blockquote>
<p>The aim of this paper is not to explore this whole space but simply to show that one fairly straightforward implementation works well and that dynamic routing helps.</p>
</blockquote>
<ul>
<li>我感觉好像Capsule没有太过跳脱出Convolution以及BP结构，算是一种网络结构 / 思想方法上的大（great）创新，但是不能算作（radical）的创新</li>
<li>CNN baseline是否太菜了一点？太浅了吧才三层？（可能是MNIST数据集不需要太花的结构）</li>
</ul>
<p></p>
<hr>
<h2 id="appendix-a---pytorch">Appendix A - Pytorch</h2>
<p>​ 记录一下实现过程中的一些基础但是没有重视的点。希望不要做调库侠。</p>
<h3 id="torch矩阵处理">torch矩阵处理</h3>
<h4 id="torch矩阵乘法的规则">torch矩阵乘法的规则</h4>
<ul>
<li>如果只有2D（size长度为2），需要符合矩阵乘法的尺寸对应要求（(m,n) (n, k) -&gt; (m, k)）</li>
<li>高维矩阵，除了最后两个维度之外，矩阵乘法需要满足：其他维度完全对应 条件。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.ones((<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.ones(<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.ones((<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>)) </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = a @ b</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c.shape</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<p>​ 也即，高维为矩阵乘法不变，最后两维满足矩阵乘法条件。在Pytorch矩阵运算的时候，可能出现矩阵维度不对应的情况，可能需要通过添加维度的方式来进行维度对应。比如本论文中，两层capsule层中，weight matrix的乘法操作：</p>
<p>​ 在本实现中，训练集batch <span class="math inline">\(x\)</span>卷积 / PrimaryCaps输出为(n, 32 * 36, 8) （进行了一个ravel操作），<span class="math inline">\(W\)</span> weight matrix是 8 * 16（右乘）的。那么<span class="math inline">\(xW\)</span>导致维度不对应（输出需要到(n, 10, 16)），那么需要增加维度。如果将<span class="math inline">\(x\)</span> 变为(<strong><u>10</u></strong>, n, 32 * 36, <strong><u>1</u></strong>, 8)，<span class="math inline">\(W\)</span>变为(10, <strong><u>n</u></strong>, 32 * 36, 8, 16) (下划线加粗的是增加的对应维度)，就可以让输出为(10, n, 32 * 36, 1, 16)。这恰好符合论文中<span class="math inline">\(\hat u_{i|j}=W_{ij}u_{ij}\)</span>的定义。在Pytorch中，维度增加使用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = x[<span class="literal">None</span>, :, :, <span class="literal">None</span>, :] @ W[:, <span class="literal">None</span>, :, :, :]</span><br></pre></td></tr></table></figure>
<p>​ None用于增加维度。</p>
<h4 id="torch.sum">torch.sum</h4>
<p>​ sum其实是带有两个参数的：</p>
<ul>
<li><code>dim</code> 指定对矩阵第dim维进行sum操作</li>
<li><code>keepdim=False</code> keepdim将会使矩阵尽可能使用原来的维度进行表示。很显然，sum操作会降维（比如一个二维数组求sum之后，就成了一个一维数组）</li>
</ul>
<p>​ 实例：对于<code>torch.FloatTensor(range(16)).view((1, 1, 4, 4))</code>的四个维求sum，输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Only <span class="built_in">sum</span>:  tensor(<span class="number">120.</span>)</span><br><span class="line">Sum dim = <span class="number">0</span>: tensor([[[ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>],</span><br><span class="line">         [ <span class="number">4.</span>,  <span class="number">5.</span>,  <span class="number">6.</span>,  <span class="number">7.</span>],</span><br><span class="line">         [ <span class="number">8.</span>,  <span class="number">9.</span>, <span class="number">10.</span>, <span class="number">11.</span>],</span><br><span class="line">         [<span class="number">12.</span>, <span class="number">13.</span>, <span class="number">14.</span>, <span class="number">15.</span>]]])</span><br><span class="line">Sum dim = <span class="number">1</span>: tensor([[[ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>],</span><br><span class="line">         [ <span class="number">4.</span>,  <span class="number">5.</span>,  <span class="number">6.</span>,  <span class="number">7.</span>],</span><br><span class="line">         [ <span class="number">8.</span>,  <span class="number">9.</span>, <span class="number">10.</span>, <span class="number">11.</span>],</span><br><span class="line">         [<span class="number">12.</span>, <span class="number">13.</span>, <span class="number">14.</span>, <span class="number">15.</span>]]])</span><br><span class="line">Sum dim = <span class="number">2</span>: tensor([[[<span class="number">24.</span>, <span class="number">28.</span>, <span class="number">32.</span>, <span class="number">36.</span>]]])</span><br><span class="line">Sum dim = <span class="number">3</span>: tensor([[[ <span class="number">6.</span>, <span class="number">22.</span>, <span class="number">38.</span>, <span class="number">54.</span>]]])</span><br></pre></td></tr></table></figure>
<p>​ 关于sum，使用时需要搞清楚其作用维度。得到作用维度之后可以进行一系列操作，如：</p>
<ul>
<li>平方后sum，求最后一维的和得到模的平方</li>
<li>对应元素相乘后sum，求对应维度的和得到点积结果</li>
</ul>
<h4 id="torch.transpose">torch.transpose</h4>
<p>​ 参数很好理解：直接transpose针对一般的二维矩阵，只需要<code>a.transpose()</code>即可。但是高维矩阵，transpose提供了两个可选参数：</p>
<ul>
<li><code>dim0</code> and <code>dim1</code> 表示，这两个dim进行互换（实际上可以不理解为transpose，理解为swap）</li>
</ul>
<h4 id="torch.cat">torch.cat</h4>
<p>​ 简单的concatenate函数。存在两个参数：</p>
<ul>
<li>需要concat的矩阵，不可变时使用tuple，可变可以使用list。</li>
<li>dim（进行concat的维度），要么dim是指定的维度，-1显然表示的是最后一维。比如二维矩阵时，dim = 0表示按行方向进行cat，为1时按列方向进行cat。</li>
</ul>
<h4 id="torch.norm">torch.norm</h4>
<p>​ 求范数。对于向量而言，设<code>a</code>为一个tensor。那么<code>a.norm()</code>直接调用输出2-范数。可以带参数：</p>
<ul>
<li>p = order，其实就是p-范数。1就是绝对值，2就是欧几里得。</li>
<li>dim（可以是int或者tuple）。torch的维度操作确实容易让人困惑。个人的理解是：传入的dim用于组织元素，对需要组织的维度进行范数计算。比如：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.arange(<span class="number">16</span>).view(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">tensor([[[[ <span class="number">0.</span>,  <span class="number">1.</span>],</span><br><span class="line">          [ <span class="number">2.</span>,  <span class="number">3.</span>]],</span><br><span class="line">         [[ <span class="number">4.</span>,  <span class="number">5.</span>],</span><br><span class="line">          [ <span class="number">6.</span>,  <span class="number">7.</span>]]],</span><br><span class="line">        [[[ <span class="number">8.</span>,  <span class="number">9.</span>],</span><br><span class="line">          [<span class="number">10.</span>, <span class="number">11.</span>]],</span><br><span class="line">         [[<span class="number">12.</span>, <span class="number">13.</span>],</span><br><span class="line">          [<span class="number">14.</span>, <span class="number">15.</span>]]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.norm(p = <span class="number">1</span>, dim = (<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">tensor([[ <span class="number">6.</span>, <span class="number">22.</span>],</span><br><span class="line">        [<span class="number">38.</span>, <span class="number">54.</span>]])</span><br></pre></td></tr></table></figure>
<p>​ 可以看出，torch将tensor a的2 / 3维度进行合并，相当于[[a, b], [c, d]]，其中a为元素[[0, 1], [2, 3]]。求1-范数即求绝对值之和。需要组织（整合成一个元素）的维度为(2, 3)。二维的例子会更加容易明白。</p>
<ul>
<li>keepdim 和sum一样，norm操作也是降维的。</li>
</ul>
<h4 id="torch.max-min">torch.max / min</h4>
<p>​ max/min是存在参数的：<code>dim</code>以及<code>keepdim</code>。dim参数会指定：max/min操作进行的维度。比如一个二维矩阵： <span class="math display">\[
A=
\begin{pmatrix}
1 &amp; 2 &amp; 3 \\
4 &amp; 5 &amp; 6 \\
7 &amp; 8 &amp; 9
\end{pmatrix}
\]</span> ​ 如果指定A.max(dim = 0)，指定在0维度（行）方向上求最大值，也就是每一列（沿着行变化方向）求最大。输出是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.return_types.<span class="built_in">max</span>(values=tensor([<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]), indices=tensor([<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]))</span><br></pre></td></tr></table></figure>
<p>​ 可以使用解包的方式，左值使用逗号分割。默认情况下会求全局最大值。</p>
<h4 id="torch.argmax-argmin">torch.argmax / argmin</h4>
<p>​ 其实max已经可以输出最大值最小值对应的位置了。arg系列可能稍微快一些，因为不用返回值。dim / keepdim用法与max/min是一致的。</p>
<h4 id="torch.index_select">torch.index_select</h4>
<p>​ 相当于切片的集成。help中说得很清楚，index_select就是用于取出矩阵中某些元素 / 行列 / 维度的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([[ <span class="number">0.1427</span>,  <span class="number">0.0231</span>, -<span class="number">0.5414</span>, -<span class="number">1.0009</span>],</span><br><span class="line">        [-<span class="number">0.4664</span>,  <span class="number">0.2647</span>, -<span class="number">0.1228</span>, -<span class="number">1.1068</span>],</span><br><span class="line">        [-<span class="number">1.1734</span>, -<span class="number">0.6571</span>,  <span class="number">0.7230</span>, -<span class="number">0.6004</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>indices = torch.tensor([<span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.index_select(x, <span class="number">0</span>, indices)</span><br><span class="line">tensor([[ <span class="number">0.1427</span>,  <span class="number">0.0231</span>, -<span class="number">0.5414</span>, -<span class="number">1.0009</span>],</span><br><span class="line">        [-<span class="number">1.1734</span>, -<span class="number">0.6571</span>,  <span class="number">0.7230</span>, -<span class="number">0.6004</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.index_select(x, <span class="number">1</span>, indices)</span><br><span class="line">tensor([[ <span class="number">0.1427</span>, -<span class="number">0.5414</span>],</span><br><span class="line">        [-<span class="number">0.4664</span>, -<span class="number">0.1228</span>],</span><br><span class="line">        [-<span class="number">1.1734</span>,  <span class="number">0.7230</span>]])</span><br></pre></td></tr></table></figure>
<p>​ dim 用于视角选择。dim = 0时，说明当前index是基于行的，一次取出n行。dim = 1则相对于列进行讨论。</p>
<h4 id="torch.squeeze-unsqueeze">torch.squeeze / unsqueeze</h4>
<ul>
<li><code>squeeze</code> 去除所有维度为1的多于维度。dim用于指定哪些维度可以被操作。
<ul>
<li>squeeze返回一个与原矩阵共享内存的矩阵（相当于一个ref）</li>
<li>squeeze可能会在batch训练中，将batch_size = 1造成的第四维将为三维。</li>
</ul></li>
<li><code>unsqueeze</code> 就是增加一个维度（为1）。参数与squeeze一致。</li>
</ul>
<h4 id="的作用">“-1”的作用</h4>
<p>​ 与矩阵乘法中使用None做索引类似，-1在torch中也有很多作用。比如最常用的：</p>
<ul>
<li>a.view(1, -1)与a.view(-1, 1)。此处-1表示，由系统自主确定此处的值，-1称为推测。但是只有一维可以被推测，高于1维没办法确定性推测。但-1还是有一些奇怪的使用：</li>
<li>sum(dim = -1) 此处是什么意思？这与-1作为索引一致。-1为最后一个，则选择最后一维进行sum操作。通常为列操作。</li>
</ul>
<hr>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title>A Duality Problem of Representations</title>
    <url>/2021/11/14/A-Duality-Problem-of-Representations/</url>
    <content><![CDATA[<h1 id="duality">Duality</h1>
<hr>
<h2 id="i.-introduction">I. Introduction</h2>
<p>In a slide talking about 3D geometry and deep learning, I found something interesting: one question, of which I can not get rid. This is a duality question about representations:</p>
<center>
<img src="/2021/11/14/A-Duality-Problem-of-Representations/dual.png" style="zoom:60%;">
</center>
<center>
Figure 1. Duality problem formulation
</center>
<p>These problems lingered in my head:</p>
<ul>
<li>Why and how we can regard probability distribution and particle filters as dual counterparts to each other?</li>
<li>Same question for occupancy map and point clouds, as they seem to be, according to the figure above, the representations under different specifications?</li>
</ul>
<p>So I took some time to sink in this problem. This post is therefore the summarization of my thoughts.</p>
<span id="more"></span>
<hr>
<h2 id="ii.-about-two-specifications">II. About two specifications</h2>
<p>​ Eulerian and Lagrangian specifications are just two perspective of perceiving the world. Wikipedia illustrate these two specs with a good example (though it is talking about flow field):</p>
<blockquote>
<p>The <strong><u>Lagrangian</u></strong> specification of the flow field is a way of looking at fluid motion where the observer follows an individual fluid parcel as it moves through space and time. Plotting the position of an individual parcel through time gives the pathline of the parcel. This can be visualized as sitting in a boat and drifting down a river.</p>
</blockquote>
<blockquote>
<p>The <strong><u>Eulerian</u></strong> specification of the flow field is a way of looking at fluid motion that focuses on specific locations in the space through which the fluid flows as time passes. This can be visualized by sitting on the bank of a river and watching the water pass the fixed location.</p>
</blockquote>
<hr>
<h2 id="iii.-thoughts">III. Thoughts</h2>
<p>You will find that this description is kind of similar to the famous "<strong><u>Wave–particle duality</u></strong>" . Somehow, the brilliant physicians device the idea of probability and "uncertainty", representing any given location of the physical world with the probabilities of different kinds of particles being present (since we know that in physics, electrons are actually a "probability cloud" around the nucleus), which resembles to occupancy grid representation. However, another intuitive representation of the world is that: The world composes of myriads of small individual particles. Now this is kind of like the point clouds, yet in the real world, the "point clouds" are much denser and complex.</p>
<p>This would mean that, (by my understanding):</p>
<ul>
<li>Eulerian specification tends to directly model the space (no matter what space this is), for each location within the interested space, we model the attributes (e.g. temporal or probabilistic) of it.</li>
<li>Lagrangian specification uses individual attention, or to say, the nonparametric, sampling-like approach to represent the interested space.</li>
</ul>
<p>Therefore, the duality between probability distribution and particle filters are quite straight forward:</p>
<div class="note info"><p>Probability distribution comes in many forms. There are basically two types: parametric and nonparametric. By "probability distribution" mentioned above, I mean the <strong><u>parametric approach</u></strong>.</p>
</div>
<p>The salient feature of parameterized approaches is: They are commonly defined on a fixed space, in this "fixed space", we can calculate the pdf of this distribution. However, nonparametric approaches are "sample-based", for example: KDE (kernel density estimation) and particle filters. For the former one, given location and parameters, the probabilistic attributes are fixed, yet for the latter one, the given location might just be "void" in terms of samples, therefore the information of the given location is subject to all the particles and every individual matters! The focus is different, one is on the fixed location in the space, and the other is on each individual. This is just the characteristic of <strong><u>parameterized distribution</u></strong> and <strong><u>particle filter method</u></strong>.</p>
<p>Say, if we have all the correct poses and transformations between the frames (point clouds), we now have two choices of map representation: Grid map (or voxel map) vs. point-clouds (and its variants like the representation I've been working on). For each grid (voxel) in the map, the focus given is "Eulerian", since we focus on the specific location. As for point clouds, it (yes I am not going to use plural) can be seen as the "particle filters" of walls and obstacles, which is sample-based and "Lagrangian".</p>
<hr>
<h2 id="iv.-can-we-dig-deeper">IV. Can we dig deeper?</h2>
<p>Now we know that, point cloud (and its variants) representations are the dual counterpart of occupancy map, yes but... what is the point? How this is going to help us? Let's talk about the merge of observations!</p>
<div class="note warning"><p>Formulation: the example of <u><strong>merge</strong></u> is that, if we observe a wall in one frame and in the successive frames we observed the same wall. Since we have the correct transformation, how we going to use the multi-view observation to get a more accurate wall?</p>
</div>
<p>For Eulerian method like occupancy grid, merge process is naturally incremental! Because Eulerian methods explicitly models each location, given the correct point cloud registration result, the update of occupancy grid is easy (using LiDAR model and the idea of "beam hitting the obstacles").</p>
<p>Unfortunately, merge for Lagrangian approaches is difficult to tackle with. The main goal is to build a incremental merge algorithm. Intuitively, merge for nonparametric approaches usually requires "total rebuild". For instance, consider every observed wall a particle filter. Every new observation might add new information to each particle filter, therefore for the final state a particle filter represents, we might need to calculate the updated stated from the scratch with no previous computation reuse (that what I currently believe). To my current belief, the incremental merge can only be implemented at a coarse-grained level.</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="http://3ddl.cs.princeton.edu/2016/slides/su.pdf">Hao Su (Stanford University): 3D Deep Learning on Geometric Forms, pdf</a></p>
<p>[2] <a href="https://en.wikipedia.org/wiki/Lagrangian_and_Eulerian_specification_of_the_flow_field">Wikipedia: Lagrangian and Eulerian specification of the flow field</a></p>
]]></content>
      <categories>
        <category>Philosophy</category>
      </categories>
      <tags>
        <tag>English</tag>
        <tag>Methodology</tag>
      </tags>
  </entry>
  <entry>
    <title>CNN Style Transfer论文复现</title>
    <url>/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/</url>
    <content><![CDATA[<h2 id="neuralstyle"># NeuralStyle</h2>
<p>My own implementation of CVPR 2016 paper: Image Style Transfer Using Convolutional Neural Networks. This work is, I think, simple but elegant (I mean the paper, not my implementation) with good interpretability.</p>
<ul>
<li>CVPR 2016 OpenAccess Link is here: <a href="https://openaccess.thecvf.com/content_cvpr_2016/html/Gatys_Image_Style_Transfer_CVPR_2016_paper.html">CVPR 2016 open access</a></li>
<li>Personal understanding of this paper [Chinese]: <a href="https://enigmatisms.github.io/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/">Blog of Enigmatisms/CNN Style Transfer论文复现</a></li>
</ul>
<div class="note success"><p>2021.11.15 complement: I have no intention to analyze and explain this paper, because I think it's simple, and I have a deep impression of this, therefore there is no point recording anything on the blog. Original Github Repo: <a href="https://github.com/Enigmatisms/NeuralStyle">Github🔗: Enigmatisms/NeuralStyle</a>. This post is exactly the README.md of the repo.</p>
</div>
<span id="more"></span>
<hr>
<h3 id="to-run-the-code">To run the code</h3>
<p>Make sure to have Pytorch / Tensorboard on your device, CUDA is available too yet I failed to use it (GPU memory not enough, yet API is good to go). I am currently using Pytorch 1.7.0 + CU101.</p>
<p>On Init, it might require you to download pretrained VGG-19 network, which requires network connection.</p>
<hr>
<h3 id="tree---working-directory">Tree - Working Directory</h3>
<ul>
<li>folder <code>content</code>: Where I keep content images.</li>
<li>folder <code>imgs</code>: To which the output goes.</li>
<li>folder <code>style</code>:
<ul>
<li><code>lossTerm.py</code>: Style loss and Content loss are implemented here.</li>
<li><code>precompute.py</code>: VGG-19 utilization, style and content extractors.</li>
<li><strong><code>transfer.py</code></strong>: executable script.</li>
</ul></li>
</ul>
<hr>
<h3 id="a-little-help">A Little Help</h3>
<p>Always run <code>transfer.py</code> in folder <code>style/</code>, using <code>python ./transfer.py -h</code>， you'll get:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">usage: transfer.py [-h] [--alpha ALPHA] [--epoches EPOCHES]</span><br><span class="line">                   [--max_iter MAX_ITER] [--save_time SAVE_TIME] [-d] [-g]</span><br><span class="line">                   [-c]</span><br><span class="line">optional arguments:</span><br><span class="line">  -h, --help            show this help message and exit</span><br><span class="line">  --alpha ALPHA         Ratio of content loss in the total loss</span><br><span class="line">  --epoches EPOCHES     Training lasts for . epoches (for LBFGS)</span><br><span class="line">  --max_iter MAX_ITER   LBFGS max iteration number</span><br><span class="line">  --save_time SAVE_TIME</span><br><span class="line">                        Save image every &lt;save_time&gt; epoches</span><br><span class="line">  -d, --del_dir         Delete dir ./logs and start new tensorboard records</span><br><span class="line">  -g, --gray            Using grayscale image as initialization for generated</span><br><span class="line">                        image</span><br><span class="line">  -c, --cuda            Use CUDA to speed up training</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="requirements">Requirements</h3>
<ul>
<li>Run:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python3 -m pip install -r requirements.py</span><br></pre></td></tr></table></figure>
<p>To find out.</p>
<hr>
<h3 id="training-process">Training Process</h3>
<ul>
<li>Something strange happened. Loss exploded twice (but recovered.). Tensorboard graphs:</li>
</ul>
<p><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/training.JPG"></p>
<p>Therefore, parameter images change like this (Initialized with grayscale image).</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/G_star_71.jpg"></th>
<th style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/G_star_221.jpg"></th>
<th style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/G_star_481.jpg"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/G_chaos_11.jpg"></td>
<td style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/G_chaos_181.jpg"></td>
<td style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/G_chaos_241.jpg"></td>
</tr>
<tr class="even">
<td style="text-align: center;">First few epochs</td>
<td style="text-align: center;">Exploded, for 2th row image</td>
<td style="text-align: center;">Recovered</td>
</tr>
</tbody>
</table>
<hr>
<h3 id="results">Results</h3>
<ul>
<li>CPU training is tooooooo slow. Took me <strong><u>2+ hours</u></strong> for 800 iterations. (i5-8250U 8th Gen @ 1.60Hz)</li>
</ul>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/star.jpg" style="zoom:80%;"></th>
<th style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/content.jpg"></th>
<th style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/G_star_801.jpg"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/chaos.jpg" style="zoom:80%;"></td>
<td style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/content.jpg"></td>
<td style="text-align: center;"><img src="/2021/04/21/CNN-Style-Transfer%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/G_chaos_801.jpg"></td>
</tr>
<tr class="even">
<td style="text-align: center;">Style</td>
<td style="text-align: center;">Content</td>
<td style="text-align: center;">Output(800 Iterations)</td>
</tr>
</tbody>
</table>
<ul>
<li>I've also done the style transfer of Van Gogh's self portrait for my dad, which is not appropriate to display, but worked.</li>
</ul>
<hr>
<h3 id="possible-todos">Possible TODOs</h3>
<ul class="task-list">
<li><input type="checkbox" disabled>
Try adding InstanceNorm into VGG-19 ? Useful ? Meaningful ?</li>
</ul>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>English</tag>
        <tag>knowings</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title>CUDA踩坑实录【1】</title>
    <url>/2021/09/23/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%901%E3%80%91/</url>
    <content><![CDATA[<h1 id="cuda-i">CUDA I</h1>
<hr>
<h2 id="i.-introduction">I. Introduction</h2>
<p>​ 在复现<a href="https://arxiv.org/abs/2104.07516"><strong>A Decomposition Model for Stereo Matching</strong></a>这篇论文的时候，发现其Sparse matching并不是直接的pytorch实现。本来我想直接pytorch了事的，但仔细一思考后觉得虽然反向传播实现不用考虑了，但是整体变得很慢。阅读官方源码发现时看到一些我不太懂的东西，后来我才知道这些是CUDA自定义pytorch算子，是pytorch的CUDA extension。出于以下目的：</p>
<ul>
<li>复习CUDA（特别是在学习完GPU存储结构与计算之后，急需实践）</li>
<li>学习setuptools的使用以及torch的CUDA extension写法</li>
</ul>
<p>​ 我给自己定了一个小型的CUDA任务，与SDF以及marching cubes算法十分相关。项目见<a href="https://github.com/Enigmatisms/CuTorch">[🔗Enigmatisms/CuTorch]</a></p>
<span id="more"></span>
<hr>
<h2 id="ii.-任务设定">II. 任务设定</h2>
<p>​ 在一个800x600的画布内，随机生成一些“泡泡”，这些泡泡在运动过程中应该可以自由地融合。泡泡的融合不是简单地叠加，叠加应当是平滑的。如下图所示：</p>
<p><img src="/2021/09/23/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%901%E3%80%91/bubbles.PNG" style="zoom: 67%;"></p>
<center>
Figure 1. 泡泡融合问题
</center>
<p>​ 每个泡泡对应着2D平面上半径为r，中心为(x, y)的一个圆。那么需要计算：</p>
<ul>
<li>每个泡泡对应圆的SDF，并且将其叠加在一起</li>
<li>设置一个阈值，跨越此阈值的部分将形成边结构（也就是等高线）</li>
</ul>
<p>​ 整个小项目的完整知识在这里：<a href="http://jamie-wong.com/2014/08/19/metaballs-and-marching-squares/">【Jamie Wong: Metaballs and Marching Squares】</a>。写得非常不错，6月份做SDF的点云融合时，曾经参考过其marching cubes的实现方法。本文与具体的算法实现没有太大的关系，因为算法本身非常简单。</p>
<hr>
<h3 id="基础知识">2.1 基础知识</h3>
<h4 id="dims">2.1.1 Dims</h4>
<p>​ grid 与 block是CUDA的分级管理的两个层次，grid相当于是block的集合，而block相当于是thread的集合（或者warp的集合）。但我在写CUDA的时候好像并没有看到warp的直接使用。注意grid与block两者的维度 gridDim以及blockDim 千万别搞混了。对于一个kernel:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">kernel_function &lt;&lt;&lt;A, B&gt;&gt;&gt; ();</span><br></pre></td></tr></table></figure>
<p>​ A指定的是grid的形状，可以是dim3类型，也可以是一个数字（指定block），A是数字的情形很常用，二维图像处理一般可以这么做：A，B分别代表图像的某一个维度。</p>
<p>​ B指定的是block形状，数据类型同理。那么gridDim则反映了A的输入，blockDim反映B的输入，比如：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>)</span></span>;</span><br><span class="line">kernel_func &lt;&lt;&lt;grid, block&gt;&gt;&gt; ();</span><br></pre></td></tr></table></figure>
<p>​ 在kernel内部，会有：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">(gridDim.x, gridDim.y, gridDim.z)=(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>);</span><br><span class="line">(blockDim.x, blockDim.y, blockDim.z)=(<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>);</span><br></pre></td></tr></table></figure>
<p>​ 相应地，blockIdx.x <span class="math inline">\(\in\)</span> [0, gridDim.x ), threadIdx.x <span class="math inline">\(\in\)</span> [0, blockDim.x)。每一个实际的id，其范围是层级式的。block id与grid有关，thread id与block有关。并且也要注意以下的问题：</p>
<blockquote>
<p>Goal: Have enough transactions in flight to saturate the memory bus.</p>
<p>Latency can be hidden by having more transactions in flight. [1]</p>
</blockquote>
<p><img src="/2021/09/23/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%901%E3%80%91/block.png"></p>
<center>
Figure 2. occupancy注意事项（来源<a href="#refs">[1]</a>)
</center>
<h3 id="dynamic-parallelism踩坑">2.2 Dynamic Parallelism踩坑</h3>
<p>​ Dynamic parallelism，我更愿意直观地称之为：nested kernels（嵌套的核函数）。以我自己的代码为例，我尝试了一下嵌套核函数：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">fineGrainedTask</span><span class="params">(<span class="type">const</span> <span class="type">float</span>* <span class="type">const</span> bubbles, <span class="type">const</span> <span class="type">int</span> x, <span class="type">const</span> <span class="type">int</span> y, <span class="type">float</span>* shared_tmp)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> id = threadIdx.x, base = <span class="number">3</span> * id;</span><br><span class="line">    <span class="type">const</span> <span class="type">float</span> cx = bubbles[base], cy = bubbles[base + <span class="number">1</span>], radius = bubbles[base + <span class="number">2</span>];</span><br><span class="line">    shared_tmp[id] = <span class="built_in">signedDistance</span>(x, y, cx, cy, radius);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">calculateSDF</span><span class="params">(<span class="type">const</span> <span class="type">float</span>* <span class="type">const</span> bubbles, <span class="type">const</span> <span class="type">int</span> num, <span class="type">float</span>* output)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> y = threadIdx.x, x = blockIdx.x, id = y * gridDim.x + x;</span><br><span class="line">    <span class="type">float</span> distance = <span class="number">0.0</span>;</span><br><span class="line">    <span class="comment">// fineGrainedTask &lt;&lt;&lt; 1, num &gt;&gt;&gt; (bubbles, x, y, tmp);</span></span><br><span class="line">    <span class="comment">// cudaDeviceSynchronize();</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; num; i++) &#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> base = <span class="number">3</span> * i;</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span> cx = bubbles[base], cy = bubbles[base + <span class="number">1</span>], radius = bubbles[base + <span class="number">2</span>];</span><br><span class="line">        distance += <span class="built_in">signedDistance</span>(x, y, cx, cy, radius);</span><br><span class="line">    &#125;</span><br><span class="line">    output[id] = distance - <span class="number">1.0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 第二个函数 <code>__global__ void calculateSDF</code> 是主核函数。其目的是求二维矩阵中每一个点(i, j)的SDF值。而显然，每次输入的泡泡数量(num)可以很大，那么内部求signed distance的for循环，应该是可以并行化的。第一个函数<code>__global__ void fineGrainedTask</code> 就是为了做这样的并行，在第十行也被调用了（num路并行，使用__shared__保存临时的结果）。</p>
<p>​ CUDA在 architecture 35以及之后就支持这种nested的dynamic parallelism结构，允许核函数内部调用核函数，因为确实也是会有层次并行的需求的。</p>
<div class="note danger"><center>
<h3>
但是CUDA dynamic parallelism + Python却有一大堆坑
</h3>
</center>
</div>
<p>​ 假如只是使用CUDA + CPP进行嵌套核函数的编写，虽然有点小坑，但是很快就能过编译：</p>
<p>​ Dynamic parallelism需要separate compilation，CMake里面有很简单的设置：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set_property</span>(CUDA_SEPARABLE_COMPILATION <span class="keyword">ON</span>)</span><br></pre></td></tr></table></figure>
<p>​ 但需要注意两点：</p>
<ul>
<li>separate compilation需要指定arch：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-gencode=arch=compute_35,code=sm_35</span><br></pre></td></tr></table></figure>
<ul>
<li>nvcc编译的时候，会指定：<code>-lcudadevrt -lcudart</code>，在/usr的某个文件夹下有一个动态库(libcudart.so)以及一个静态库（我的设备上是静态库：cudadevrt.a）。不方便设置这两个编译flag的时候，在target_link_libraries中可以手动链接。</li>
</ul>
<p>​ 但是Python setuptools编译并没有那么友好。首先我也知道我需要进行separate compilation，所以我需要指定：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">setup(</span><br><span class="line">    name=<span class="string">&#x27;march&#x27;</span>,</span><br><span class="line">    ext_modules=[</span><br><span class="line">        CUDAExtension(<span class="string">&#x27;march&#x27;</span>, [</span><br><span class="line">                <span class="string">&#x27;src/marchingCubes.cu&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;src/sdf_kernel.cu&#x27;</span>,</span><br><span class="line">            ],</span><br><span class="line">            include_dirs=[include_dirs],</span><br><span class="line">            extra_compile_args=&#123;<span class="string">&#x27;cxx&#x27;</span>: [<span class="string">&#x27;-g&#x27;</span>,</span><br><span class="line">            ],</span><br><span class="line">                <span class="string">&#x27;nvcc&#x27;</span>: [<span class="string">&#x27;-O3&#x27;</span>, <span class="string">&#x27;-use_fast_math&#x27;</span>,</span><br><span class="line">                 <span class="comment">################# Here #############</span></span><br><span class="line">				<span class="string">&#x27;-rdc=true&#x27;</span>, <span class="string">&#x27;-gencode=arch=compute_35,code=sm_35&#x27;</span></span><br><span class="line">            ]&#125;,</span><br><span class="line">        )</span><br><span class="line">    ],</span><br><span class="line">    cmdclass=&#123;</span><br><span class="line">        <span class="string">&#x27;build_ext&#x27;</span>: BuildExtension</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p>​ <code>-rdc=true</code>貌似和<code>-dc</code>作用差不多。还需要手动指定一下架构代数，默认好像是一个很小的代。好，不要忘了增加<code>-lcudadevrt</code>以及<code>-lcudart</code>以“保证”可以链接到CUDA的一些库。</p>
<p>​ 看起来很简单，编它。编译通过，很好，跑它。首先import torch（由于本项目C++内部使用了libtorch，里面的libc10.so需要torch导入，不先import的话会报错）。再import march（我的库名称），这一步直接死掉：</p>
<blockquote>
<p>什么什么undefined symbol，与CUDA库相关。</p>
</blockquote>
<p>​ 大概意思就是：<code>cudadevrt.a</code>你根本没有链接上，里面还有一些函数定义呢。好家伙，python的所有库都是动态加载的，你一个静态库你叫我怎么加载（简单的方法就是：(1) 重新编译静态库为动态库 (2) 编译整个项目为一个extension，具体原理我也不懂）？我还指望你直接给我编译到march这个库里面呢。</p>
<p>​ 尝试了很多方法，无论是在C++ 编译flags里面链接，还是nvcc flags，还是stackoverflow上说的所谓：setup函数的extra_compile_objects参数，没有一个有效果的。</p>
<p>​ 我也尝试过手动分别编译：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nvcc -O3 -use_fast_math -gencode=arch=compute_70,code=sm_70 -dc -I/opt/libtorch/include/ -I/opt/libtorch/include/torch/csrc/api/include/ -I//usr/include/python3.6m src/sdf_kernel.cu src/marchingCubes.cu -Xcompiler -fPIC </span><br><span class="line">nvcc -O3 -use_fast_math -gencode=arch=compute_70,code=sm_70 -dlink -L/usr/local/cuda-10.1/targets/x86_64-linux/lib/ -lcudadevrt -lcudart sdf_kernel.o marchingCubes.o -shared -o libdlink.so</span><br></pre></td></tr></table></figure>
<p>​ 想把两个cuda文件编译跟原有的静态动态库一起编译成一个动态库，但是中途报了有关fPIC的错误，说是这样编译是不被允许的，反正不是那种很简单的错误。。。搞了半天，无果。各种问题都出了，最后我甚至都怀疑是编译器的bug（自信！）。最后貌似在CUDA forum的某个地方看见有人说，Python现在对这个的支持还不是特别好，就弃坑了。</p>
<p>​ 最后一个小坑就是：tmd不要随便用很高的代数！不知道为什么，我在setup函数nvcc参数设置时，定代数为：<code>-gencode=arch=compute_70,code=sm_70</code>。结果跑结果的时候，输出图像一片漆黑。最后查出来结果是：<strong><u>核函数根本没有被执行，跳过了</u></strong>，开始我以为出了内存问题（老 千（次）越（界）了）（PS：CUDA runtime出错可能导致核函数不执行），写了个CUDA错误检查，发现完全没有错误。最后灵光一闪，我把代数改成了35，好了。。。</p>
<p>​ 感觉被坑死了。原本预计一个下午解决，结果因为grid/block搞混，结果错误，多调了3小时，又因为dynamic parallelism，多调了6小时。</p>
<p>​ 菜，或许就是这样的吧？</p>
<p>​ 完整的项目以及结果见<a href="https://github.com/Enigmatisms/CuTorch">[🔗Enigmatisms/CuTorch]</a></p>
<hr>
<h2 id="reference">Reference</h2>
<p><span id="refs"></span></p>
<p>[1] <a href="https://on-demand.gputechconf.com/gtc-express/2011/presentations/cuda_webinars_WarpsAndOccupancy.pdf">CUDA Warps and Occupancy</a></p>
<p></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>GPU</tag>
        <tag>CUDA</tag>
      </tags>
  </entry>
  <entry>
    <title>CUDA踩坑实录【2】</title>
    <url>/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/</url>
    <content><![CDATA[<h1 id="cuda-ii">CUDA II</h1>
<hr>
<h2 id="i.-introduction">I. Introduction</h2>
<p>​ CUDA十分有趣。因为我基本就是做算法和软件的，所以对于计算机体系结构，硬件设计等等了解得不多。尽管个人这方面知识有限，我仍然觉得这方面知识十分必要。Profiler能帮助我们在数据驱动的形式下优化代码，但并不会有助于我一开始就写出高质量、符合相应设备特性的代码。而深入了解CUDA对理解计算机内部一些底层的实现非常有帮助，比如说：内存访问，存储结构，流水线设计，带宽利用... 等等。</p>
<p>​ 为了进一步精进CUDA技术，我又设计了一个新的项目：粒子滤波加速。本来是想给之前的<a href="https://enigmatisms.github.io/2021/08/07/Particle-Filter-Simulation/">【Particle Filter Simulation】</a>这篇博文中使用的Volume2D算法进行加速，但做着做着就发现该算法不适合加速，遂推倒重来，重构的过程中学习了很多新的知识。整个项目作为 <strong><u>激光雷达仿真器LiDARSim2D</u></strong>的一个补充模块，现在更新在了<a href="https://github.com/Enigmatisms/LiDARSim2D">[仿真器repo：LiDARSim2D]</a>下。</p>
<p><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/pic1.png"></p>
<center>
Figure 1. 粒子广场
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-pf-gpu管线">II. PF-GPU管线</h2>
<h3 id="之前的算法">2.1 之前的算法</h3>
<p>​ 之前的粒子滤波基于Volume2D算法，主要问题有两个：</p>
<div class="tabs" id="algos"><ul class="nav-tabs"><li class="tab active"><a href="#algos-1">速度慢</a></li><li class="tab"><a href="#algos-2">二维定位</a></li></ul><div class="tab-content"><div class="tab-pane active" id="algos-1"><p>不是说Volume2D算法慢，Volume2D算法虽然是性能瓶颈，但是单次也能只花0.2ms就算出结果来。而问题是，粒子滤波需要计算成千上万次，0.2ms在2000粒子的情况下，经过8线程加速，也就大概6fps的样子，远远达不到实时性要求。</p></div><div class="tab-pane" id="algos-2"><p>前一版算法，只对2D（x,y）进行了定位，这存在两个问题：</p>
<ul>
<li>旋转这个维度，虽然相对平移来说只有一维，但是其对结果的影响一般来说都更大。（旋转导致视角变化，视角变化导致观测可以发生巨大改变）。此外，不做角度维度的滤波使得这个粒子滤波直接失去了当2D建图中的一个附加算法模块的可能。</li>
<li>为了保证采样充分，三个维度比两个维度需要更多的采样点（比如之前如果是1600=40*40，那么直觉上来说，三维应该需要40*40*40=64000），这就引回到第一个“计算慢”的问题上了（20000点，0.6fps）。</li>
</ul></div></div></div>
<p>​ 两个问题都是无法接受的！！！！不过！<strong><u>解决这两个问题的关键，是解决速度问题</u></strong>。速度上去了，那么可以接受更多点的采样，也就能解决维度问题。于是我开始思考如何加速Volume2D计算，Volume2D见<a href="https://enigmatisms.github.io/2021/08/02/Volume2D-Shader-Pro/">[我的博文]</a>。其中最有并行加速希望的地方在这：</p>
<details class="note warning"><summary><p>长代码段</p>
</summary>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">ParticleFilter::edgeIntersect</span><span class="params">(<span class="type">const</span> Edge&amp; eg, <span class="type">const</span> Eigen::Vector2d&amp; obs, std::vector&lt;<span class="type">double</span>&gt;&amp; range)</span> </span>&#123;</span><br><span class="line">    <span class="type">double</span> angle_start = eg.<span class="built_in">front</span>().<span class="built_in">z</span>(), angle_end = eg.<span class="built_in">back</span>().<span class="built_in">z</span>();</span><br><span class="line">    <span class="type">int</span> id_start = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(<span class="built_in">ceil</span>((angle_start + M_PI) / angle_incre)), </span><br><span class="line">        id_end = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(<span class="built_in">floor</span>((angle_end + M_PI) / angle_incre));</span><br><span class="line">    <span class="keyword">if</span> (id_start == id_end + <span class="number">1</span>) <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">if</span> (id_start &gt; id_end) &#123;            <span class="comment">// 奇异角度</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = id_start; i &lt; ray_num; i++) &#123;</span><br><span class="line">            <span class="type">double</span> angle = angle_incre * <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(i) - M_PI;</span><br><span class="line">            <span class="function">Eigen::Vector3d <span class="title">vec</span><span class="params">(cos(angle), sin(angle), angle)</span></span>;</span><br><span class="line">            Eigen::Vector2d intersect = eg.<span class="built_in">getRayIntersect</span>(vec, obs);</span><br><span class="line">            range[i] = intersect.<span class="built_in">norm</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt;= id_end; i++) &#123;</span><br><span class="line">            <span class="type">double</span> angle = angle_incre * <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(i) - M_PI;</span><br><span class="line">            <span class="function">Eigen::Vector3d <span class="title">vec</span><span class="params">(cos(angle), sin(angle), angle)</span></span>;</span><br><span class="line">            Eigen::Vector2d intersect = eg.<span class="built_in">getRayIntersect</span>(vec, obs);</span><br><span class="line">            range[i] = intersect.<span class="built_in">norm</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = id_start; i &lt;= id_end; i++) &#123;</span><br><span class="line">            <span class="type">double</span> angle = angle_incre * <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(i) - M_PI;</span><br><span class="line">            <span class="function">Eigen::Vector3d <span class="title">vec</span><span class="params">(cos(angle), sin(angle), angle)</span></span>;</span><br><span class="line">            Eigen::Vector2d intersect = eg.<span class="built_in">getRayIntersect</span>(vec, obs);</span><br><span class="line">            range[i] = intersect.<span class="built_in">norm</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</details>
<p>​ 但是实际缺很难做，一是因为此处求交点是针对一段折线，需要先旋转数组二分查找。此外，Edge这个数据结构也不方便使用（变长Eigen::Vector2d的deque），还逼得我了解了一下thrust的libcu++ vector。遂放弃加速。</p>
<h3 id="渲染管线">2.2 渲染管线</h3>
<p>​ 突然有一天上午，我觉得自己之前很蠢：之前的粒子滤波是写着玩的，要不然求range image的方法也不会是这样（当时因为受Volume2D的启发，想要复用一下这个算法）。事实证明，这个算法不适合求深度图。想到这个，我直接开始思考用激光雷达模型</p>
<blockquote>
<p>我称之为：正向法，也即求激光雷达发射光线生成深度图的模型。</p>
</blockquote>
<p>​ 深度图获取，在我看来就是一条GPU渲染管线（渲染经常做这个事情啊），而且我觉得本问题用GPU实现实在太适合了，原因有二：</p>
<ul>
<li>每个粒子根据此时的位姿求深度图，进而求重采样权重，是完全相互独立的。</li>
<li>每个粒子内部，渲染深度图使用Z buffer方法，应该是有很不错的并行度的。</li>
</ul>
<p>​ 于是我直接设计了一个Z buffer方法：</p>
<center>
<img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/zbuf.png" style="zoom:50%;">
</center>
<center>
Figure 2. Z buffer 方法说明
</center>
<p>​ Z buffer 很好理解，它与Volume2D的异同是：</p>
<div class="tabs" id="princ"><ul class="nav-tabs"><li class="tab active"><a href="#princ-1">体积光算法</a></li><li class="tab"><a href="#princ-2">Z Buffer</a></li></ul><div class="tab-content"><div class="tab-pane active" id="princ-1"><p>计算哪些地图边界能被实际观测到（计算遮挡关系，求出没被遮挡的所有边），使用未被遮挡的边计算激光交点以及对应深度。</p></div><div class="tab-pane" id="princ-2"><p>不管遮挡关系，激光与所有可能边相交，取离自己最近的那个值（最小值）。也就是说，Z buffer直接计算所有可能的相交，求最小值。</p></div></div></div>
<hr>
<h2 id="iii.-算法设计">III. 算法设计</h2>
<h3 id="第一代">3.1 第一代</h3>
<blockquote>
<p>数据关联越不紧密的，并行的粒度应该越粗。--- 我的理解</p>
</blockquote>
<p>​ 这么说的原因是：数据关联紧密的，可能可以使用共享内存。比如本问题中，不同粒子之间，经过背面剔除(back culling)之后的边都不一致，并且观测点也不一致，不适合放在同一个block内部，故一个粒子应该是一个block。而block内部细粒度的并行，应该针对【一个确定粒子下（观测点确定）】的所有地图边（地图两个相连角点确定的线段）（见下图说明：）</p>
<center>
<img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/para.png" style="zoom:50%;">
</center>
<center>
Figure 3. 并行说明
</center>
<p>​ 不同的观测点位于不同block，同一观测点下的不同线段（比如observing point 1下的地图线段），线段之间是thread并行的（不同颜色线段产生的深度信息是并行计算的）。使用线段而不是Edge作为处理单元以及这样设置并行带来几个好处：</p>
<ul>
<li>线段是定长的数据（4个float就可以表示）</li>
<li>不同block可以在常量内存中共用同一个地图（初始线段）</li>
<li>同一个block内处理不同线段的thread，可以将back culling的结果输出到一个共享的flag数组上，并且计算的深度值也可以使用共享内存保存，加速内存读写。</li>
</ul>
<p>​ 于是初代算法的流程大概是这样：</p>
<ul>
<li>观测点数为girdDim.x（也即block数）（10000+），线段数量为blockDim.x（也即线程数）（通常小于400）.</li>
</ul>
<p><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/flow.png"></p>
<center>
Figure 4. 算法流程
</center>
<p>​ 由于第一代算法几乎就是整个算法的思想主体（之后的都是优化迭代，没有大改），重点说一下。</p>
<h4 id="背面剔除">3.1.1 背面剔除</h4>
<p>​ 背面剔除需要flags：输入的是原始地图，原始地图中有些线段是不需要的（背面），在背面剔除函数中每个线程计算自己对应的线段是否是正面，保存在flag中。以下代码块是动态内存分配，平均每个block使用1-2KB的共享内存（很节约）。由于CUDA动态共享内存 <strong><u>只有这一种方法分配</u></strong>，所以跨类型或者多数组是不可能直接写的，需要强转指针（我哥建议我使用reinterpret_cast来完成指针转换，但是我发现这样也没问题）。注意由于分配的是int数组，故在kernel launch时，指定的数组字节数需要为4的整数倍（bool只占1字节，所以可能需要padding）。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">extern</span> __shared__ <span class="type">int</span> range[];          <span class="comment">//...一个数据类型分为了两个不同意义以及类型的块</span></span><br><span class="line"><span class="type">bool</span>* flags = (<span class="type">bool</span>*)(&amp;range[range_num]);</span><br></pre></td></tr></table></figure>
<h4 id="单线段z-buffer">3.1.2 单线段Z buffer*</h4>
<p>​ 假设本thread的id对应的线段需要被处理（事实上如果不需要被处理，会直接return，这确实会引起warp divergence，但是overhead可以忽略），那么就需要计算这个线段产生的局部深度图。</p>
<p>​ 其中的难点在于控制逻辑：<strong><u>-PI~PI</u></strong>是atan2的角度输出范围，角度奇异性（由于是逆时针，一般情况下起始点角度小于终止点，但是跨<span class="math inline">\(\pm\pi\)</span>界限（x负半轴）时会出现奇异）会影响数组下标 / 角度id等等的计算，这里不多讲，有兴趣直接看代码吧。</p>
<p>​ 此外重要的一点就是：Z buffer保存的始终是某个角度上深度的最小值，但是如何计算最小？需要我们把所有线段深度算出来然后求最小？<strong><u>显然不是，这样太慢了，而且需要线程间数据交流（共享内存）</u></strong>。我们考虑增量式的方法：</p>
<div class="note primary"><p>​ 计算值每次和深度值数组range（共享内存）对应id进行比较，保留更小的值。但是这会涉及到一个问题：<strong><u>线程访问冲突</u></strong>。</p>
</div>
<div class="note success"><p>​ 使用原子操作！原子地进行比较并且替换为更小值就行。但是很可惜：<strong><u>CUDA不支持float原子比较</u></strong>。</p>
</div>
<p>​ 那么怎么办呢？stackoverflow上有人给了方法：</p>
<div class="note info"><p>​ 把Float直接按位解释为int，对此int进行一些计算，转化为一个可以保序的（ordered）int，对int进行原子比较可以使用atomicMin。</p>
</div>
<p>​ 关于Ordered int转换，见这篇别人写的博客<a href="http://stereopsis.com/radix.html">[Float radix sort]</a>, 以及stackoverflow上的<a href="https://stackoverflow.com/questions/17399119/how-do-i-use-atomicmax-on-floating-point-values-in-cuda">[一个回答]</a>（最高赞的是错的，Informate.it写的是对的）。原子操作十分香，而且感觉很优雅。</p>
<h4 id="相似度权重">3.1.3 相似度权重</h4>
<p>​ 所有线程计算结束之后（相当于本粒子对应观测点的深度图算完了），一个block内计算参考深度图与本观测点深度图的L1误差<span class="math inline">\(L_e\)</span>，<span class="math inline">\(1/(L_e+1)\)</span>是本观测点的权重。</p>
<h3 id="之后的优化">3.2 之后的优化</h3>
<p>​ 第一代算法存在一些速度缺陷：</p>
<ul>
<li>使用double，进行计算：CUDA对double并不是特别友好，一些double函数比如atan2就更不用说了。int也是滥用了，有些数字使用short即可，完全不必用int。</li>
<li>Z buffer中的线段求交点函数<code>__device__ __forceinline__ float getRange(...)</code>内部过多Eigen或者自定义数据结构的重复索引操作，并且有些计算没有复用。这个函数是整个单线段Z buffer的瓶颈。</li>
<li>使用Eigen，库虽然方便，但是速度慢了</li>
<li><strong><u>（重要）：</u></strong>并行度低，没有使用流水线(stream)，单kernel，GPU占用巨大。</li>
</ul>
<p>​ 第一个问题优化之后，使得我的算法从与CPU差不多的速度升到的CPU的五倍（相比于8线程），第二三个问题修正使得我的速度上升为CPU速度的16倍（相比于8线程），而profile以及流水线优化使得我的算法先后达到了32x，45x加速！所以我重点说一下stream concurrency。</p>
<h3 id="stream-concurrency">3.3 Stream Concurrency</h3>
<p>​ stream，翻译是“流”，我将其理解成为流水线。实际上是GPU的一个操作“队列”：</p>
<p><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/nvvp.png"></p>
<center>
Figure 5. stream示意图[1]
</center>
<p>stream有这样的特性：</p>
<ul>
<li>如果一个kernel或者是cuda操作（比如Memcpy）在同一个stream下被launch，那么是按照issue-order（发射的顺序）执行（与之相对的是乱序发射）。</li>
<li>如果分配到不同的stream下，那么可以乱序执行，并且根据GPU资源利用情况，可能有overlap。</li>
</ul>
<p>​ 那么显然，overlap多大，说明GPU越不容易空闲，很可能可以有几个kernel函数的并行执行，相当于流水线操作，上一个kernel还没执行完，下一个kernel已经开始了。如果不指定stream，使用default stream，那么profile得到的图会是一个完全阶梯状的，阶梯之间一般没有并行（issue-order限制），一开始我就是单stream执行的，<strong><u>并且是一个超大的kernel（需要处理上万个block）</u></strong>。</p>
<p>​ 当我意识到这一点之后，我将kernel拆分了，反复调用particle filter这个核函数，不过每次只处理不到100个block。开始时跑的效果并不好，<strong><u>直到我使用了CUDA Profiler</u></strong>，将运行状态绘制出来之后发现，诶？完全阶梯状的kernel调用，并且profiler也告诉我：“<strong><u>kernel overlap too small: 0%</u></strong>”，也就是说，block几乎是顺序计算的，这样的效率太低！</p>
<p>​ 查阅了很多资料[1][2][3]，最后确定使用stream：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">cudaStream_t streams[<span class="number">8</span>];</span><br><span class="line">streams[<span class="number">0</span>] = cudaStreamDefault;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; <span class="number">8</span>; i++)</span><br><span class="line">    <span class="built_in">cudaStreamCreateWithFlags</span>(&amp;streams[i],cudaStreamNonBlocking);</span><br><span class="line"><span class="comment">// cudaProfilerStart();</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; cascade_num; i++) &#123;</span><br><span class="line">    particleFilter &lt;&lt;&lt; <span class="number">16</span>, seg_num, shared_to_allocate, streams[i % <span class="number">8</span>]&gt;&gt;&gt; (...);</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">CUDA_CHECK_RETURN</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line"><span class="comment">// cudaProfilerStop();</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; <span class="number">8</span>; i++)</span><br><span class="line">    <span class="built_in">cudaStreamDestroy</span>(streams[i]);</span><br></pre></td></tr></table></figure>
<p>​ 创建了不同的stream（cudaStreamNonBlocking），循环地把不同的kernel（处理particles的不同offset位置）发射到不同的stream上，实现更加紧凑的并行。cudaStreamDefault 在CUDA7之后不会有之前的隐式同步问题（默认stream会导致操作串行化），所以可以使用。</p>
<p>​ 当然，流水线最后的级数，block的大小都是profile试着调整过来的。32x加速的版本，使用的grid有点过小（4个粒子，8个streams）：</p>
<ul>
<li>4个粒子的kernel会迅速执行完，但是kernel时间并没有长到可以充分利用流水线调度空余时间。</li>
<li>最后使用16个粒子的kernel，速度提到了45x（profile之后突然想到的）</li>
</ul>
<h3 id="一些其他的加速尝试">3.4 一些其他的加速尝试</h3>
<p>​ 以下是证明在本问题中无效的加速尝试：</p>
<ul>
<li>动态并行（dynamic parallelism，这也是在上一篇CUDA博客中折磨我的东西）。<strong><u>这个完全没用！</u></strong>反倒是增大了每个kernel的线程资源消耗（一个block就只有最多1024线程），导致算法变得更慢。很显然嘛，一个block大概200-300个线程，那么每个线程还得再launch一个子kernel（多线程），显然资源会不够。</li>
<li>内存吞吐流水操作：CUDA希望我做这个事情：内存的移动是小块小块的，不要一起完成，否则没有太大的流水线加速效果。但实际情况是：即使是个几百MB的global memory复制，也非常迅速地完成了（貌似没到1ms）</li>
</ul>
<p><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/cuda.png"></p>
<center>
Figure 6. CUDA stream化的优势
</center>
<ul>
<li>更加激进的位宽优化（能换short就short了），剩余的一些优化用处不大。</li>
<li>等等等等：尝试了很多方法，不一一列举了。</li>
</ul>
<h3 id="采样点不足">3.5 采样点不足</h3>
<p>​ 旋转对算法结果的影响能力比平移大。试想一下自己平移一些之后看到的世界与旋转一点看到的世界的差异就知道了。开始时，角度的采样明显是欠缺的：</p>
<ul>
<li>三个轴上都使用均匀分布随机数。因为开始时我希望保证三个维度下的采样应该一致，但这种做法并不好，因为我 <strong><u>并不能保证</u></strong>，在每一个平移位置，旋转的采样都足够了。</li>
</ul>
<p>​ 之后我使用了如下的策略：12800个点，先在平移上均匀采样1280个点，每个平移位置：360度等间隔采样（10个点，36度一个），那么一个平移位置对应了10个点，再对这10个点加少量位置噪声。这种策略，<strong><u>可以保证每个平移位置的角度采样都是充分的</u></strong>，就不会因为角度采样过于随机导致视角缺失。</p>
<h3 id="一些坑">3.6 一些坑</h3>
<ul>
<li>Eigen/CUDA不兼容的坑：在同学的RTX 2070设备上测试时，他的驱动是CUDA 10.2，Eigen 3.3.4，我的驱动CUDA 10.1，Eigen相同，我可以编译，他报错：找不到<code>Eigen 找不到&lt;math_functions.hpp&gt;</code>：把Eigen升级到3.4.0 （直接上Gitlab爬下它的源码进行include），正确选择arch代数（RTX 2070至少应该选arch=sm_70? 我的MX150是sm_61）就可以通过编译。</li>
<li>std::atomic库与CUDA不兼容：我想把之前写的键盘操作用在CUDA可视化中，但是编译不过，CUDA中的std::atomic部分类型的copy constructor是deleted functions，没有实际意义。最后没有解决，放弃了，直接使用OpenCV。</li>
<li>nvcc要加一些flags才能避免Eigen的一些傻逼warning：<code>--expt-relaxed-constexpr -Xcudafe --diag_suppress=esa_on_defaulted_function_ignored</code>，CMake添加这个：<code>add_compile_options(-Wno-deprecated-declarations)</code></li>
<li>__constant__ memory访问的问题：定义__constant__ 变量，是不能用extern的，并且constant内存是已经存在的，只需要声明用多少(不能malloc)，只要能看到这个变量的定义，那么这个变量对能看到它的函数都是全局的。<strong><u>在不同文件中使用同一个constant memory变量，需要：</u></strong>打开CUDA的separate compilation选项（目的是生成一个relocatable的代码），separate compilation在之前的动态并行中说过。</li>
<li>一些结构体定义的函数如果需要在GPU上用，要声明为__host__ __device__ （双重属性），这样的话，CPU / GPU上会各有一份实现。</li>
<li>带cuda开头的cuda runtime API一般都是host only，不要使用在kernel中。</li>
<li>使用nvvp进行可视化profiling，需要安装java8，配置jre-1.8（针对Ubuntu18.04），环境错了是打不开profile工具的。并且profile的时候需要有root权限。</li>
<li>粒子的运动：每个粒子应该朝自己的方向前进后退左移右移，而不是与控制点保持一样的方向。方向一致的运动结果是有问题的。</li>
</ul>
<hr>
<h2 id="iv.-实验结果">IV. 实验结果</h2>
<h3 id="粒子滤波效果一览">4.1 粒子滤波效果一览</h3>
<p>​ 6fps慢速播放效果：</p>
<video src="cv_output1.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<center>
Video 1. 慢速播放效果
</center>
<video src="cv_output2.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<center>
Video 2. 常速播放效果（特意找了一个较长时间没有收敛的情况）
</center>
<h3 id="profile结果">4.2 Profile结果</h3>
<p>​ 小block的kernel方便进行kernel之间的并发，而大block的kernel就可以明显看出执行偏顺序化了。</p>
<p><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/Screenshot%20from%202021-10-16%2014-24-07.png"></p>
<center>
Figure 7. 8 streams 小block kernel
</center>
<p><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/Screenshot%20from%202021-10-16%2014-26-17.png"></p>
<center>
Figure 8. 8 streams 大block kernel
</center>
<p>​ 极端情况是单stream大block，由于资源占用过多，kernel之间完全是串行执行了。</p>
<p><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/Screenshot%20from%202021-10-16%2014-28-26.png"></p>
<center>
Figure 9. 单 stream 大block kernel
</center>
<h3 id="速度说明">4.3 速度说明</h3>
<p>​ 已经测试的速度（12800粒子，$$115度激光，角分辨率0.5度，共330个激光点的情况）：</p>
<ul>
<li>GeForce MX150: 约为42fps</li>
<li>GeForce RTX 2070: 约为116.5fps</li>
</ul>
<h3 id="四张图">4.4 四张图</h3>
<p>​ 红色粒子为采样，红色粒子内部有黄色箭头（很小），指示了粒子的方向。蓝绿色点是所有粒子按照权重加权平均的结果（带权重心），黄色点是真值。</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/pic0.png"></th>
<th style="text-align: center;"><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/pic1.png"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">开始阶段：粒子簇在平移均匀分布（略带噪声）</td>
<td style="text-align: center;">移动一段距离，每个粒子都更新了自己的位置</td>
</tr>
<tr class="even">
<td style="text-align: center;"><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/pic2.png"></td>
<td style="text-align: center;"><img src="/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/pic3.png"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">收敛中：粒子均值已经收敛到真值附近</td>
<td style="text-align: center;">收敛，有偏差，这是初值估计可以容忍的</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://developer.download.nvidia.com/CUDA/training/StreamsAndConcurrencyWebinar.pdf">Steve Rennich - CUDA C/C++ Streams and Concurrency</a></p>
<p>[2] <a href="https://www.olcf.ornl.gov/wp-content/uploads/2020/07/07_Concurrency.pdf">Nvidia Bob Crovella CUDA Concurrency</a></p>
<p>[3] <a href="https://on-demand.gputechconf.com/gtc/2014/presentations/S4158-cuda-streams-best-practices-common-pitfalls.pdf">Justin Luitjens - CUDA streams best practices common pitfalls</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>GPU</tag>
        <tag>CUDA</tag>
      </tags>
  </entry>
  <entry>
    <title>Correspondence Problem Papers</title>
    <url>/2021/10/15/Correspondence-Problem-Papers/</url>
    <content><![CDATA[<h1 id="correspondence-problem">Correspondence Problem</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<blockquote>
<p>The <strong>correspondence problem</strong> refers to the problem of ascertaining which parts of one image correspond to which parts of another image, where differences are due to movement of the camera, the elapse of time, and/or movement of objects in the photos. ---Wikipedia</p>
</blockquote>
<p>​ 最近一直在做与匹配相关的问题：点云配准。点云配准就是一个非常经典的匹配问题，在基于特征的方法下，找到两帧点云对应位置的特征，建立匹配关系，可以根据计算好的匹配算出位姿变换，而由于引入特征以及特征匹配，通常情况下可以使得配准算法具有全局性。</p>
<p>​ 我在最近的一次组会上做了论文分享，讲了两篇具有很强关联性的论文（这两篇论文都很好懂，ICCV 2005的尤其简单，看完就能写出代码来）：</p>
<ul>
<li><a href="https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/leordeanu-iccv-05.pdf">ICCV 2005: A Spectral Technique for Correspondence Problems Using Pairwise Constraints</a></li>
<li><a href="https://arxiv.org/abs/2103.05465">CVPR 2021: PointDSC: Robust Point Cloud Registration using Deep Spatial Consistency</a></li>
</ul>
<p>​ 我将本人论文分享时做的PPT贴在本文内。</p>
<span id="more"></span>
<hr>
<h2 id="ii.-ppts">II. PPTs</h2>
<p><img src="/2021/10/15/Correspondence-Problem-Papers/2021-10-15%20(1).png"></p>
<center>
Figure 1. 典型匹配对问题：点云配准
</center>
<p><img src="/2021/10/15/Correspondence-Problem-Papers/2021-10-15%20(2).png"></p>
<center>
Figure 2. 变换一致性在刚体变换中的应用：旋转平移距离不变性
</center>
<p><img src="/2021/10/15/Correspondence-Problem-Papers/2021-10-15%20(3).png"></p>
<center>
Figure 3. 思想：构建图问题，使用谱方法
</center>
<p><img src="/2021/10/15/Correspondence-Problem-Papers/2021-10-15%20(8).png"></p>
<center>
Figure 4. 本人对论文I的方法总结
</center>
<p><img src="/2021/10/15/Correspondence-Problem-Papers/2021-10-15%20(5).png"></p>
<center>
Figure 5. 论文I存在的问题（毕竟是很老的工作了）
</center>
<p><img src="/2021/10/15/Correspondence-Problem-Papers/2021-10-15%20(6).png"></p>
<center>
Figure 6. 方法总结：第一部分，包含变换一致性的全局神经网络模块以及种子点选取的特征筛选
</center>
<p><img src="/2021/10/15/Correspondence-Problem-Papers/2021-10-15%20(7).png"></p>
<center>
Figure 7. 方法总结：第二部分，KNN子集扩增，NSM概率计算，加权最小二乘，propose and verify
</center>
<hr>
<h2 id="今日快乐">今日快乐</h2>
<p>​ 击败了巨人（快乐），但是之后被国王之手干死了（不快乐）：</p>
<p><img src="/2021/10/15/Correspondence-Problem-Papers/2021-10-15.png"></p>
<center>
Figure 8. 我的王啊... 真他妈是个不可救药的混蛋
</center>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title>CycleGAN Paper Summary</title>
    <url>/2021/02/10/CycleGAN-Paper-Summary/</url>
    <content><![CDATA[<h1 id="cyclegan">CycleGAN</h1>
<hr>
<h2 id="preface">Preface</h2>
<p>​ GAN常用作风格迁移或者是object transfiguration，但是普通的GAN实际上并不能很好地胜任这些任务。原始的GAN是从一个隐含向量z（常服从一个简单的多维分布）映射到一个具有丰富信息的更高维空间的过程，而这种映射往往“arbitrary”，它可以乱射（随机性的生成）。比如在object transfiguration中，A-&gt;B集合映射过程可以通过此网络实现，但B集合进入网络后，生成出来的（例应是原始的B）却与原始B相差很远。当然，在object transfiguration中，更加有挑战性的问题是，对于pix2pix论文提出的成对图像转换而言，成对图像一般很难获得。如果只有两个集合A / B，A / B内的对象为不同属性的，那么在没有预先产生匹配关系的情况如何将A / B集合内的物体互相映射呢？</p>
<span id="more"></span>
<p>​ 在论文 <em>Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks</em> （arXiv链接：<a href="https://arxiv.org/abs/1703.10593">【arXiv Preview】🔗</a>）中，作者提出了：Cycle Consistancy的思想（好了，xxx一致性，听多了）（循环一致性），在误差函数中添加了两项：</p>
<ul>
<li>循环一致误差（CCL），用于控制一致性（显然）</li>
<li>本征一致性，感觉作者没有提。但是我觉得可以通过CCL推导出来。</li>
</ul>
<h3 id="复现的结果">复现的结果</h3>
<p>​ 由于受到设备的限制（GeForce MX150，三年的i5小米Air轻薄本的渣显卡）网络只训练了25个迭代（原文使用了50个学习率恒定迭代，此后50个迭代学习率线性递减至0），也没有修改学习率设置。一张图片大概需要计算1s，995张图片需要15min+才能完成一轮迭代。结果如图：</p>
<p><img src="/2021/02/10/CycleGAN-Paper-Summary/result.JPG"></p>
<center>
Figure 1. 训练结果
</center>
<p>​ 两行为一组，一共六行。前两行是橙子-&gt;苹果，中间两行是苹果-&gt;橙子，后两行是初始情况（欠训练时的结果）。</p>
<hr>
<h2 id="论文的细节">论文的细节</h2>
<h3 id="ccl的定义">CCL的定义</h3>
<p>​ 在【3. Formulation】中，作者提到：循环一致性就是：假设集合<span class="math inline">\(X\)</span>与<span class="math inline">\(Y\)</span>分别包含两种类型物体，<span class="math inline">\(G\)</span>与<span class="math inline">\(F\)</span>分别是两个生成器，其中<span class="math inline">\(G\)</span>用于利用集合<span class="math inline">\(X\)</span>对象生成集合<span class="math inline">\(Y\)</span>的对象，<span class="math inline">\(F\)</span>则正好相反。也就是： <span class="math display">\[
G: X\rightarrow Y,G(x)\rightarrow Y,\text{for each }x\in X \\
F: Y\rightarrow X,F(y)\rightarrow X,\text{for each }y\in Y
\]</span> ​ 那么对于这样的映射，应该有：<span class="math inline">\(F(G(x))\approx x\)</span>（也就是经过两个生成网络后，<span class="math inline">\(X\rightarrow Y\rightarrow X\)</span>），数据应该和初始输入保持一致。在object transfiguration或是style transfer中，我觉得这种想法十分自然，并且很妙。由于在这两个问题中，图像本身的形状特征并不会发生巨大的变化，变化的只是颜色 / 纹理属性，在object transfiguration中，从物体A变成物体B以及其反过程是对称的，风格迁移中，风格的加入和消除也是对称的（可以将原图看成另一种风格），那么由反函数的性质，应该存在上式的结果。于是，作者定义了一个Cycle Consistancy Loss： <span class="math display">\[
L_{cyc}(G,F,x,y)=\Vert G(F(y))-y\Vert_1+\Vert F(G(x))-x\Vert_1
\]</span> ​ 也就是用（理论上的identity变换）变换前后的图像的1-范数进行比较。显然是越小越好，希望这种identity映射前后基本不变。</p>
<p>​ 但其实整篇论文传达的意思就那么简单，18页的论文，放了一半页数的图，但是做的事情却牛大了（虽然已经是4年前的论文了）。不得不吐槽一下，原论文中提到的信息不太多（可能是因为这些基本的问题作者认为大家都应该明白所以不说了？），所以这篇文章非常好懂，复现起来也相对简单（但是我太菜了，遇到了一些坑）。</p>
<hr>
<h3 id="ccl可以推出什么">CCL可以推出什么</h3>
<p>​ 个人认为，既然存在CCL（<span class="math inline">\(X\rightarrow Y\rightarrow X\)</span>循环映射不变），那么以下想法也是自然应该成立的：设<span class="math inline">\(x\in X, y \in Y\)</span>，那么应该存在： <span class="math display">\[
\begin{equation}
G:X\rightarrow Y, G(y)\approx y\\
F:Y\rightarrow X, F(x)\approx x
\end{equation}
\]</span> ​ 也就是说，由于G的输出空间为<span class="math inline">\(Y\)</span>（期望），所以对于已经在y空间里的数据而言，生成网络不应该改变其特征。所以可以定义本征一致性loss： <span class="math display">\[
\begin{equation}\label{equ:ind}
L_{ind}=\mathbb E_{p\_data(y)} \Vert G(y)-y\Vert_1 + \mathbb E_{p\_data(y)} \Vert F(x)-x\Vert_1
\end{equation}
\]</span> ​ 可以认为这是循环的一半情况吧，但是确实是应该加入到loss项中的，既然存在循环一致性，那么本征一致性理论上来说也是存在的。</p>
<p>​ 于是，full objective应该是： <span class="math display">\[
\begin{equation}
L_{full}(X,Y,G,F)=L_{adv}(X,Y,G,F)+L_{cyc}(X,Y,G,F)+L_{ind}(X,Y,G,F)
\end{equation}
\]</span></p>
<hr>
<h3 id="网络结构">网络结构</h3>
<h4 id="生成器">生成器</h4>
<p><span id="generator"></span></p>
<p>​ 论文中的生成器采用了ResNet结构，首先图片都是256 * 256 * 3的图片，以6个Residual Block结构进行说明：</p>
<ul>
<li>输入层：输入3 输出64，<span class="math inline">\(7\times 7\)</span> 大小的卷积网络，使用ReLU激活函数，InstanceNorm
<ul>
<li>Reflection Padding</li>
</ul></li>
<li>输入64 输出128，<span class="math inline">\(3\times 3\)</span> 卷积网络，<strong><u>步长2</u></strong>，其余同上
<ul>
<li>Reflection Padding</li>
</ul></li>
<li>输入128 输出256，<span class="math inline">\(3\times 3\)</span> 卷积网络，<strong><u>步长2</u></strong>，其余同上</li>
<li>Residual Block 1，256-&gt;256，<span class="math inline">\(3\times 3\)</span> 卷积网络，<strong><u>步长2</u></strong>，其余同上，个人使用了ZeroPadding</li>
<li>Residual Block 2，Residual Block 3，Residual Block 4，Residual Block 5，Residual Block 6</li>
<li>非整数步长的卷积（ConvTranspose，反卷操作）， <span class="math inline">\(3\times 3\)</span> ，步长1/2，256-&gt;128</li>
<li>非整数步长的卷积， <span class="math inline">\(3\times 3\)</span> ，步长1/2，128-&gt;64</li>
<li>输出层，（64-&gt;3）其余同输入层，Tanh激活</li>
</ul>
<p></p>
<h4 id="判别器">判别器</h4>
<p><span id="clf"></span></p>
<p>​ 判别器使用PatchGAN结构，也就是说不只输出一个值（比如过卷积后再过全连接输出1）。输出的是一个super image，super image是一张size更小的单通道图，每个像素表示的是：<strong><u>判别器输出的结果，图像上每小块为real的概率（重新组织的特征图）</u></strong>。也就是说，输出层只需要卷积，输出卷积结果。</p>
<ul>
<li><span class="math inline">\(4\times 4\)</span> Convolution，64-&gt;128，很奇怪吧。偶数大小的kernel，所以anchor在哪？ LeakyReLU(0.2)
<ul>
<li>InstanceNorm</li>
</ul></li>
<li><span class="math inline">\(4\times 4\)</span> Convolution，128-&gt;256 LeakyReLU(0.2)</li>
<li><span class="math inline">\(4\times 4\)</span> Convolution，256-&gt;512 LeakyReLU(0.2)</li>
<li><span class="math inline">\(4\times 4\)</span> Convolution，512-&gt;1，直接输出</li>
</ul>
<p>额，不讲武德。为什么网络结构细节放在Appendix？搞得我以为我读完了，最后一乱翻发现了更重要的东西。</p>
<p></p>
<hr>
<h3 id="原始gan模式崩塌">原始GAN模式崩塌?</h3>
<h4 id="模式崩塌的定义">模式崩塌的定义</h4>
<p>​ 模式崩塌也就是多个输入映射到同一个输出上的情况。这通常出现在输出模式具有多峰分布的情况。通常我们希望，在目标分布（不可知，但是可以通过采样学习近似）多峰的情况下，拟合的近似分布也应该是多峰的。但如果出现了生成器过强的情况，直接导致生成器每次都拟合到其中一个峰上，就很可能导致模式崩塌。</p>
<p><img src="/2021/02/10/CycleGAN-Paper-Summary/adver.JPG"></p>
<center>
Figure 2. 图片来自Goodfellow著名论文 GAN[1]
</center>
<p>​ 上图说明的是，多峰分布时，每一次训练生成器后的生成分布。训练造成了模式崩塌，也就是输出的低丰富性，这就失去了GAN本身的意义。</p>
<p>​ Goodfellow在论文中提到两种可能产生模式崩塌的原因：</p>
<h5 id="jskl散度的使用导致模式崩塌">JS/KL散度的使用导致模式崩塌</h5>
<p>​ JS散度： <span class="math display">\[
\begin{equation}\label{equ:js}
2D_{JS}(P_R|P_G)=\int_xP_R(x)log(\frac{P_R(x)}{\frac{P_R(x) + P_G(x)}{2}})dx + \int_xP_G(x) log(\frac{P_G(x)}{\frac{P_R(x) + P_G(x)}{2}})dx
\end{equation}
\]</span> ​ KL散度： <span class="math display">\[
\begin{equation}
D_{KL}(P|Q)=\int_xP(x)log(\frac{P(x)}{Q(x)})dx
\end{equation}
\]</span> ​ KL散度能造成更加恐怖的模式崩塌。由于KL散度的非对称性，每次求导都会往特定方向逼近。求导时往特定方向趋近的问题导致了模式崩塌？为什么会这样？KL散度的不对称性决定了其可以从两个方向进行观察，两个方向上的KL散度不是相同的，Goodfellow称<span class="math inline">\(D_{KL}(p_{data}\Vert p_{model})\)</span>（以data分布为主导的KL散度）为正KL散度，<span class="math inline">\(D_{KL}(p_{model}\Vert p_{data})\)</span>为逆KL散度。正KL散度和逆KL散度在优化上的表现是有所不同的。可以从直观上理解，前者是给定数据分布（的计算 / 估计）时，模型分布于数据分布的差别，那么此时模型分布 <strong><u>将会是被动的</u></strong>，只要能达到最小拟合的情况，模型分布怎么样都可以。</p>
<p><img src="/2021/02/10/CycleGAN-Paper-Summary/collapse.JPG"></p>
<center>
Figure 3. 模式崩塌问题中的两种KL散度[1]
</center>
<p>​ 如上图左图，由于原始（数据）分布已知，模型分布为了产生最小散度，形状可以很奇怪。而在逆KL散度中，已经知道的是模型分布，也就是说：已经出现在模型中的模式<strong><u>概率分布大</u></strong>，尚未出现的模式概率分布小。这样一加权，就会让已经生成的模式被强化，造成单峰性（如上图右）。</p>
<p>​ 这两种KL散度倾向性不同：</p>
<ul>
<li>正KL散度倾向于满足数据分布，不考虑模型已经有的分布，所以很可能生成一些奇怪的模式（比如上图中概率分布大的部分在两峰中间，这是不合理的），但是理论上其多样性更佳</li>
<li>逆KL散度倾向于生成已经存在的模式，不习惯于跳出圈子。显然这样做会产生更多我们熟悉的模式，更少奇怪的新模式，但是容易引起模式崩塌。</li>
</ul>
<p>​ 关于这点，Goodfellow这样说到：</p>
<blockquote>
<p>We can think of <span class="math inline">\(D_{KL}(p_{data}\Vert p_{model})\)</span> as preferring to place high probability everywhere that the</p>
<p>data occurs, and <span class="math inline">\(D_{KL}(p_{model}\Vert p_{data})\)</span> as preferrring to place low probability wherever the data does not occur.</p>
</blockquote>
<h5 id="minmax顺序问题">min/max顺序问题</h5>
<p>​ Goodfellow在GAN论文中也提到，GAN的原理（min max）可能会引起模式崩塌。通常我们说，GAN是：minmax结构的，也就是： <span class="math display">\[
\begin{equation}\label{equ:minmax}
G^*=\mathop{argmin}_{G} \mathop{max}_{D}L(G,D)
\end{equation}
\]</span> ​ 其意义也就是（在前某篇文章中提到过）：在判别器最优的情况下进行生成器的最优化。我们希望在一个十分强的判别器存在的情况下仍然能尽可能优化生成器，直到生成器骗过判别器。而Goodfellow说到：</p>
<blockquote>
<p>We use it in the hope that it will behave like min max but it often behaves like max min.</p>
</blockquote>
<p>​ max min也就是公式<span class="math inline">\(\eqref{equ:minmax}\)</span>对于min / max的取反结果。个人认为可以这样理解：max min结构也就是：训练生成器在内循环，训练判别器在外循环。直观上看也就是每一次训练判别器，可能会训练多次生成器。这样是不好的。判别器训练一次之后，生成器会有过拟合到<strong><u>判别器认为最像real data的一种（或少数几种）模式上</u></strong>的趋势（由于生成器要训练多次）。这就导致了模式崩塌。关于这个理解，原文是这样写的：</p>
<blockquote>
<p>The generator is thus asked to map every <strong>z</strong> value to the single <strong>x</strong> coordinate that the discriminator believes is most likely to be real rather than fake.</p>
</blockquote>
<p>​ 有些情况下可能会导致GAN的行为更像max min而非min max。个人认为：训练一次判别器后训练多次分类器可能造成此情况（我之前也这么写过，效果是好的，毕竟生成出来的图片最像真的，但是多样性变差了）。</p>
<hr>
<h2 id="复现的细节">复现的细节</h2>
<h3 id="反卷积过程">反卷积过程</h3>
<p>​ 在CycleGAN<a href="#generator">[网络结构细节]</a>中，作者使用了这样的一个结构：非整数步长的卷积（ConvTranspose，反卷操作）， <span class="math inline">\(3\times 3\)</span> ，步长1/2，256-&gt;128。反卷积之前试着使用过，但是由于（当时我以为）1/2步长时其输出只能为奇数，就没有深入了解了。结果此处碰上了，为了尽可能按照论文复现，重新了解了一下这个玩意。</p>
<p>​ ConvTranspose就是卷积的逆过程，在有步长的情况下更为明显。常用于上采样放大。但实际上，即使步长为1，“放大”也是做不到的。由于ConvTranspose实际上也是用卷积核生成输出，卷积核必然导致输出小于输入，所以需要加入padding。padding让我感觉反卷积在放大过程中需要加入太多无效的信息（即使reflection padding也是一样的），毕竟是上采样过程（信息 少-&gt;多）。这种“无效信息的加入”在步长不为1的1时候更能体现出来（如下图片列表）</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><img src="/2021/02/10/CycleGAN-Paper-Summary/pad.gif"></th>
<th><img src="/2021/02/10/CycleGAN-Paper-Summary/nopad2.gif"></th>
<th><img src="/2021/02/10/CycleGAN-Paper-Summary/nopad3.gif"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">padding放大</td>
<td>stride放大（奇数）</td>
<td>stride放大（偶数）</td>
</tr>
</tbody>
</table>
<p>​ 分数步长的卷积就是需要上采样的卷积。整数步长将会使卷积核跳过一些位点，而分数（小于1）则是需要在位点之间进行padding的。非1步长 / 有padding的卷积计算就不再赘述了。</p>
<p>​ 值得注意的是分数步长的卷积，当步长不为1时（比如stride = 2），两个原始位点之间会填充一个位点。这样导致了：当stride = 2时，不管原来的输入size为奇数还是偶数，输出一定是奇数size的（<strong><u>此处说的是kernel size为奇数，个人感觉偶数的kernel size不够自然，需要讨论anchor</u></strong>）（偶数kernel size可以让输出为偶数，比如ConvTranspose2d(n, n, 4, 2, 1) 就是放大size为原来的两倍）。我实现的第一版CycleGAN使用的是ConvTranspose，附带了一个output_padding (由于当时使用奇数核)，正如图三所示，感觉其结果十分不自然，但效率上并没有太大的区别。对于偶数kernel，其anchor默认在最左上方。</p>
<p>​ 然而在第二版CycleGAN中我就把反卷积换成了卷积+上采样了，网络看起来更正常一些。</p>
<hr>
<h3 id="patchgan">PatchGAN</h3>
<p>​ 这里指的是分类器设计，CycleGAN作者在其论文中采用了CycleGAN的结构，也就是分类器不输出二分类概率值，而是直接输出一个channel-1的卷积结果。例如，一个256*256的图像可以被一个70*70的特征图给表达，这70*70个元素，每个元素代表着图上的某个区域的真实性。自然我们希望，在判定为真实时这个输出接近ones(70, 70)，反之接近zeros(70, 70)。论文中使用了70*70，我的实现中并没有这么做。我写的判别器结构：</p>
<ul>
<li>(256, 256, 3) -&gt; (128, 128, 8) kernel size = 4，stride = 2，padding = 1，no norm</li>
<li>(128, 128, 8) -&gt; (64, 64, 16) kernel size = 4，stride = 2，padding = 1，instance norm</li>
<li>(64, 64, 16) -&gt; (32, 32, 32) kernel size = 4，stride = 2，padding = 1，instance norm</li>
<li>(32, 32, 32) -&gt; (16, 16, 1) kernel size = 4，stride = 2，padding = 1，no activation, no norm.</li>
</ul>
<p>​ 当然，如果要说的话，个人还有几个没有复现的部分：</p>
<ul>
<li>ResNet residual block我只用了两个。在论文中，128*128使用了6个resBlock，256*256则使用了9个。</li>
<li>没有避免model oscillation的trick（使用历史生成的图片而非当前最新生成的图片进行训练）</li>
<li>可能本征Loss是我加进去的东西，我在原文中并没有读出这样的意思来。（<strong><u>张麻子：这tm是复现？</u></strong>）</li>
</ul>
<hr>
<h3 id="normalization谈">Normalization谈</h3>
<p>​ 首先看一张图（来自西交袁泽剑老师的CVPR课PPT，而PPT上的图又是来自<a href="https://arxiv.org/abs/1803.08494">【Wu and He, “Group Normalization”, ECCV 2018🔗】</a></p>
<p><img src="/2021/02/10/CycleGAN-Paper-Summary/norm.JPG"></p>
<center>
Figure 4. 4种normalization
</center>
<p>​ 上图描述了常用的（第四种我在写这篇文章之前也不知道是啥）4种norm（我目前见过用的只有BN与IN）。Normalization的作用就是神经网络的“白化操作”，将NN的输出固定于Norm(0, 1)，可以稳定训练。</p>
<h4 id="bn">BN</h4>
<p>​ BatchNorm看名字就应该能知道，这种Normalization与batch有关。看第一张图，当Batch size为N时，将会对某个channel做batch内的norm操作（也就是一个batch里的所有训练用例 + 一个channel的特征）。显然这个操作在batch size为1时意义不大（退化成了instance norm？）。类似于多张图片训练的（判别模型）常用这个。</p>
<h4 id="in">IN</h4>
<p>​ 显然instance norm与batch没有关系，它是对单张图片意义上的norm。图片每个通道进行normalization。通道数对应了filter数，filter对应了生成的特征。实际上instance norm就是对不同的特征进行normalization。instance norm由于针对单张图片的不同通道，常用于生成式技术比如style transfer。</p>
<h4 id="layernorm-groupnorm">LayerNorm &amp; GroupNorm</h4>
<p>​ Laynorm 是一张图的所有通道做normalization。网上说是对RNN明显的，至于为什么，我没有深入了解过。而GroupNorm相当于是多个通道的Instance Norm，选取的通道数是可变的。</p>
<hr>
<h3 id="resnet相关">ResNet相关</h3>
<p>​ ResNet专注于学习输入输出残差的表示，而不是学习简单的输入输出关系。为什么说学习残差？普通的CNN网络输入输出结构是这样的： <span class="math display">\[
x\mathop{\rightarrow}^F F(x)\rightarrow y
\]</span> ​ 学习的是x与y之间的映射关系，而在res net种，增加了一个identity mapping的合并： <span class="math display">\[
x\mathop{\rightarrow}^F F(x)\rightarrow x&#39;,y=x+x&#39;
\]</span> ​ 那么，真正的输出是y，但是存在参数的部分输入输出只有x'，也就是说学习的实际上只是y-x（输出 - 输入），也就是说：学习的是残差，残差表示将可以使深层网络收敛速度加快，并且网络过深时模型准确率并不会有太大的损失。实际上ResNet的 residual block结构也就是一个identical mapping和卷积的并联，个人在刚开始什么都不懂的时候，曾经将两个不同kernel size的卷积层并联在一起，觉得这会提高网络的表达能力（虽然不知道为什么，只是一种感觉）。所以CycleGAN为什么要使用ResNet结构？</p>
<p>​ 个人的理解是：网络层数加深时，原始图的信息会在经过卷积发生损失，层数越深，积累的损失越大。加入直接的信息通道（shortcut）可以减少这样的信息损失。（可能个人原来使用不同的kernel size核并联时觉得，这样可以在同一层聚合不同大小的特征）。CSDN上有一篇文章说的很好（总结起来就是如下观点）[2]:</p>
<ul>
<li><p>孙剑（？是我们学校的孙剑老师吗）认为ResNet可以避免梯度弥散问题（过深的网络优化时梯度不明显）</p></li>
<li><p>特征冗余可以被削弱：减少信息损失问题（和我的想法有点类似）</p></li>
<li><p>ensemble 特征融合：实际的网络层数由于shortcut的加入变得并不太深</p></li>
<li><p>层次性：shortcut保留了简单的特征，与复杂的特征（参数卷积部分）融合</p></li>
<li><p>凸函数性：层数越深，函数非凸性越严重，找不到全局最优，ResNet结构可以优化函数非凸性</p></li>
</ul>
<hr>
<h3 id="一些细节问题">一些细节问题</h3>
<ul>
<li>关于激活函数：Sigmoid通常用于概率映射，Tanh通常用于图像输出层，而ReLU和LeakyReLU通常作为中间层的输出函数。注意不要乱加。</li>
<li>为什么有的时候输入层会倾向于不进行normalization？很显然，输入的数据会进行预处理，通常都在DataLoader的transform中。比如说使用normalize，以及shuffle，就已经可以保证数据的标准高斯分布。这种情况下，第一层是不需要进行normalize的。</li>
<li>Conv2D不提供padding的模式变换（same和circular选项不算），需要在nn模块下使用ReflectionPad / ZeroPad 等等Padding方式。</li>
</ul>
<hr>
<h2 id="参考文献">参考文献</h2>
<p>[1] Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks.</p>
<p>[2] Ian J. Goodfellow, Jean Pouget-Abadie∗ , Mehdi Mirza, Bing Xu, David Warde-Farley, Generative Adversarial Nets</p>
<p>[3] 《ResNet个人理解》https://blog.csdn.net/nini_coded/article/details/79582902</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title>Contrastive Learning Intros</title>
    <url>/2021/08/29/Contrastive-Learning-Intros/</url>
    <content><![CDATA[<h1 id="cl">CL</h1>
<hr>
<h2 id="i.-introduction">I. Introduction</h2>
<p>​ 根据个人粗浅的了解，有监督的简单图像分类在高一些奇怪的东西，比如我觉得Inception就很奇怪，强行变宽，更不要说它的改进了。新的网络结构感觉就是，没什么理论道理，全是 empirical xxxx的，让人看得一头雾水，做这样的浅层次理解或者是复现也没有什么太大意思，只能让Pytorch技术更加熟练罢了，没有别的作用。为了寻找新的有趣理论，我入门了一下无监督学习（入门水准），这个领域里面有些很有趣的理论以及思想值得借鉴。本文在回顾了一下一些概率论理论之后，内容主要有：</p>
<ul>
<li>Contrastive Predictive Coding (CPC) 论文的理解</li>
<li>何恺明大神（同样姓何为何我这么菜）Momentum Contrast (MoCo) 论文的理解</li>
<li>MoCo实现以及与基于ResNet思想的baseline模型比较（实现见：<a href="https://github.com/Enigmatisms/MoCo">🔗Enigmatisms/MoCo</a>）</li>
</ul>
<span id="more"></span>
<hr>
<h2 id="ii.-两个曾经的sota">II. 两个曾经的SOTA</h2>
<h3 id="nce">2.1 NCE？</h3>
<p>​ 在之前我们已经介绍了CL的工作原理：对输入数据进行encode，在某一个高维metric space下对两个输入encode后的特征向量进行相似度比较。给定正负样本（正负样本的获得是无监督的）后，我们需要通过训练集来优化我们的encoder，使得经过encode之后，原空间下就相似的样本能在变换后也十分相似（表现在内积上）。那么这就要求我们使用一个loss来优化encoder，论文中使用的是InfoNCE。</p>
<div class="note warning"><p><strong><u>注意，NCE不是 negative cross entropy！（这是开始时本人认为的东西）</u></strong>。但是既然那么有缘，还是复习一下NCE相关的知识。</p>
</div>
<p>​ 首先简单地回忆一下交叉熵与KL散度（长时间不用就容易忘），首先是信息熵（与最小编码有关） <span class="math display">\[
\begin{equation}\label{ent}
H(x)=-\sum p(x)\log\left(p(x)\right)
\end{equation}
\]</span> ​ 而KL散度的定义是： <span class="math display">\[
\begin{equation}\label{kl}
D_{KL}(P||Q)=\sum P(x)\log\frac{P(x)}{Q(x)}
\end{equation}
\]</span> ​ 在之前的一些博文中我们分析过，KL散度是用来衡量两个分布的近似程度的。</p>
<div class="note info"><p>​ 原始的信息论问题是：对于两个不同概率分布的字母表P, Q，如果已经在Q上计算出了最优编码，那么只要字母表P的分布越接近Q，那么编码整个字母表P所需的平均信息就越接近Q的理论最小值。显然，这个问题的推广就是衡量两个分布的近似性。</p>
</div>
<p>​ 而交叉熵可以用KL散度来定义（Wiki上说的）： <span class="math display">\[
\begin{equation}\label{ce}
\text{CE}(x)=H(p)+D_{KL}(p||q)=-\sum P(x)\log{Q(x)}
\end{equation}
\]</span> ​ 那么请问此式的意义应该如何解读？由于<span class="math inline">\(P(x),Q(x)\)</span>都是概率分布，越接近1则<span class="math inline">\(-\log f(x)\)</span>越小，那么以下两种极端情况可以定性解释这个loss的正确性：</p>
<p><img src="/2021/08/29/Contrastive-Learning-Intros/1.PNG"></p>
<p>​ 如果如上左图，两个分布相差较大，那么会有这样的情况：<span class="math inline">\(-\log Q(x)\)</span>较大时（也就是<span class="math inline">\(Q(x)\)</span>较小），<span class="math inline">\(P(x)\)</span>恰好较大，相当于对大值，加大权重。那么最后的loss很大。如果分布较为相似，那么则相反，对大值加小权，对小值加大权，这样得到的loss很小，也就直观上说明了Cross Entropy的作用方式。而二分类中，交叉熵的写法如下： <span class="math display">\[
\begin{equation}\label{cel}
\text{CEL}(x)=-(y\log(p)+(1-y)\log(1-p))
\end{equation}
\]</span> ​ 为什么会是这样的呢？显然，二分类情况下，只有错分才会有loss。根据交叉熵表达式<span class="math inline">\(\eqref{ce}\)</span>，假定<span class="math inline">\(P(x)\)</span>是真实分布，<span class="math inline">\(Q(x)\)</span>是估计分布。</p>
<p>​ 讲完了CE，要来讲讲真正的NCE与InfoNCE是什么了，在这里我只简要说说，因为我也是查出来的（精力有限，不能过分地递归学习），知乎上有篇文章讲得还行[1]。在这个文章中，作者开始就从NLP切入，我觉得这个切入点还不错，因为NLP中很多问题都是和序列有关的，于是存在这种：context，通过context来进行推断的语言模型之类的东西。那么InfoNCE的作用原理是什么？首先给出公式： <span class="math display">\[
\begin{equation}\label{infonce}
L_q=-\log\frac{\exp(q\cdot k_{+}/\tau)}{\sum_{i=0}^K\exp{(q\cdot k_i/\tau})}
\end{equation}
\]</span> ​ 其中，<span class="math inline">\(k_+\)</span>是与query <span class="math inline">\(q\)</span> 能够match的正sample key。其余的都是负sample key。可以发现这种 Q K V 设计还是非常普遍的，对每一个需要使用的value，都存在一个对应的key，以应对不同query，虽然在CL问题中没有显式的value，因为value就是key。</p>
<p>​ 那么上式就是一个负对数表达，因为概率越小 loss越大。在MoCo中，个人的理解是：由于MoCo的queue以及momentum update设计，使得key dictionary相对不变，提供的key相对稳定，在假设key正确的情况下，需要找到一个好的encoder参数<span class="math inline">\(f_q\)</span>使得产生的<span class="math inline">\(q\)</span>能够与其中一个key完成匹配。不过这个<span class="math inline">\(k_{+}\)</span>的选取倒是没有说过。</p>
<h3 id="infonce-in-cpc">2.2 InfoNCE in CPC</h3>
<p>​ CPC[3]论文中明确定义了InfoNCE（应该是首次出现）。这篇文章的理论部分更加清楚，并且用到了一些概率论知识，我重点理解和推导一下。首先需要搞清楚的是：什么是context，关于context，CPC论文中说了它具体的产生：</p>
<blockquote>
<p>Next, an autoregressive model gar summarizes all z≤t in the latent space and produces a context latent representation ct = gar(z≤t).</p>
</blockquote>
<p>​ 那么可以认为，context实际上就是对一个序列信息（或者有顺序关联性的信息），前述信息的一个提炼，相当于提供了一个背景。CPC后文中提到的使用上下文指导的prediction，可以佐证这样的理解：context信息就是生成对应prediction的背景信息，只有给定背景，predict才不会漫无目的地乱猜。于是才会有两种不同的概率：</p>
<ul>
<li>条件概率<span class="math inline">\(P(x_{t+k}|c_t)\)</span>，<span class="math inline">\(c_t\)</span>可以认为是截止到t时刻的上下文信息，<span class="math inline">\(x_{t+k}\)</span>是一个正样本（为什么？等会儿说）（prediction），或者就如论文自己说的：理解成一个生成式模型，根据latent vector <span class="math inline">\(c_t\)</span>来生成prediction的一个分布模型</li>
<li>直接概率<span class="math inline">\(P(x_{t+k})\)</span>则是被预测量的分布，是我们想知道的那个分布吗？并不是这样理解的，论文中自己说到了：</li>
</ul>
<blockquote>
<p>N-1 negative samples from the ’proposal’ distribution <span class="math inline">\(p(x_{t+k})\)</span></p>
</blockquote>
<p>​ 这个<span class="math inline">\(P(x_{t+k})\)</span>就是我们随机采样的 <u><strong>噪声建议分布</strong></u>。</p>
<p>​ 当时觉得，诶有点似曾相识。当我看到论文中写到importance sampling以及"proposal distribution"的时候我感觉，坏了，开始有点像粒子滤波了。那么可以结合起来理解，只需要简单回顾一下重要性采样即可。</p>
<div class="note success"><p>回顾一下重要性采样，也就是“建议分布 (proposal) ”如何转向“目标分布”</p>
</div>
<p>​ 假设我们需要计算关于<span class="math inline">\(f(x)\)</span>的某个积分（比如期望），但是要么<span class="math inline">\(f(x)\)</span> 是高维复杂分布，要么<span class="math inline">\(f(x)\)</span>难以积分，总之就是不方便从此分布中直接采样，而同时我们又有另一个简单的分布<span class="math inline">\(g(x)\)</span>，那么有： <span class="math display">\[
\begin{equation}\label{imp}
\int f(x)dx=\int\frac{f(x)}{g(x)}g(x)dx
\end{equation}
\]</span> ​ 相当于是：我们在求<span class="math inline">\(g(x)\)</span>的某个积分，对应的随机变量函数是<span class="math inline">\(f(x)/g(x)\)</span>，在粒子滤波中是有相应应用的。那么<span class="math inline">\(f(x)/g(x)\)</span>看起来还是和<span class="math inline">\(f(x)\)</span>有关，是不是也很难求呢？在粒子滤波里面我们已经说明了，这个值并不难求，<span class="math inline">\(f(x)/g(x)\)</span>相当于对建议分布<span class="math inline">\(g(x)\)</span>的一个加权因子，这个加权因子由<u><strong>建议分布和目标分布的一致性</strong></u>决定，在localization问题中，我们通过粒子在对应位置模拟的scan与实际scan的相似度估计出了这个值，粒子滤波妙就妙在这里。我不需要知道任何与<span class="math inline">\(f(x)\)</span>有关的计算公式，我也可以巧妙地设计加权因子求出与<span class="math inline">\(f(x)\)</span>相关的值。</p>
<p>​ 而在CPC论文中，作者希望的应该是最大化<span class="math inline">\(x_{t+k}\)</span>与上下文<span class="math inline">\(c_t\)</span>的互信息： <span class="math display">\[
\begin{equation}\label{info}
I(x,c)=\sum_{x,c}p(x,c)\log\frac{p(x|c)}{p(x)}
\end{equation}
\]</span> ​ 作者显式地去建模<span class="math inline">\(p(x|c)/p(x)\)</span>，并且作者使用的这个比值不一定需要有归一化属性，只需要建模一个函数<span class="math inline">\(f(x)\)</span>与<span class="math inline">\(p(x|c)/p(x)\)</span>成正比即可。关于公式<span class="math inline">\(\eqref{info}\)</span>，作者自己是这么说的：</p>
<blockquote>
<p>By using a density ratio <span class="math inline">\(f(x_{t+k},c)\)</span> and inferring $ {z_{t+k}}$ with an encoder, we relieve the model from modeling the <strong><u>high dimensional distribution</u></strong> <span class="math inline">\(x_{t+k}\)</span>. Although we cannot evaluate p(x) or p(x|c) directly, we can use samples from these distributions, allowing us to use techniques such as Noise-Contrastive Estimation and <u><strong>Importance Sampling</strong></u> that are based on comparing the target value with randomly sampled negative values.</p>
</blockquote>
<p>​ 确实，作者没有用生成式模型去直接建模概率分布，而是使用类似重要性采样的方式去保证互信息可以得到尽可能大的值。</p>
<h3 id="cpcmoco的基本思想">2.3 CPC/MoCo的基本思想</h3>
<p>​ 是啊，理论很妙，是啊。。。但是？他们用这些理论在干什么来着？推了那么久公式，我们仿佛忘记了他们的目标究竟是什么。注意CPC中使用了NCE（<strong><u>Noise Contrastive</u></strong> Estimation），并且也要记住，这种<strong><u>无监督的</u></strong>对比学习方法核心就在于【对比】。那么和谁对比？<strong><u>噪声分布</u></strong>的数据对比，所以会有NCE。</p>
<ul>
<li><span class="math inline">\(P(x_{t+k}|c_t)\)</span>是根据上下文进行的采样，采样得到的结果就是正样本</li>
<li><span class="math inline">\(P(x_{t+k})\)</span>是负样本的来源分布</li>
</ul>
<p>​ 最大化正样本和负样本之间的互信息（衡量两个随机变量的独立性，或者说观察其中一个变量可以得到另一个变量的信息）。这里是在最大化<span class="math inline">\(x_{t+k}\)</span>与<span class="math inline">\(c_t\)</span>这两个随机变量的互信息，我们希望，根据上下文信息<span class="math inline">\(c_t\)</span>就能很好地对<span class="math inline">\(x_{t+k}\)</span>进行预测。但是在对比学习里面，预测并不是我们的目的。个人认为，对比学习的目的应该是：</p>
<div class="note primary"><p>​ 为了更好地区分正负样本，需要一个特征向量提取器，将所有输入映射为某个metric space中的一些向量。将这些向量用在下游任务上，比如用一个简单的MLP接受CL输出的向量的输出进行分类。（我在写这个的时候，我还完全没有实现过，并且也没有看到两篇论文的实验部分）。</p>
</div>
<p>​ 为了实现以上目的，两篇论文使用了不同的方法。</p>
<h4 id="cpc总体思想">2.3.1 CPC总体思想</h4>
<p>​ CPC最后希望生成encoder或者autoregressive model，来接收一个数据或者是一个数据序列，生成高维表征。CPC对于InfoNCE的优化，实际上是在优化一个交叉熵函数（二分类），由于二分类的交叉熵函数可以被写为：</p>
<p><span class="math display">\[
\begin{equation}\label{infonce2}
p(d=i|X,c_t)=\frac{p(x_i|c_t)\prod_{l\neq i}p(x_l)}{\sum_{j=1}^N p(x_j|c_t)\prod_{l\neq j}p(x_l)}
\end{equation}
\]</span> ​ <span class="math inline">\(p(x_i|c_t)\prod_{l\neq i}p(x_l)\)</span>表示了当<span class="math inline">\(x_i\)</span>是从正样本的上下文条件分布中采样得到，而其他的<span class="math inline">\(x_j\)</span>都是噪声采样时的概率。上式的所有连乘中均缺少本<span class="math inline">\(p(x_i)\)</span>，于是可以很容易写成<span class="math inline">\({p(x|c)}/{p(x)}\)</span>的形式。写成这个形式就可以使用CPC中对这个比值的建模了。总之也是构建encoder，encoder最终输出<span class="math inline">\(f(x_{t+k},c_t)\)</span>而中间产生的变量<span class="math inline">\(z_t\)</span>（隐变量）可以拿去用。</p>
<h4 id="moco总体思想">2.3.2 MoCo总体思想</h4>
<p>​ 对于CPC而言，其encoder每个minibatch都会更新，变化很快，可能就是属于MoCo论文中三种分类的第一种。</p>
<p><img src="/2021/08/29/Contrastive-Learning-Intros/2.PNG" style="zoom: 50%;"></p>
<center>
Figure 2. MoCo论文中对CL结构的三种分类
</center>
<p>​ 为了避免end2end造成的不稳定性（没有一致性），MoCo的key encoder相当于是在query encoder上做了一个指数平均（低通滤波），使得key encoder的参数变化很平滑。使得更新具有一致性。MoCo其他方面的基本思想与CPC也类似：</p>
<ul>
<li>对一个batch中的每一张图片，自身的增强为正样本，其他图片的增强为负样本</li>
<li>优化InfoNCE定义的函数：使得正样本最能被正确区分出来</li>
<li>使用query encoder的参数缓慢更新key encoder，并且key encoder不参与反向传播</li>
</ul>
<hr>
<h2 id="iii.-实现---moco">III. 实现 - MoCo</h2>
<p>​ Momentum contrast 的实现非常简单，论文中也提供了pseudo code，所以在实现过程中并没有遇到什么十分困难的问题。我倒是在训练过程中遇上了一些问题。首先，我实现了一个Encoder（轻量级的具有一些Residual Blocks的网络），结构大概是这样的：</p>
<p><img src="/2021/08/29/Contrastive-Learning-Intros/3.PNG"></p>
<center>
Figure 3. Encoder网络
</center>
<p>​ 因为我料到我可能跑不动论文里说的ResNet50以及ImageNet的巨大数据集，所以我针对CIFAR10设计了一个无监督pretext task。本来就是打算用这个网络结构当encoder来跑MoCo，但是发现，这个网络会使得loss一直卡在一个值上不动（极其长的时间，长到我没有耐心等待）并且波动很小。我怀疑这不能成功地训练，所以用这个网络直接做了一个Baseline训练了一下，emmm，结果很不错：大约96%的测试集准确率，虽然我不知道这是怎么算出超过1来的。不过训练集的准确率有时甚至可以达到1.00，说明这个网络还是有能力做好分类的。</p>
<p><img src="/2021/08/29/Contrastive-Learning-Intros/4.PNG"></p>
<center>
Figure 4. 简单ResNet结构的Baseline
</center>
<p>​ 我最后因为受不了垃圾MX150显卡，跑去租了一个云电脑。很爽啊，推荐<a href="http://gpu.ai-galaxy.cn/console">【智星云】</a>✨。租了一个这玩意：</p>
<p><img src="/2021/08/29/Contrastive-Learning-Intros/5.PNG"></p>
<p>​ 3.5元1h，不知道算不算便宜。我知道这个设备肯定能跑更强的网络，于是用torchvision内置的ResNet18（没有预训练）+一个从1000到128的ReLU FC层，训练了200个epochs，batch size为100。确实还挺快的，1秒多一个batch，要我的渣机跑可能得10s一个batch。训练的Loss结果如下。这个loss就比较符合预期了。</p>
<p><img src="/2021/08/29/Contrastive-Learning-Intros/6.PNG"></p>
<center>
Figure 5. ResNet18 MoCo Encoder loss训练成果
</center>
<p>​ 随后，使用这个训练好的Encoder，固定参数进行下游任务：有监督的MLP分类训练。MLP结构是128-&gt;64-&gt;64-&gt;32-&gt;10。结果挺 拉的💢，完全比不上Baseline，不知道为什么，个人觉得可能有几个tricks没用：</p>
<ul>
<li>loss是单向的，也就是说，生成出的q就当q用，k就当k用，只存k不存q，虽然q，k是不同的两次transform，但是没有做反向的loss</li>
<li>Shuffle BN，整个resnet内部都使用了BN，作者说直接使用BN是不好的</li>
<li>反正最后的结果也就是50%的样子，太拉了。</li>
</ul>
<p><img src="/2021/08/29/Contrastive-Learning-Intros/7.PNG"></p>
<center>
Figure 5. MLP 有监督evaluation 45 epochs batch_size 50
</center>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://zhuanlan.zhihu.com/p/334772391">Noise Contrastive Estimation 前世今生——从 NCE 到 InfoNCE</a></p>
<p>[2] <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html">He K, Fan H, Wu Y, et al. Momentum contrast for unsupervised visual representation learning[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 9729-9738.</a></p>
<p>[3] <a href="https://arxiv.org/pdf/1807.03748.pdf?fbclid=IwAR2G_jEkb54YSIvN0uY7JbW9kfhogUq9KhKrmHuXPi34KYOE8L5LD1RGPTo">Oord A, Li Y, Vinyals O. Representation learning with contrastive predictive coding[J]. arXiv preprint arXiv:1807.03748, 2018.</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>无监督</tag>
      </tags>
  </entry>
  <entry>
    <title>Depth Completion论文三篇</title>
    <url>/2022/01/23/Depth-Completion%E8%AE%BA%E6%96%87%E4%B8%89%E7%AF%87/</url>
    <content><![CDATA[<h1 id="depth-completion">Depth Completion</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​ 深度补全中存在多模态数据融合的问题：单目RGB图像直接进行深度估计比较困难（直接深度估计，个人感觉只能凭借常识和先验知识），而如果同时存在稀疏激光点云（散步在稠密的图像上），可以通过“传播的思想”将一些位置的深度传播出去。在返乡的高铁上没事干（事实上由于河南大雪以及湖北大雨，高铁变成了低铁，时间+2h），看了五篇论文，本文简要分析了其中三篇关于 guided深度补全的文章：</p>
<ul>
<li>ICCV 2019: <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Xu_Depth_Completion_From_Sparse_LiDAR_Data_With_Depth-Normal_Constraints_ICCV_2019_paper.pdf">Xu, Yan, et al. "Depth completion from sparse lidar data with depth-normal constraints." <em>Proceedings of the IEEE/CVF International Conference on Computer Vision</em>. 2019.</a></li>
<li>ICRA 2020 (可能写得不行 才6引): <a href="https://arxiv.org/abs/2103.00783">Hu, Mu, et al. "Towards Precise and Efficient Image Guided Depth Completion." <em>arXiv e-prints</em> (2021): arXiv-2103.</a></li>
<li>AAAI 2020: <a href="https://ojs.aaai.org/index.php/AAAI/article/view/6635">Cheng, Xinjing, et al. "Cspn++: Learning context and resource aware convolutional spatial propagation networks for depth completion." <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>. Vol. 34. No. 07. 2020.</a></li>
</ul>
<p>​ 本文可能写得<strong><u>很烂</u></strong>，笔者在看这三篇论文以及写博客时，由于返乡安排太紧，只睡了3.25小时。</p>
<span id="more"></span>
<h3 id="需要解决的问题">1.1 需要解决的问题</h3>
<p>​ 这里我就直接摘抄CSPN++中对于深度补全预期效果的阐述：</p>
<blockquote>
<p>CSPN claims three important properties should be considered for the depth completion task, 1) <strong><u>depth preservation</u></strong>, where the depth value at sparse points should be maintained, 2) <strong><u>structure alignment</u></strong>, where the detailed structures, such as edges and object boundaries in estimated depth map, should be aligned with the given image, and 3) <strong><u>transition smoothness</u></strong>, where the depth transition between sparse points and their neighborhoods should be smooth. [1]</p>
</blockquote>
<p>​ 但实际上，阅读ICCV 2019文章之后，个人觉得可能还差了这两点：</p>
<ul>
<li>符合3D约束，2D深度图能满足一些3D假设</li>
<li>正确的平滑假设：edge preserving的平滑假设（类似双边滤波的思想）</li>
</ul>
<hr>
<h2 id="ii.-sparse-lidar-guidance-iccv-2019">II. Sparse LiDAR Guidance (ICCV-2019)</h2>
<p><img src="/2022/01/23/Depth-Completion%E8%AE%BA%E6%96%87%E4%B8%89%E7%AF%87/iccv2019.png"></p>
<center>
Figure 1. 网络处理架构
</center>
<p>​ 个人认为本工作虽然比ICRA-2020这篇早了一年，但是质量更高。本论文看问题的角度非常独特：</p>
<div class="note primary"><ul>
<li>一般论文：直接在2D空间，硬凿loss，或者像ICRA-2020的PENet，包含一些不明所以的3D信息</li>
<li>本论文：直接在3D空间下建模 深度与法向量的关系，放弃piece-wise depth constant假设，转向piece-wise plain假设（观测由一块块平面构成）</li>
</ul>
</div>
<p>​ 个人认为，piece-wise depth constant是不优雅的，首先，这个假设的直接结果就是：边缘的模糊与平滑（相当于加了一个平均核），在2D CV邻域，成像结果可以是piece-wise constant的，光学成像结果不仅与深度有关，与反射率、材质、介质等等均有关系，十分复杂。但对于深度而言，此假设太过简单粗暴，而作者提到的 “plain-origin distance piece wise constant”则是基于：大量人工场景都是由碎片化的平面构成 这一特点，比较符合实际。举个例子，我们观测两堵墙，两堵墙都不是完全垂直于我们视线的。使用Piece-wise constant假设将会使得深度过渡更加平滑，对于多平面深度不连续情况而言，误差较大（会平均一些不该平均的位置），而“plain-origin distance piece-wise constant”则可以准确描述两堵墙（甚至是更多的平面）。</p>
<p>​ 本论文的一般处理步骤：</p>
<div class="note "><h4 id="特征提取网络prediction-stage">特征提取网络（prediction stage）</h4>
<div class="note danger no-icon">
<p>
​ UNet-ResNet34 backbone 提取特征，生成：<strong><u>coarse深度图</u></strong>，<strong><u>Guidance Feature</u></strong>（相当于context信息），<strong><u>法向量估计</u></strong>，<strong><u>置信度</u></strong>。
</p>
</div>
<div class="note warning no-icon">
<p>
​ 根据粗深度 + 法向量，变换到每个点所在平面到原点（也即相机中心）的距离
</p>
</div>
</div>
<div class="note "><h4 id="recurrent-refinement-stage">Recurrent Refinement Stage</h4>
<p>​ 使用Diffusion model（类似置信传播，但并未直接使用MRF或者CRF相关公式），可以认为是一种规则的图卷积？迭代多次，diffusion根据两个像素位置对应的guidance feature相似度判定diffusion coefficient。最后的结果从plain-origin distance变换为原始的深度。</p>
<p>​ 当然，如果涉及到存在sparse LiDAR深度点的像素位置，特征提取网络输出的 confidence 将会把原深度以及预测深度加权求和。</p>
</div>
<p>​ 这里只简单推一推Plain-origin distance：已知点到平面的距离公式是 <span class="math display">\[
\begin{equation}\label{dist}
N(\pmb{X})\cdot \pmb{X} -P=0
\end{equation}
\]</span> ​ 其中<span class="math inline">\(N(\pmb{X})\)</span>是三维点<span class="math inline">\(X\)</span>所在表面的切平面（tangent space）的法向量，通常来说，给定足够多的点，可以使用PCA或者求解协方差矩阵最小特征值对应特征向量（实际上还是类似PCA）的方法求解。<span class="math inline">\(\pmb{X}\)</span>是平面上一点到相机中心的相机坐标系3D vector。公式<span class="math inline">\(\eqref{dist}\)</span>表达的意义很清晰，<span class="math inline">\(N(\pmb{X})\cdot\pmb{X}\)</span>是 <span class="math inline">\(\pmb{X}\)</span> 在平面法向量上的投影距离，也就是原点到平面的距离。</p>
<p>​ 而有深度值 + 相机内参 + 像素位置，可以根据<span class="math inline">\(zK\pmb{x}=\pmb{X}\)</span>求的<span class="math inline">\(\pmb{X}\)</span>。那么正逆变换： <span class="math display">\[
\begin{align}
&amp;P(\pmb{x})=D(\pmb{x})N(\pmb{x})K\pmb{x}\\
&amp;D(\pmb{x})=\frac{P(\pmb{x})}{N(\pmb{x})K\pmb{x}}
\end{align}
\]</span> ​ 总的来说，这篇文章很好理解，写得很清晰。</p>
<hr>
<h2 id="iii.-penet-icra-2020">III. PENet (ICRA-2020)</h2>
<p>​ PENet个人感觉创新点很有限，这个网络给人一种十分魔法的感觉，比如Color-dominant和Depth-dominant是如何进行处理的，为什么可以做到不同模态数据的dominant。</p>
<img src="/2022/01/23/Depth-Completion%E8%AE%BA%E6%96%87%E4%B8%89%E7%AF%87/icra2020.png">
<center>
Figure 2. 看到网络结构后我就觉得 坏了 应该很魔法
</center>
<h3 id="dilated-accelerated-cspn">3.1 Dilated &amp; Accelerated CSPN++</h3>
<p>​ 作者唯一花了大篇幅介绍的，有实质内容的部分就是这一部分。其中有个很奇怪的地方（可能是我不懂Spatial Propagation Network），其中的公式（3）： <span class="math display">\[
\begin{equation}\label{map}
D_{i}^{t+1}=W_{ii}D_i^0+\Sigma_{j\in N(i)}W_{ji}D_j^t
\end{equation}
\]</span> ​ 对于这种迭代式的结构，个人感觉有点类似RNN（RAFT里就有RNN的某个经典结构：GRU）。但这和卷积的区别在哪？看起来很像卷积：对于图像某个位置的输出第t+1层卷积的输出，是上一层此位置周围邻域内所有输入线性组合的非线性映射（考虑激活函数）。关于这个translated propagation，照我个人理解，其意思大致是这样：仍以论文中<span class="math inline">\(3\times3\)</span>邻域为例：</p>
<p>​ 在一般情况下，对于一个【特征图】进行计算的<span class="math inline">\(3\times3\)</span>矩阵实际上应该是一个张量，此张量可以是<span class="math inline">\(3\times3\times C\)</span>大小的。换句话说，这里有9个特征向量，被组织成了二维grid结构。那么如果需要输出是一个向量，那针对每一个向量的映射就应该是大小为<span class="math inline">\(C\times C\)</span>的矩阵。故公式<span class="math inline">\(\eqref{map}\)</span>中定义的<span class="math inline">\(W\)</span>实际上应该是<u><strong>很多矩阵</strong></u>。</p>
<p>​ 这里与卷积不同的是：卷积层的每一个kernel都会考虑感受野内的每一个输入（除非这个卷积学习得很奇怪，就只有一个点值非0）。比如此处的<span class="math inline">\(3\times3\times C\)</span>的输入。假设我们使用一个<code>Conv2d(C, N, k = 3)</code>进行计算（输出一个大小为<span class="math inline">\(1\times1\times N\)</span>的向量），输出的第k个通道（此处也即<span class="math inline">\(\text{output}_{[0,0,k]}\)</span>）是： <span class="math display">\[
\begin{equation}
N_k=\sum_{t=0}^C\left\{\sum_{i=0}^2\sum_{j=0}^2A_t(i, j)C_t(i,j)\right\}+\text{bias},\text{ where }A\text{ is input and }C\text{ is kernel}
\end{equation}
\]</span> ​ 卷积实际上是将图像以通道划分的，处理信息的视角是 通道。而此处的Spatial Propagation，是以每个像素的特征向量为视角： <span class="math display">\[
\begin{equation}
V_o=\sum_{i=0}^2\sum_{j=0}^2W_{ij}A(i,j),\text{ where }W_{ij}\in\R^{C\times C}
\end{equation}
\]</span> ​ 我们可以认为这就是一个<strong><u>向量的线性组合</u></strong>过程。综上所述，通俗地来说：</p>
<ul>
<li>卷积是以通道为视角的，卷积核都是每个通道进行计算的</li>
<li>Spatial propagation（至少在这篇论文里）是特征向量（某一点的所有通道值）为视角的，可以视作向量的线性组合。</li>
</ul>
<p>​ 但需要注意的是，以上只是个人认为的【卷积】与【SP】的区别，论文中实际以【深度图】（单通道，而不是上文所说的特征图）进行计算，故每个<span class="math inline">\(W_{ij}\)</span>实际是一个具体的值。由于第t+1次迭代的输出（x, y）是第t次迭代输入（x, y）邻域值的组合。而由于不同像素<span class="math inline">\((x_1, y_1)\)</span>相对于其邻域某个点（比如相对距离(-1, -1)的像素）与<span class="math inline">\((x_2, y_2)\)</span>相对于相同的相对位置点，affinity值是不一样的，<strong><u>权重并不是共享</u></strong>的，故简单卷积是无法计算的。</p>
<p><img src="/2022/01/23/Depth-Completion%E8%AE%BA%E6%96%87%E4%B8%89%E7%AF%87/onehot.png"></p>
<center>
Figure 3. One-hot convolution --- affinity map shifting
</center>
<p>​ 事实上，按照SP的思想，每个像素相对于邻域内某个相对位置点将得到一affinity值，那么对于某一个相对位置点，将得到一个大小为<span class="math inline">\((H, W)\)</span>的单通道affinity map，就比如：，图像中所有像素相对于<span class="math inline">\(3\times 3\)</span>邻域内(-1, -1)位置将形成一个单通道affinity map，那么<span class="math inline">\(3\times 3\)</span>邻域将形成9个相对于不同位置的单通道affinity map。而且这些affinity map就像是relative positional embeddings一样，需要与正确相对位置的值运算，举例说明：</p>
<ul>
<li>考虑图像上（1, 1）点对应的像素，并考虑一个<span class="math inline">\(3\times 3\)</span>邻域</li>
<li>(1, 1)点对应像素在迭代生成输出时首先应将自身值与【相对位置(0, 0)的affinity map通道】上的【(1, 1)位置值（代表了(1, 1)点相对于与自身相对距离为(0, 0)点的affinity）】进行相乘，作为base值</li>
<li>后(1, 1)点计算其领域点信息：
<ul>
<li>(0, 0)点相对于【（-1, -1）affinity map通道上的(1, 1)位置】值相乘，叠加到base值上</li>
<li>(0, 1)点相对于【（-1, 0）affinity map通道上的(1, 1)位置】值相乘，叠加到base值上..., etc.</li>
</ul></li>
<li>从Figure 2中也看出相应的意思：<span class="math inline">\(A^x\)</span>是不同方向（x为方向，也即相对位置）对应的affinity map，在经过one-hot convolution之后，组成一个乘法kernel。</li>
</ul>
<p>​ 显然我们是不希望使用for循环的（对于CUDA加速不友好）。作者的方法实际上就是使用one-hot convolution实现了tensor的roll操作，并且此roll不是循环的（设0），因为有些像素就是没有某个特定位置的值（比如右下角点没有(1, 1)相对位置点）。直接roll可能需要借助额外的masking操作，故作者就使用固定的one-hot卷积核，卷积affinity map的每一个通道（每个通道的one-hot 卷积核不一样，因为所表示的相对位置不一样），卷积的结果可以直接用于【乘法 + 叠加】操作。</p>
<h2 id="iv.-cspn-aaai-2020">IV. CSPN++ (AAAI-2020)</h2>
<p><img src="/2022/01/23/Depth-Completion%E8%AE%BA%E6%96%87%E4%B8%89%E7%AF%87/aaai2020.png"></p>
<center>
Figure 4. 看成了CSDN...
</center>
<p>​ 本论文可以称为是：终极自适应 工作。CSPN++在两方面进行了自适应考虑：</p>
<ul>
<li>Context-aware：对于图像内容本身的处理进行自适应，用以提升精度</li>
<li>Resouce-aware：对于计算资源的自适应，比如自适应选择 <strong><u>卷积核大小（或propagation域大小）</u></strong> 以及 <strong><u>迭代次数（per-pixel）</u></strong></li>
</ul>
<p>​ 两方面的awareness存在权衡关系：计算资源富足时在计算精度以及结果质量上必然更好，反之亦然。其中，个人觉得Context-aware没有特别多可以说的，作者也就是从两个不同的角度进行信息综合：</p>
<ul>
<li>每一个像素使用不同大小的kernel得到的结果综合</li>
<li>每一个像素迭代不同阶段时的信息综合</li>
</ul>
<p>​ CSPN block迭代公式本身是： <span class="math display">\[
\begin{equation}
H^+_x(t+1)=\kappa(x) H_x(0) + \sum_{y\in N(x)}\kappa(y)H_y(t),\text{ where }N(x) \text{ is the neighbor of }x
\end{equation}
\]</span> ​ 其中的neighbor表示去心邻域，以上操作记为<span class="math inline">\(H_{CSPN}(x,t)\)</span></p>
<p>​ 综合 迭代平均 以及 核平均，更新公式应该是（我们令<span class="math inline">\(H_x(t )\)</span>为迭代第t次时，像素位置x的深度值hidden state）： <span class="math display">\[
\begin{align}
&amp; H^+_x(t+1)=\lambda_x(k, t+1)H_{CSPN}(x,t)+H^+_x(t)\\
&amp; H^+_x(t)=\sum_{i=0}^k\alpha_x(k)H^+_x(t,i), \text{ where }H_x^+(t, i) \text{ also indicates kernel size}
\end{align}
\]</span> ​ 其中<span class="math inline">\(\lambda_x(k, t)\)</span>（迭代综合系数）以及<span class="math inline">\(\alpha_x(k)\)</span> （kernel综合系数）都是网络的输出，注意这些系数均带有下标，说明是与像素有关的 per-pixel prediction coefficient。</p>
<p>​ 本论文有意思的点在于，论文通过Context-aware propagation过程定义的公式，导出了computational cost的简单表达式，computational cost在此处的作用相当于惩罚项。由于Context aware的过程是：multi-branch prediction，最后根据预测的<span class="math inline">\(\alpha\)</span> 以及 <span class="math inline">\(\lambda\)</span>系数整合多branch的预测结果。此处，<span class="math inline">\(\alpha\)</span>以及<span class="math inline">\(\lambda\)</span>是先于CSPN block实际迭代过程给出的（由一个修改的ResNet-34网络给出）。在Resource-aware计算过程中，作者将 “weighted average”变为了“max pool”：根据预测系数，每个像素位置选择“最大”branch进行计算： <span class="math display">\[
\begin{equation}
k_x^*=\mathop{\arg\max \alpha_x(k)}_k,t^*_x=\mathop{\arg \max\lambda(k_x^*,t)}_t
\end{equation}
\]</span> ​ 这样可以省去多路计算的计算开销，但显然这样牺牲了结果质量。</p>
<p>​ 另一方面，作者在论文中对computational cost进行了建模： <span class="math display">\[
\begin{align}
&amp; E(c_x|\{\alpha_x, \lambda_x\})=\frac  1{hw}\sum_x E(c_x|\alpha_x, \lambda_x)\label{normx}\\
&amp;E(c_x|\alpha_x, \lambda_{x})=\frac 1 {Nk_{\max}}\sum_{k}\sum_t\alpha_x(k)\lambda_x(k,t)k^2t\label{norma}
\end{align}
\]</span> ​ <span class="math inline">\(\eqref{normx}\)</span>相当于是所有像素位置求平均（期望），<span class="math inline">\(\eqref{norma}\)</span>则是某一个确定的像素位置进行的期望计算：因为一个像素位置进行传播的复杂度显然是<span class="math inline">\(O(k_{\max}^2N)\)</span>，其中<span class="math inline">\(k_{\max}\)</span>是最大核大小，<span class="math inline">\(N\)</span>是迭代次数，而如果将<span class="math inline">\(\alpha\)</span>以及<span class="math inline">\(\lambda\)</span>分别看作核取大小 <span class="math inline">\(k\)</span> 以及 迭代次数为 <span class="math inline">\(t\)</span> 时的概率（个人认为这是可以的，在“max pool”下选取的就是最大“概率”branch进行计算），cost的期望便可以以上述两个公式进行计算。</p>
<p>​ 事实上作者也将此惩罚项向有约束优化中拓展了，但最后的形式还是惩罚项（因为这个优化问题non-convex，拉格朗日对偶没啥大用处）。惩罚项的坏处就是，约束是软约束，超出约束范围是可能的。</p>
<p>​ 不过综上所述，个人觉得CSPN++这篇论文相对还是比较有意思的（尤其是Resource-aware部分），有一定启发性，相比ICRA 2020的PENet，个人觉得这篇文章写的更不那么魔法。</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>深度补全</tag>
      </tags>
  </entry>
  <entry>
    <title>Distance Metrics on Point Clouds</title>
    <url>/2021/11/14/Distance-Metrics-on-Point-Clouds/</url>
    <content><![CDATA[<h1 id="distance-metrics">Distance Metrics</h1>
<hr>
<h2 id="i.-introduction">I. Introduction</h2>
<p>​ 近期的研究有探究一个好的尺度的需求：判断配准是否完成。针对这个问题，我脑子里想的第一件事就是：判定两个点云在某个尺度上是否相近。带着这个目的，我结合之前看过的文献，在解决这个问题的方案中补充了一些新的内容。本文主要包括一下几个内容：</p>
<ul>
<li>三种传统点云尺度的简介（Hausdorff，Chamfer，Earth Mover's）</li>
<li>一种基于深度学习的距离尺度（ECCV 2020）<a href="https://link.springer.com/content/pdf/10.1007/978-3-030-58621-8_32.pdf">DPDist: Comparing Point Clouds Using Deep Point Cloud Distance</a></li>
</ul>
<blockquote>
<p>低维的最邻近点并不意味着结果能很好地适用于任务，高维的最邻近才是最终的追求。就像你和你异地的（男）女朋友，你们地理上不是最邻近，但是在某个高维空间中，确实是最邻近的，这就是为什么我们需要变换尺度与维度看问题。--- 哲♂学家 千越 · 让 · 德 · 叠buff · 何</p>
</blockquote>
<span id="more"></span>
<hr>
<h2 id="ii.-点云距离尺度">II. 点云距离尺度</h2>
<h3 id="引">2.1 引</h3>
<p>​ 在某些任务中，我们希望得到两个点云之间的一种接近程度的描述。比如在配准任务中，两个点云中相似的点或特征越接近，那么意味着配准结果越好。但由于点云表征不同于Grid、体素或者深度图等表征方式，点云是无结构，无顺序的。一些简单的比较方式不再适用，比如说：我有两个体素化的点云，这两个点云的接近我可以使用两个体素相减（体素内部含有占用概率），最后对这个结果张量求范数即可。这就是论文中说的：</p>
<blockquote>
<p>They are not a function on a grid, point clouds cannot be compared using a common metric (such as Euclidean metric)</p>
</blockquote>
<p>​ 一般来说点云的距离尺度有三个非常著名的距离：Hausdorff距离，Chamfer距离，Earth Mover's距离（EMD，或者叫Wasserstein距离，又或者叫Kantorovich-Rubinstein距离）。</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><img src="/2021/11/14/Distance-Metrics-on-Point-Clouds/haus.png"></th>
<th style="text-align: center;"><img src="/2021/11/14/Distance-Metrics-on-Point-Clouds/cd.png"></th>
<th style="text-align: center;"><img src="/2021/11/14/Distance-Metrics-on-Point-Clouds/haus.png"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Hausdorff</td>
<td style="text-align: center;">Chamfer</td>
<td style="text-align: center;">Earth Mover's</td>
</tr>
</tbody>
</table>
<center>
Figure 1. 三种常用的Distance metrics图示[1]
</center>
<h3 id="hausdorff">2.2 Hausdorff</h3>
<p>​ Hausdorff距离是一种：worst-case的距离描述，它描述了两个点云之间的一个距离上界。通俗地说，Hausdorff距离（单边）是这样定义的，假设我们有两个点集A，B：</p>
<ul>
<li>A中任意一个点p，都能在B中找到其最邻近点q。那么A中每个点有一个最小距离：<span class="math inline">\(d_i=\mathop{\min}_{q_j}\Vert p_i-q_j\Vert\)</span></li>
<li>取A中每个点最小距离的最大值（也就是最邻近距离的最大值）</li>
</ul>
<p>​ 完整的Hausdorff应该是：</p>
<ul>
<li>最后反过来，B中也有同样的一个最邻近距离的最大值。求A-&gt;B,B-&gt;A这两个距离中的大者。正式定义应该是：</li>
</ul>
<p><span class="math display">\[
\begin{equation}\label{haus}
d_{haus}=\max \left\{ D(A,B),D(B,A)\right\},\text{ where }D(X,Y)=\mathop{\max}_{p_i} \mathop{\min}_{q_j}\Vert p_i - q_j\Vert,p_i\in X,q_j\in Y
\end{equation}
\]</span></p>
<p>​ 这个公式的问题还是很大的，此距离很容易受到外点（outliers）的影响。在文献中已经提到了此距离的修改版，简单来说就是截断Hausdorff距离，超过一定阈值的<span class="math inline">\(\mathop{\min}_{q_j}\Vert p_i - q_j\Vert\)</span>不会被记录。但不管怎么样，这个距离都是一个最坏距离的衡量。</p>
<h3 id="chamfer">2.3 Chamfer</h3>
<p>​ Chamfer距离是一种平均意义上的距离，其意义很好理解：平均的最近点距离，定义如下： <span class="math display">\[
\begin{equation}\label{chamfer}
d_{chamfer}=\text{normalize}(\sum_{q_j\in B}\mathop{\min}_{p_i}\Vert p_i-q_j\Vert + \sum_{p_i\in A}\mathop{\min}_{q_j}\Vert p_i-q_j\Vert)
\end{equation}
\]</span> ​ 这个距离倒是没什么好说的，它是一个平均意义上的距离，实现起来比较方便，但是对基于特征的方法并不友好（高维最邻近点计算很恶心）。很常用，因为Chamfer distance相对于EMD存在一个优点：它并不要求建立双射，也就不要求两个点集的大小一致，可以有一对多联系。在骷髅融合者这篇博客中，我分析了一下作者提出的Composite Chamfer Loss，作者通过修改反向距离，建立了一个非对称的，针对不同稠密程度点云的Chamfer loss。</p>
<h3 id="earth-movers">2.4 Earth Movers'</h3>
<p>​ 这是最理想的距离尺度，其基本定义为： <span class="math display">\[
\begin{equation}\label{emd}
d_{EMD}(A, B)=\mathop{\min}_{\phi: A\rightarrow B}\sum_{p_i\in A}\Vert p_i - \phi(p_i)\Vert
\end{equation}
\]</span> ​ 其中<span class="math inline">\(\phi\)</span>是点集A到B的一个双射。由于是双射，上式是一个双向对称的距离。在2.3中已经说了，双射就要求集合大小一致，通常情况下，这并不容易满足，特别是在SLAM背景下，部分观测（见3.3）导致一般用不了这个距离。但在一般意义下，这个距离是最优的：</p>
<p><img src="/2021/11/14/Distance-Metrics-on-Point-Clouds/emd-cd.png"></p>
<center>
Figure 2. EMD与CD的比较，这张图的结果是很显然的[1]
</center>
<p>​ 接下来到了科普思考时间。为什么这个距离叫做Earth Mover's（我称之为，搬砖者距离）？ 维基百科上这么说</p>
<blockquote>
<p>In statistics, the earth mover's distance (EMD) is a measure of the distance between two probability distributions over a region D. Informally, if the distributions are interpreted as two different ways of piling up a certain amount of earth (dirt) over the region D, the EMD is the minimum cost of turning one pile into the other; where the cost is assumed to be the amount of dirt moved times the distance by which it is moved.[2]</p>
</blockquote>
<p>​ 嗯，intuitively，确实是这样的。所以称这个距离为搬砖者距离也没有问题。</p>
<hr>
<h2 id="iii.-dpdist">III. DPDist</h2>
<h3 id="基本思想">3.1 基本思想</h3>
<p>​ Deep Point Cloud Distance，则是一种新的距离尺度，相当于是一种基于深度学习输出的误差函数定义（本身DPDist也就可以当做误差函数）。其最主要的思想就是：</p>
<div class="note primary"><p>我们不应该直接去比较两个点云，这是非常不优雅的。点云的比较，点云之间的距离，说白了应当是：其中一个点云的每一个点，到另一个生成点云<strong><u>原本的真实世界障碍物表面</u></strong>的距离。不应当是直接的：点-点距离，应当是：点-面距离。</p>
</div>
<p>​ 这个想法确实是自然的，点云表征具有稀疏性，除非两个点云在物理世界的采样点完全一致，否则点-点距离再如何好都只是一个近似罢了。</p>
<center>
<img src="/2021/11/14/Distance-Metrics-on-Point-Clouds/dpdist.png">
</center>
<center>
Figure 3. 论文中有关DPDist与CD（Chamfer distance）的比较
</center>
<p>​ 但新的问题同时会出现：真实世界的表面，我们是无法获得的，只能从点云中估计出来。表面估计可以是全局的，也可以是局部的。但一般来说，全局的非常难做：我们要从一个2D点云中，估计一整个连续函数用来表征点云的采样表面，这可能还稍微容易一些，但是3D，emmm，文中说某个网络想做这个事，用了亿点点参数，也没做好。</p>
<p>​ 局部表面估计首先简单，参数量可以小，并且，局部近似度能更高（就比如，局部线性化，局部范围越小，近似度可以越高）。那这就产生了两个问题：</p>
<ul>
<li>我怎么能确定，点云A上的给定点p，应该使用点云B的哪一块计算局部表面来估计距离？</li>
<li>局部表面如何估计，计算如何进行？</li>
</ul>
<h3 id="作者的魔法解决之路">3.2 作者的魔法解决之路</h3>
<p>​ 首先，我们需要点云的全局特征。说是全局，不如说是很多局部特征的组合，分块儿的局部特征，合成一个全局特征。作者使用3DmFV（没细看过这篇论文），大概思路就是：</p>
<p>​ 首先将空间划分为一个个的Grid（可以是一个粗粒度的划分），假设空间中存在<span class="math inline">\(K\times K\times K\)</span>个grid。由于原点云已经生成了一个N成分的混合高斯模型（GMM）（也就是一个多高斯分布加权的分布）， 在不同的Grid中，都可以求到一个Fisher Vector（也就是综合了Grid局部信息的一个GMM梯度）。由于Grid划分是固定的，固定就意味着训练方便。</p>
<div class="note danger no-icon"><p><span class="math inline">\(K\times K\times K\)</span>每个格提取GMM的特征，得到一个四维张量：<span class="math inline">\(K\times K\times K\times F\)</span>。这是整个点云的全局特征，它是一种固定的，有结构的特征。假设这个特征是点云A的，我们将之记为：<span class="math inline">\(L^{S_A}\)</span></p>
</div>
<div class="note warning no-icon"><p>对于每个点云B中的query点（要求点-面距离的点），总是在A中寻找里query点(<span class="math inline">\(b_i\)</span>)最近的grid，在最近Grid周围扩散n步，形成一个<span class="math inline">\(k\times k \times k\)</span>大小的子grid，k当然是奇数，因为最近点是中心，向外扩散n步则<span class="math inline">\(k=2n+1\)</span>。</p>
</div>
<div class="note info no-icon"><p>这<span class="math inline">\(k\times k \times k\times F\)</span>大小的张量（subgrid的特征）将被concat到<span class="math inline">\(b_i\)</span>的点云坐标上（好魔法啊，又开始concat了）。最后过一个三层全连接层，得到距离。</p>
</div>
<div class="note success no-icon"><p>由于存在对称性，A-&gt;B以及B-&gt;A的DPDist都需要计算，最后按照点数平均，得到最终的距离。</p>
</div>
<p><img src="/2021/11/14/Distance-Metrics-on-Point-Clouds/struct.png"></p>
<center>
Figure 4. DPDist的网络结构
</center>
<h3 id="个人觉得存在的问题">3.3 个人觉得存在的问题</h3>
<p>（1）部分观测。整个网络还是限定了：每个点都能有个属于自己的表面。这在一些object点云数据集上是成立的，但是在SLAM系统中很难成立。由于使用最近grid，那些两个观测点观测的对称差集中的点，会被错误地assign到一个不属于自己的表面上，这在计算中会导致问题（不准）。所以让我感到迷惑的是，作者将DPDist用在了PCRNet中（PCRNet是一个。。。emmm很魔法的网络），作为点云配准的距离尺度，替换了原来的EMD。看了它的实验就知道：人家搁这搞一张椅子的配准：</p>
<blockquote>
<p>Using the ”Chair” category and following [20], we randomly generate 5070 different transformations for training and other 5070 transformations for testing.</p>
</blockquote>
<p>​ 这种物体级数据集当然不会遇到部分观测问题。事实上，部分观测问题也限制了EMD（毕竟EMD希望能建立一个点集之间的双射），部分观测导致双射无法建立。并且在SLAM问题下，对同一个物体进行不同分辨率下的观测，也直接限制了EMD的使用。</p>
<p>（2）3DmFV？虽然，论文中说3DmFV特征描述比PointNet描述更好，但是3DmFV却引入了“体素化”这种东西（虽然可以是一个很粗粒度的）。但这是否会带来accuracy-memory tradeoff？高斯表征与混合高斯模型的描述能力以及是否有正确的物理含义也是没有说清楚的。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="http://3ddl.cs.princeton.edu/2016/slides/su.pdf">Hao Su (Stanford University): 3D Deep Learning on Geometric Forms, pdf</a></p>
<p>[2] <a href="https://en.wikipedia.org/wiki/Earth_mover%27s_distance">Wikipedia: Earth Mover's Distance</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>PointCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>Dynamic Routing Between Capsules 复现</title>
    <url>/2021/07/18/Dynamic-Routing-Between-Capsules-%E5%A4%8D%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="capsules-network">Capsules Network</h1>
<hr>
<p>​ 上一次看这篇论文：<a href="https://arxiv.org/abs/1710.09829"><em>Dynamic Routing Between Capsules</em></a> 的时候，Pytorch技术还很菜，不是特别熟练，被矩阵计算的维数问题搞傻了，写得很痛苦，loss没写完就放弃了。这次在重新读完论文之后，重新试着复现了一波，最后差点败在一个softmax的执行维度上（可以说很奇异了）。第一版caps net网络结构非常简单，对应的evaluation / experiments也很简单。实现见<a href="https://github.com/Enigmatisms/CapsNet">[Github🔗Enigmatisms/CapsNet]</a></p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><img src="/2021/07/18/Dynamic-Routing-Between-Capsules-%E5%A4%8D%E7%8E%B0/G_1101.jpg" alt="G_1101" style="zoom:150%;"></th>
<th style="text-align: center;"><img src="/2021/07/18/Dynamic-Routing-Between-Capsules-%E5%A4%8D%E7%8E%B0/G_1151.jpg" alt="G_1151" style="zoom:150%;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">根据digital capsule重建（MNIST 7 epochs）</td>
<td style="text-align: center;">根据digital capsule重建（MNIST 7 epochs）</td>
</tr>
</tbody>
</table>
<span id="more"></span>
<hr>
<p>​ 等待填坑</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title>Enigma&#39;s First Blog</title>
    <url>/2021/01/29/Enigma&#39;s-First-Blog/</url>
    <content><![CDATA[<p>​ This post is for testing all the configurations and settings are good to go.</p>
<p>​ I decided to start my own blog, for keeping track of the knowledge and skills I have learned. This blog site may well be known to others one day, and there is nothing to lose for me if otherwise. (Self pleasuring, I like to see things organized.)</p>
<ul>
<li><p>A lot of markdown notes of mine are poor-organized for the lack of a good platform in which those notes can be published.</p></li>
<li><p>A blogging website might motivate me to interpret the essence of knowledge learned in my own language, moving from 'self teaching' to teaching others (Deeper understanding is established on the ability to teach others).</p></li>
<li><p>"Open source in Knowledge" is another reason, for there were many times at which I can read blogs of others when I need help. Thereby, publishing what you know might, in turn, help others.</p></li>
<li><p>Unfortunately, I found my words messy, ambiguous and sometimes unorganized, making practices demanded increasingly.</p></li>
<li><p>3-2 term in XJTU, I have a computer network related course incoming. I think I can learn something from maintaining my own blog pages.</p></li>
</ul>
<p>​ This blog might be written in both English and Chinese, which depends on the depth of contents. The page is also deployed to <code>enigmatisms.github.io</code>.</p>
<center>
<i>Amat Victoria Curam.</i>
</center>
]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>English</tag>
        <tag>personal</tag>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title>GAN原理与实现</title>
    <url>/2021/02/02/GAN%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="gan-生成对抗网络">GAN 生成对抗网络</h1>
<hr>
<h2 id="编码器原理">编码器原理</h2>
<h3 id="自动编码器">自动编码器</h3>
<p>​ 自动编码器，简单地说就是以下结构：</p>
<p><img src="/2021/02/02/GAN%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0/GAN_1.JPG"></p>
<p>​ 从原始输入，对其进行编码（编码过程可以使用感知机（前馈，无BP操作）或者神经网络（现在的架构一般是BP式的优化）），生成 <strong><u>压缩后的编码数据</u></strong>。再想办法从编码中（必然存在信息损失）恢复原来的图片。但是一般而言，自动编码器（AE）都是确定输入输出的，每一种编码会由训练得到唯一的输出。</p>
<p>​ 我们希望生成更多的数据或者达到人工智能创作 / 想象的目的，需要随机的输出。我们希望可以加入编码的扰动（Perturbance）或者人工的干预（Intervention），让编码更加多样化 / 随机化，而且Decoder可以对这种加入的噪声鲁棒。这就得到了VAE（Variational Auto Encoder）变分自动编码器。</p>
<h3 id="变分自动编码器">变分自动编码器</h3>
<p>​ 一个想法：首先一个随机的编码器在数学上的表现应该是给定一个向量（比如编码）Z，从Z中恢复X（训练集的分布）。那么就是从<span class="math inline">\(P_Z(x)\)</span>到<span class="math inline">\(P_X(x)\)</span>的映射（编码分布空间到样本空间的映射），得到新的分布<span class="math inline">\(P_{\hat X}(x)\)</span>。那么根据贝叶斯的想法，可以表示分布<span class="math inline">\(P_X(x)\)</span>为： <span class="math display">\[
\begin{equation}
P_X(x)=\sum_kP(X|Z_k)P(Z_k)\label{YY}
\end{equation}
\]</span> ​ 意思是：不同编码的分布 与 给定编码下，输出数据为对应类型X 两者的条件概率结合。那么数据生成和分布之间的关系又是什么呢?直观地理解一下：</p>
<p>​ 世界上有几乎无数种猫，猫产生的后代也不是和其父母一致的。那么我们如果想从数据层面【生成猫】，应该首先知道 <strong>不同表现型的猫的【总体分布】</strong>，如果知道这个分布，显然只需要从这个分布中随机采样就可以得到任意新性状的猫。但是这个分布基本是不可知的，即使存在海量数据我们也没办法得到这个分布的表达式。所以我们希望通过别的方式来近似表达这个分布，比如使用式(1)。</p>
<p>​ 假设Z不是编码而是不同的形状，那么可以建立一个性状以及含有对应组合表现型的猫的概率映射，通过贝叶斯全概率公式获得。而把Z换为编码（<strong>更加抽象的形状表示</strong>），也是一样的，编码存在分布（正如不同性状如黑白存在一定分布），而给定编码（给定形状）时也存在其他的分布（Z=公猫，公猫中的白猫 / 花猫分布等等）。</p>
<p>​ VAE中，<span class="math inline">\(P(Z)\)</span>被建模成了标准正态分布（其他分布也可），原因有以下两点：</p>
<ul>
<li>标准正态分布常见，并且方便进行熵计算（<strong><u>或者说，KL散度计算时不会出现问题（比如均匀分布会存在概率密度为0导致奇异性的现象）</u></strong>）</li>
<li>天然的exp性质，并且表示容易，只需要对<span class="math inline">\(\mu,\sigma\)</span>进行建模表示即可。</li>
</ul>
<hr>
<h2 id="gan原理">GAN原理</h2>
<ul>
<li>GAN需要构建一个生成器和一个判别器，生成器需要生成能够以假乱真的数据。生成出的数据需要输入到判别器中，由判别器进行判定：此数据是真的（非生成的）还是假的（生成的）。<strong><u>固定判别器的参数，训练生成器参数，</u></strong>使得生成器生成的结果输入到判别器中，二分类（真假判定）得到结果尽可能接近1.</li>
<li>判别器的训练：我们希望我们的判别网络尽可能强大，能够区分真假数据，这样再进行生成器训练时，生成器训练会有更加严格的监督。判别器训练时，固定生成器网络参数，生成器生成的数据需要使label尽可能为false。</li>
</ul>
<p><img src="/2021/02/02/GAN%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0/GAN_2.JPG"></p>
<ul>
<li>并且，分类器不仅能正确处理生成器生成的数据（正确地label成false类）（True Positive），还需要有处理True Negative的能力，对于真实的数据，需要正确分类为真。</li>
</ul>
<hr>
<h2 id="gan的数学原理">GAN的数学原理</h2>
<h3 id="kl散度">KL散度</h3>
<p>​ 需要回忆一下KL散度的定义，KL散度描述的是两个概率分布的相似程度，又称为相对熵。既然是“熵”，那么相对熵就与绝对熵（信息熵）存在关系。信息熵是信息不确定程度的度量。而信息量的度量是： <span class="math display">\[
I(x_i)=-log(p(x_i))
\]</span> ​ 也就是说：事件发生的概率越小，若发生，携带的信息量是越大的。对于一个具有一定不确定度的信息源，一个事件<span class="math inline">\(x_i\)</span>发生的概率若是<span class="math inline">\(P(x_i)\)</span>，那么信息熵为： <span class="math display">\[
H(x_i)=-p(x_i)log(p(x_i))
\]</span> ​ 如果信息源发送的“事件”存在n个不同的取值，每个事件的概率为<span class="math inline">\(p(x_i)\)</span>，那么，信息源熵为： <span class="math display">\[
H(U)=-\sum_{i=1}^np(x_i)log(p(x_i))
\]</span> ​ 可以看出，信息熵是系统信息量根据概率分布的加权，是一个系统的平均（期望）信息量。</p>
<h3 id="kl散度的由来">KL散度的由来</h3>
<p>​ 对于一个字符集（比如26字母，需要进行不等长编码），假设每个字符X出现的概率是<span class="math inline">\(P(x)\)</span>，那么可以知道，一个字符需要编码的字节数（或者位数）会对等于信息量<span class="math inline">\(I(x)\)</span>，那么一个字符集编码的平均字节数等于信息熵<span class="math inline">\(H(U)\)</span>。假设，这个字符集的真实概率分布为<span class="math inline">\(P(x_i)\)</span>，那么其平均编码数为 <span class="math display">\[
H(X)=\sum_{i=1}^n p(x_i)log(\frac{1}{p(x_i)})
\]</span> ​ 由于，<span class="math inline">\(P(x_i)\)</span>是字符集X的真实概率分布，对于X是最优的（对应的编码方式是最优的）。如果需要以这种编码方式对字符集Y（对应的概率分布为<span class="math inline">\(Q(x_i)\)</span>）进行编码，编码平均字节数必然是更多的（因为不是最优的），那么这种编码下存在的差异是： <span class="math display">\[
D_{KL}(P||Q)=\sum P(x)log(\frac{1}{Q(x)}) - \sum P(x)log(\frac{1}{P(x)})=\sum P(x)\frac{P(x)}{Q(x)}
\]</span> ​ 理解了编码的物理意义就知道，为什么是<span class="math inline">\(\frac {P(x)}{Q(x)}\)</span>了，因为<span class="math inline">\(Q(x)\)</span>并非最优分布，需要的编码量更大。而我们不喜欢负数，为了让KL散度为正，故这样定义。</p>
<p>​ 穿插一点优化原理的知识：为什么使用交叉熵作为很多网络的损失函数？</p>
<h3 id="交叉熵与kl散度的关系">交叉熵与KL散度的关系</h3>
<p>​ 交叉熵的定义： <span class="math display">\[
H_c(x)=-\sum_{i=1}^np(x_i)log(q(x_i))=\sum P(x)log(\frac{1}{Q(x)})
\]</span> ​ 与KL散度的公式进行对比，可以发现： <span class="math display">\[
D_{KL}(P||Q)=H_c(x)-\sum P(x)log(P(x))
\]</span> ​ 其中：<span class="math inline">\(\sum P(x)log(P(x))\)</span>表征的是原始分布。在训练过程中（比如典型的分类器训练），<span class="math inline">\(P(x)\)</span>一般是给定的：比如我们给定数据的原始label就是给定了一个原始分布，我们希望网络学习到的分布参数能够尽可能与原始分布接近。而由于<span class="math inline">\(\sum P(x)log(P(x))\)</span>是常数（给定的原始分布是常的），优化交叉熵就相当于优化训练集与输出的KL散度。</p>
<h3 id="gan在优化什么">GAN在优化什么</h3>
<p>​ GAN的训练过程本质上就是构造一个近似的原始分布。由于我们只有原始分布的采样（比如MNIST手写数据集，是手写数字的采样），我们希望得到采样外的数据，那就需要原始分布。那么构建原始分布，可以看作是：构建一个带有参数集合<span class="math inline">\(\{\theta\}\)</span>的分布<span class="math inline">\(P_G\)</span>，使得，从<span class="math inline">\(P_G\)</span>中采样得到的原始分布的采样（给定的数据集）的概率尽可能大（个人理解）。</p>
<p>​ 什么意思？我们认为：在极大似然的思想下，参数应该尽可能反映采样的结果，也就是给定真实分布<span class="math inline">\(P_R\)</span>的抽样集合<span class="math inline">\(d = \{x_1, x_2, ... x_n\}\)</span>，应该使下式最大（极大似然）。 <span class="math display">\[
\begin{align}
&amp;L(\theta)=\prod_{i=1}^n P_G(x_i|\theta) \\
&amp;\theta^*=\mathop{argmax}_{\theta}\prod_{i=1}^n P_G(x_i|\theta)
\end{align}
\]</span> ​ 接下来我们对公式(10)进行一些数学上的变换：</p>
<ol type="1">
<li>log化：由于log是严格增的，加log将不影响结果</li>
</ol>
<p><span class="math display">\[
\theta^*=\mathop{argmax}_{\theta}\;log(\prod_{i=1}^n P_G(x_i|\theta))=\mathop{argmax}_{\theta}\;\sum_{i=1}^nlog(P_G(x_i|\theta))
\]</span></p>
<ol start="2" type="1">
<li>与真实分布进行关联：在生成器对应的生成分布近似于原始分布的情况下，生成分布下讨论最优参数<span class="math inline">\(\theta^*\)</span>对应的似然，就等价于讨论原始分布采样得到结果概率。</li>
</ol>
<p><span class="math display">\[
\theta^* \approx \mathop{argmax}_{\theta}\;S_x\{P_R|log(P_G(x|\theta))\}
\]</span></p>
<p>​ 上式的意义是：<span class="math inline">\(\sum_{i=1}^nlog(P_G(x_i|\theta))\)</span>-&gt;中的<span class="math inline">\(x_i\)</span>相当于从真实分布<span class="math inline">\(P_R\)</span>中抽样得到，隐含了抽样概率（得到<span class="math inline">\(x_i\)</span>的概率被隐含了），如果抽样次数接近无穷大，相当于对全空间进行抽样，可以连续化为： <span class="math display">\[
\theta^*=\mathop{argmax}_{\theta}\;\int_x P_R(x)log(P_G(x|\theta))dx
\]</span></p>
<ol start="3" type="1">
<li>转化为KL散度：实际上(13)已经有KL散度的影子了，KL散度的连续形式为：</li>
</ol>
<p><span class="math display">\[
D_{KL}(P||Q)=\int_x P(x)log(\frac{P(x)}{Q(x)})dx
\]</span></p>
<p>​ 则，由于在argmax过程中引入与<span class="math inline">\(\theta\)</span>无关的常数因子，不影响结果，那么(13)可以写为： <span class="math display">\[
\theta^*=\mathop{argmax}_{\theta}\;\int_x P_R(x)log(P_G(x|\theta))dx-\int_x P_R(x)log(P_R(x))dx
\]</span> ​ 与(14)对比，发现，后端需要优化的式子就是对应的KL散度： <span class="math display">\[
\int_x P_R(x)log(P_G(x|\theta))dx-\int_x P_R(x)log(P_R(x))=\int_x P_R(x)log(\frac{P_G(x)}{P_R(x)})dx=D_{KL}(P_R||P_G)
\]</span> ​ 也就是说：得到最优生成分布的参数<span class="math inline">\(\theta\)</span>的过程就是在优化原始分布（未知，但是采样已知）与最优生成分布的KL散度。</p>
<h3 id="生成分布的计算">生成分布的计算</h3>
<p>​ 那么，为什么GAN要在高斯中采样？原来的latent vector(z)又是如何一步步变到生成数据的？我们已经通过近似证明了（其中一个巧妙的思想就是：采样得到的样本隐含了其概率分布）优化GAN生成器与优化生成分布/原始分布KL散度的等价性。</p>
<p>​ 在公式(16)中，存在<span class="math inline">\(P_G(x|\theta)\)</span>，这是之前从未出现过的。我们通过latent vector z（从多维高斯中采样的随机向量）构造了一个从多维高斯分布经非线性映射得到的生成分布。那么<span class="math inline">\(P_G(x|\theta)\)</span>自然与高斯分布有关。那么<span class="math inline">\(P_G(x|\theta)\)</span>可以被表示为：</p>
<p><span class="math display">\[
P_G(x|\theta)=\int_zP_{prior}(z)I_G(z)dz \\
I_G(z)=
\left\{
    \begin{array}{**lr**}
        1,\;if\;G(z)=x,\\
        0,\;if\;G(z)\neq x
    \end{array}
\right.
\]</span></p>
<p>​ 也就是说此处使用了一个类似边缘分布的求取的方法，将所有可以生成x的z找到，求取其概率。其中<span class="math inline">\(P_{prior}\)</span>是先验分布，在此处是多维高斯。以上只是理论推导，实际上，指示函数<span class="math inline">\(I_G(z)\)</span>是不可知的，那么使用公式(17)是无法计算<span class="math inline">\(P_G(x|\theta)\)</span>的。此时我们引入了判别器 Discriminator，用以取代MLE的指示函数处理。</p>
<h3 id="判别器与js散度的导出">判别器与JS散度的导出</h3>
<p>​ 每次生成器G训练时，我们都希望，在给定的判别器D较优时，生成器G仍然能骗过D。首先，根据简单的BCELoss，我们定义需要优化的score（最大化）： <span class="math display">\[
S(G, D)=S_{x\{P_R\}}\;log(D(x))+S_{x\{P_G\}}\;log(1-D(X))
\]</span> ​ 上式也就是D训练时，希望能最优地区分原始数据与生成数据所定义的Score。那么采样<span class="math inline">\(S_{x\{dist\}}\)</span>可以展开为定积分： <span class="math display">\[
S(G,D)=\int_xP_R(x)log(D(x))dx+\int_x P_G(x) log(1-D(x))dx
\]</span> ​ 判别器训练时，G的参数不变，原始分布参数也不变，那么公式(19)中的可变量就是D的参数。我们需要求到一个最优的D（<span class="math inline">\(D^*\)</span>）以最终求得G：也即最优判别器下对应的最优生成器。 <span class="math display">\[
G^*=\mathop{argmin}_{G}\;\mathop{argmax}_{D}\;S(G,D)
\]</span> ​ 可以将(19)式合并积分内式子，并且进行求导（对D）： <span class="math display">\[
\begin{align}
    &amp;S_n(D)=P_R(x)log(D(x))+P_G(x) log(1-D(x))\\
    let:\;&amp;\frac{\partial S_n}{\partial D}=\frac{P_R(x)}{D}-\frac{P_G(x)}{1-D}=0
\end{align}
\]</span></p>
<p>​ 可以得到最优判别器的参数D为： <span class="math display">\[
D(x)=\frac{P_R(x)}{P_R(x) + P_G(x)}
\]</span></p>
<p>​ 那么公式(19)的D(X)表达式已经知道了，带入得到： <span class="math display">\[
S(G,D)=\int_x
\left\{
    P_R(x)log(\frac{P_R(x)}{P_R(x) + P_G(x)}) + P_G(x) log(\frac{P_G(x)}{P_R(x) + P_G(x)})
\right\}
dx
\]</span></p>
<p>​ 单独讨论(24)积分内部的式子，可以发现，当我们进行如下处理后： <span class="math display">\[
\begin{equation}
\int_x P_R(x) log(\frac{P_R(x)}{\frac{P_R(x) + P_G(x)}{2}})dx + \int_x P_G(x) log(\frac{P_G(x)}{\frac{P_R(x) + P_G(x)}{2}})dx-2log2\\
=D_{KL}(P_R|{\frac{P_R(x) + P_G(x)}{2}})+D_{KL}(P_G|{\frac{P_R(x) + P_G(x)}{2}})-2log2\\
=2D_{JS}(P_R|P_G)-2log2
\end{equation}
\]</span> ​ 我们将式(25)化简结果的部分进行定义： <span class="math display">\[
D_{JS}(P|Q)\overset{\Delta}{=}{\frac12}D_{KL}(P|M)+{\frac12}D_{KL}(Q|M),\\
where\;\;M=\frac{P+Q}2
\]</span> ​ 可以看出，JS散度相比于KL散度而言，其是对称的。我们优化的是关于 {生成分布}{原始分布}的JS散度，其中借助了判别器，判别器将复杂的MLE指示函数（形式不负责，但是难算）转化为了易于计算的JS散度，以优化两个分布的差异。</p>
<hr>
<h2 id="原始gan为什么难以训练">原始GAN为什么难以训练</h2>
<p>​ 原始GAN实际在优化(25)式对应的JS散度。<span class="math inline">\(P_G\)</span>与<span class="math inline">\(P_R\)</span>可以互相接近（<span class="math inline">\(P_G\)</span>通过梯度来调整）。而如果，这两个分布本身就几乎不重合（什么叫不重合？），会怎么样？</p>
<p>​ 不重合的定义很简单，概率密度不为0的位置错开了（或概率密度较大的位置错开了）。那么假设<span class="math inline">\(P_G\)</span>与<span class="math inline">\(P_R\)</span>的关系是任意的，那么会有如下四种关系：</p>
<ul>
<li><span class="math inline">\(P_G(x)\approx 0,P_R(x)&gt;&gt;0\)</span></li>
<li><span class="math inline">\(P_G(x)&gt;&gt; 0,P_R(x)\approx 0\)</span></li>
<li><span class="math inline">\(P_G(x)&gt;&gt; 0,P_R(x)&gt;&gt;0\)</span></li>
<li><span class="math inline">\(P_G(x)\approx 0,P_R(x)\approx 0\)</span></li>
</ul>
<p>​ 在前两种情况成立时，不重合（一个分布有值的地方，另一个分布基本上没有值）。那么在不重合情况下，我们重新看一下公式(25): <span class="math display">\[
2D_{JS}(P_R|P_G)=\int_xP_R(x)log(\frac{P_R(x)}{\frac{P_R(x) + P_G(x)}{2}})dx + \int_xP_G(x) log(\frac{P_G(x)}{\frac{P_R(x) + P_G(x)}{2}})dx
\]</span> ​ 当<span class="math inline">\(P_G\)</span>不为0的位置，<span class="math inline">\(P_R\)</span>接近0，那么可以知道，(27)的计算结果为log2，对于第二种情况，计算结果也是log2（或与x有关，但是x的影响极其小）。可以知道，在这种情况下，需要优化的<span class="math inline">\(D_{JS}\)</span>已经不具备指导意义了，梯度已经消失了。生成器无法得到有用的信息。</p>
<blockquote>
<p><span class="math inline">\(P_R\)</span>与<span class="math inline">\(P_G\)</span>不重叠或重叠部分可忽略的可能性有多大？不严谨的答案是：非常大。比较严谨的答案是：当<span class="math inline">\(P_R\)</span>与<span class="math inline">\(P_G\)</span>的支撑集（support）是高维空间中的低维流形（manifold）时，<span class="math inline">\(P_R\)</span>与<span class="math inline">\(P_G\)</span>重叠部分测度（measure）为0的概率为1。</p>
</blockquote>
<ul>
<li>其中，支撑集就是（1）函数的非零部分集合（2）概率分布的非0部分集合。</li>
<li>流形：就是高维空间中的，拥有实质更低自由度的形体。</li>
</ul>
<p>​ 那么可知：<span class="math inline">\(P_G\)</span>的支撑集恰好就是高维空间中的低维流形。由于我们使用的latent vector比原图片flatten之后的大小小得多：比如196 dims的z，全连接至56 * 56 * 2 再卷积到56 * 56，<span class="math inline">\(P_G\)</span>就是低维空间的流形。</p>
<hr>
<h2 id="介绍wasserstein距离的一些数学准备">介绍Wasserstein距离的一些数学准备</h2>
<h3 id="lipschitz-条件">Lipschitz 条件</h3>
<p>​ 这个是高等数学中没有要求掌握的部分，但是在此处又提到了。</p>
<p>​ 若x为有界空间<span class="math inline">\(\mathbb R^n\)</span>中的一个向量，定义在<span class="math inline">\(\mathbb R\)</span>上的函数<span class="math inline">\(f(x)\)</span>有界的<strong><u>充分</u></strong>条件是：<span class="math inline">\(f(x)\)</span>满足Lipschitz连续性条件： <span class="math display">\[
f:D \subset \mathbb R^n\rightarrow \mathbb R,\;\exists K,\;|f(a)-f(b)|\leq K|a-b|,\; a,b \in D
\]</span> ​ 函数值的距离与函数变量的距离存在一个上界关系。所以<span class="math inline">\(f\)</span>又称为收缩映射，K（若&lt;1）称为Lipschitz常数。而Lipschitz连续性如果存在，训练时将将不会出现梯度爆炸的情况，由于Lipschitz连续性可以限制梯度，防止梯度爆炸。而WGAN使用的是剪裁的方法，权值剪裁可以保证1-Lipschitz连续性，但是效果不太好。权值剪裁可能导致权值的集中化。</p>
<hr>
<h2 id="gan实现过程中的一些问题">GAN实现过程中的一些问题</h2>
<ul>
<li>分类器过强导致gan_v2在无法判断终止的情况下，分类器一直进行训练，导致分类器的loss减到0.0001左右，而生成器的loss上涨到10左右。这样导致了生成器生成的图片完全为黑色图。</li>
<li>之前WGAN的训练效果并不好，没有直接GAN的训练效果好。
<ul>
<li>原因是：使用的网络结构根本不需要那么复杂。之前使用了奇怪的：卷积 + upsample结构。最后一层输出还使用了并联两个大小卷积核输出结果的方法，导致训练慢。</li>
</ul></li>
<li>将网络全部替换成全连接层，训练600个Batch之后就已经可以看出数字的形状了，但训练batch增加并没有显著导致外围的高斯噪声减少，个人认为这是由于全连接层特性决定的。</li>
<li>于是我尝试将全连接层的输出层替换为3 * 3的卷积网络。卷积输出会导致模糊，3 * 3卷积网络模糊减退十分慢。在参考了GAN training tricks之后，将3 * 3 kernel替换为 5 * 5 kernel，最后得到了平滑结果，外围噪声可以完全消除，网络输出具有平滑度。</li>
<li>WGAN 的 <strong>clipping parameter</strong>对输出的影响也比较大，当clipping parameter比较大的时候输出直接变成了奇怪的浮雕。</li>
</ul>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title>GPU Architecture Intros</title>
    <url>/2021/09/03/GPU-Architecture-Intros/</url>
    <content><![CDATA[<h1 id="gpu">GPU</h1>
<hr>
<p>​ 懂GPU加速必须要懂GPU设计，GPU和CPU太不一样了。之前写CUDA的时候感觉都是瞎写。在开学花个时间补了补，花一天时间（没有实践的那种）看完了加州理工的CS179以及一些附属资料：</p>
<center>
<img src="/2021/09/03/GPU-Architecture-Intros/amd.gif" style="zoom:120%;">
</center>
<center>
Figure 1. 什么？CUDA是Nvidia的？
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-preliminaries">II. Preliminaries</h2>
<h3 id="名词解释">2.1 名词解释</h3>
<h4 id="vertex-与-vertex-shader">Vertex 与 Vertex Shader</h4>
<p>​ 顶点表示了什么，这很好理解，wikipedia一看就懂：</p>
<blockquote>
<p>A vertex (plural vertices) in computer graphics is a data structure that describes certain attributes, like the position of a point in 2D or 3D space, or multiple points on a surface.</p>
</blockquote>
<p>​ 但是，vertex从何而来，为什么会有这个数据结构，其存在的意义是什么？这个貌似没有那种一搜就能明白的解释。对于以上的这几个问题，我的理解是：</p>
<div class="note info"><p>​ 顶点可以就是模型数据本身，比如模型就给定了一个需要进行渲染的mesh。或者，给定的是一个更加精细的模型，根据某种采样+生成算法，得到的vertex。注意vertex在意义上就有别于point，point是无空间关联关系的，而vertex是存在邻接结构的。</p>
</div>
<p>​ 而节点着色器的职责则是：把原本模型空间中的顶点，转换（transform）到屏幕空间坐标下。根据个人的理解，我觉得相机模型就是一个非常简单的顶点着色器，根据外参内参将世界系下的点转换到二维屏幕上。</p>
<h4 id="primitives-基本图形">Primitives 基本图形</h4>
<p>​ GPU渲染管线用于渲染的最基本图形，比如根据顶点着色器的输出，生成很多小的三角形进行后续处理。一般来说，这些primitive都是不可再分的（atomic），这些基本图形之后会被送到。。。比如，光栅化器（rasterizer）中进行一种采样量化操作（因为屏幕的表示能力受到了分辨率的限制）。</p>
<h4 id="fragment-rasterizer">Fragment &amp; Rasterizer</h4>
<p>​ Fragment可以认为是每个基本图形量化后的结果，也就是一堆没有着色的像素集合。我们的采样量化精细程度就决定了图像的质量，比如说：当我们需要抗锯齿的时候，可以提高rasterizer的采样精细度，并辅助羽化。光栅化则是我们这段时间接触过的内容，光栅化就是一种采样过程，对于不同精度的数据，将其采样到合适的分辨率下。</p>
<center>
<img src="/2021/09/03/GPU-Architecture-Intros/raster.gif" style="zoom:67%;">
</center>
<center>
Figure 2. Top-left triangle rasterization rule[1]
</center>
<p>​ 在光栅化过程中，经常遇到的问题就是：锯齿。解决锯齿问题就需要一些亚像素精度的操作。</p>
<p>​ 而片段着色器的作用则是：对已经生成的raster图像，进行渲染。比如光照，根据光照模型渲染像素的颜色，或者根据alpha通道信息进行绘制。</p>
<h3 id="pipeline-加速方式">2.2 Pipeline &amp; 加速方式</h3>
<p><img src="/2021/09/03/GPU-Architecture-Intros/pipeline.PNG"></p>
<center>
Figure 3. GPU简化管线示意图
</center>
<p>​ 从CPU如何到GPU？可能是需要摒弃一些CPU的设计思想的，毕竟CPU/GPU的功能非常不同，自然就应该对应不同的结构，不同的结构就会引出不同的特性。</p>
<p>​ CPU通常有很多针对一条指令流程优化的方式：</p>
<ul>
<li>多级cache（prefetching），嵌入式课讲过</li>
<li>分支预测（branch），嵌入式也讲过</li>
<li>乱序执行（这个嵌入式课程中没有显式提到，但是实际上存在于分支处理中，比如将一些指令移动位置以填充分支）</li>
</ul>
<p>​ 但是这些在GPU中显得不那么重要。GPU的并行任务通常都是：对大量数据做类似的操作，比如Fragment渲染，深度学习。CPU中ALU资源是有限的，每次就只能处理几个输入数据，显然没有办法很好地并行，那么这种需求很可能要求我们需要多个数据处理单元（比如ALU）。如果每个处理单元（比如ALU）都配置多级cache，分支预测等等CPU标配，那么谁来控制芯片的面积？谁来控制不同单元的分支预测？涉及到CPU的一些耗时操作怎么办（比如上下文切换，cache coherence等等）看看：</p>
<blockquote>
<p>In computer architecture, a branch predictor is a digital circuit that tries to guess which way a branch (e.g., an if–then–else structure) will go before this is known definitively. --Wikipedia</p>
</blockquote>
<p>​ 直接复制CPU cores肯定会让GPU变得笨重。所以这些特性可以都砍掉。</p>
<p>​ 针对我们的第一个要求，显然最好的处理方式是：引入SIMD（single instruction multiple data）的思想。毕竟GPU最常做的事情就是这个，输入不同，操作相同。那么这就涉及到：</p>
<ul>
<li>多个处理单元fetch/decode/execute同一条指令</li>
<li>多路数据同时输入：取数据不再像CPU处理一样，比如进行像素处理时，一个个位置访问，而是一组组位置访问。有N个处理单元就一次同时访问N个位置，取数据，可以节省大量fetch data的时间。</li>
</ul>
<p>​ 那么可以认为，CPU是一种<strong><u>标量</u></strong> (literally) 处理器（这里说的标量和 scalar processor不一样），GPU是一种向量处理器（一次处理一个向量，因为有多个处理单元）。将这些处理单元归为一组，GPU可以有多个这样的组。组间可以遵循流水线设计（避免长时间阻滞带来的吞吐量下降）。</p>
<p>​ 当GPU有多个这样的SIMD核可以并行时，可能可以演化为MIMD。实际上有些架构（比如N卡中），使用的是SIMT（multiple threads），每个线程是独立的，可以存在不同线程不同分支或者是非连续访问的情况。</p>
<h3 id="更多关键词">2.4 更多关键词</h3>
<p>​ 参考加州理工CS179 <a href="http://courses.cms.caltech.edu/cs179/2021_lectures/cs179_2021_lec02.pdf">lecture 2</a> [2]，这里就不赘述了。</p>
<hr>
<h2 id="iii.-gpu存储结构">III. GPU存储结构</h2>
<p>​ GPU（CUDA为例）的存储结构大致如下：</p>
<center>
<img src="/2021/09/03/GPU-Architecture-Intros/structure.PNG" style="zoom:67%;">
</center>
<center>
Figure 4. GPU存储结构
</center>
<p>​ 如果要说这几个不同的存储空间的特点，网上应该有很多介绍了。无非就是：</p>
<ul>
<li>constant/texture是可以由host修改的不可变内存，被cache掉了</li>
<li>global memory是host device可以共同修改的，最慢的内存，shared memory应该多用，因为通常很快，shared memory是同一个block的</li>
</ul>
<p>​ 之前太年轻，写CUDA程序的时候也没有特别去学过CUDA的内存管理，疯狂使用全局内存，应该是会很慢的吧？global memory倒是没有太多可以说的，接下来主要讲一下shared memory吧。</p>
<h3 id="shared-memory">3.1 Shared memory</h3>
<p>​ shared memory是一种存取很快的内存，硬件实现与L1 cache是一样的（那么可以体会一下其速度级别）。有些地方说，shared memory存取只需要1个周期，有些材料（比如加州理工的PPT）说是5ns（这也很快，毕竟我记得GPU的时钟一般会比CPU慢一些？emmm，说GPU是低频高吞吐率）。</p>
<p>​ 但是shared memory有两个限制：</p>
<ul>
<li>shared memory物理实现与L1 cache相同，这意味着shared memory不可能太大（SRAM很贵），对于一个block中的warps来说，所有warps使用的共享内存不能超过每个block所具有的内存。这就需要一定的精巧设计：充分利用shared memory使得尽可能多的warps工作。</li>
<li><strong><u>Bank conflict，这是一个有趣的问题。</u></strong>Bank conflict很像在嵌入式课程中学到的cache冲突问题，cache频繁冲突会引起cache内容的频繁擦写，由于cache coherence，导致多个存储器需要被修改，这很不好。而Bank conflict产生则是引起读写操作的并行化。</li>
</ul>
<p>​ Bank conflict的定义：</p>
<blockquote>
<p>A <strong>bank conflict</strong> occurs when 2 threads in a warp access different elements in the same bank. Shared memory is setup as 32 <strong>banks</strong></p>
</blockquote>
<p>​ 根据stackoverflow上一个佬外“可视化”的bank（或者shared memory分块），加入我们假设管理内存的单元是4字节，那么：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">0-3</th>
<th style="text-align: center;">4-7</th>
<th style="text-align: center;">...</th>
<th style="text-align: center;">120-123</th>
<th style="text-align: center;">124-127</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">data</td>
<td style="text-align: center;">data</td>
<td style="text-align: center;">...</td>
<td style="text-align: center;">data</td>
<td style="text-align: center;">data</td>
</tr>
<tr class="even">
<td style="text-align: center;">data</td>
<td style="text-align: center;">data</td>
<td style="text-align: center;">...</td>
<td style="text-align: center;">data</td>
<td style="text-align: center;">data</td>
</tr>
<tr class="odd">
<td style="text-align: center;">...</td>
<td style="text-align: center;">...</td>
<td style="text-align: center;">...</td>
<td style="text-align: center;">...</td>
<td style="text-align: center;">...</td>
</tr>
</tbody>
</table>
<p>​ 也就是说，这是一个“循环索引”的存储空间。连续的字节流会直接在不同bank之间切换，到末尾bank就会循环切回到第一个bank上。那么，当32个线程（一个warp）所需的内存是线性连续的，那么此时就不会出现两个线程同时访问一个bank的情况。</p>
<p>​ 假设我们的bank设置就是按照如上方式进行的，并且假设线程数量为32。那么当每个线程访问的步长为1是，没有bank conflict。</p>
<p>​ 当步长为2时，显然，只有一半的bank被访问，16个线程之后就会循环回到第一个bank。那么此时会引发两路冲突的bank conflict。</p>
<p>​ 同理，步长为4时，会引发4路冲突...</p>
<p>​ 当步长为32时。有两种说法：</p>
<ul>
<li>shared memory 也存在broadcast机制，多路访问我直接广播。</li>
<li>32路冲突，这种情况完全串行，需要进行+1步长的padding。</li>
</ul>
<p>​ 当前的GPU对于bank conflict基本上都更友好，遇到多路同时访问时，可以采用多播(multicast)或者广播策略。这是global memory所没有的。</p>
<h3 id="reduction-example-sum">3.2 Reduction Example: Sum</h3>
<p>​ CS179的lecture 7讲了两个很有意思的例子。第一个就是：并行时我如何对一个数组进行求和？</p>
<p>​ 显然，要利用并行计算的资源，两两求和的过程不能顺序进行（否则就是串行）。显然，求和过程可以分层进行，比如数组长度为32，第一层我就并行执行16个两两相加，保存，同步。第二层就执行8个...</p>
<p>​ 这例子看起来很简单嘛。都能想出来怎么做呢，但实际上这里全是坑。</p>
<p><img src="/2021/09/03/GPU-Architecture-Intros/bin1.PNG"></p>
<center>
Figure 5. 直接二分树状分解并行[3]
</center>
<p>​ 看起来不错。但是会遇上一个巨大的问题，warp divergence。显然，上图中我们实际使用了16个线程（奇数id线程什么都没做，但是由于处在同一个warp中，还是要执行NOP）。这非常不好，意味着我们每次相加操作之后，还有一段时间的NOP。（很奇怪，为什么可以使用数量为16的warp）</p>
<p>​ 既然这样，那我们可以：</p>
<p><img src="/2021/09/03/GPU-Architecture-Intros/bin2.PNG"></p>
<center>
Figure 6. 连续线程并行[3]
</center>
<p>​ 虽然我觉得这里有点奇怪，我用了一个大小为8的warp，之后又用了大小为4的warp... 并且bank的组织和我每次使用的warp大小是一致的。</p>
<p>​ 这样确实可以避免warp divergence，但是又会引起新的问题：bank conflict。由于第一次我使用了一个大小为8的block（属实理解不了这个组织，所以我查了一下为什么，列在了3.2末尾），那么bank根据线程数组织：8个bank，啊哦，这就是一个步长为2的2路冲突。因为此时，bank从10这个位置开始，到3，5（5 exactly）位置结束。后面是循环回到第一个bank存储。</p>
<p>​ 第二个循环中，4线程的block是4 banks，那么直接导致了4路冲突... 依此类推。</p>
<p><img src="/2021/09/03/GPU-Architecture-Intros/bin3.PNG"></p>
<center>
Figure 7. 序列寻址并行[3]
</center>
<p>​ 这样就完全好了。</p>
<p>​ 而关于：“What happens when threads per block is less than 32”问题，我一直觉得这里是存在warp divergence的。来自这个回答 <a href="https://stackoverflow.com/questions/40112959/what-will-happen-if-the-number-of-threads-in-a-warp-are-less-than-32">stackoverflow/What will happen if the number of threads in a warp are less than 32?</a></p>
<blockquote>
<p>Regarding warps, it's important to remember that warp and their size is a property of the hardware. Warps are a grouping of hardware threads that execute the same instruction (these days) every cycle. In other words, the size width indicates the SIMD-style execution width, something that the programmer can not change. In CUDA you launch blocks of threads which, when mapped to the hardware, get <strong><u>executed in warp-sized bunches</u></strong>. If you start blocks with thread count that is not divisible by the warp size, the hardware will simply execute the last warp with some of the threads "<strong><u>masked out</u></strong>"</p>
</blockquote>
<p>​ CUDA官方的论坛上，技术大佬貌似没有看懂提问者的问题，提问者想问（就跟我的问题一致）：</p>
<blockquote>
<p>I know that you can specify a block size that is less than 32, but I expect that will make part of the <strong><u>warp idle</u></strong>, and reduce resource utilization.</p>
</blockquote>
<p>​ 那。。。这些不就是warp divergence吗？除非，GPU做了一些实际的优化，对于一个warp中没有用到的线程直接mask掉，那么第一种实现又有何不可呢？感觉要么就是自己没理解透，再要么就是自己没理解透，最后要么就是 这个例子就是有问题，只能强行解释。</p>
<h3 id="parallelism-example-quick-sort">3.3 Parallelism Example: Quick sort</h3>
<p>​ 这是另一个很有趣的例子：如何在GPU上并行快排？</p>
<p>​ 首先，老师们把这个问题拆解成了两部分。第一部分是：根据条件，选择出符合要求的数组元素形成新的数组。比如：[4, 5, 2, 5, 8, 9, 1, 0, 3, 7] 选出大于4的部分：[5, 5, 8, 9, 7]。</p>
<p>​ GPU能并行做这个事情吗？回答是可以的，但是不是一步并行的，因为这种往数组中 <strong><u>保序</u></strong> 添加是不好做的。这样一个任务被拆解为三个串行部分：</p>
<ul>
<li>True / False 标签：创建一个等大小的flag数组来指示每个元素是否满足要求，满足为1，不满足为0，这个可以全并行。比如例子中[0, 1, 0, 1, 1, 1, 0, 0, 0, 1]</li>
<li>prefix sum，讲flag数组prefix sum求和：[0, 1, 1, 2, 3, 4, 4, 4, 4, 5]，这也是可以并行（分级）的（数组记作prefix）</li>
<li>最后：并行访问flag数组以及prefix sum数组，如果flag[i] = 1，那么原数组[i]保存在新数组的prefix[i]-1位置。也是可以全并行的</li>
</ul>
<p>​ 这件事做完之后就是标准的快排流程了。选pivot，甚至可以在GPU里递归。</p>
<h3 id="practical-slides">3.4 Practical slides</h3>
<p>​ 很有用，总结的也很好，我没有产生自己的新理解，就直接把这些slides[6]放上来当作保存了。</p>
<p><img src="/2021/09/03/GPU-Architecture-Intros/2021-09-05%20(1).png"></p>
<p><img src="/2021/09/03/GPU-Architecture-Intros/2021-09-05%20(2).png"></p>
<p><img src="/2021/09/03/GPU-Architecture-Intros/2021-09-05.png"></p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://en.wikipedia.org/wiki/Rasterisation">Wikipedia - Rasterization</a></p>
<p>[2] <a href="http://courses.cms.caltech.edu/cs179/2021_lectures/cs179_2021_lec02.pdf">CalTech CS 179 lecture 2</a></p>
<p>[3] <a href="http://courses.cms.caltech.edu/cs179/2021_lectures/cs179_2021_lec07.pdf">CalTech CS 179 lecture 7</a></p>
<p>[4] <a href="http://courses.cms.caltech.edu/cs179/">California Tech CS179</a></p>
<p>[5] <a href="https://www.cs.cmu.edu/afs/cs/academic/class/15462-f11/www/lec_slides/lec19.pdf">CMU/How a GPU works</a></p>
<p>[6] <a href="https://www.techylib.com/en/view/sizzlepicture/introduction_to_nvidia_cuda">Introduction to Nvidia CUDA</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>GPU</tag>
      </tags>
  </entry>
  <entry>
    <title>Instant Neural Graphics Primitives</title>
    <url>/2022/01/23/Instant-Neural-Graphics-Primitives/</url>
    <content><![CDATA[<h1 id="instant-ngp">Instant NGP</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​ 保研前是想搞3D重建来着，大概是无缘吧（xD）。最近老被安利 【5s NeRF训练】，听起来很强的样子，速度提升了好几个数量级，遂观摩了一下：</p>
<ul>
<li><a href="https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.pdf"><strong>Instant Neural Graphics Primitives with a Multiresolution Hash Encoding</strong> Thomas Müller, Alex Evans, Christoph Schied, Alexander Keller arXiv:2201.05989 [cs.CV], Jan 2022</a></li>
</ul>
<p>​ 文章很有趣，对我现有工作有一定的启发价值，当然结果也很nice：</p>
<center>
<img src="/2022/01/23/Instant-Neural-Graphics-Primitives/robot5.gif" style="zoom:125%;">
</center>
<center>
Figure 1. Hoho. Da. Nice.
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-简单分析">II. 简单分析</h2>
<h3 id="本文在解决什么问题">2.1 本文在解决什么问题</h3>
<p>​ 本领域我了解很少，在搞2D SLAM时了解过一些SLAM对地图的建模方式。其中有一个方式叫做隐式函数（implicit functions），旨在用一个参数化的函数来表示一个曲面。而当下神经网络应用火爆，这种参数化的表面表征当然可以使用深度学习的方式来学习。比如如下两篇论文所说的：</p>
<blockquote>
<p>Neural SDFs are typically encoded using large, fixed-size MLPs which are expensive to render.[1]</p>
</blockquote>
<blockquote>
<p>Our algorithm represents a scene using a fully-connected (non-convolutional) deep network, whose input is a single continuous 5D coordinate (spatial location (x, y, z) and viewing direction (θ, φ)) and whose output is the volume density and view dependent emitted radiance at that spatial location.[2]</p>
</blockquote>
<p>​ 最容易理解的例子应该就是SDF（有向距离场），之前也做过有向距离场表示的点云融合。有向距离场的0集（0-水平集）代表了真实曲面，而有向距离场就是给定一个d维输入（d维空间中的一点），输出正负值（在d-1维流形的“内部”还是“外部”）。那么这个d-1维流形（高维曲面）可以使用神经网络来表示，毕竟神经网络是万能的函数逼近器。如上引用所说，可以使用一个MLP（多层感知机）来“拟合”这个SDF。</p>
<p><img src="/2022/01/23/Instant-Neural-Graphics-Primitives/mlp.png"></p>
<center>
Figure 2. SDF的神经网络表征[1]
</center>
<p>​ 但在3D重建领域，训练这个神经网络表征可能非常困难，首先是因为数据的维度比较高，此外是输入量较大。举个例子：NeRF（Neural Radiance Field）需要一个物体的多角度输入图像，两张不同图象上对应的不同像素，可能就是两条不同的光线，需要通过已知的相机位姿 + 由内参确定的光线方向求解交点以求解真实的3D点，这一步计算量已经很大了（但按照个人的理解，这一步应该是与神经网络无关的），下一步又需要把真实的3D点与不同角度下的2D点联系起来，训练【5D输入：相机中心位置 + 本图像某一像素点对应的光线两轴角度（没有roll所以是两轴）】-&gt;【5D输出：density（相当于alpha通道）+ view-dependent RGB】的这样一个网络。如果直接把点值输入，希望在某一个小范围上直接端到端，那可能需要很深的MLP层数才能学到足够好的神经网络近似表征，这样的MLP，一是<strong><u>大</u></strong>，二是 <strong><u>fixed-size and task dependent</u></strong>，既不好训练又没有普适性。</p>
<p>​ 而作者在related work中举了一个例子：attention机制中为位置信息引入的positional embeddings可以使得网络很好地使用（甚至学出）位置信息。把我们的低维信息embed到某个高维空间，使得我们需要训练的MLP输入不再是原始的或者简单处理的数据，而是一个个高维空间中具有良好性质（比如 <strong><u>可插值，n阶连续等等</u></strong>）的encoding，对缩减MLP大小非常有好处。反观attention机制中的一些learnable positional embeddings，他们的实现也不过就是（以torch为例）<code>nn.Parameter</code>，并没有说让输入过一些新的层，以一种不额外延长forward pass长度的方式增加了参数数量。</p>
<p>​ 不过实际上，用参数embeddings表示的情况有人已经做过了。举个例子，假设我有一个voxel map，大小为<span class="math inline">\(L\times W\times H\)</span>，voxel map中每一个点我都会有一个高维encoding。但作者也说，这存在三个很大的问题：</p>
<div class="note danger"><p>Memory footprint. 如果只用这样的方式设计，内存开销将会是<span class="math inline">\(O(n^3)\)</span>，这还是非常大的，很容易炸显存。</p>
</div>
<div class="note "><p>Trade-off并不值得。如果使用过量的embeddings，很可能出现：整个feature embeddings 参数块只更新一小部分参数：比如如果是2D地图上的query，在双线性插值的情况下需要取周围四个feature vectors，更新四个feature vectors，但MLP的反向传播还是会改动整个MLP的所有参数，花大力气就优化了小部分encodings，可能不值。</p>
</div>
<div class="note warning"><p>稀疏化也不好做。首先，稀疏化是必要的。拿另一个领域（SLAM）中的一个例子来说：占用栅格图，对于没有物体的地方我真的有必要存吗？显然我只需要存障碍物栅格即可。但稀疏化可能很困难，比如用hash方法，可能哈希冲突啊，怎么解决？链表？存到别的位置的冲突处理？这非常不利于GPU并行加速。</p>
</div>
<h3 id="multiresolution-grid">2.2 Multiresolution Grid</h3>
<p>​ 个人感觉视角合成或3D重建与双目匹配、光流类似问题还是有很大区别的，而在后两者中，一种常用的处理办法就是特征金字塔（feature pyramid），其一般目的很简单：在特征金字塔趋于顶端位置（多次下采样后），可以进行粗匹配，粗匹配可以给向下不断扩大的精细特征图提供初值，使之更容易收敛到正确的位置（初值估计）。而视角合成与3D重建中，应该没有这种说法。个人倾向于这样认为：</p>
<ul>
<li>考虑一个一般一维信号，此信号可以进行频谱分解，存在不同频率成分</li>
<li>如果我们把低分辨率（coarse部分）当作低频部分，此部分可以大致刻画局部趋势</li>
<li>把高分辨率部分（fine）当作高频部分，此部分可以刻画局部细节</li>
<li>就比如一座山峰，其整体趋势由低频决定，而山峰上的各种崎岖地形由高频 部分决定</li>
</ul>
<p>​ 也即，multi-resolution grids是为了兼顾不同方面（低分辨率局部趋势）（高分辨率局部细节）而设置的结构。而作者在此处的设计是这样的：</p>
<p><img src="/2022/01/23/Instant-Neural-Graphics-Primitives/struct.png"></p>
<center>
Figure 3. 整体结构
</center>
<p>​ 作者并没有使用稠密的grid结构，稠密的特征grid开销太大了（所以RAFT搞的full correlation volume到底在干什么），作者在不同的分辨率层级上射击了双射或满射（应该是满射吧），也即 <span class="math inline">\(f:R^2\rightarrow R\)</span>：</p>
<ul>
<li>在低分辨率层级上，由于grid数量本来就较少，那么每个grid足够分配到一个特征向量</li>
<li>在高分辨率层级上，grid数量多，为了不<span class="math inline">\(O(N^2)\)</span>复杂度增加特征向量，将根据分辨率线性增加特征向量数目，此时可能引发 <u><strong>哈希冲突</strong></u>。</li>
</ul>
<p>​ 而暴力划分grid，重建精度将会收到grid分辨率影响，作者直接使用临近点线性插值的方式获得更加“精细”的特征，可插值性在本问题中非常有意义，如果在同一个grid（四个角点对应相同的特征向量index）中两个不同点特征向量在网络输出上并没有平滑性，那么将会使学习到的函数（比如SDF或者radiance field）<strong><u>不连续</u></strong>，0阶不连续代表着表面连接特性的跳变，在与深度视觉相关的邻域中，0阶不连续是可以容忍的（毕竟存在不同位置的物体以及遮挡），而在单个物体表面重建或视角合成中将导致结果有问题。至于为什么此结构具有可插值性，我将在后文分析。</p>
<p>​ 最后不同分辨率的特征将被concat在一起。用concat的理由：</p>
<blockquote>
<p>First, it allows for independent, fully <strong><u>parallel</u> processing</strong> of each resolution. Second, a reduction of the dimensionality of the encoded result <strong>y</strong> from <em>LF</em> to <em>F</em> may be <strong><u>too small</u></strong> to encode useful information. (要知道F才2)</p>
</blockquote>
<h3 id="哈希冲突">2.3 哈希冲突</h3>
<p>​ 作者说自己并不显式处理哈希冲突，因为哈希冲突的解决涉及到较为复杂的逻辑（并且判断是显著增了）。我们知道，在一个wrap中存在逻辑分支，将会引起wrap divergence，对于if/else同等计算量需求的操作，将损失至少50%的计算速度。但不解决哈希冲突将导致 <strong><u>两个不相的grid（甚至可能物理距离就很远）</u></strong>映射到同一个特征向量上（hash出来的index是一致的），理论上来说，这将对反向传播过程产生影响（一个特征向量同时在多个不相关的位置贡献loss）。而实际情况中没有影响主要有这么三个原因：</p>
<div class="note "><p>​ Multi-resolution 结构。我们已经提到，（1）低分辨率决定了局部趋势（2）低分辨率足够双射。这样一来，低分辨率决定的局部趋势就可以保证正确性。此外，所有可能产生哈希冲突的分辨率层级同时产生哈希冲突是“statistically very unlikely to occur simultaneously”，那么我们就应该看高分辨率下哈希冲突时具体的学习过程。</p>
</div>
<div class="note "><p>​ 【这部分我感觉作者有点强行解释】：梯度加权平均。作者认为，即使两个不关联点A，B拥有同一个特征向量，A，B最终贡献给loss的大小也几乎不可能相同。比如A接近物体表面，B在empty space中，那么最后loss很可能会更倾向于给A更大的权重，造成：同样一个特征向量产生的两份不同梯度，A的梯度方向占主导地位。最后网络也会自行向与A相关的方向优化。</p>
</div>
<p>​ 但若考虑到产生多次哈希冲突的情况，个人觉得很有可能产生哈希冲突的这些点各自可能的权重 <strong><u>也随机散布在空间中</u></strong>，那最后合成出来的梯度实际上是个四不像梯度... 还是有可能产生奇怪输出的，只不过“statistically very unlikely to occur”罢了。于其说是：“implicit hash collision resolution”，不如说是：我发现不解决哈希冲突本来就基本不可能有啥问题。我个人对这种处理方法的看法是：“mostly elegant, statistically unlikely to be inelegant”。</p>
<h3 id="可插值性与平滑性">2.4 可插值性与平滑性</h3>
<p>​ 笔者已经在上文解释过了，可插值性是<strong><u>非常重要</u></strong>的。但本设计为什么会存在这种可插值性？有如下几个疑问：</p>
<ul>
<li>此设计是天然具有可插值性（就像CNN的平移不变性以及transformer的置换不变性）还是需要靠其他人为步骤的设计使其具有可插值性？</li>
<li>如果是后者，这种奇妙功能是如何实现的？</li>
<li>如果不仅仅需要连续，还需要可导的平滑表面，应该怎么做？</li>
</ul>
<p>​ 作者说：</p>
<blockquote>
<p>Interpolating the queried hash table entries ensures that the encoding enc(x; θ), and by the chain rule its composition with the neural network m(enc(x; θ); Φ), are continuous.</p>
</blockquote>
<p>​ 也就是说，multi-resolution hash table 本身是没有可插值性的，正是因为我的插值操作使得网络具有了可插值性【Counter-intuitive】。为什么会这样呢？</p>
<p>​ 对于低分辨率层级来说，可能很多输入点都落于一个grid（或者voxel）内部，这时这些点将会共用grid（或者voxel）的角点index，也就是插值所使用的特征向量索引。由于可以认为，输入点在空间上临近，输出结果也要求需要在空间上临近。举一个这样的例子，假设我需要根据2D图像恢复3D模型，那么2D输入点临近对于一个原本连续的形体，应该就是连续的（对于原本就是不连续的形体则另说）。那么，网络根据A,B,C几个点插值后的特征的相似性，结合输出结果在监督下的ground truth相似性，就能推出此局部是否应该具有可插值性：</p>
<ul>
<li>临近输入导致临近以及相似输出 --- 说明是可插值的，<strong><u>映射函数连续</u></strong></li>
<li>临近输入导致结果差别大或者不相似 --- 说明局部不可插值（可能分属不同物体或者是一个物体的几个分立子原件），允许映射函数不连续</li>
</ul>
<p><img src="/2022/01/23/Instant-Neural-Graphics-Primitives/bunny.png"></p>
<center>
Figure 4. 可插值性图示（图源 Stanford bunny）
</center>
<p>​ 学习连续性还是较为简单的，只需要设置相应的监督【相似/近输入】--&gt; 【相似/近输出】。而对于高阶平滑，比如SDF就要求一阶（导）连续（代表着可导）作者说有如下两种方法：</p>
<div class="tabs" id="span-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#span-unique-name-1">二次或三次插值</a></li><li class="tab"><a href="#span-unique-name-2">插值近似函数</a></li></ul><div class="tab-content"><div class="tab-pane active" id="span-unique-name-1"><p>双二次以及双三次插值可以使得导数不再是呈块状的，而是连续的。但是需要的lookup成本变高了，就拿双三次插值来说，双三次插值需要一次采样16个点的特征向量，而双线性只需要四个点，放在3维空间中开销更加难以接受。</p></div><div class="tab-pane" id="span-unique-name-2"><p><span class="math display">\[
\begin{align}
&amp;S(x)=x^2(3-2x)\\
&amp;S&#39;(x)=6x(1-x)
\end{align}
\]</span> ​ 作者推荐这样的插值公式，在双（三）线性情况下只采样4（8）个点，又可以：</p>
<blockquote>
<p>The derivative of the smoothstep vanishes at 0 and at 1, causing the discontinuity in the derivatives of the encoding to vanish by the chain rule.</p>
</blockquote>
<p>​ 意思是：导数在0，1（也就是插值边界处）为0，根据链式求导的导数相乘，使得边界点的导数为0。也即不会因为线性插值这样在边界出现导数不连续的情况。感觉有点妙。</p></div></div></div>
<hr>
<h2 id="iii.-其他后续">III. 其他后续</h2>
<p>​ 笔者近几天回到家没有可用设备来训练，想试试demo但没有办法。笔者之后可能写一篇本文官方实现的源码分析，暂定应该是《CUDA踩坑实录【4】》的内容。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://arxiv.org/pdf/2003.08934.pdf">Mildenhall, Ben, et al. "Nerf: Representing scenes as neural radiance fields for view synthesis." <em>European conference on computer vision</em>. Springer, Cham, 2020</a></p>
<p>[2] <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Takikawa_Neural_Geometric_Level_of_Detail_Real-Time_Rendering_With_Implicit_3D_CVPR_2021_paper.pdf">Takikawa, Towaki, et al. "Neural geometric level of detail: Real-time rendering with implicit 3D shapes." <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 2021.</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>3D重建</tag>
      </tags>
  </entry>
  <entry>
    <title>LaTex基础语法记录</title>
    <url>/2021/02/05/LaTex%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<h1 id="latex基础语法记录"><span class="math inline">\(\LaTeX{}\)</span>基础语法记录</h1>
<hr>
<h2 id="一些关键词">一些关键词</h2>
<p><strong><code>\lipsum</code></strong></p>
<p>​ <code>\lipsum</code>是宏包<code>&#123;lipsum&#125;</code>中的命令，用于生成随机的文本。一般用于模板的演示。</p>
<p>​ 对于宏包而言，可以使用<code>\usepackage</code>调用</p>
<p><strong>倾斜与加粗</strong></p>
<p>​ <code>\emph&#123;% text %&#125;</code>是将text变为斜体，但是<code>\emph&#123;&#125;</code>适合单行，<code>\em ... \em</code>回对两个成对的<code>\em</code>之间的所有字体（包括标题）进行斜体化。</p>
<p>​ <code>\textbf</code>是 文字粗体（text bold font）<span class="math inline">\(\textbf{Like: Test}\)</span> &lt;-&gt; <span class="math inline">\(\text{Like: test}\)</span>。</p>
<p>​ <code>\mathbf</code> 是tex中的数学粗体，<span class="math inline">\(\text{vector }\mathbf{a,b,A}\)</span></p>
<p>​ <code>\pmb</code> 是粗斜体：<span class="math inline">\(\pmb{b}=\pmb{Ax}\)</span></p>
<p><strong>其他常用操作</strong></p>
<p>（1）字体大小更换 (定性) <span class="math display">\[
\begin{align}
&amp;\tiny \text{\tiny font for the things I have written. 1234567890}\\
&amp;\scriptsize  \text{\scriptsize font for the things I have written. 1234567890}\\
&amp;\small \text{\small font for the things I have written. 1234567890}\\
&amp;\normalsize  \text{\normalsize font for the things I have written. 1234567890}\\
&amp;\large \text{\large font for the things I have written. 1234567890}\\
&amp;\Large \text{\Large font for the things I have written. 1234567890}\\
&amp;\LARGE \text{\LARGE font for the things I have written. 1234567890}\\
&amp;\huge \text{\huge font. 1234567890}\\
&amp;\Huge \text{\Huge font. 1234567890}\\
\end{align}
\]</span> ​ 使用一些常用的大小描述词即可。</p>
<p>（2）字体大小更换（定量）</p>
<p>​ <code>\fontsize</code>是可以调整字体大小的，但貌似不是很好用。对于公式<code>\begin&#123;align&#125;</code>以及<code>\emph</code>中的字体大小可以进行更改，但是对于<code>\text</code>内部的字体，无法很好地修改。</p>
<p>（3）字体切换： <span class="math display">\[
\begin{align}
\sf {\text{That is the most wonderful thing I know. \sf} } \\
\tt {\text{That is the most wonderful thing I know. \tt}} \\
\rm {\text{That is the most wonderful thing I know. \rm}}
\end{align}
\]</span> ​ <code>\sf</code> 为sans-serif字体集合，<code>\tt</code>为typewriter字体，<code>\rm</code>为罗马字体集。</p>
<p>（4）矩阵的书写</p>
<ul>
<li><code>matrix</code>: 无框matrix</li>
<li><code>pmatrix</code>: 圆括号matrix</li>
<li><code>vmatrix</code>: 行列式matrix</li>
<li><code>bmatrix</code>与<code>Bmatrix</code>: 中括号matrix与大括号matrix</li>
</ul>
<p><span class="math display">\[
\begin{pmatrix}\label{mats}
1,0,0\\
0,1,0\\
0,0,1
\end{pmatrix},
\begin{pmatrix}
1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 1
\end{pmatrix},
\begin{matrix}
1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 1
\end{matrix},
\begin{bmatrix}
1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 1
\end{bmatrix},
\begin{vmatrix}
1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 1
\end{vmatrix},
\begin{Bmatrix}
1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 1
\end{Bmatrix}
\]</span></p>
<p>（5）其他常用命令</p>
<table>
<colgroup>
<col style="width: 20%">
<col style="width: 29%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>命令</th>
<th>作用</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>\newpage</code></td>
<td>直接换页（相当于html的 div always）</td>
<td>markdown不支持</td>
</tr>
<tr class="even">
<td><code>\item</code></td>
<td>分点，加小圆点</td>
<td><code>\begin&#123;itemize&#125; \item ... \item ...  \end&#123;itemize&#125;</code></td>
</tr>
<tr class="odd">
<td><code>\section&#123;name&#125;</code></td>
<td>一级标题（1. ）</td>
<td><code>\section&#123;Header&#125;</code></td>
</tr>
<tr class="even">
<td><code>\subsection&#123;name&#125;</code></td>
<td>二级标题（1.1.）</td>
<td><code>\subsection&#123;Header&#125;</code></td>
</tr>
<tr class="odd">
<td><code>\subsubsection&#123;n&#125;</code></td>
<td>三级标题（1.1.1.）</td>
<td><code>\subsubsection&#123;Header&#125;</code></td>
</tr>
<tr class="even">
<td><code>\begin&#123;Lemma&#125;</code></td>
<td>引理开始</td>
<td><code>\begin&#123;Lemma&#125; \label&#123;name&#125;... \end&#123;Lemma&#125;</code></td>
</tr>
<tr class="odd">
<td><code>\begin&#123;Theorem&#125;</code></td>
<td>定理开始</td>
<td><code>\begin&#123;Theorem&#125; \label&#123;name&#125;... \end&#123;Theorem&#125;</code></td>
</tr>
<tr class="even">
<td><code>\eqref</code></td>
<td>公式引用，相当于设置内部链接</td>
<td><span class="math inline">\(\eqref{mats}\)</span>，<code>\eqref&#123;mats&#125;</code></td>
</tr>
<tr class="odd">
<td><code>\ref</code></td>
<td>非公式引用</td>
<td><span class="math inline">\(\ref{mats}\)</span>，<code>\ref&#123;mats&#125;</code></td>
</tr>
<tr class="even">
<td><code>\url</code></td>
<td>链接</td>
<td><code>\url&#123;http://www.latexstudio.net/&#125;</code></td>
</tr>
<tr class="odd">
<td><code>\eqno</code></td>
<td>在非编号模式下，可以进行编号</td>
<td><code>\eqno&#123;(1)&#125;</code>，<code>\eqno</code>可以无视原有的标号，并且支持字符串</td>
</tr>
<tr class="even">
<td><code>\vspace&#123;&#125;</code></td>
<td>插入竖直方向的空行</td>
<td>比如<code>\vspace&#123;\parskip&#125;</code>，跳过的距离相当于两个段落之间的距离</td>
</tr>
<tr class="odd">
<td><code>\textcolor[rgb]&#123;r,g,b&#125;</code></td>
<td>修改字体颜色</td>
<td><span class="math inline">\(\textcolor[rgb]{0,0,1}{1,2,3}\)</span>.<code>$\textcolor[rgb]&#123;0,0,1&#125;&#123;1,2,3&#125;$</code></td>
</tr>
</tbody>
</table>
<ul>
<li>对于引用而言，提到公式就需要进行<code>\eqref</code>，其他的如见figure x，也需要用到<code>\ref</code></li>
</ul>
<hr>
<h2 id="图片操作">图片操作</h2>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;figure&#125;[h]		<span class="comment">% 如果没有[h] LaTex可能会自动排版</span></span><br><span class="line"><span class="keyword">\centering</span>				<span class="comment">% 一般都是需要居中的</span></span><br><span class="line"><span class="keyword">\includegrahics</span>[width=xxcm]&#123;name<span class="built_in">_</span>of<span class="built_in">_</span>the<span class="built_in">_</span>pic.jpg&#125;</span><br><span class="line"><span class="keyword">\caption</span>&#123;test the fig&#125; <span class="keyword">\label</span>&#123;fig:test1&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;figure&#125;</span><br></pre></td></tr></table></figure>
<p>​ 按照以上语法可以插入一张图片，并且，对于第三行的include graphics，会按照宽度自动横向，竖向编排。如果需要多图，可以多个<code>\includegraphics</code>，当然也可以使用子图：主要是minipage的使用与subfigure</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="comment">% latex 竖排操作</span></span><br><span class="line"><span class="keyword">\begin</span>&#123;figure&#125;[h]</span><br><span class="line"><span class="keyword">\centering</span></span><br><span class="line"><span class="keyword">\subfigure</span>[line1]&#123;</span><br><span class="line"><span class="keyword">\begin</span>&#123;minipage&#125;[b]&#123;0.23<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;minipage&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">\subfigure</span>[line2]&#123;</span><br><span class="line"><span class="keyword">\begin</span>&#123;minipage&#125;[b]&#123;0.23<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;minipage&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">\subfigure</span>[line3]&#123;</span><br><span class="line"><span class="keyword">\begin</span>&#123;minipage&#125;[b]&#123;0.23<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;minipage&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">\subfigure</span>[line4]&#123;</span><br><span class="line"><span class="keyword">\begin</span>&#123;minipage&#125;[b]&#123;0.23<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\linewidth</span>]&#123;4.jpg&#125;<span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;minipage&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">\caption</span>&#123;multiple dogs&#125; <span class="keyword">\label</span>&#123;fig:dogs&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;figure&#125;</span><br></pre></td></tr></table></figure>
<p>显示的结果如下：</p>
<p><img src="/2021/02/05/LaTex%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E8%AE%B0%E5%BD%95/dogs.JPG"></p>
<h3 id="相关代码理解">相关代码理解</h3>
<p>​ <code>\subfigure[name]&#123;&#125;</code> 花括号内的内容与普通的<code>\begin&#123;figure&#125;[xxx]</code>内部的内容极其相似，甚至可以一样。比如说我不需要多图（上述代码是4*4 多图显示的情况），我只需要每列一张图片，那么minipage完全不需要使用（<code>\minipage</code>相当于将页面分割为更小的页面）。只需按照如下方式书写即可：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\subfigure</span>[name]&#123;</span><br><span class="line">	<span class="keyword">\includegraphics</span>[width=xxxcm]&#123;name.jpg&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 对于<code>\minipage</code>的设置，<code>\begin&#123;minipage&#125;[b]&#123;0.23\linewidth&#125;</code>其中<code>[b]</code>可能与位置设置有关，只要所有minipage的设置一致就不会出现图片错位的问题。而<code>&#123;0.23\linewidth&#125;</code>表示的是当前的【正文的，原page的】linewidth（行的宽度（跨度））的0.23倍。也就是设置这个minipage的宽度大小。由于4 * 4，所以设置约1/4，需要留一定余量。</p>
<p>​ 而由于在<code>\minipage</code>花括号之内，<code>\linewidth</code>将与定义的minipage一致，那么可以简单地写为：插入图片的宽度就为<code>\linewidth</code>，占满整个minipage行宽即可。</p>
<p>​ 图片的插入并非什么困难的问题，主要是图片的排版。排版的话，传统的<code>\begin&#123;figure&#125;[htbp]</code>用处不大，可以考虑：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\usepackage</span>&#123;float&#125;		<span class="comment">% 图片浮动宏包</span></span><br><span class="line"><span class="keyword">\begin</span>&#123;figure&#125;[H]		<span class="comment">% 图片定位在当前位置</span></span><br></pre></td></tr></table></figure>
<p>显示效果如图所示：</p>
<p><img src="/2021/02/05/LaTex%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E8%AE%B0%E5%BD%95/float.JPG"></p>
<hr>
<h2 id="表格的插入">表格的插入</h2>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;table&#125;  </span><br><span class="line"><span class="keyword">\centering</span></span><br><span class="line"><span class="keyword">\caption</span>&#123;table&#125; <span class="keyword">\vspace</span>&#123;4pt&#125;</span><br><span class="line"><span class="keyword">\begin</span>&#123;tabular*&#125;&#123;12cm&#125;&#123;cccc&#125;</span><br><span class="line"><span class="keyword">\hline</span><span class="keyword">\vspace</span>&#123;1pt&#125;</span><br><span class="line"><span class="keyword">\textbf</span>&#123;Name&#125; <span class="built_in">&amp;</span> <span class="keyword">\textbf</span>&#123;Gender&#125;  <span class="built_in">&amp;</span> <span class="keyword">\textbf</span>&#123;Current Address&#125; <span class="built_in">&amp;</span> <span class="keyword">\textbf</span>&#123;Score&#125;<span class="keyword">\vspace</span>&#123;1pt&#125;<span class="keyword">\\</span>  </span><br><span class="line"><span class="keyword">\hline</span><span class="keyword">\vspace</span>&#123;1pt&#125;</span><br><span class="line">Tobby  <span class="built_in">&amp;</span> Male <span class="built_in">&amp;</span> 4 Avenue, Chicago, Illinois <span class="built_in">&amp;</span> 99<span class="keyword">\vspace</span>&#123;1pt&#125;<span class="keyword">\\</span>  </span><br><span class="line">Laura  <span class="built_in">&amp;</span> Female <span class="built_in">&amp;</span> unknown town, Atlanta, Georgia <span class="built_in">&amp;</span> 98<span class="keyword">\vspace</span>&#123;1pt&#125;<span class="keyword">\\</span>  </span><br><span class="line"><span class="keyword">\hline</span><span class="keyword">\vspace</span>&#123;1pt&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;tabular*&#125;  </span><br><span class="line"><span class="keyword">\end</span>&#123;table&#125; </span><br></pre></td></tr></table></figure>
<p>输出的结果如下图所示：</p>
<p><img src="/2021/02/05/LaTex%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E8%AE%B0%E5%BD%95/table.JPG"></p>
<h3 id="相关代码理解-1">相关代码理解</h3>
<p><strong>- 为什么要用<code>&#123;tabular\*&#125;</code>?</strong></p>
<p>​ <code>&#123;tabular\*&#125;</code>是可以进行线表宽度调整的，比如表格太小了，希望宽度方向能占更大的空间，需要使用语法：<code>\begin&#123;tabular*&#125;&#123;宽度&#125;[位置]&#123;对齐样式与列数&#125;</code></p>
<p>​ 普通的<code>&#123;tabular&#125;</code>只需要：<code>\begin&#123;tabular&#125;[位置]&#123;对齐样式与列数&#125;</code>。这样的表格是根据内容自适应调整大小的。</p>
<p>​ 其中<code>&#123;cccc&#125;</code>表示4列，每列都是举中对齐。如果需要左边对齐，使用llll。</p>
<p><strong>- 线表样式</strong></p>
<p>​ <code>\hline</code>表示插入一根横向线，<code>\vline</code>可以在cell元素值内部使用，相当于竖线。</p>
<p>​ <code>\vspace</code>一般用于调整间距，<code>&amp;</code> 用于分割。</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>typesetting</tag>
      </tags>
  </entry>
  <entry>
    <title>Nvidia 简单环境工程</title>
    <url>/2021/11/21/Nvidia-%E7%AE%80%E5%8D%95%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="ampere-pytorch">Ampere Pytorch</h1>
<hr>
<h2 id="i.-introduction">I. Introduction</h2>
<p>​ 近日训练神经网络花了五六十块钱，在<a href="http://www.ai-galaxy.cn/">智星云</a>平台上。这个云平台总的来说还是很便宜的，RTX 3090大概4元/h，之前训练胶囊网络的时候还狠吹了这个平台一波。但我最近感觉，该平台貌似有点坑：</p>
<ul>
<li>RTX 2080Ti的训练速度比我的MX 150（比GTX 960更差一点的卡）更慢，RTX 3090没有3090的样子</li>
<li>环境非常迷惑：比如其1080 Ti的环境，CUDA10.0 + Torch 1.4.0，直接没办法跑</li>
</ul>
<p>​ 于是乎我在办公室一个同事的电脑上装了整个深度学习环境。很不幸（又幸运）的是，他的显卡是RTX 3060，对应架构为安培（Ampere sm_86），不兼容低版本torch，使用不了CUDA加速。考虑到我之前有装显卡驱动搞爆系统的经历，我决定记录一下本次环境工程的过程。</p>
<center>
<img src="/2021/11/21/Nvidia-%E7%AE%80%E5%8D%95%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B/3060.png" style="zoom:67%;">
</center>
<center>
Figure 1. 看起来很便宜 黄仁勋Yes
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-过程">II. 过程</h2>
<h3 id="查看环境">2.1 查看环境</h3>
<p>​ 第一步当然是需要查看硬件参数：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure>
<p>​ 其中右上角会出现CUDA版本：</p>
<center>
<img src="/2021/11/21/Nvidia-%E7%AE%80%E5%8D%95%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B/smi.png">
</center>
<center>
Figure 2. nvidia-smi版本号
</center>
<p>​ 但这只是该驱动（426.00）可以支持的 <strong><u>最高版本CUDA</u></strong>。需要查看自己的CUDA版本则需要使用：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nvcc --version</span><br></pre></td></tr></table></figure>
<p>​ 然后我发现，该同学的驱动是475.05.xx（忘了），但是CUDA版本却是9.1。虽说英伟达驱动向下兼容，但是9.1听起来像是上个世纪的东西（雾）。直接升级CUDA即可。</p>
<h3 id="乱搞驱动">2.2 乱搞驱动</h3>
<p>​ 我选择的是CUDA 11.4，其安装程序可以附带安装驱动，也就是说，没有驱动也没有什么问题。Ubuntu 18.04端我选择的是脚本文件安装(.run 文件)，因为这个可以受控。但是安装时遇到了一些问题：</p>
<blockquote>
<p>Existing package manager found... (然后建议你在继续安装前remove这个existing package manager of the driver).</p>
</blockquote>
<p>​ <a href="https://askubuntu.com/questions/1211919/error-installing-cuda-toolkit-existing-package-manager-installation-of-the-driv">Ask Ubuntu</a>上有对应的解决方案，说是<code>--toolkit --silent --override</code>等等flag上去就行了。但个人尝试无效，按照回答直接执行之后，没有报错，但是同样也没安装好CUDA。直接运行脚本，暗装脚本会列举将会被安装的内容，第一次安装时我直接取消了除了Toolkit之外的其他选项，最后貌似也没装上去。</p>
<p>​ <strong><u>我怒了，开始暴力了起来（安全的暴力）</u></strong>。我啪地一下站起来了，很快啊，输入了以下脚本：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">下面这一句为了看看这个电脑上都装了哪些CUDA相关库</span></span><br><span class="line">dpkg -l | grep &quot;cuda&quot;</span><br><span class="line"><span class="meta"># </span><span class="language-bash">删除CUDA相关包以及其配置文件</span></span><br><span class="line">sudo apt-get remove cuda*</span><br><span class="line">sudo apt-get purge cuda*</span><br><span class="line"><span class="meta"># </span><span class="language-bash">不要随便用autoremove！除非你知道你在干什么或者你对autoremove的包进行仔细的检查</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">CSDN上就有autoremove，评论区已经有崩溃老哥说自己autoremove了一些重要包不得不重装系统了</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">显卡驱动，删除</span></span><br><span class="line">sudo apt-get remove nvidia*</span><br><span class="line">sudo apt-get purge nvidia*</span><br></pre></td></tr></table></figure>
<p>​ 执行结束之后，reboot。</p>
<h3 id="安装驱动">2.3 安装驱动</h3>
<p>​ 执行了上面这些命令之后我重启了电脑，果然，图形界面打不开了 ，因为显卡驱动已经没了。看到这里并且执行到这里的xdm可以准备重装系统了（误）。在电脑启动界面，GRUB有选择系统的画面，选择Ubuntu Recovery项，进入recovery模式进行驱动安装。recovery不需要显卡驱动也可以启动图形界面。</p>
<p>​ 进入recovery模式之后，既然我们已经知道，系统里没有显卡驱动了（nvidia-smi报错了），那就可以肆无忌惮地装驱动了。直接运行驱动安装脚本，安装项可以全部勾选。安装完毕之后，安装程序将会提示我们进行环境变量设定，此时只需要修改<code>.bashrc</code>文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export PATH=$PATH:...</span><br><span class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:...</span><br></pre></td></tr></table></figure>
<p>​ 检查<code>nvidia-smi</code>以及<code>nvcc</code>两个指令是否可以正确执行。按以上步骤（先删除，再重装）的方式，应该是没有问题的。重启即可，重启之后安装一些扩展库（可选）比如cuDNN以及NCCL，这两个库的安装要领只有一个：上英伟达官网对照清楚自己的驱动、CUDA版本对应哪个版本的cuDNN或者NCCL，版本对了就没问题，反正都是<code>.deb</code>包，一个<code>sudo dpkg -i</code>安装就结束了。</p>
<h3 id="安装pytorch">2.4 安装Pytorch</h3>
<p>​ Pytorch即使在最新的驱动以及CUDA（11.4）安装好之后，仍然不厌其烦地告诉你：<code>sm_86</code> is not a supported architecture for Pytorch, among [... up to sm_70] blahblahblah。在这里我遇到了两个坑：</p>
<h4 id="多重pytorch">2.4.1 多重Pytorch</h4>
<p>​ 我惊奇地发现，pip管理包的时候，同一个库允许多个版本存在。对于这种行为，我不是很能理解，毕竟按我的理解，大多数用户的Python版本是固定的，没有跨版本的需求（用Docker或者Conda管一管不好么）。但我在执行<code>pip3 list</code> 之后，发现电脑上有：<code>1.7.1\1.8.0\1.10.0</code> 三个版本的torch，每次安装前的删除实际上都没有删除干净。</p>
<h4 id="cuda-wheel">2.4.2 CUDA Wheel</h4>
<p>​ 本地安装 CUDA 11.4 并不意味着我们可以直接使用 CUDA11.4 支持。我们知道（你知道吗），Python虽然作为一种动态语言，运行时解释，它也是支持使用编译好的库的（只要编译成 <code>.so</code> 或者 <code>.dll</code> 动态库就行），pip3 不只是安装源码，它也会安装一些动态库，<strong><u>这些动态库的编译方式</u></strong>决定了 pip3 安装的库本身的一些性质。比如我们在 <a href="https://enigmatisms.github.io/2021/09/23/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%901%E3%80%91/">CUDA 踩坑实录 【1】</a> 中已经实践过，CUDA程序作为CUDA Extension被 pytorch / python 调用，被调用的程序是由 nvcc 编译的，nvcc的一些 flag 则决定了代码受到什么样的 architecture 支持，比如我们可以显式定义 <code>-arch=sm_86</code> 就能使得 <code>sm_86</code> 架构得到支持。也就是说，我们在安装的过程中需要选择CUDA Wheels，也就是手动写一个（+xxx）：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip3 install torch==1.10.0+cu113</span><br></pre></td></tr></table></figure>
<p>​ 上面的 <code>+cu113</code> 就表示，我们选择CUDA 11.3 wheels，应该就是说，本库的编译是有 CUDA 11.3 完成的。虽然本地是11.4，但并没有什么影响，对于 RTX 3060 这种 <code>sm_86</code> capability 的设备，只要 CUDA 11 + 就可以了。</p>
<p>​ 另一种方法，可以直接使用本地 CUDA 完成库安装：从官网上下载source（Pytorch底层就是在调用C++代码嘛），本地用 nvcc 对 source 进行手动编译，但这确实有一点麻烦。</p>
<h3 id="验证">2.5 验证</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cuda.is_available()</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tmp = torch.zeros(<span class="number">1</span>).cuda()</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>
<p>​ 只要没有任何warning或者error，就是成功。</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>环境工程</tag>
      </tags>
  </entry>
  <entry>
    <title>Particle Filter Simulation</title>
    <url>/2021/08/07/Particle-Filter-Simulation/</url>
    <content><![CDATA[<h1 id="particle-filter">Particle Filter</h1>
<hr>
<h2 id="i.-introduction">I. Introduction</h2>
<p>​ 大二买了一本 <em>Probability Robotics(of Sebastian Thrun, et al)</em>，其中粒子滤波的概率论知识讲得很清楚。大二学完概率论之后给我看明白了，人生第一次在理论学习上那么有成就感。但是看完之后总觉得干巴巴的，不知道如何应用。最近写完了 Volume2D Shader，突然想到一个很好的方法可以应用粒子滤波，于是实现了一版。半天写完，效果不错，见<a href="https://github.com/Enigmatisms/ParticleFilter">[Github Repo🔗:Enigmatisms/ParticleFilter]</a>：</p>
<p><img src="/2021/08/07/Particle-Filter-Simulation/ray2.png"></p>
<center>
Figure 1. Particle Filter 中使用Volume2D Shader进行的激光雷达scan仿真
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-理论推导">II. 理论推导</h2>
<h3 id="目标">2.1 目标</h3>
<p>​ 我仅仅讨论粒子滤波在localization中的作用，虽然localization只是PF理论应用的一个小方向。如果没有给定初值，也没有很好地利用观测信息，localization基本就是在乱猜其在空间中的位置。并且，通常情况下，只使用当前scan也无法准确获得定位，因为可能存在大量的重复地图特征。</p>
<p>​ 好在我们有连续的观测以及连续的控制，假设控制与观测序列：</p>
<ul>
<li>控制序列: <span class="math inline">\(U_t:\{u_1,u_2,...u_{t}\}\)</span>​​，<span class="math inline">\(u_t\)</span>​表示从状态<span class="math inline">\(x_{t-1}\)</span>​过渡到<span class="math inline">\(x_t\)</span>​的控制​</li>
<li>观测序列：<span class="math inline">\(Z_t:\{z_0,z_1,....z_{t}\}\)</span>​​，<span class="math inline">\(z_t\)</span>​表示在状态<span class="math inline">\(x_t\)</span>​​下的观测​</li>
</ul>
<p>​ 我们不希求通过<span class="math inline">\(z_t\)</span>​来求使得<span class="math inline">\(P(x_t|z_t)\)</span>​​最大的<span class="math inline">\(x_t\)</span>，而是需要求： <span class="math display">\[
\begin{equation}\label{post}
x_t^* = \mathop{\arg \max}_{x_t}P(x_t|Z_t,U_t)
\end{equation}
\]</span> ​ 实际上，可以说公式<span class="math inline">\(\eqref{post}\)</span>定义的是一个后验概率。也就是最大化一个后验概率了，啊这不就是 贝叶斯滤波吗？确实，粒子滤波就是贝叶斯滤波的一个非参数实现。</p>
<p>​ 但是一般来说，没有马尔可夫假设，事情会变得很复杂，如果我们需要对一大串控制 / 状态序列进行处理，应该怎么做？</p>
<h3 id="粒子与采样">2.2 粒子与采样</h3>
<p>​ 这是不是自然计算？粒子是一个个的可能状态：<span class="math inline">\(x_{t,1},x_{t,2},...x_{t,k}\)</span>​，假设我们有k个假设的状态。此时我们应该运用贝叶斯学派知识，首先由信息包含关系（之前的观测与控制包含在状态<span class="math inline">\(x_{t-1,i}\)</span>中） <span class="math display">\[
\begin{equation}\label{info}
P(x_{t,i}|Z_t,U_t,x_{0,i})=P(x_{t,i}|z_t,u_t,x_{t-1,i})
\end{equation}
\]</span> ​ 接下来的贝叶斯滤波变换可以说很妙了： <span class="math display">\[
\begin{equation}
P(x_{t,i}|z_t,u_t,x_{t-1,i}) = \frac{P(x_{t,i}, z_t,u_t,x_{t-1,i})}{P(z_t,u_t,x_{t-1,i})}
\end{equation}
\]</span> ​ 既然是要使用贝叶斯，那么就要想办法把观测和状态互换位置： <span class="math display">\[
\begin{equation}\label{eqn4}
\frac{P(x_{t,i}, z_t,u_t,x_{t-1,i})}{P(z_t,u_t,x_{t-1,i})}=\frac{P(z_t|x_{t,i},u_t,x_{t-1,i})P(x_{t,i},u_t,x_{t-1,i})}{P(z_t|u_t,x_{t-1,i})P(x_{t-1,i},u_t)}
=\frac{P(z_t|x_{t,i},u_t,x_{t-1,i})P(x_{t,i}|u_t,x_{t-1,i})}{P(z_t|u_t,x_{t-1,i})}
\end{equation}
\]</span> ​ 注意，我们有如下两个论断成立： <span class="math display">\[
\begin{align}
&amp; P(z_t|x_{t,i},u_t,x_{t-1,i}) = P(z_t|x_{t,i})\label{within} \\
&amp; P(x_{t,i}|u_t,x_{t-1,i}) \text{ is a known prior}\label{prior}
\end{align}
\]</span> ​ 公式<span class="math inline">\(\eqref{within}\)</span>​说的是：观测<span class="math inline">\(z_t\)</span>​只与当前状态<span class="math inline">\(x_t\)</span>​有关。论断<span class="math inline">\(\eqref{prior}\)</span>​指的是，由控制引起的状态转移误差分布是已知的（比如本实现中，我假设我的控制噪声是白噪声，那么此处就是一个高斯项）。​</p>
<p>​ 那么公式<span class="math inline">\(\eqref{eqn4}\)</span>​可以被进一步化简为下式，其中<span class="math inline">\(\eta\)</span>是我们不关心的归一化因子。 <span class="math display">\[
\begin{equation}\label{eqn7}
\eta P(z_t|x_{t,i})P(x_{t,i}|u_t,x_{t-1,i})
\end{equation}
\]</span> ​ 那么可以这么理解：状态粒子i在第t时刻的观测<span class="math inline">\(z_t\)</span>​​下，拥有状态<span class="math inline">\(x_{t,i}\)</span>​的概率为<span class="math inline">\(\eqref{eqn7}\)</span>，包含两个组份：</p>
<ul>
<li>状态粒子与观测的契合程度（给定状态能生成对应观测吗）<span class="math inline">\(P(z_t|x_{t,i})\)</span></li>
<li>控制状态转移噪声先验<span class="math inline">\(P(x_{t,i}|u_t,x_{t-1,i})\)</span>​</li>
</ul>
<p>​ 在2.5小节里，我简单地说一下我是如何对这个问题进行建模的。</p>
<h3 id="分布变换">2.3 分布变换</h3>
<p>​ 粒子滤波实际上是用粒子与采样来近似任意分布，在公式<span class="math inline">\(\eqref{eqn7}\)</span>​​​中，已经说明了<span class="math inline">\(P(x_{t,i}|x_{t-1,i},z_t,u_t)\)</span>​的组成成分。粒子滤波实际上还做了一个这样的事情，我们知道概率论中，概率是需要归一化的，而归一化因子在连续PDF中一般都涉及到积分。很多时候，积分是很难的，不一定能积出来。要获取目标分布，就存在一定难度了。这个时候，粒子滤波可以通过一个简单的建议分布，去推导一个复杂的目标分布。</p>
<p>​ 我们重新定义一下问题。<span class="math inline">\(P(x_{t,i}|x_{t-1,i},z_t,u_t)\)</span>是当前点的存在置信度，而我们希望，算法可以是迭代式（马尔可夫）的，也就是要从上一个迭代的粒子对应的置信度，计算本次迭代对应粒子的置信度。于是根据控制状态转移分布，可以得到建议分布： <span class="math display">\[
P(x_{t,i}|x_{t-1,i},z_t,u_t)=P(x_{t,i}|x_{t-1,i},u_t)P(x_{t-1,i}|x_{t-2,i},z_{t-1},u_{t-1})
\]</span> ​ 可以发现，等号右边第二项就是上一次迭代对应粒子的分布。根据状态转移进行了分布变换，得到了新的建议分布。<strong><u>但是我们并非直接接受新的建议分布，</u></strong>为什么？</p>
<blockquote>
<p>状态的转移带来新的信息。通俗地说，到一个新的地点，就可以从不同的角度观察环境。</p>
</blockquote>
<p>​ 我们可以通过新的观测，来衡量，这些新的点是否适合？原来的粒子，是分布的采样。那么，符合新的观测的粒子，自然可以给一个大权重，而不符合新观测的粒子，自然也就不那么重视。这就涉及到对粒子进行加权以及重采样。</p>
<h3 id="加权-重采样">2.4 加权 重采样</h3>
<p>​ 我们希望给粒子impose一个权重。但是粒子已经是分布的一个例化了（采样），这个时候有两种方案：</p>
<ul>
<li>每个粒子维护一个权重，每次更新权重</li>
<li>每次重新生成一群粒子，根据权重进行生成</li>
</ul>
<p>​ 第一种思想很好理解。比如在localization问题中，我在位姿空间中有很多位姿的估计粒子，那么最后粒子求加权平均应该就是结果。</p>
<p>​ 而第二种思想，则是把权重隐含在粒子数量中，这种思想是真正符合“粒子是对应分布的采样”的。显然，在N维空间中某个区域粒子数多，自然此处分布就应该比较大。</p>
<p>​ 直接进行随机的Metropolis-Hasting采样，需要的时间开销比较大？为什么？根据这篇文章[2]，里面说：</p>
<blockquote>
<p>简单随机重采样：（1）生成N个均匀分布随机数（2）随机数数列排序（3）根据随机数数列以及粒子的权重进行重采样。</p>
</blockquote>
<p>​ 这个步骤是：设点i的权重是<span class="math inline">\(w_i\)</span>，生成的随机数数列是<span class="math inline">\(y_i\)</span>。则对于所有的<span class="math inline">\(y_i\)</span>，如果<span class="math inline">\(y_i\)</span>落在<span class="math inline">\(\left(\sum_{k=1}^iw_k,\sum_{k=1}^{i+1}w_k\right]\)</span>中，那么对应粒子的采样数+1。可知这样的采样方法，复杂度是<span class="math inline">\(O(NlogN)\)</span>，毕竟需要排序，但是这是完全随机的。完全随机的两个坏处就体现出来了：</p>
<ul>
<li>不能保证数据集的遍历性，有些数据可能根本没有办法被采样到</li>
<li>计算复杂度大，大型采样时间消耗大。</li>
</ul>
<p>​ 更好的算法，这里就不再赘述了，详见《概率机器人》第四章。我的实现中，使用的就是《概率机器人》中的“低方差采样”，时间复杂度为O(N)，并且是遍历性的。</p>
<p>​ 重采样的目的就是使得建议分布转化为目标分布。对于粒子滤波，如果我们这样理解问题：滤波的完整迭代过程（从0到收敛有t个迭代），那么希望最大化： <span class="math display">\[
\begin{equation}\label{new_obj}
P(x_{0:t,i}|z_{1:t},u_{1:t})
\end{equation}
\]</span> ​ 以localization任务来说。如果一个状态是比较正确的，那么不管如何迭代，其置信度在不同的迭代中都应该比较大。那么根据公式<span class="math inline">\(\eqref{eqn7}\)</span>​​，可以展开为类似的结构（这是目标分布）： <span class="math display">\[
\begin{equation}\label{eqn11}
\eta P(z_t|x_{0:t,i}, z_{1:t},u_{1:t})P(x_{0:t,i}|u_t,z_{1:t-1,i})
\end{equation}
\]</span> ​ 进一步根据贝叶斯和马尔可夫性，可以作进一步展开，可得到建议分布与目标分布之比与<span class="math inline">\(P(z_t|x_{t_i})\)</span>​成正比。</p>
<h3 id="简单建模">2.5 简单建模</h3>
<p>​ 此部分，我简要介绍一下在基于Volume2D Shader的激光雷达模拟器中，如何建模一些分布。最为重要的首先就是似然<span class="math inline">\(P(z_t|x_t)\)</span>，也即，给定状态下，产生观测<span class="math inline">\(z_t\)</span>的可能性。此处我将其建模为：</p>
<ul>
<li>给定<span class="math inline">\(x_t\)</span>（状态，也即粒子对应的位姿），我在此处模拟一个激光点云（因为已知地图），与实际的观测<span class="math inline">\(z_t\)</span>进行比较。相似则对应的概率大，不相似则概率小。</li>
<li>那么相似性的比较，则是基于模拟激光点云对应角度上的range差值。其实只要理解似然在此处的作用，这个模型很好建立。</li>
</ul>
<p>​ 另一方面，是状态转移模型。此处直接使用了一个方差与移动大小相关的高斯噪声。</p>
<hr>
<h2 id="iii.-结果">III. 结果</h2>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><img src="/2021/08/07/Particle-Filter-Simulation/img1.png"></th>
<th style="text-align: center;"><img src="/2021/08/07/Particle-Filter-Simulation/img3.png"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">长走廊问题 初始化</td>
<td style="text-align: center;">长走廊问题 第三次迭代（移动3次）</td>
</tr>
<tr class="even">
<td style="text-align: center;"><img src="/2021/08/07/Particle-Filter-Simulation/img9.png"></td>
<td style="text-align: center;"><img src="/2021/08/07/Particle-Filter-Simulation/img16.png"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">长走廊问题 第九次迭代（移动9次）</td>
<td style="text-align: center;">长走廊问题 第十六次迭代（移动16次）</td>
</tr>
</tbody>
</table>
<p>​ 对于不完全的长走廊问题（虽然相似但是还有一定区别的环境），粒子滤波还是可以应对的。（2000个粒子）。</p>
<video src="cv_output.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<center>
Video 1. 长走廊问题迭代过程（慢速）
</center>
<video src="cv_output2.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<center>
Video 2. 随机地图定位问题（慢速）
</center>
<hr>
<h3 id="reference">Reference</h3>
<p>[1] Probability Robotics (Sebastian Thrun, et al)</p>
<p>[2] 粒子滤波常用重采样算法分析比较，范澎湃等</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>概率论</tag>
        <tag>SLAM</tag>
      </tags>
  </entry>
  <entry>
    <title>SVM算法与实现</title>
    <url>/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="svm">SVM</h1>
<hr>
<h2 id="preface">Preface</h2>
<p>​ SVM (Support Vector Machine 支持向量机) 曾一度导致深度学习的退潮（1995）。Geoffrey Hinton提出BP之后，遇到了sigmoid激活函数梯度消失问题，恰好此时Vapnik提出统计学习理论，正式提出非线性SVM并将其应用，使得这个分类器盛行了20年？直到DL的梅开三度。 恰好大三下学期有《模式识别》课，且有学长说他考前每天必推一遍SVM原理，不如现在趁《运筹学》还热着，尝试自己推导一遍，并实现这一个经典算法。</p>
<p><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/history.jpg"></p>
<center>
Figure 1. 深度学习的发展历程 以及95年SVM带来的冲击（图源不明）
</center>
<span id="more"></span>
<p>​ SVM作为经典的“最大间隔”（maximum margin）分类器，除了其精巧的数学变换（Lagrange对偶，可能是因为我自己推出来了所以觉得很妙吧:laughing:）之外，“支持向量”的思想是最妙之处。这种方法大大减少了训练时使用的维数，避免了内存爆炸问题，并且可以使用少量样本进行训练。</p>
<hr>
<h2 id="超平面的意义">超平面的意义</h2>
<p>​ 假设一个平面，其到原点的法向量为<span class="math inline">\(\pmb{w}\)</span>，到原点的距离为<span class="math inline">\(b\)</span>，那么平面方程应该是： <span class="math display">\[
\begin{equation}\label{equ:hyper}
\pmb{w}^T\pmb{x}+b=0
\end{equation}
\]</span> ​ 实际上这是方程： <span class="math display">\[
\begin{equation}\label{equ:plain}
Ax+By+Cz+....+b=0
\end{equation}
\]</span> ​ 进行的推广，那么对于公式<span class="math inline">\(\eqref{equ:hyper}\)</span>，如此定义方式为什么可以定义一个平面？x为什么一定在一个由<span class="math inline">\(\pmb{w}\)</span>以及<span class="math inline">\(b\)</span>定义的唯一平面上？推导如下，如图(1)，过原点做垂直于超平面的垂线，设交点为P，平面上一点x相对于P点的相对向向量为x'。那么有： <span class="math display">\[
\begin{align}
&amp; \pmb{v}=\vert b\vert\frac{\pmb{w}}{\Vert\pmb{w}\Vert} \\
&amp; \pmb{x}=\pmb{x}&#39;+\pmb{v}      \\
&amp; \pmb{w}^T\pmb{x}+b = \pmb{w}^T\pmb{x}&#39;+\pmb{w}^T\pmb{v}+b = 0
\end{align}
\]</span> ​ 推导还是比较简单的。</p>
<p><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/svm.JPG"></p>
<center>
Figure 2. 超平面数学意义探究
</center>
<p>​ 如果要推算一个点到超平面的距离，比如上图的点y到超平面的距离，相当于是：y交超平面于y'点，而由于y'在超平面上，于是有<span class="math inline">\(\pmb{w}^T\pmb{y}&#39;+b=0\)</span>，那么由于<span class="math inline">\(\pmb{y} = \pmb{y}&#39;+\pmb{y}&#39;&#39;\)</span>，那么可以知道： <span class="math display">\[
\begin{equation}\label{equ:predist}
\pmb{w}^T\pmb{y}+b=\pmb{w}^T\pmb{y}&#39;&#39;
\end{equation}
\]</span> ​ 而公式<span class="math inline">\(\eqref{equ:predist}\)</span>右侧相当于是y''在未单位化的方向向量上的投影，单位化之后可以得到距离。那么整个点到超平面距离公式如下： <span class="math display">\[
d = \frac{\vert \pmb{w}^T\pmb{x}+b\vert}{\Vert \pmb{w}\Vert}
\]</span></p>
<hr>
<h2 id="目标函数导出">目标函数导出</h2>
<p>​ 对于一个二分类的SVM，我们希望找到<strong>一个</strong>超平面，能够最优地将两类数据分开。如下图所示，图片来源见reference[1]。</p>
<p><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/margin.png"></p>
<center>
Figure 3. SVM与超平面
</center>
<p>​ 联系以下其他的分类方法，比如说LDA（Linear Discriminative Analysis），在算法构建时就存在一点就是：使类间方差是最大的。也就是希望两类之间的间隔是最大的。在SVM中，不衡量类间方差，衡量的是“margin”（就是Figure 3中的黄色区域）。</p>
<p>​ 从简单的例子引入，我们讨论二分类线性分类器。对于一个线性可分的待分类数据集，两个类别间需要找一个超平面。显然，两个类别都会有离这个超平面距离最近的数据点，这个最短距离（表征的是一种错误容限，如果为0则恰好在不可判定的边界上）如果记为<span class="math inline">\(d_1, d_2\)</span>的话，我们显然是希望<span class="math inline">\(d_1, d_2\)</span>尽可能大的（最容易出现错误的数据点（离分类超平面最近的点）离分类界限越远）。像这样可以定义超平面所在位置的数据点（最容易出现分类错误，最应该被讨论），被称为“支持向量（support vector）”，此后讨论的都是支持向量确定的超平面间的距离间隔。如何衡量这个距离？显然可以使用几何距离的推广（维数上的推广）。可以通过2-范数来定义空间中两个点之间的距离，但由于这是点与平面之间的距离，需要点与平面的距离公式。</p>
<p>​ 从我们上面所说的：“希望最可能分类错误的数据点对应的最短超平面距离间隔-是-最大的”这个想法上来看我们应该将距离的生成分为两步：</p>
<ul>
<li>给定超平面时，如何衡量哪个数据点是最容易分类错误的？</li>
<li>在给定支持向量时，如何进行超平面参数的确定与优化？</li>
</ul>
<p>​ 开始时个人感觉，这个问题<strong><u>有点自循环的感觉</u></strong>。超平面确定依赖支持向量？支持向量给定后才能确定超平面参数？这不就产生了鸡生蛋 蛋生鸡的悖论了吗？有关这个问题的讨论，在处理完目标函数的数学变换之后我再从数学的角度上谈一下我个人的理解。</p>
<h3 id="距离衡量">距离衡量</h3>
<p>​ 对于一个二分类问题，超平面已经定义为：<span class="math inline">\(\pmb w^Tx+b = 0\)</span>，那么如果所有数据都能正确分类，两个数据集的数据点一定会呈现：一个类别的数据在超平面的“上方”（正方向上），另一个类别则全部在“下方”。相应地，<span class="math inline">\(\pmb w^Tx+b\)</span>可能大于0或者小于0。也就是说： <span class="math display">\[
\left\{
\begin{array}{l}
\pmb w^Tx+b &gt; 0,\large{\text{正类}} &amp;\\
\pmb w^Tx+b &lt; 0,\large{\text{负类}} &amp;
\end{array}
\right.
\]</span> ​ 而很明显，我们的样本点是有限的，也就是说，每个一定会存在一个点，在正类中，正值最小，负类中赋值最小。那么可以根据这两个最小值进行尺度归一化： <span class="math display">\[
\left\{
\begin{array}{l}
\pmb w^Tx+b \ge 1,\large{\text{正类}} &amp;\\
\pmb w^Tx+b \le -1,\large{\text{负类}} &amp;
\end{array}
\right.
\]</span> ​ 那么使用一个小trick，用sgn(·) 函数处理以上式子： <span class="math display">\[
\begin{equation}\label{equ:dist}
d_f=y_i(\pmb w^Tx+b),\text{ where } y_i =1 \text{ if 正类 otherwise } y_i = -1
\end{equation}
\]</span> ​ 这样可以保证：<span class="math inline">\(d_f\)</span>在分类正确时恒为正值，并且让问题尽可能简单化。（<span class="math inline">\(y_i\)</span>当然可以不取正负1，但是取其他的值让问题形式稍微复杂了一点点，没有什么必要）。根据在之前小节讨论的超平面距离公式，已知<span class="math inline">\(\vert\pmb w^Tx+b=1\vert\)</span>（对于支持向量而言），那么两个类距离超平面的距离是各为<span class="math inline">\(1/\Vert\pmb{w}\Vert\)</span>。那么优化问题即为： $$ <span class="math display">\[\begin{equation}\label{equ:simple}
\left\{
\begin{array}{l}
\text{max }\frac{2}{\Vert\pmb{w}\Vert} &amp;\\
\text{s.t. } y_i(\pmb w^Tx+b) \ge 1, \text{ for } i\in1,2,...n &amp;
\end{array}
\right.

\rightarrow

\left\{
\begin{array}{l}
\text{min }{ \frac 12 \Vert\pmb{w}\Vert^2} &amp;\\
\text{s.t. } y_i(\pmb w^Tx+b) \ge 1, \text{ for } i\in1,2,...n &amp;
\end{array}
\right.
\end{equation}\]</span> $$ ​ 理想情况下，需要优化的问题就是按照公式<span class="math inline">\(\eqref{equ:simple}\)</span>定义的。</p>
<h3 id="非理想情况">非理想情况</h3>
<p>​ 哪有那么多线性可分的数据集？分类错误在大多数情况下都无法避免（他们中出了一个叛徒）。原有的线性可分条件太强了，需要进行一定的松弛才具有泛化能力。聪明的数学家们想到的办法是：设定一个容限<span class="math inline">\(\zeta_i\)</span>，也就是一个松弛因子，不追求找到最小的那对。反之，我们需要在超平面间隔宽度以及允许的错分类深度（某个数据集误入敌营的距离）之间进行权衡。</p>
<p>​ 由于<span class="math inline">\(y_i(\pmb w^Tx+b) \ge 1\)</span>很难达成，那么总可以<span class="math inline">\(y_i(\pmb w^Tx+b) \ge 1 - \zeta_i，\zeta_i \ge 0\)</span>吧。那么，所有<span class="math inline">\(\zeta_i\)</span>的和（它们都是非负的）显然反映了对这个分类器的松弛程度。问题就在于，我们希望 松弛一点，泛化能力强一点？还是严格一点，正确率高一点？通过一个可调的系数来决定： <span class="math display">\[
\sum_{i=1}^n\zeta_i+\frac{\lambda}{2}\Vert\pmb{w} \Vert^2
\]</span> ​ <span class="math inline">\(\lambda\)</span>就是起权衡作用的加权系数。</p>
<hr>
<h2 id="目标函数数学变换">目标函数数学变换</h2>
<p>​ 松弛后的问题原目标函数表达式如下： <span class="math display">\[
\begin{equation}\label{equ:tar1}
\left\{
\begin{array}{l}
    \text{min } \frac 1n \sum_{i=1}^n\zeta_i+\frac{\lambda}{2}\Vert\pmb{w} \Vert^2 &amp;\\
    \text{s.t. }y_i(\pmb{w}^T\pmb{x}_i+b) \ge 1-\zeta_i,\zeta_i\ge0\text{ for }i\in1,2,...n &amp;\\
\text{where } \zeta_i \text{ is max} (0, 1-y_i(\pmb{w}^T\pmb{x}_i+b)) &amp;
\end{array}
\right.
\end{equation}
\]</span> ​ 由于这是一个多变量有约束优化问题。可以使用Lagrange乘子法写出其Lagrange乘子函数。根据运筹学学过的知识（运筹学 第三章第五讲 有约束最优化问题的KKT方法）：</p>
<p><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/or.JPG"></p>
<center>
Figure 4. 来自西安交大 运筹学课程 翟桥柱老师等
</center>
<p>​ 需要注意的是，虽然<span class="math inline">\(\zeta_i \text{ = max} (0, 1-y_i(\pmb{w}^T\pmb{x}_i+b))\)</span>成立，<span class="math inline">\(\zeta_i\)</span>仍然是一个人为选取的参数，用于规定：第i个数据点相对边界的偏离（进入错误分类区的深度）大小容许值，所以实际上<span class="math inline">\(\zeta_i\)</span>并不是<span class="math inline">\(\pmb{w}\)</span>或者<span class="math inline">\(b\)</span>的函数。 <span class="math display">\[
\begin{equation}\label{equ:lag}
L(\pmb{w},b, \zeta_i,\lambda_i,\mu_i)=\frac 1n \sum_{i=1}^n\zeta_i+\frac{\lambda}{2}\Vert\pmb{w} \Vert^2-\sum_{i=1}^n\lambda_i[y_i(\pmb{w}^T\pmb{x}_i+b)+\zeta_i-1]-\sum_{i=0}^n\mu_i\zeta_i
\end{equation}
\]</span> ​ 则由KKT条件，需要对<span class="math inline">\(\eqref{equ:lag}\)</span>定义的<span class="math inline">\(L(\pmb{w},b, \zeta_i,\lambda_i,\mu_i)\)</span>进行微分操作。也即所有偏导数都应该是0： <span class="math display">\[
\begin{align}
&amp;\frac{\partial L}{\partial \pmb{w}} = \lambda\pmb{w} - \sum_{i=1}^n\lambda_iy_i\pmb{x_i} = 0\rightarrow\lambda\pmb{w} =\sum_{i=1}^n\lambda_iy_i\pmb{x_i}\label{equ:pw}\\
&amp;\frac{\partial L}{\partial b} =\sum_{i=1}^n \lambda_iy_i = 0\label{equ:pb}\\
&amp;\frac{\partial L}{\partial \zeta_i} = \frac 1n -\lambda_i-\mu_i = 0\label{equ:pz}
\end{align}
\]</span> ​ 将公式<span class="math inline">\(\eqref{equ:pw}\eqref{equ:pb}\eqref{equ:pz}\)</span>带入到公式<span class="math inline">\(\eqref{equ:lag}\)</span>中，可以得到Lagrange对偶问题，显然有： <span class="math display">\[
\begin{align}
&amp;\sum_{i=1}^n\lambda_i[y_i(\pmb{w}^T\pmb{x}_i+b)+\zeta_i-1] = 0 \quad\text{(KKT条件)}\\ 
&amp;\begin{array}
&amp;L=\sum_{i=1}^n(\frac 1n-\lambda_i-\mu_i)\zeta_i+\frac{\lambda}{2}\Vert\pmb{w} \Vert^2-\sum_{i=1}^n\lambda_iy_i(\pmb{w}^T\pmb{x}_i+b)+\sum_{i=0}^n\lambda_i\\=\frac{\lambda}{2}\Vert\pmb{w} \Vert^2-\sum_{i=1}^n\lambda_iy_i\pmb{w}^T\pmb{x}_i+\sum_{i=0}^n\lambda_i
\end{array}\\
&amp;L=\frac{1}{2\lambda}\left (\sum_{i=1}^n\lambda_iy_i\pmb{x_i}\right)^T\sum_{i=1}^n\lambda_iy_i\pmb{x_i}-
\frac{1}{\lambda}\sum_{i=1}^n\lambda_iy_i\left(\sum_{j=1}^n\lambda_jy_j\pmb{x_j}\right)^T\pmb{x}_i+\sum_{i=0}^n\lambda_i
\end{align}
\]</span> ​ 最后化简得到，相对于原问题（Primal），此为Lagrange对偶问题，注意在对偶讨论下，需要进行最大化。 <span class="math display">\[
\begin{equation}\label{equ:dual}
L&#39;(\lambda_i)=\sum_{i=0}^n\lambda_i - \frac{1}{2\lambda}\left (\sum_{i=1}^n\lambda_iy_i\pmb{x_i}\right)^T\sum_{i=1}^n\lambda_iy_i\pmb{x_i}
\end{equation}
\]</span> ​ 约束条件如何变换？也就是此处每个<span class="math inline">\(\lambda_i\)</span>的约束条件是？首先，公式<span class="math inline">\(\eqref{equ:pb}\)</span>定义的约束没有能够带入原问题中，于是称为对偶问题的一个约束项，并且<span class="math inline">\(\lambda_i\)</span>本身就是大于等于0的。那么它有上界吗？有的，由于公式<span class="math inline">\(\eqref{equ:pz}\)</span>中<span class="math inline">\(\mu_i\)</span>是非负的，可以得到： <span class="math display">\[
\begin{equation}\label{equ:cond}
\text{s.t. }\sum_{i=1}^n \lambda_iy_i = 0 \text{ and } 0\le\lambda_i\le\frac 1n
\end{equation}
\]</span></p>
<p>​ 而实际上，只要能求出公式<span class="math inline">\(\eqref{equ:dual}\)</span>对应的对偶问题的解（<span class="math inline">\(\lambda_i\)</span>），也就可以根据公式<span class="math inline">\(\eqref{equ:pw}\)</span>计算出<span class="math inline">\(\pmb{w}\)</span>，而由所有的support vector以及<span class="math inline">\(\pmb{w}\)</span>可以求出b，也就唯一确定了超平面。之所以进行对偶变换，是因为原问题太难以讨论了，原问题并不是简单的二次规划问题，并且存在烦人的<span class="math inline">\(\zeta_i\)</span>，约束条件也令人难受，而对偶之后，约束变成了线性的，并且目标函数的形式变得简单了，可以使用一些二次规划的算法求出<span class="math inline">\(\lambda_i\)</span>。</p>
<hr>
<h2 id="逻辑自循环">逻辑自循环？</h2>
<p>​ 开始我对这个算法的思想非常不理解。我起初认为：</p>
<blockquote>
<ul>
<li>给定了超平面，才知道不同类别中哪个数据点距离超平面最近</li>
<li>给定了支持向量，才能求出超平面参数来（间隔最大嘛）</li>
</ul>
</blockquote>
<p>​ 这两点看起来就跟悖论一样，解决其中一点仿佛是要基于另一点的解决。但最后我们化简得到的目标函数却很有趣：<span class="math inline">\(\eqref{equ:dual}\)</span>中并没有出现【（1）超平面参数（2）选谁为支持向量 】的信息。</p>
<p>​ 解开这个“自循环”的关键在于对偶问题的<span class="math inline">\(\lambda_i\)</span>，对偶问题的解决确实是不依赖于以上信息的，它是根据所有的训练样本点优化出来的，而这个<span class="math inline">\(\lambda_i\)</span>实际上就蕴含了支持向量的信息。假设<span class="math inline">\(\lambda_k = 0\)</span>，由公式<span class="math inline">\(\eqref{equ:pw}\)</span>知，样本<span class="math inline">\(x_k\)</span>就不影响<span class="math inline">\(\pmb{w}\)</span>的计算了，也就是说<span class="math inline">\(x_k\)</span>就不是支持向量。<span class="math inline">\(\lambda_i\)</span>不为0的数据才是我们需要的支持向量，他们才参与计算，决定超平面。</p>
<p>​ 也就是说：算法的推导逻辑有赖于这样的一个“逻辑自循环”，因为只要循环之中的一个环节被解决了，另一个环节也就随之解决了。而通过巧妙的数学变换，我们可以找到绕开“自循环”的方法，通过优化先求出蕴含了支持向量选取意义的<span class="math inline">\(\lambda_i\)</span>，再求出超平面参数<span class="math inline">\(\pmb{w},b\)</span>。</p>
<hr>
<h2 id="smo-二次规划求解">SMO 二次规划求解</h2>
<p>​ SMO（Sequential Minimal Optimization）<a href="#ref">[3]</a> 是一个SVM算法对偶问题的快速计算方法，它可以极大地减小内存空间消耗，并且其解是解析的，而不需要对QP对偶问题<span class="math inline">\(\eqref{equ:dual}\)</span>进行复杂的数值解计算。SMO的两大精髓思想是：</p>
<ul>
<li>参数迭代计算“分治”得到一个个的QP sub-problems，每个sub-problem只需要解一个两参数QP优化问题。</li>
<li>使用一个启发式算法，选择每次进行迭代的两个参数。</li>
</ul>
<p>​ 由于论文<a href="#ref">[3]</a>中，启发式算法部分我没怎么看懂，只看懂子问题分割部分，所以在接下来的算法实现过程中，只实现非启发式（随机的）参数选择，也就是一个非启发的SMO，效率上可能会低一些。</p>
<blockquote>
<p>In order to speed convergence, SMO uses heuristics to choose which two Lagrange multipliers to jointly optimize.</p>
</blockquote>
<p>​ 有关KKT条件不满足点的删除以及非边界点的处理这里没有看懂（不是很清楚这样做的理由究竟是什么，可能对KKT条件的理解不够深入吧，不太能想清楚 不满足KKT条件对优化的影响）。所以整个2.2小节读完之后，在实现中都略过了。</p>
<h3 id="kernel-非线性">Kernel 非线性</h3>
<p>​ 为了使讨论不失一般性，上来就应该讨论核函数表示下的SVM，而非之前小节中推导的线性SVM（线性SVM也就是核函数是标准内积的情况）。</p>
<p>​ 之前我们介绍的都是标准内积核，也就是两个向量直接进行内积操作。在公式<span class="math inline">\(\eqref{equ:dual}\)</span>中，用到了内积，因为公式<span class="math inline">\(\eqref{equ:dual}\)</span>实际可以写为： <span class="math display">\[
\begin{equation}\label{equ:dot}
L&#39;(\lambda_i)=\sum_{i=0}^n\lambda_i
-\frac{1}{2\lambda}\sum_{i=1}^{n}\sum_{j=1}^n\lambda_i\lambda_jy_iy_j\pmb{x}_i^T\pmb{x}_j
\end{equation}
\]</span> ​ 而直接内积对应的是线性的空间。如果对x做非线性变换，达到空间变换的目的，在变换后的空间下是线性的超平面，但在原空间下已经变成别的形状，使得原本线性不可分的数据在新空间下可分。 <span class="math display">\[
\begin{equation}\label{equ:kernel}
k(\pmb{x}_i, \pmb{x}_j)=\phi(\pmb{x}_i)\phi(\pmb{x}_j)
\end{equation}
\]</span> ​ 公式<span class="math inline">\(\eqref{equ:dot}\)</span>中的内积项替换为公式<span class="math inline">\(\eqref{equ:kernel}\)</span>的核函数即可。</p>
<h3 id="参数分治">参数“分治”</h3>
<p>​ SMO算法在干什么呢？个人感觉这有点像coordinate descent，但是感觉简单的coordinate descent无法胜任SVM对偶问题的求解。因为式<span class="math inline">\(\eqref{equ:cond}\)</span>中定义了线性约束，coordinate descent没有办法直接满足线性约束。在论文中（SMO算法论文），作者也说到 问题的最小讨论参数个数为2，因为只讨论一个参数时无法满足线性约束条件。于是作者真就两个两个参数进行讨论，作者说到：</p>
<blockquote>
<p>The advantage of SMO lies in the fact that solving for two Lagrange multipliers can be done analytically.</p>
</blockquote>
<p>​ 确实如此，并且这个解析解的推导还算比较简单。由于SMO中sub-problem求解的论文思路是比较清晰的，在此处只简单回顾一下论文的方法。</p>
<h4 id="i.-约束确定">I. 约束确定</h4>
<p>​ 由于只选取两个参数，维度好低啊，可以进行可视化。注意我自己的推导和《模式识别》书以及SMO论文上的问题形式均不同，书以及论文均是<span class="math inline">\(C\)</span>定义的，也就是下式定义的loss，为了与论文一致，我现在就讨论公式<span class="math inline">\(\eqref{equ:book}\)</span>）定义的loss导出的对偶问题： <span class="math display">\[
\begin{equation}\label{equ:book}
C\sum_{i=1}^n\zeta_i+\frac{1}{2}\Vert\pmb{w} \Vert^2
\end{equation}
\]</span> ​ 由约束项<span class="math inline">\(\eqref{equ:cond}\)</span>结合下图可以看出，选取的<span class="math inline">\(\alpha_i(即\lambda_i),\alpha_j\)</span>的线性约束与constatnt值约束在二维情况下很简单。分<span class="math inline">\(y_i==y_j\)</span>是否为true两种情况来看，每种存在两个情况（论文中每种只画出一条线性约束的可视化图，红线是我后来加上的）：</p>
<p><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/fig1.JPG"></p>
<center>
Figure 5. 二维约束可视化
</center>
<p>​ 每次只需在这斜率为<span class="math inline">\(\pm1\)</span>的线段上求约束极小值（二次函数（线性核）或是其他凸问题（非线性核））即可。</p>
<h4 id="ii.-极值求解">II. 极值求解</h4>
<p>​ 显然，由于只有两个参数时，根据线性约束，一个参数可以使用另一个参数表示，使得我们可以先更新一个参数，再根据更新值求另一个参数的值，完成迭代。那么在求其中一个参数时，根据线性约束，问题就优点类似于coordinate descent了。</p>
<ul>
<li>首先确定带优化参数的值区间(L, H)</li>
<li>求一维最小值问题的极值点<span class="math inline">\(\alpha^{new}\)</span></li>
<li><span class="math inline">\(\alpha^{new}\)</span>可能不在(L, H)范围内，根据单峰以及凸性需要进行clipping
<ul>
<li><span class="math inline">\(\alpha^{new} &gt; H\)</span>，则最小值在H处取得</li>
<li>反之<span class="math inline">\(\alpha^{new}&lt;L\)</span>则最小值在L处取得</li>
<li>否则 <span class="math inline">\(\alpha^{new}\in(L,H)\)</span>，最后的极小值点就是<span class="math inline">\(\alpha^{new}\)</span></li>
</ul></li>
</ul>
<p><span class="math display">\[
\begin{equation}\label{equ:update}
\alpha_2^{new}=\alpha_2+\frac{y_2(E_1-E_2)}{\eta}\\
\text{where } \eta = k(\pmb{x}_1, \pmb{x}_1)+k(\pmb{x}_2, \pmb{x}_2)-2k(\pmb{x}_1, \pmb{x}_2)
\end{equation}
\]</span></p>
<p>​ 此处<span class="math inline">\(\eta\)</span>是公式<span class="math inline">\(\eqref{equ:dot}\)</span>在核函数替换下的目标函数的 二阶导。E则是预测误差<span class="math inline">\(u_{pred}-y_i\)</span>。感觉更新式<span class="math inline">\(\eqref{equ:update}\)</span>有点像牛顿法的迭代过程。则根据线性约束，<span class="math inline">\(\alpha_1\)</span>更新后的值也可以写出来。</p>
<h4 id="iii.-计算需要的结果">III. 计算需要的结果</h4>
<p>​ 每一步<span class="math inline">\(\alpha_1,\alpha_2\)</span>更新都可以根据新的值计算一次<span class="math inline">\(\pmb{w},b\)</span>。当所有参数计算完毕之后，算法也就结束了。<span class="math inline">\(\pmb{w}^{new}\)</span>怎么来的很好懂，而<span class="math inline">\(b\)</span>的更新迭代过程相对麻烦一些。由于<span class="math inline">\(b=\pmb{w}^Tx_i-y_i\)</span>成立，在kernel存在的情况下，b是： <span class="math display">\[
b=\left[
\sum_{i=1}^n\lambda_iy_ik(\pmb{x}_j, \pmb{x}_i)
\right] -y_i
\]</span> ​ 根据上式进行更新，写出相对值表达式即可。</p>
<hr>
<h2 id="实现smo算法">实现SMO算法</h2>
<p>​ 论文中给出了 给定两个数据时计算的伪代码。按照论文进行实现，代码见<a href="https://github.com/Enigmatisms/TorchLearning/blob/master/optim/svm.py">Github Repository 🔗:TorchLearning</a>，结果如下：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/res1.png"></th>
<th style="text-align: center;"><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/res2.png"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">距离适中</td>
<td style="text-align: center;">距离较远</td>
</tr>
<tr class="even">
<td style="text-align: center;"><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/res3.png"></td>
<td style="text-align: center;"><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/res4.png"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">存在较大重叠</td>
<td style="text-align: center;">存在较小重叠</td>
</tr>
</tbody>
</table>
<p>​ 在使用不同的随机数据进行超平面求解时发现，存在当C过大时，导致计算的超平面完全错误的问题。SMO算法的收敛速度看起来极快，通常只需要迭代3-6次就能收敛。注意，在这里数据点并不算多：</p>
<ul>
<li>维数3，正负类总和只有84个样本。</li>
</ul>
<hr>
<h2 id="其他的讨论">其他的讨论</h2>
<h3 id="空间变换">空间变换</h3>
<p>​ 之前我就听说，SVM是将低维数据升维到高维空间，低维中不好进行分类的数据，高维下可能可以很好分开。但是读完原理，实现完代码之后也没有发现哪里有维度的升高。</p>
<p>​ 实际上，维度的升高在核函数中“有所体现”，在<a href="https://zhuanlan.zhihu.com/p/57648645">【这篇文章】</a>中，作者提到：</p>
<blockquote>
<p>那我们我们是否可以将数据映射到高维空间呢？即创建一些新的特征。我们可以创建特征 <span class="math inline">\(x_3=x^2,x_4=y^2\)</span></p>
</blockquote>
<p>​ 虽然看起来维数从(x, y)变为了<span class="math inline">\((x, y, x_3, x_4)\)</span>，但是<span class="math inline">\(x_3,x_4\)</span>并不是独立的维度，个人倾向于认为这是在原空间对数据的空间分布进行了变换。比如说将两类环形（同心圆）分布的数据变换到相同维度的另一个空间下，但是在这个空间下两类数据是线性可分的。当然，非要说这是高维空间，应该也可以吧。</p>
<p>​ 核函数方法固然是线性的非线性迈出的一大步，但是个人感觉核函数的选择有赖于数据的空间分布。在不明分布的情况下，随意选择核函数将会造成分类能力的下降，靠人工比较选择显然不是个很好的办法。</p>
<h3 id="多分类问题">多分类问题</h3>
<p>​ SVM是典型的二分类分类器，但我们用的SVM却有多分类的能力。关于多分类，个人的想法是：</p>
<ul>
<li>对每个类，只需要区分本类和其他即可。构建一个个的本类以及其他类的二分类问题应该就可以。</li>
</ul>
<p>​ 维基上说：</p>
<blockquote>
<p>Building binary classifiers that distinguish between one of the labels and the rest (<em>one-versus-all</em>) or between every pair of classes (<em>one-versus-one</em>).</p>
</blockquote>
<p>​ 个人更倾向于one-versus-one形式的。在《模式识别》一书上介绍了如何处理多分类问题（感觉像是one-versus-all形式的）。而one-versus-one存在这样的特点（个人认为）：</p>
<ul>
<li>实现简单，不需要做过多算法改动，可以直接由多个二分类SVM组合（优点）</li>
<li>内存/计算资源消耗大，每两个数据类别之间都需要计算/储存一个<span class="math inline">\(\pmb{w},b\)</span>（缺点）</li>
</ul>
<p>​ 根据one-versus-one思想以及二分类SVM构建的一个多分类SVM结果如下（只画出超平面 / 数据），如果需要进行predict，predict思想如下：</p>
<ul>
<li>求所有的二分类SVM predict，对每一类进行累加（可以用一个list保存每一类累加结果）</li>
<li>取累加值最大的类（简单的想法，对于一个数据点，其落在正确的类中时，在每个二分类SVM中的输出应该都为1）作为predict值。</li>
</ul>
<p><img src="/2021/02/24/SVM%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/res5.png"></p>
<center>
Figure 6. 多分类one-versus-one的超平面
</center>
<hr>
<h2 id="reference">Reference</h2>
<p><span id="ref"></span></p>
<p>[1] By Larhmam - Own work, CC BY-SA 4.0,<a href="https://commons.wikimedia.org/w/index.php?curid=73710028">link🔗</a></p>
<p>[2] Wikipedia, <a href="https://en.wikipedia.org/wiki/Support-vector_machine">Support-vector machine</a></p>
<p>[3] Platt, John (1998). <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-98-14.pdf">"Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines"</a></p>
<p>[4] 张学工（编著），模式识别（第三版），清华大学出版社</p>
<p></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>&lt;i class=&quot;fas fa-quote-left&quot;&gt;&lt;/i&gt;   To strive, to seek, to find, and not to yield.   &lt;i class=&quot;fas fa-quote-right&quot;&gt;&lt;/i&gt;</title>
    <url>/2021/02/11/To-strive-to-seek-to-find-and-not-to-yield/</url>
    <content><![CDATA[<center>
<i class="fas fa-quote-left"></i> To follow knowledge like a sinking star<br> Beyond the utmost bound of human thought. <i class="fas fa-quote-right"></i>
</center>
<p><br> <span id="more"></span></p>
<p>Read, and fell in love. Wondering whether I will lose restless heart like this when I'm old. Yet here I am, and I possess.</p>
<hr>
<p><br></p>
<center>
<font size="5"><b>Ulysses </b></font><font size="2">by Tennyson</font>
</center>
<p><br></p>
<p>It little profits that an idle king,</p>
<p>By this still hearth, among these barren crags,</p>
<p>Match’d with an aged wife, I mete and dole</p>
<p>Unequal laws unto a savage race,</p>
<p>That hoard, and sleep, and feed, and know not me.</p>
<p><br></p>
<p>I cannot rest from travel: I will drink</p>
<p>Life to the lees: all times I have enjoyed</p>
<p>Greatly, have suffered greatly, both with those</p>
<p>That loved me, and alone; on shore, and when</p>
<p>Through scudding drifts the rainy Hyades</p>
<p>Vexed the dim sea: I am become a name</p>
<p><br></p>
<p>For always roaming with a hungry heart</p>
<p>Much have I seen and known – cities of men</p>
<p>And manners, climates, councils, governments,</p>
<p>Myself not least, but honored of them all –</p>
<p>And drunk delight of battle with my peers,</p>
<p>Far on the ringing plains of windy Troy,</p>
<p>I am a part of all that I have met;</p>
<p>Yet all experience is an arch wherethrough</p>
<p>Gleams that untravelled world, whose margin fades</p>
<p>For ever and for ever when I move</p>
<p><br></p>
<p>How dull it is to pause, to make an end,</p>
<p>To rust unburnished, not to shine in use!</p>
<p>As though to breathe were life. Life piled on life</p>
<p>Were all too little, and of one to me</p>
<p>Little remains: but every hour is saved</p>
<p>From that eternal silence, something more,</p>
<p>A bringer of new things; and vile it were</p>
<p>For some three suns to store and hoard myself,</p>
<p>And this grey spirit yearning in desire</p>
<p>To follow knowledge like a sinking star,</p>
<p>Beyond the utmost bound of human thought.</p>
<p><br></p>
<p>This is my son, mine own Telemachus,</p>
<p>To whom I leave the sceptre and the isle –</p>
<p>Well-loved of me, discerning to fulfil</p>
<p>This labour, by slow prudence to make mild</p>
<p>A rugged people, and through soft degrees</p>
<p>Subdue them to the useful and the good.</p>
<p>Most blameless is he, centred in the sphere</p>
<p>Of common duties, decent not to fail</p>
<p>In offices of tenderness, and pay</p>
<p>Meet adoration to my household gods,</p>
<p>When I am gone. He works his work, I mine.</p>
<p><br></p>
<p>There lies the port; the vessel puffs her sail:</p>
<p>There gloom the dark broad seas. My mariners,</p>
<p>Souls that have toil’d, and wrought, and thought with me –</p>
<p>That ever with a frolic welcome took</p>
<p>The thunder and the sunshine, and opposed</p>
<p>Free hearts, free foreheads – you and I are old;</p>
<p>Old age hath yet his honour and his toil;</p>
<p>Death closes all: but something ere the end,</p>
<p>Some work of noble note, may yet be done,</p>
<p>Not unbecoming men that strove with Gods.</p>
<p><br></p>
<p>The lights begin to twinkle from the rocks:</p>
<p>The long day wanes: the slow moon climbs: the deep</p>
<p>Moans round with many voices. Come, my friends,</p>
<p>‘Tis not too late to seek a newer world.</p>
<p>Push off, and sitting well in order smite</p>
<p>The sounding furrows; for my purpose holds</p>
<p>To sail beyond the sunset, and the baths</p>
<p>Of all the western stars, until I die.</p>
<p>It may be that the gulfs will wash us down:</p>
<p>It may be we shall touch the Happy Isles,</p>
<p>And see the great Achilles, whom we knew.</p>
<p>Tho’ much is taken, much abides; and though</p>
<p><br></p>
<p>We are not now that strength which in old days</p>
<p>Moved earth and heaven; that which we are, we are;</p>
<p>One equal temper of heroic hearts,</p>
<p>Made weak by time and fate, but strong in will</p>
<p>To strive, to seek, to find, and not to yield.</p>
<p><br></p>
<hr>
<p>Poem written by <a href="https://en.wikipedia.org/wiki/Alfred%2C_Lord_Tennyson">Alfred, Lord Tennyson <i class="fab fa-wikipedia-w"></i></a>.</p>
<p>可惜wiki被墙了，看百度吧-&gt;<a href="https://baike.baidu.com/item/%E9%98%BF%E5%B0%94%E5%BC%97%E9%9B%B7%E5%BE%B7%C2%B7%E4%B8%81%E5%B0%BC%E7%94%9F/3303915?fr=aladdin">Alfred, Lord Tennyson</a></p>
<p><br></p>
<hr>
]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>poetry</tag>
      </tags>
  </entry>
  <entry>
    <title>Swin Transformer 复现</title>
    <url>/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="swin-transformer">Swin Transformer</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​ Swin Transformer获ICCV best paper之后，就总有很多人提起它。个人在前段时间复现了一个与ViT相关的工作（Compact Convolution Transformer），感觉实现太简单（训练难），遂想尝试一些更加复杂的工作。同时我当然也想看看best paper到底是什么水平。此论文写得很清晰，实验做得非常漂亮，思想也很有趣，不过可以说是一篇typical神经网络文章：<strong><u>一个公式都没有</u></strong>（attention公式以及复杂度计算公式不算）。个人虽然惊叹于其SOTA表现，但由于存在不可解释的魔法，也始终觉得很膈应。本文是我在复现过程中的整理的一些思路和我觉得本论文中疑难之处及其理解。复现见：<a href="https://github.com/Enigmatisms/Maevit/tree/master/swin">Github/Maevit(这实际是ViT的复现repo)</a></p>
<p>​ 论文原文：<a href="https://arxiv.org/abs/2103.14030">Liu, Ze, et al. "Swin transformer: Hierarchical vision transformer using shifted windows." <em>arXiv preprint arXiv:2103.14030</em> (2021).</a></p>
<p><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/intro.png"></p>
<center>
Figure 1. 艺术之国：还有一个XJTU的（MSRA nb）[1]
</center>
<span id="more"></span>
<h2 id="ii.-some-points">II. Some Points</h2>
<h3 id="复杂度">2.1 复杂度</h3>
<p>​ 复杂度计算（二次部分）：图像大小为<span class="math inline">\(h\times w\)</span>，那么由分块大小为M，可以得到<span class="math inline">\(h\times w/M^2\)</span>个patch，每个pacth的大小是<span class="math inline">\(M^2\)</span>。而对于一个patch，相当于是用一个小ViT，对<span class="math inline">\(M^2\)</span> patch token进行 “global” attention，复杂度<span class="math inline">\(O({(M^2)}^2)=O(M^4)\)</span>故总复杂度：<span class="math inline">\(O(M^2hw)\)</span>，对于通道数为2C的embedding而言，就如论文所说的：<span class="math inline">\(O(2M^2hwC)\)</span></p>
<p>​ 这么说Set transformer中的induced point 机制，可能也可以应用到这里来？</p>
<h3 id="masked-attention">2.2 Masked Attention</h3>
<p>​ Masking 很好理解，由于原图是物理上连续的，经过了一次循环移动操作之后，循环移动的分界面是物理上不连续的区域，故在进行注意力机制处理时不能包括分界面两边的区域。比如：</p>
<center>
<img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/shift.png" style="zoom:100%;">
</center>
<center>
Figure 2. 循环移动示意图
</center>
<p>​ 右边是循环移动前的图，左边是循环移动后的图。我们希望，能够分块进行attention。个人的理解大概是这样的，其实这个很简单：我使用官方实现做了一个小实验之后，大概明白了其包含的思想（但是这个矩阵操作我可能做不来，有点妙，我顶多自己在这循环）：</p>
<p>​ 这个小实验的设置大概是这样的：图像大小为 4 * 4，window大小为 2 * 2，偏移为1 * 1，得到的四个mask长这样(其中，黄色为0，紫色为-100）：</p>
<p><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/mask.png"></p>
<center>
Figure 3. attention mask
</center>
<p>​ なんで？可以看下面这个可视化：我们将16个块编号，并进行循环移动，循环移动后的图和原图：</p>
<p><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/new.png" style="zoom:50%;"></p>
<center>
Figure 4. 循环移动illustration
</center>
<p>​ 注意力操作将把一个window内的元素flatten，比如第一个window内的 ((6, 7), (10, 11)) -&gt; (6, 7, 10, 11)。flatten操作是行优先的。故对于第一个window而言，由于内部的所有元素都是原图中的元素，可以直接进行attention操作，故attention mask值全为0。</p>
<ul>
<li>第二个window：((8, 5), (12, 9)) -&gt; (8, 5, 12, 9)。由于(8, 5) 以及 (12, 9)两两不能做attention操作，故mask应该就是figure 2中的第二个图。比如图中4 * 4矩阵的(0, 1)位置是-100，代表了块8与块5之间的attention logit值应该加一个很大的负偏置，也就是消去了两个块之间的关联。</li>
<li>此后的两个window都能很快以这个思想推出。</li>
</ul>
<p>​ 代码中则是这么实现的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">H, W = input_resolution</span><br><span class="line">img_mask = torch.zeros((<span class="number">1</span>, H, W, <span class="number">1</span>))  <span class="comment"># 1 H W 1</span></span><br><span class="line">h_slices = (<span class="built_in">slice</span>(<span class="number">0</span>, -self.window_size),</span><br><span class="line">            <span class="built_in">slice</span>(-self.window_size, -self.shift_size),</span><br><span class="line">            <span class="built_in">slice</span>(-self.shift_size, <span class="literal">None</span>))</span><br><span class="line">w_slices = (<span class="built_in">slice</span>(<span class="number">0</span>, -self.window_size),</span><br><span class="line">            <span class="built_in">slice</span>(-self.window_size, -self.shift_size),</span><br><span class="line">            <span class="built_in">slice</span>(-self.shift_size, <span class="literal">None</span>))</span><br><span class="line">cnt = <span class="number">0</span></span><br><span class="line"><span class="comment"># 分块赋值操作 经过分块赋值之后，一个window内可以进行attention操作的块为同一个id</span></span><br><span class="line"><span class="keyword">for</span> h <span class="keyword">in</span> h_slices:			</span><br><span class="line">    <span class="comment"># 比如cnt = 0，根据h_slices与w_slices的第一个元素，赋值给[0:-win_size, 0:-win_size] 这样是没有问题的</span></span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> w_slices:							 </span><br><span class="line">        img_mask[:, h, w, :] = cnt</span><br><span class="line">        cnt += <span class="number">1</span></span><br><span class="line">mask_windows = window_partition(img_mask, self.window_size)  <span class="comment"># nW, window_size, window_size, 1 --&gt; 分window操作</span></span><br><span class="line">mask_windows = mask_windows.view(-<span class="number">1</span>, self.window_size * self.window_size)	<span class="comment"># flatten操作：（所有batch的所有window，window内所有块）</span></span><br><span class="line"><span class="comment"># 此处魔法：unsqueeze(1) 导致 mw 为 (B, 1, N), unsqueeze(2) 导致 mw 为 (B, N, 1)</span></span><br><span class="line"><span class="comment"># 相当于计算时，一个按行repeat（前者） 一个按列repeat（后者），相当于自己减自己的转置 就可以得到：相同id的位置是0，不同的是一个非0值</span></span><br><span class="line">attn_mask = mask_windows.unsqueeze(<span class="number">1</span>) - mask_windows.unsqueeze(<span class="number">2</span>)		   </span><br><span class="line"><span class="comment"># 所有非零值变为-100</span></span><br><span class="line">attn_mask = attn_mask.masked_fill(attn_mask != <span class="number">0</span>, <span class="built_in">float</span>(-<span class="number">100.0</span>)).masked_fill(attn_mask == <span class="number">0</span>, <span class="built_in">float</span>(<span class="number">0.0</span>))</span><br></pre></td></tr></table></figure>
<h2 id="iii.-relative-position-bias">III. Relative Position Bias</h2>
<h3 id="positional-embeddings">3.1 Positional Embeddings</h3>
<p>​ 实际上，我对position embeddings（特别是non-learnable PE）到底是如何工作的还并不是特别清楚。position embeddings 如何表示位置 是否有直观的理解？</p>
<blockquote>
<p>Moreover, positional embeddings are trainable as opposed to encodings that are fixed.</p>
</blockquote>
<p>​ 意思大概是这样的，一个简单的positional embeddings（只在初始时加入的那种）可以被如下公式表示： <span class="math display">\[
\begin{equation}\label{pos}
\epsilon_{ij}=\frac{\text{lin}_q(x_i)(\text{lin}_k(x_j))^T+\text{lin}_q(x_i)(\text{lin}_k(p_{j}))^T}{\sqrt d_k}
\end{equation}
\]</span> ​ 个人认为更加合理的表示应该是（如果对于初始就加到embedding上的position embeddings来说）： <span class="math display">\[
\begin{equation}
\epsilon_{ij}=\frac{\text{lin}_q(x_i + p_i)(\text{lin}_k(x_j + p_j))^T}{\sqrt d_k}
\end{equation}
\]</span> ​ 在某篇博客中的表述是这样的：对于公式<span class="math inline">\(\eqref{pos}\)</span>中的<span class="math inline">\(\text{lin}_k(p_{j})\)</span> 我们将其改为<span class="math inline">\(p_{ij}\)</span>，此处<span class="math inline">\(p_{ij}\)</span>是整个positional embeddings的(i, j)元素，表示了处于位置i的query相对于处于j位置的key的位置关系，可以理解成是与位置有关系的相关性。比如，在CV应用中，常见的inductive bias就是：临近关联性，即使经过分块，相邻的块与块（或者位置相近的）之间也是有关联性的。一般的positional embeddings，临近的两个位置，positional embeddings的某个metrics（比如差值、点乘）可能比较小（大）。</p>
<p>​ 本节的重点是讨论相对位置嵌入，因为绝对位置嵌入之前已经实现过了（就很简单），特别是learnable positional embeddings，就没有什么好讨论的。我们已经说了，相对位置嵌入是为了解决绝对位置嵌入无法编码任意多的位置的缺点。这里我讨论一下music transformer中的relative positional embeddings（计算比较简单）： <span class="math display">\[
\begin{equation}
\text{Attn}_{rel}=\text{softmax}(\frac{QK^T+S_{rel}}{\sqrt{d_k}})V,\text{ where }S_{rel}=QR^T
\end{equation}
\]</span> ​ 我感觉上面的公式怪怪的，因为：</p>
<ul>
<li><span class="math inline">\(Q\)</span>（query）不仅与映射<span class="math inline">\(W_q\)</span>有关，与数据本身也是有关系的，不同的图像<span class="math inline">\(Q\)</span>差别很大，那么一个<span class="math inline">\(R\)</span>怎么能很好捕获到不同query向量之间的关联性？举一个具体的例子：</li>
</ul>
<p><span class="math display">\[
\begin{equation}
A=\begin{pmatrix}
1 &amp; 2 &amp; 3 &amp; 4 \\
5 &amp; 6 &amp; 7 &amp; 8 \\
9 &amp; 10 &amp; 11 &amp; 12 \\
13 &amp; 14 &amp; 15 &amp; 16 \\
\end{pmatrix}\xrightarrow{\text{flatten}}(1,...,16)
\end{equation}
\]</span></p>
<p>​ 上例子中（CV二维），元素1在位置上应与（2，5）有着最紧密的关系，那么应该<span class="math inline">\(QR^T\)</span>计算的结果在(0,1)(1,0)位置都较大（softmax之后也会较大），但是<span class="math inline">\(QR^T\)</span>的计算中，对任何<span class="math inline">\(Q\)</span>而言<span class="math inline">\(R\)</span>是相同的，不同的矩阵<span class="math inline">\(A\)</span>，元素1与元素2、5均应该有此关系，那么在<span class="math inline">\(Q\)</span>改变的情况下，什么机制保证了<span class="math inline">\(QR^T\)</span>的稳定性呢？这已经是人类难以理解的魔法了，例如：相邻两patch，由于位置临近可能确实存在一定关系，对于不同的数据都有这样的共性，<span class="math inline">\(R\)</span>也只能去学可以泛化的共性了。</p>
<h3 id="rpe的实现">3.2 RPE的实现</h3>
<h4 id="music-transformer">3.2.1 Music Transformer</h4>
<p>​ 不同的relative positional embeddings实现有一些差别。最早期的relative positional embeddings 有这样的问题：空间复杂度是<span class="math inline">\(O(L^2D)\)</span>。因为：</p>
<p>​ 求解relative positional embeddings带来的距离logit，需要得到query与PE之间的点乘。考虑一个head的情况，Q的形状应该是：<span class="math inline">\((L,D_h)\)</span>，其中L是序列长度，<span class="math inline">\(D_h\)</span>是对应head的embedding dimension。我们希望知道，query的每个向量（embedding）与不同距离位置的相关程度，比如，<span class="math inline">\(Q\)</span>的第i行（序列中第i个token的embedding），需要计算其与各个位置的分数，那么就需要： <span class="math display">\[
\begin{equation}
\text{logit}(q_i)=q_iE_r^T,\text{ where }E_r=(\text{PE}_0,...,\text{PE}_{L-1}) ,\text{PE.shape}=(1,D_h)
\end{equation}
\]</span> ​</p>
<p>​ 而直接计算<span class="math inline">\(QE_r^T\)</span>的结果并不是我们想要的：它算出来的矩阵和我们需要的矩阵分别是这样的,其中<span class="math inline">\(v_{i,j}\)</span>表示的是第 i 个query向量和 与其距离为j的位置的logit bias。 <span class="math display">\[
\begin{equation}
A=\begin{pmatrix}
v_{0,0} &amp; v_{0,1} &amp; ... &amp; v_{0, L-1}\\
v_{1,0} &amp; v_{1,1} &amp; ... &amp; v_{1, L-1}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
v_{L-1,0} &amp; v_{L-1,1} &amp; ... &amp; v_{L-1, L-1}\\
\end{pmatrix},B=\begin{pmatrix}
v_{0,0} &amp; v_{0,1} &amp; ... &amp; v_{0, L-1}\\
v_{1,1} &amp; v_{1,0} &amp; ... &amp; v_{1, L-2}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
v_{L-1,L-1} &amp; v_{L-1,L-2} &amp; ... &amp; v_{L-1, 0}\\
\end{pmatrix}
\end{equation}
\]</span> ​ 以A的最后一个行的首尾两个元素为例。<span class="math inline">\(v_{L-1,0}\)</span>表示的是最后一个embedding与自身的位置偏移logit偏置，而最后一个元素<span class="math inline">\(v_{L-1,L-1}\)</span>表示的则是：最后一个embedding与相距L-1距离位置的logit偏置。而我们反过来看最后一行的self attention，最后一行的self attention的结果logit中，最后一个元素表示的才是自己与自身的attention值。</p>
<p>​ 也就是说，直接计算<span class="math inline">\(QE_r^T\)</span>是不行的，这样计算会导致self attention 与 positional attention求出的logit在逻辑意义上的错位。B才是我们需要的：从对角线元素的下标就能看出。</p>
<p>​ 那么如果要进行直接的矩阵运算，一个简单的想法就是：我可以直接计算一个中间矩阵R，R包含了（旋转过的）<span class="math inline">\(E_r\)</span>，这样，对于每一个query向量，其计算都应该是正确的，再直接矩阵相乘（<u><strong>毕竟能直接矩阵运算的，CPU上可以SIMD，GPU上并行度好</strong></u>）。那么可以将<span class="math inline">\(Q\)</span>与<span class="math inline">\(E_r\)</span>处理成这样： <span class="math display">\[
\begin{equation}
Q.\text{shape}=(L,1,D_h),R.\text{shape}=(L,L,D_h),S_{rel}=QR^T
\end{equation}
\]</span> ​ 其中，R第一维度下每一个元素都是一个<span class="math inline">\(E_r\)</span>。这种实现简单直观，但是，内存开销很大，长序列不友好。既然相对位置嵌入是为了解决长序列建模问题，那么自然其时间复杂度以及空间复杂度不能因为序列长度增长而变得难以接受。于是，music transformer的作者提出了一种空间复杂度为<span class="math inline">\(O(LD)\)</span>的方法。</p>
<p>​ 很显然，直接计算<span class="math inline">\(QE_r^T\)</span>已经包含了所有需要<span class="math inline">\(S_{rel}\)</span>的信息，只不过对应关系错了（位置有误）。如何通过<span class="math inline">\(QE_r^T\)</span>的结果计算<span class="math inline">\(S_{rel}\)</span>？</p>
<p>​ 作者用了一个巧妙的矩阵操作：pad + reshape：图示一下：</p>
<p><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/rel.png" style="zoom: 67%;"></p>
<center>
Figure 5. skewing操作图示
</center>
<p>​ 作者在文章中说到：</p>
<blockquote>
<p>Pad a dummy column vector of length L before the leftmost column.</p>
</blockquote>
<p>​ 这样再reshape之后，导致了一个问题，原有的有效元素丢失，引入的矩阵中出现了一些dummy elements。并且感觉出现了：第i行元素被挤到第j行的情况。举个例子，正常情况下，一个长度为5的序列，<span class="math inline">\(S_{rel}\)</span>的index 2行应该是（循环右移2）： <span class="math display">\[
\begin{equation}
(1,2,3,4,5)\rightarrow(4,5,1,2,3)
\end{equation}
\]</span> ​ 所以个人感觉padding是有点问题的，应该直接进行一些变换：线性变换是不可能的（不存在一个矩阵R，可以将第一行旋转0，第二行旋转1，第三行旋转2,...，因为如果存在这样的矩阵，则对于矩阵A，A只有第一列全是1，其他全是0，这样显然没有逆的矩阵，R成了它的逆）。个人觉得，一个简单的实现应该是：计算一个循环移动过的索引矩阵，比如我知道本次需要计算的seq length为N，那么我首先计算一个大小为<span class="math inline">\(N * N\)</span>的索引矩阵，根据此索引矩阵取<span class="math inline">\(QE_r^T\)</span>元素，但这样又引入了一个<span class="math inline">\(O(N^2)\)</span>复杂度的存储开销（比<span class="math inline">\(O(N^2D)\)</span>小了很多，16位一般就够用，相当于几张大型双通道图像）。</p>
<div class="note info"><p>可能这是优雅的实现，毕竟我发现swin也是这么求的。music transformer在干啥？是我没看懂还是本身就是错的？不应该错了啊。</p>
</div>
<h4 id="感觉正确的实现">3.2.2 感觉正确的实现</h4>
<p>​ 所以，我带着怀疑态度看了一下music transformer以及swin transformer的实现。music transformer还真是这样写的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> self.relative_pos:</span><br><span class="line">    <span class="comment">#apply same position embeddings across the batch</span></span><br><span class="line">    <span class="comment">#Is it possible to apply positional self-attention over</span></span><br><span class="line">    <span class="comment">#only half of all relative distances?</span></span><br><span class="line">    Er  = self.Er[:, embedding_start:, :].unsqueeze(<span class="number">0</span>)</span><br><span class="line">    QEr = torch.matmul(queries, Er.transpose(-<span class="number">1</span>,-<span class="number">2</span>))</span><br><span class="line">    QEr = self._mask_positions(QEr)</span><br><span class="line">    <span class="comment">#Get relative position attention scores</span></span><br><span class="line">    <span class="comment">#combine batch with head dimension</span></span><br><span class="line">    SRel = self._skew(QEr).contiguous().view(b*h, t, t)</span><br></pre></td></tr></table></figure>
<p>​ 其中的skew毫无保留地实现了论文的思想，个人感觉非常诡异。个人觉得原因可能是：它是music transformer，只保留一个方向的attention，故可能有所不同？</p>
<p>​ 个人思考后出来的实现与这篇博客：<a href="https://theaisummer.com/positional-embeddings/">AI Summer:How Positional Embeddings work in Self-Attention (code in Pytorch)</a>给出的实现方法很相似。但在swin transformer中，我还是忽略了一个很重要的问题：普通的序列一般是一维的，所以展开之后的相对距离实际上是一维度量： <span class="math display">\[
\begin{equation}\label{rm}
\begin{pmatrix}
0 &amp; 1 &amp; 2 &amp; ... &amp; L-1\\
-1 &amp; 0 &amp; 1 &amp; ... &amp; L-2\\
-2 &amp; -1 &amp; 0 &amp; ... &amp; L-3\\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 
-L+1 &amp; -L+2 &amp; -L+3 &amp; ... &amp; 0\\
\end{pmatrix}
\end{equation}
\]</span> ​ 而对于二维图像中的embeddings，注意两点：</p>
<ul>
<li>相对位置编码以及绝对位置编码解决的是同一个问题，所以实际上是可以相互转化的</li>
<li>正负方向有别，x+1以及x-1是不一样的，但是x，y方向也是不一样的</li>
</ul>
<p>​ 我们以 window size = 2 的情况来说明swin transformer中的“相对位置 <strong><u>bias</u></strong>（至于为什么要 <strong><u>加粗</u></strong>以及“双引号”，之后会说到）”的实现：对于以下A，B，C，D四个位置的像素每个位置相对于其他不同位置像素的二维距离分别是（注意有方向） <span class="math display">\[
\begin{align}
&amp;\text{image}=\begin{pmatrix}
A &amp; B\\
C &amp; D
\end{pmatrix}\\
&amp;A:\begin{pmatrix}
(0,0) &amp; (0,1)\\
(1,0)  &amp; (1, 1)
\end{pmatrix}\\
&amp;B:\begin{pmatrix}
(0,-1) &amp; (0,0)\\
(1,-1)  &amp; (1, 0)
\end{pmatrix}\\
&amp;C:\begin{pmatrix}
(-1,0) &amp; (-1,1)\\
(0,0)  &amp; (0, 1)
\end{pmatrix}\\
&amp;D:\begin{pmatrix}
(-1,-1) &amp; (-1,0)\\
(0,-1)  &amp; (0, 0)
\end{pmatrix}\\
\end{align}
\]</span> ​ 随便说明一个元素的意义，以D的第一行第二列元素(-1, 0)为例：这里说明的是：<span class="math inline">\(D\)</span>与<span class="math inline">\(B\)</span>的相对位置差别：B相对于D是行-1，列不变，故为(-1, 0)。那么将每个元素战平可以得到： <span class="math display">\[
\begin{equation}\label{flat}
\begin{pmatrix}
(0,0) &amp; (0,1) &amp; (1,0)  &amp; (1, 1)     \\
(0,-1) &amp; (0,0) &amp; (1,-1)  &amp; (1, 0)   \\
(-1,0) &amp; (-1,1) &amp; (0,0)  &amp; (0, 1)   \\
(-1,-1) &amp; (-1,0) &amp; (0,-1)  &amp; (0, 0) \\
\end{pmatrix}\\
\end{equation}
\]</span> ​ 我在公式<span class="math inline">\(\eqref{rm}\)</span>下面的无序列表中说到：x、y方向是等价的，故实际上公式<span class="math inline">\(\eqref{flat}\)</span>中不同的相对坐标值可以简化：比如我们从左下角开始标记id，相同的相对坐标值id相同，可以将公式<span class="math inline">\(\eqref{flat}\)</span>标记为（标记不唯一）： <span class="math display">\[
\begin{equation}\label{id}
\begin{pmatrix}
4 &amp; 5 &amp; 7  &amp; 8  \\
2 &amp; 4 &amp; 6  &amp; 7  \\
1 &amp; 3 &amp; 4  &amp; 5  \\
0 &amp; 1 &amp; 2  &amp; 4 \\
\end{pmatrix}\\
\end{equation}
\]</span> ​ 我们可以：</p>
<ul>
<li>在一个表中预存不同id对应的bias</li>
<li>将这个表变成learnable的，每次索引就好了，让网络自己学值</li>
</ul>
<p>​ 公式<span class="math inline">\(\eqref{id}\)</span>看起来真的很像绝对位置编码的样子，事实上这里就体现了绝对位置编码和相对位置编码的共同性以及相互转化。就像相对位姿一样，只要与一个global项（绝对量）结合，相对就会转化成绝对，反之亦然。</p>
<p>​ 值得一提的是：对于window size为L的window来说，因为每个像素点在不同方向上最多有<span class="math inline">\(2L-1\)</span>个不同位置，那么(x, y)的相对位置组合也就有<span class="math inline">\((2L-1)^2\)</span>种情况。比如，公式<span class="math inline">\(\eqref{id}\)</span>对应L=2的情况，就有9种不同的位置，L=3时为49种... 等等，都是可以验证的。理解了这个，indexing机制就只剩一个问题了：怎么实现。这个... 也不能完全说是问题吧。</p>
<div class="note warning"><p>​ 我在某天午夜思考实现方法，想了一小时没有头绪，遂睡觉。第二天早上醒来在床上花了三分钟想到了实现方法，这告诉我们睡眠非常重要。实现思想非常简单，所有其他位置的index，都可以复用(0, 0)位置的index，并在(0, 0)位置的index表元素中加上相同的偏置就可以了。</p>
</div>
<p>​ 关于2D relative positional bias，还有一个问题就是：positional bias的shape应该如何？</p>
<blockquote>
<p>当然是<span class="math inline">\((\text{head num}, 2L-1,2L-1)\)</span></p>
</blockquote>
<p>​ 但是为什么是这样呢？</p>
<p>​ 首先，relative positional bias之所以与embedding dimension一点关系都没有，是因为人家叫 <strong><u>bias</u></strong>，学的内容并不是一个什么向量，它就是一个在计算softmax时加入的偏置，是一维的，并且每个head是不一样的。</p>
<p>​ 其次，为什么是一个大小为<span class="math inline">\(2L-1\)</span>的方阵呢？因为两个方向都有<span class="math inline">\(2L-1\)</span>种不同的位置。</p>
<hr>
<h2 id="iv.-复现结果">IV. 复现结果</h2>
<p>​ swin transformer针对的是大型数据集（ImageNet），显然，这是我电脑没办法带动的（实验室的单3060也没办法跑）。所以我找了一些"compact ImageNet"，最后选定的是imagenette2-320（与timm docs使用同一个数据集）。数据集中图像的高固定为320。数据集共有十个分类，每个分类大约1000张图片（很小了）。</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/1.JPEG"></th>
<th style="text-align: center;"><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/2.JPEG"></th>
<th style="text-align: center;"><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/3.JPEG"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">收音机</td>
<td style="text-align: center;">卡车</td>
<td style="text-align: center;">鱼</td>
</tr>
</tbody>
</table>
<center>
Figure 6. 一些分类图片（相比之下CIFAR-10就是高糊）
</center>
<p>​ 不得不说，224 * 224的图像确实非常吃显存。batch size为50时显存占用是10GB，再高就炸我显卡了，故最后batch size取了一个保险的40（约8GB占用）。复现结果如下：</p>
<p>​ 首先得说明的是，我使用的参数基本与CCT一致，并没有调过，也不想费事去调，只是想理解一下本文的思想。文中使用的现代CV训练方法，比如cutmix等等这些操作，我一概没有使用，scheduler曾经使用过timm实现的余弦退火，但是最大最小学习率设置不合适，导致训练结果直接崩了（从70%调到10%），笔者也并不想花时间调。最终的结果大概是（存在过拟合，同样笔者也懒得调优了）：</p>
<ul>
<li>训练集83.5% 测试集78% (imagenette2-320)</li>
<li>除了第一次使用160 epochs之外，其余均是250 epochs，学习率固定分别固定(1e-5, 5e-6以及4e-6)</li>
</ul>
<p><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/trainacc.png"></p>
<center>
Figure 7. train set accuracy
</center>
<p><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/testacc.png"></p>
<center>
Figure 8. test set accuracy
</center>
<p><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/trainloss.png"></p>
<center>
Figure 9. train set loss
</center>
<p><img src="/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/testloss.png"></p>
<center>
Figure 10. test set loss
</center>
<hr>
<h2 id="v.-一些torch函数">V. 一些torch函数</h2>
<h5 id="torch.triu">torch.triu</h5>
<blockquote>
<p>triu(input, diagonal=0, *, out=None) -&gt; Tensor Returns the upper triangular part of a matrix (2-D tensor) or batch of matrices</p>
</blockquote>
<p>​ 也即可以通过这个函数获得某个矩阵的上三角部分。对应的下三角是<code>torch.tril</code>。其中的diagonal参数指示了：相对于真正的对角线的偏移量，默认为0，也即对角线下方的所有元素设为0。如果是正数，比如1，将会使得0元素分界线向右上方偏移（1），反之往左下方。不是很常用。</p>
<h5 id="torch.masked_fill">torch.masked_fill</h5>
<p>​ 本实现中使用了此函数：在attention mask中，将所有为负数的区域变为-100（使得logit很小）。传入的第一个参数相当于条件张量（一般会转化成true false的bool张量），第二个参数是需要fill的值。</p>
<h5 id="torch.gather">torch.gather</h5>
<p>​ 本实现中，relative positional bias一开始的实现使用过。gather实际上在没有view改变形状的情况下，直接根据提供的index，在原始矩阵中进行索引，得到的值组成一个新的矩阵：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rpe = torch.gather(s, -<span class="number">1</span>, self.relp_indices.repeat(batch_size, win_num, self.head_num, <span class="number">1</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>​ 上公式可以直接在最后一维度选择（第二个参数，dim = -1），直接根据索引(self.relp_indices)，从一个（最后两个维度）shape为(2L - 1, 2L-1)的矩阵中直接取出一个大小为(L, L)的矩阵。</p>
<h5 id="torch.register_buffer">torch.register_buffer</h5>
<p>​ torch有两个常用的 与 "register" 有关的函数：<code>register_buffer</code>以及<code>register_parameter</code></p>
<ul>
<li>register_buffer会将对应的张量加入到model.state_dict中，但是它不会参与反向传播计算。这给我们保存模型中一些无关参数（或者常数）提供了便利，这样加入model.state_dict中的参数可以直接被torch.save保存</li>
</ul>
<h5 id="torch.view-torch.reshape-torch.contiguous">torch.view / torch.reshape / torch.contiguous</h5>
<blockquote>
<p>help(torch.reshape): Contiguous inputs and inputs with compatible strides can be reshaped without copying, but you should not depend on the copying vs. viewing behavior.</p>
</blockquote>
<p>​ view只能针对contiguous的数据进行操作，是在底层数据内存组织基础上，返回一种以不同于底层数据内存组织方式的视角（view，或认为是步长）来查看数据的tensor。比如：底层是矩阵<span class="math inline">\(A_{2\times2}\)</span>，transpose之后是<span class="math inline">\(B_{2\times2}\)</span> <span class="math display">\[
\begin{equation}
A=\begin{pmatrix}
1 &amp; 2\\
3 &amp; 4
\end{pmatrix},
B=\begin{pmatrix}
1 &amp; 3\\
2 &amp; 4
\end{pmatrix}
\end{equation}
\]</span> ​ A在内存中实际上是按照行优先进行一维存储的：实际上保存的数据是(1, 2, 3, 4)并且按照stride = (2, 1)进行访问。而B作为A的transpose，实际上没有修改内存组织（transpose后的数据与A共用内存（<strong><u>如果不小心可能会导致不想要的修改</u></strong>）），但是是以stride = (1, 2) 访问数据。这里的stride = (i, j)可以认为是：</p>
<ul>
<li>行方向上的索引增加1，在物理地址的寻址中需要移动i个位置</li>
<li>列方向上索引增加1，物理地址寻址需要移动j个位置</li>
</ul>
<p>​ 故由于B是(1, 2)，那么B[0, 1] = (B基地址 + 1 * 2偏移).value = 3。B[1, 0] = (B基地址 + 1 * 1偏移).value = 2。</p>
<p>​ 上示例中，A是contiguous的，但B并不是，因为其访问数据的方式在内存中不是线性连续的。故B这样的矩阵，<strong><u>不能直接view</u></strong></p>
<ul>
<li>直接view操作不改变内存组织方式，view前后数据共享内存</li>
<li>reshape相当于是 X.contiguous().view。如果一个矩阵不是contiguous的，contiguous操作将会开辟新的内存空间并复制原来的tensor，以新的view进行数据存储</li>
<li>值得一提的是，<code>permute</code>, <code>narrow</code>, <code>expand</code>, <code>transpose</code>操作之后，均会使得contiguous不成立。但是<code>view</code>操作过后，虽然stride可能发生改变，但其并不影响contiguous性。</li>
</ul>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://github.com/microsoft/Swin-Transformer">Github: microsoft/Swin-Transformer</a></p>
<p>[2] <a href="https://arxiv.org/abs/1809.04281">Huang, Cheng-Zhi Anna, et al. "Music transformer." <em>arXiv preprint arXiv:1809.04281</em> (2018).</a></p>
<p>[3] <a href="https://theaisummer.com/positional-embeddings/">AI Summer:How Positional Embeddings work in Self-Attention (code in Pytorch)</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>Typora &amp; Markdown Intros</title>
    <url>/2021/02/09/Typora-Markdown-Intros/</url>
    <content><![CDATA[<h1 id="typora-markdown">Typora &amp; Markdown</h1>
<hr>
<h2 id="why">Why?</h2>
<p><span id="start"></span></p>
<p>​ 此文撰写的目的是：</p>
<ul>
<li>归纳Typora（Markdown编辑器） 的基本使用（常用的都能找到）</li>
<li>给我Raven的安利。</li>
</ul>
<center>
效率工具，绝不白启
</center>
<p></p>
<span id="more"></span>
<h3 id="why-markdown">Why Markdown?</h3>
<p>​ 虽说markdown实际是给 不爱使用鼠标在word上点来点去的人使用的（并且面向的人群一般是对敲代码有兴趣的人），但由于Markdown上手极其简单，并且使用效率极高，<strong><u>极其适合：</u></strong></p>
<ul>
<li>撰写ReadMe，帮助他人理解某个程序 / 文件包 / 压缩包文件 / 文档 / 代码 如何使用。</li>
<li>写一些风格简约而又好看的文档，方便撰写 tutorials / ideas / agenda / 会议记录 / <strong><u>学习笔记</u></strong> / <strong><u>实验报告</u></strong> / 等等，<strong><u>并快速生成PDF文件</u></strong>。</li>
<li>【Event Horizon】上的所有博文，均是markdown渲染出来的。</li>
</ul>
<h3 id="why-typora">Why Typora?</h3>
<p><img src="/2021/02/09/Typora-Markdown-Intros/from_site.png"></p>
<center>
Figure 1. 来自官网的图片
</center>
<p>​ Typora 是一款极其轻量级的Markdown语法编辑器，其界面就像windows自带的记事本。并且，对于markdown语法支持实时渲染（直接显示效果）。易用性与美观性（尤其是其自带的Pixyll主题，中英文都极其美观）是其另外两个优点。Typora支持：</p>
<ul>
<li>Markdown所有语法</li>
<li>LaTex数学公式渲染</li>
<li>html支持（网页前端语言，markdown进阶中用于美化，本文会提几个常用栗子）</li>
</ul>
<hr>
<h2 id="level-1-skills">Level 1 Skills</h2>
<p>​ 本节将会介绍基础的markdown语法。记忆这些语法是非常容易的，因为都很简单。</p>
<h3 id="无序-有序items">无序 &amp; 有序items</h3>
<h4 id="无序items">无序items</h4>
<p>​ 在分点操作时，常常会使用 (1) 分点内容前面加上一个黑色圆点 (2) 使用编号（有序排列），在markdown中，无需进行鼠标点击（鼠标 / 触控板 / 触屏 在文档撰写的时候真的累赘）。对于 <strong>无序分点，可以如下输入：</strong></p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> Markdown is easy to use.</span><br><span class="line"><span class="bullet">-</span> Markdown is so goodlooking.</span><br><span class="line"><span class="bullet">-</span> Simplicity is the basic traits.</span><br></pre></td></tr></table></figure>
<p>​ （前面的- 就是减号，当然 “*” 号也是可以替换“-” 号的），在Typora页面上实时显示的结果是：</p>
<ul>
<li>Markdown is easy to use.</li>
<li>Markdown is so goodlooking.</li>
<li>Simplicity is the basic traits.</li>
</ul>
<p>​ 当然，不同级别的items（分级）也是支持的，只需要通过缩进的方式（比如TAB缩进，或是Typora提供的 <code>Ctrl + ]</code> 增加缩进（级别减小（子item）），<code>Ctrl + [</code> 减少缩进（或者说：级别增大））：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> Markdown is easy to use.</span><br><span class="line"><span class="bullet">	-</span> Gramma is easy to remember.</span><br><span class="line"><span class="bullet">		-</span> &quot;- + indent&quot; is unordered item.</span><br><span class="line"><span class="bullet">    -</span> Then What?</span><br></pre></td></tr></table></figure>
<p>​ 在Typora页面上实时显示的结果是：</p>
<ul>
<li>Markdown is easy to use.
<ul>
<li>Gramma is easy to remember.
<ul>
<li>"- + indent" is unordered item.</li>
</ul></li>
<li>Then What?</li>
</ul></li>
</ul>
<h4 id="有序items">有序items</h4>
<p>​ 需要按照编号排列时，可以输入以下语句：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> Open the gate.</span><br><span class="line"><span class="bullet">2.</span> Let the army in.</span><br><span class="line"><span class="bullet">3.</span> Close the gate.</span><br></pre></td></tr></table></figure>
<p>​ 这个其实有点鸡肋了，markdown会自动帮你调整编号的位置。Typora则会帮你自动添加编号，也即：输入一个 1. 再换行，会自动出现 2. 3. 等等。以上的输出结果是：</p>
<ol type="1">
<li>Open the gate.</li>
<li>Let the army in.</li>
<li>Close the gate.</li>
</ol>
<p>​ 当然，有序items也是可以分级的。同样使用缩进的方法可以达到目的。</p>
<h4 id="typora-items使用的一个坑">Typora items使用的一个坑</h4>
<ul>
<li><p>随便写的一句话。</p>
<p>随便写的第二句话。</p></li>
<li><p>随便写的一句话</p></li>
</ul>
<p>​ 随便写的第二句话。</p>
<p>​ 在写完items后，不想要分下一个点了，想要开始另一端正文，但是无论使用 backspace 删除 还是使用 <code>Ctrl + [</code> 删去自动添加的分点，都会让下一行的首行缩进变得很奇怪，主要体现在：按下TAB之后，正常情况下只会缩进一个字符，但是此情况下，缩进了不止一个字符，并且出现了错位的情况。</p>
<table>
<thead>
<tr class="header">
<th><img src="/2021/02/09/Typora-Markdown-Intros/ind_1.JPG"></th>
<th>错误情况，正文与item文字对齐了。并且一个tab就能缩进到此情况</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="/2021/02/09/Typora-Markdown-Intros/ind_2.JPG"></td>
<td>正确情况，需要两个tab才能达到首行缩进两个字符的情况</td>
</tr>
</tbody>
</table>
<p>​ 对于强迫症患者而言（如作者），这是不能被接受的。解决方法是：</p>
<ul>
<li>在错误情况的行首 两次tab键，先进行一次首行两字符缩进。</li>
<li>再使用<code>Ctrl + [</code> 取消Typora自动设置的item缩进，即可。</li>
</ul>
<hr>
<h3 id="字体变换">字体变换</h3>
<p>​ Markdown 如何打出：<em>斜体（Italic）</em>，<strong>加粗（Bold）</strong>，<strong><em>斜体加粗（Combined）</em></strong>，<u>下划线</u>，<del>删除线</del>呢？</p>
<ul>
<li><p>斜体使用：<code>*斜体*</code>，输入两个<code>**</code> 在<code>*</code>包括的部分内部内输入需要斜体的文字即可。当然，不管是word，OneNote还是Typora，快捷键都是<code>Ctrl+I</code></p></li>
<li><p>加粗：<code>**加粗**</code>，需要加粗的文字需要左右各两个<code>*</code>。不管是word，OneNote还是Typora，快捷键都是<code>Ctrl+B</code></p></li>
<li><p>斜体加粗：<code>***斜体加粗***</code>，也就是需要加粗的部分左右各3星。不管是word，OneNote还是Typora，快捷键都是<code>Ctrl+I+B</code></p></li>
<li><p>下划线：<font color="blue">这是第一个HTML语法的小栗子，不过很简单</font>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;u&gt;需要下划线的部分&lt;/u&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>&lt;u&gt;</code>表示起始（underline），<code>&lt;/u&gt;</code>前的<code>/</code>表示结束。</li>
<li>不管是word，OneNote还是Typora，快捷键都是<code>Ctrl+U</code></li>
</ul></li>
<li><p>删除线：<code>~~需要删除的部分~~</code>，也就是左右各两个<code>~</code>。Typora中，默认快捷键是：<code>Alt+Shift+5</code>。</p></li>
</ul>
<p>​ 给出一个实际的例子，输入如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">开始：*这是文中需要倾斜的部分*，这是正常的部分，这是**需要加粗的部分**，而这是***综合部分***。下划线可以&lt;u&gt;这么加&lt;/u&gt;，而下划线+加粗可以这样，&lt;u&gt;**虽然Ctrl+B+U快捷键完全可以解决**&lt;/u&gt;。删除线则是~~这样使用的~~。</span><br></pre></td></tr></table></figure>
<p>​ 实际输出如下：</p>
<p>​ 开始：<em>这是文中需要倾斜的部分</em>，这是正常的部分，这是<strong>需要加粗的部分</strong>，而这是<strong><em>综合部分</em></strong>。下划线可以<u>这么加</u>，而下划线+加粗可以这样，<u><strong>虽然Ctrl+B+U快捷键完全可以解决</strong></u>。删除线则是<del>这样使用的</del>。</p>
<hr>
<h3 id="标题与分割线">标题与分割线</h3>
<p><span id="caption"></span></p>
<p>​ Markdown中的标题是格式化的。不需要设置大小与格式（不过正常情况下标题是左对齐的）。标题使用 <code>#</code> + 空格来表示。</p>
<p></p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="section"># 一级标题</span></span><br><span class="line"><span class="section">## 二级标题</span></span><br><span class="line"><span class="section">### 三级标题</span></span><br><span class="line"><span class="section">#### 四级标题</span></span><br><span class="line"><span class="section">##### 五级标题</span></span><br></pre></td></tr></table></figure>
<p>​ 输出结果是长这样的：</p>
<p><img src="/2021/02/09/Typora-Markdown-Intros/caption.png"></p>
<center>
Figure 2. 标题样式
</center>
<p>​ 注意，<code>#</code>之后一定要跟上空格，再输入标题内容。</p>
<p>​ 分割线：只需要在需要分割的位置，加入<code>---</code>即可进行分割（注意<code>---</code>一定要另起一行，分割线行中只能写这一个内容）。比如文中的分割线，都是<code>---</code>的渲染结果，例子：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Contents I</span><br><span class="line">---</span><br><span class="line">Contents II</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="超链接的两种常见方式">超链接的两种常见方式</h3>
<p>​ HyperLink （超链接）最常见的使用方式就是 <strong><u>网页跳转</u></strong>。当然，markdown中存在另一种页内跳转的方式。假设我们希望读者在读到这段文字的时候，去查看本文其他位置的内容，比如 <a href="#start">【点我查看文章开头】</a>，确实也是可以做到的。</p>
<h4 id="网页跳转">网页跳转</h4>
<p>​ reference编写时，可能我们希望读者可以通过点击直接跳转到某个位置，可以使用以下方式进行编写：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[跳转链接](https://www.baidu.com/)</span><br></pre></td></tr></table></figure>
<p>​ <code>[]</code>内部指定：超链接嵌入在<code>[]</code>包括的文字内部，也就是说，点击此段被包括的部分，可以进行跳转。<code>()</code>内部则是网址了，网址只需要在浏览器上复制后粘贴于此处即可。上述渲染结果如下：</p>
<p>​ <a href="https://www.baidu.com/">跳转链接</a></p>
<h4 id="页内跳转">页内跳转</h4>
<p>​ 如果是PDF文件，需要读者可以方便地随着作者的思路走，可以使用如下方式。</p>
<ol type="1">
<li><p>在需要跳转到的位置插入：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;span id=&#x27;name&#x27;&gt;</span><br><span class="line">需要跳转的位置，比如上个&quot;超链接的两种常见方式&quot;开头部分跳转到文章开头，则将此块插入到文章开头</span><br><span class="line">&lt;/span&gt;</span><br><span class="line">例如：</span><br><span class="line">&lt;span id=&#x27;start&#x27;&gt;</span><br><span class="line">	此文撰写的目的是：</span><br><span class="line">- 归纳Typora（Markdown编辑器） 的基本使用（常用的都能找到）</span><br><span class="line">- 给我Raven的安利。</span><br><span class="line">&lt;/span&gt;</span><br></pre></td></tr></table></figure>
<p>​ 需要说明的是，id='name' 在这里设置了一个标签，name是标签的名字。比如一篇文章内部可能有很多跳转，为了不混淆目的地，需要标记不同的目的地的名称。比如开头标记为<code>span id='start'</code>，而结尾标记为<code>span id='ending'</code>。此后就根据标记跳转到需要的地方。</p></li>
<li><p>在开始跳转位置处写：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[点我跳转](#name)</span><br></pre></td></tr></table></figure>
<p>​ 由于作者在文章开头处设置了一个跳转目的地，写的是<code>&lt;span id='start'&gt;</code>，也就是目的地被称为了<code>start</code>，上面这个例子的name 如果设置成start，则结果是这样的：</p>
<p>​ <a href="#start">点我跳转</a>。当然一般为了美观，可以在<code>[]</code>内再加上一个<code>[]</code>，就会变成<a href="#name">[点我跳转]</a>。注意在<code>()</code>内，需要一个<code>#</code>，此处不表示一级标题。</p></li>
<li><p>查看结果。</p></li>
</ol>
<hr>
<h3 id="图片与表格插入">图片与表格插入</h3>
<h4 id="图片插入">图片插入</h4>
<p>​ Markdown的图片插入语法如下图所示：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">![<span class="string">文章中给图片起的别名</span>](<span class="link">图片所在位置</span>)</span><br></pre></td></tr></table></figure>
<p>​ <code>[]</code>中的内容可以不填写，但是图片位置必须要指定。在Typora中，有两种方式可以快速插入图片：(1) 右键-&gt;插入-&gt;图片。(2) 快捷键<code>Ctrl+Shift+I</code>。</p>
<table>
<thead>
<tr class="header">
<th><img src="/2021/02/09/Typora-Markdown-Intros/insert1.JPG"></th>
<th>可以点击文件夹图标进行图片插入</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="/2021/02/09/Typora-Markdown-Intros/insert2.JPG"></td>
<td>也可以手动输入，默认是绝对路径（就是要输入从盘位置开始的路径）</td>
</tr>
</tbody>
</table>
<p>​ 注意，与word不同：word插入图片后，修改文件夹中的图片，不会对已经在文章里的内容产生影响（比如更改大小 / 删除等等，文中的图片保持不变），因为word中的图片是一份copy。而Markdown中的图片，只是原图片的<strong><u>链接</u></strong>，任何对源文件的修改都将影响文中的图片。其好处是：更改图片的细节很容易，无需重新插入。但是，在完成文章，输出成pdf前一定要确保对应名字的图片能够被找到。</p>
<p>​ <code>()</code>中，除了可以填写本地图片（插入本地图片），也可以插入网络上的图片。浏览器一般会提供<strong>复制图片链接</strong>选项，只需要将链接填写在<code>()中即可</code>。比如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">![起子](https://bkimg.cdn.bcebos.com/pic/bba1cd11728b4710dac3926bc9cec3fdfd0323ac?x-bce-process=image/watermark,image_d2F0ZXIvYmFpa2U4MA==,g_7,xp_5,yp_5/format,f_auto)</span><br></pre></td></tr></table></figure>
<p>​ 输出结果如下：</p>
<p><img src="https://bkimg.cdn.bcebos.com/pic/bba1cd11728b4710dac3926bc9cec3fdfd0323ac?x-bce-process=image/watermark,image_d2F0ZXIvYmFpa2U4MA==,g_7,xp_5,yp_5/format,f_auto" alt="起子" style="zoom:50%;"></p>
<center>
Figure 3. 起子的百度百科上复制的图片
</center>
<p>​ Typora提供了图片大小缩放的快捷选项，只需要对插入的图片按右键，找到<code>【缩放图片到】</code>即可。缩放后，图片的源码栏 <strong><u>不再是markdown语法</u></strong>，而变成了 <strong><u>HTML语法</u></strong>，因为原生markdown不支持缩放，但是与使用者无关，其插入路径还是可以随意更改，这个特性对本地图片也是适用的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;img src=&quot;https://bkimg.cdn.bcebos.com/pic/bba1cd11728b4710dac3926bc9cec3fdfd0323ac?x-bce-process=image/watermark,image_d2F0ZXIvYmFpa2U4MA==,g_7,xp_5,yp_5/format,f_auto&quot; alt=&quot;起子&quot; style=&quot;zoom:50%;&quot; /&gt;</span><br></pre></td></tr></table></figure>
<p>​ 注意到上述代码中有一项：<code>style="zoom:50%;"</code>，表明缩放的大小。Typora只提供了默认的几个缩放等级，如果要更灵活的缩放可以直接更改<code>50%</code>为其他数值。</p>
<h4 id="表格插入">表格插入</h4>
<p>​ 原生Markdown支持表格，但是表格的输入有点麻烦（Typora提供了更快捷的插入方式），可以先看原生语法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">|姓名|班级|学号|成绩|</span><br><span class="line">|:-|:-:|-:|:-:|</span><br><span class="line">|A|1|001|59|</span><br><span class="line">|B|1|002|58|</span><br><span class="line">|C|1|003|57|</span><br></pre></td></tr></table></figure>
<p>​ 输出的结果如图（Pixyll主题下的图表，最美观的那种）：</p>
<p><img src="/2021/02/09/Typora-Markdown-Intros/table.png"></p>
<center>
Figure 4. Typora Pixyll主题表格
</center>
<p>​ 注意到其中有些奇怪的东西：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">|:-|:-:|-:|:-:|</span><br></pre></td></tr></table></figure>
<p>​ 这是什么？此处表示图表的对齐方式：<code>:-</code>冒号在左边表示左对齐。<code>:-:</code>两边有冒号表示居中，<code>-:</code>右边冒号表示右对齐。原生语法下，不写对齐方式是不会渲染表格的，出来的就是这一堆神秘代码。</p>
<p>​ Typora右键可以插入表格，在插入的表格左上方可以选择对齐方式 / 表格size（列 * 行）。但是表格的大小（每个cell的长宽）根据所在列和行的内容自动调整。注意，表格内也可以使用markdown / HTML / LaTex语法。</p>
<hr>
<h3 id="todos与引用">TODOs与引用</h3>
<p>​ 代办项 / 引用 是markdown提供的另外两种输出样式：如图所示</p>
<p><img src="/2021/02/09/Typora-Markdown-Intros/todos.png"></p>
<center>
Figure 5. 引用与待办项输出示例
</center>
<h4 id="引用">引用</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; 一级引用</span><br><span class="line">&gt;&gt; 二级引用</span><br><span class="line">&gt;&gt;&gt; 三级引用</span><br></pre></td></tr></table></figure>
<p>​ 注意&gt;号后面要加空格。引用可以一直套娃下去。</p>
<p>​ 有的时候可能卡在引用语法里出不来（输入不了正常的文字，换行之后仍然是引用区内），只需要使用<code>Ctrl+[</code>减少缩进即可退出引用。</p>
<h4 id="todos">TODOs</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- [x] 14:00-16:00</span><br><span class="line">- [ ] 16:00-18:00</span><br></pre></td></tr></table></figure>
<p>​ 注意：首先是<code>-</code>号，<strong>空格</strong>后，再输入<code>[ ]</code>（中有空格），再空格输入文字。其中输入有x的表明已经完成的，原生markdown中需要输入x，但Typora中可以直接点击，自动输入x。</p>
<hr>
<h3 id="代码片段与代码块">代码片段与代码块</h3>
<p>​ 一般会给程序员使用，比如要强调一块代码的时候。Markdown是可以根据选择的语言进行语法高亮(Syntax Highlights) 以及自动标注行号的，以下是C++代码的一个实例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>** argv)</span></span>&#123;</span><br><span class="line">	std::cout &lt;&lt; <span class="string">&quot;Hello Markdown!\n&quot;</span>;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 实际上，所有需要强调的非文章内容都可以放在代码块中。原生markdown语法是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">```</span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line">...</span><br><span class="line">​```</span><br></pre></td></tr></table></figure>
<p>​ 需要指定语言时，Typora在代码块右下角可以输入语言（点击代码块后右下角会出现），原生语法是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">```语言名称</span><br><span class="line"></span><br><span class="line">​```</span><br><span class="line">例如</span><br><span class="line">​```python</span><br><span class="line">print(&quot;Hello markdown.&quot;)</span><br><span class="line">​```</span><br></pre></td></tr></table></figure>
<p>​ 如果不需要整段的代码，而是需要强调某些小部分的话，可以使用“`”符号。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">插入图片的快捷键是`Ctrl+Shift+I`</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="emoji">Emoji</h3>
<p>​ 这个好像是Typora提供的（原生markdown好像也有，但是emoji的名称要去记，很不方便）。比如我要输入一个微笑：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">:smile:</span><br></pre></td></tr></table></figure>
<p>​ 微笑将会按照上面的语法显示出来：:smile:。对Typora而言，输入英文冒号后，随便输入一个字母都可能有对应的emoji，比如：</p>
<p><img src="/2021/02/09/Typora-Markdown-Intros/emoji.png"></p>
<center>
Figure 6. Markdown自带的emoji
</center>
<hr>
<h3 id="typora的一些设置与功能">Typora的一些设置与功能</h3>
<p><span id="setting"></span></p>
<p>​ Typora个性化设置可以帮助用户更好地使用其携带的一些功能：右上角<code>[文件]</code>-&gt;<code>[偏好设置]</code>-&gt;<code>[Markdown]</code>中（markdown设置更为常用）：</p>
<p></p>
<p><img src="/2021/02/09/Typora-Markdown-Intros/setting1.png"></p>
<center>
Figure 7. 常用设置1
</center>
<p><img src="/2021/02/09/Typora-Markdown-Intros/setting2.png"></p>
<center>
Figure 8. 常用设置2
</center>
<p>​ 在Typora中还有两种模式可以设置：</p>
<ul>
<li>打字机模式（页面自动定位到当前行所在位置，无需滚轮滚动）（可以自己试试看：快捷键<code>F8</code>）</li>
<li>专注模式（其他内容的可见性会变低（加雾），当前书写内容正常显示）（可以自己试试看：快捷键<code>F9</code>）
<ul>
<li>左上角：视图中可以进行设置</li>
</ul></li>
</ul>
<h4 id="目录组织">目录组织</h4>
<p>​ 如果需要快速建立目录，可以直接在文章开头输入:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[toc]</span><br></pre></td></tr></table></figure>
<p>​ 表示（table of contents），这个目录的建立是根据<a href="#caption">【标题与分割线】</a>中的标题级数来组织的。目录可以用在：</p>
<ul>
<li>实验报告 / 长文 中</li>
<li>并且，生成pdf时，会自动插入书签（每个标题都会有书签，书签下根据标题级数还会有子书签）</li>
</ul>
<hr>
<h2 id="level-2-skills">Level 2 Skills</h2>
<p>​ 此部分内容较为进阶，但是如1 / 3节而言，对于大多数人来说都很实用（第三节难记），包括：</p>
<ul>
<li>实用的HTML命令（简单可复制）</li>
<li>LaTex数学公式输入</li>
<li>mermaid（块状流程图） / flow（标准流程图） / gantt（甘特图）绘制</li>
</ul>
<hr>
<h3 id="实用html命令">实用HTML命令</h3>
<blockquote>
<p><em>HTML</em>称为超文本标记语言，是一种标记语言。它包括一系列标签．通过这些标签可以将网络上的文档格式统一，使分散的Internet资源连接为一个逻辑整体。<a href="https://baike.baidu.com/item/HTML/97049?fr=aladdin">HTML 百度百科</a></p>
</blockquote>
<p>​ 本文不教HTML怎么写（不是本文的目的），并且HTML也不像原生markdown那么简洁，但是有些非常实用的编辑命令不得不提。</p>
<h4 id="文字的居中与修改">文字的居中与修改</h4>
<p>​ 原生markdown貌似不支持直接居中，作为使用者，我也不可能直接就用空格手动居中了。居中 / 字体调整等方面相对麻烦（虽然无需鼠标点击）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;center&gt;需要居中的部分&lt;/center&gt;</span><br></pre></td></tr></table></figure>
<p>​ 显示的结果是：</p>
<center>
需要居中的部分
</center>
<p>​ 而字体大小 / 颜色 / 字型调整，需要应用<code>&lt;font&gt;</code>语法：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">font</span> <span class="attr">size</span>=<span class="string">3</span> <span class="attr">color</span>=<span class="string">&#x27;blue&#x27;</span> <span class="attr">face</span>=<span class="string">&#x27;黑体&#x27;</span>&gt;</span>黑体，size=3的蓝色字<span class="tag">&lt;/<span class="name">font</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">font</span> <span class="attr">size</span>=<span class="string">4</span> <span class="attr">color</span>=<span class="string">&#x27;red&#x27;</span> <span class="attr">face</span>=<span class="string">&#x27;微软雅黑&#x27;</span>&gt;</span>微黑，size=4的红色字<span class="tag">&lt;/<span class="name">font</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">font</span> <span class="attr">size</span>=<span class="string">5</span> <span class="attr">color</span>=<span class="string">&#x27;green&#x27;</span> <span class="attr">face</span>=<span class="string">&#x27;Arial&#x27;</span>&gt;</span> Arial字体，size=5的绿色字<span class="tag">&lt;/<span class="name">font</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><font size="3" color="blue" face="黑体">黑体，size=3的蓝色字</font> <font size="4" color="red" face="微软雅黑">微黑，size=4的红色字</font> <font size="5" color="green" face="Arial"> Arial字体，size=5的绿色字</font></p>
<p>​ 多重特性叠加也是可以的：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;center&gt;&lt;font size=3 color=&#x27;blue&#x27; face=&#x27;黑体&#x27;&gt;居中黑体size3蓝色字/font&gt;&lt;/center&gt;</span><br></pre></td></tr></table></figure>
<center>
<font size="3" color="blue" face="黑体">居中黑体size3蓝色字/font&gt;
</font></center>
<hr>
<h4 id="分页-高级表格">分页 / 高级表格</h4>
<p>​ 假如我们希望某处文字后，另起一页，直接打换行太不方便了（并且markdown中没有页数这个概念，转为pdf后才能看到分页效果）。可以复制以下代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;div style=&quot;page-break-after: always;&quot;&gt;&lt;/div&gt;</span><br></pre></td></tr></table></figure>
<p>​ 表示此处之后，进行新加一页的操作。通常用于：abstract与下文的分割 / 目录与下文的分割 / 正文与reference的分割。</p>
<p>​ <strong><u>高级表格</u></strong>：原生markdown不支持单元格合并，需要使用HTML的<code>&lt;table&gt;</code>标签才能得到扩展。具体方法十分复杂，不作为重点，只是提一下，有兴趣者参看：</p>
<ul>
<li><a href="https://www.runoob.com/html/html-tables.html">【HTML 表格 | 菜鸟教程🔗】</a></li>
<li><a href="https://blog.csdn.net/lhrdlp/article/details/100861546">【CSDN HTML表格 单元格合并🔗】</a></li>
</ul>
<hr>
<h4 id="之前讲过的html">之前讲过的HTML</h4>
<ul>
<li><code>&lt;u&gt;...&lt;/u&gt;</code> 下划线语法</li>
<li><code>&lt;span id='name'&gt;...&lt;/span&gt;</code>，设置跳转位置标记语法</li>
</ul>
<hr>
<h3 id="latex-数学公式渲染">LaTex 数学公式渲染</h3>
<p>​ 什么是<a href="https://baike.baidu.com/item/LaTeX/1212106?fr=aladdin">[<span class="math inline">\(\LaTeX\)</span>百度百科🔗]</a>，<a href="(https://www.latex-project.org/)">[<span class="math inline">\(\LaTeX\)</span>官网]</a></p>
<p>​ 原生的markdown不支持（Github上的readme就不直接支持<span class="math inline">\(\LaTeX\)</span>语法），但是Typora支持。有数学公式输入需要的朋友可以使用内置的功能。注意可能需要在设置中打开LaTex支持，详见<a href="#setting">【Typora的一些设置与功能】</a>。</p>
<h4 id="内联公式">内联公式</h4>
<p>​ 就是行内嵌入公式，比如：<span class="math inline">\(P(x|y)=\frac{P(x,y)}{P(y)}\)</span>或是：<span class="math inline">\(f:D \subset \mathbb R^n\rightarrow \mathbb R\)</span>。只需要使用：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">比如：$P(x|y)=\frac&#123;P(x,y)&#125;&#123;P(y)&#125;$</span><br></pre></td></tr></table></figure>
<p>​ 也就是LaTex语法是被$符号（左右各一个）包围的。</p>
<h4 id="公式块">公式块</h4>
<p><span class="math display">\[
2D_{JS}(P_R|P_G)=\int_xP_R(x)log(\frac{P_R(x)}{\frac{P_R(x) + P_G(x)}{2}})dx + \int_xP_G(x) log(\frac{P_G(x)}{\frac{P_R(x) + P_G(x)}{2}})dx
\]</span></p>
<p>​ 还没有接触过LaTex的朋友，就不指望你立马写出以上的公式来了。上面公式的代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$$</span><br><span class="line">2D_&#123;JS&#125;(P_R|P_G)=\int_xP_R(x)log(\frac&#123;P_R(x)&#125;&#123;\frac&#123;P_R(x) + P_G(x)&#125;&#123;2&#125;&#125;)dx + \int_xP_G(x) log(\frac&#123;P_G(x)&#125;&#123;\frac&#123;P_R(x) + P_G(x)&#125;&#123;2&#125;&#125;)dx</span><br><span class="line">$$</span><br></pre></td></tr></table></figure>
<p>​ 重点就是开头和结尾插入两个<code>$$</code>。</p>
<h4 id="常用latex语法">常用<span class="math inline">\(\LaTeX\)</span>语法</h4>
<p><img src="/2021/02/09/Typora-Markdown-Intros/latex1.png"></p>
<center>
Figure 9. LaTex常用语法
</center>
<p>​ 公式块语法（多行公式，<strong><u>左对齐</u></strong>，每个公式<strong><u>独立标号</u></strong>）</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;align&#125;</span><br><span class="line"><span class="built_in">&amp;</span> x = a + b 	<span class="keyword">\\</span> <span class="comment">% \\为换行</span></span><br><span class="line"><span class="built_in">&amp;</span> x = c + d</span><br><span class="line"><span class="keyword">\end</span>&#123;align&#125;</span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
\begin{align}
&amp; x = a + b     \\ % \\为换行
&amp; x = c + d
\end{align}
\]</span></p>
<p>​ 多行公式，所有公式标号只有一个:</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;equation&#125;</span><br><span class="line">x = a + b 	<span class="keyword">\\</span> <span class="comment">% \\为换行</span></span><br><span class="line">x = c + d</span><br><span class="line"><span class="keyword">\end</span>&#123;equation&#125;</span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
\begin{equation}
x = a + b   \\ % \\为换行
x = c + d
\end{equation}
\]</span></p>
<p>​ 其他的语法可以见上一篇博文<a href="https://enigmatisms.github.io/2021/02/05/LaTex%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E8%AE%B0%E5%BD%95/">[LaTex基础语法记录]</a>。有些语法支持（比如矩阵 / 大花括号 / 公式lable添加），有些不支持（图片操作 / 分节）</p>
<hr>
<h3 id="mermaid-flow-gantt">Mermaid / Flow / Gantt</h3>
<p>​ 这三种是常见的图表（块状逻辑图）（流程图）（甘特图（多用于项目管理）），这些图表都是基于三个“`”符号的代码块：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">```mermaid</span><br><span class="line">...</span><br><span class="line">​```</span><br><span class="line"></span><br><span class="line">​```flow</span><br><span class="line">...</span><br><span class="line">​```</span><br><span class="line"></span><br><span class="line">​```gantt</span><br><span class="line">...</span><br><span class="line">​```</span><br></pre></td></tr></table></figure>
<h4 id="mermaid">Mermaid</h4>
<p>​ 只提供简单的示例：mermaid图表通常的输出如下：</p>
<p><img src="/2021/02/09/Typora-Markdown-Intros/mermaid2.png"></p>
<center>
Figure 10. TB与LR两种空间排布的输出
</center>
<p>​ 左图是上下式排列（<code>graph TB</code>）右图是左右式排列（<code>graph LR</code>）。</p>
<p>​ mermaid图提供了几种 <strong>【线型】</strong>，【<strong>框型</strong>】。比如：</p>
<ul>
<li>细直线（无向<code>---</code>），细箭头（有向<code>--&gt;</code>），粗直线（<code>===</code>），粗箭头（<code>==&gt;</code>）</li>
<li>直角框（A[内容]），圆角框（ A(内容) ），圆形框（ A((内容)) ），如下代码所示。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph LR</span><br><span class="line">A((A))--&gt;B[B]</span><br><span class="line">B--&gt;C((C))</span><br><span class="line">B---D(D)</span><br><span class="line">C===E(E)</span><br><span class="line">D==&gt;E((E))</span><br></pre></td></tr></table></figure>
<p>​ 输出的结果为：</p>
<p><img src="/2021/02/09/Typora-Markdown-Intros/mermaid3.png"></p>
<center>
Figure 11. 不同线型与框型的输出
</center>
<h4 id="flow流程图">Flow流程图</h4>
<p>​ 流程图中有五个主要结构：其书写如表所示：</p>
<table>
<thead>
<tr class="header">
<th>结构</th>
<th>书写方式</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>开始框（圆角框）</td>
<td>start</td>
</tr>
<tr class="even">
<td>输入输出框（平行四边形）</td>
<td>inputoutput</td>
</tr>
<tr class="odd">
<td>流程框（直角框）</td>
<td>operation</td>
</tr>
<tr class="even">
<td>条件判定（菱形框）</td>
<td>condition</td>
</tr>
<tr class="odd">
<td>结束框（圆角框）</td>
<td>end</td>
</tr>
</tbody>
</table>
<p>​ 一个书写示例如下图所示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">start=&gt;start: Program starts</span><br><span class="line">input=&gt;inputoutput: Input</span><br><span class="line">operation=&gt;operation: System checking</span><br><span class="line">condition=&gt;condition: System failed?</span><br><span class="line">output=&gt;inputoutput: Output</span><br><span class="line">error=&gt;operation: Error</span><br><span class="line">end=&gt;end: Shutdown</span><br><span class="line"></span><br><span class="line">start(right)-&gt;input</span><br><span class="line">input(right)-&gt;operation</span><br><span class="line">operation(right)-&gt;condition</span><br><span class="line">condition(no,right)-&gt;output</span><br><span class="line">condition(yes,bottom)-&gt;error(right)-&gt;output</span><br><span class="line">output(right)-&gt;end</span><br></pre></td></tr></table></figure>
<p>​ 对于<code>=&gt;</code>左边的部分，其实是每个框的名称，比如定义一个operation框叫做error。<code>=&gt;</code>右边则是框类型。上半部分中，所有的框被定义了，包括其类型以及内容（类型后冒号 + 空格 输入内容），下半部分则是其中的流程转换关系（<code>-&gt;</code>表示 flow的方向）</p>
<p>​ 注意 condition可多分支，所以会有(no) / (yes)标签，其他的(right / bottom)都指的是箭头的空间方向。事实上，flow只能画一些简单的流程图，复杂的流程图中各个框的位置极其难编排。输出结果如下：</p>
<p><img src="/2021/02/09/Typora-Markdown-Intros/flow.JPG"></p>
<center>
Figure 12. flow流程图输出的结果
</center>
<h4 id="gantt时间图">Gantt时间图</h4>
<p>​ 给一个例子吧，from <a href="https://blog.csdn.net/zyxhangiian123456789/article/details/102479437">[CSDN Gantt Graph]</a>。个人其实没有使用在这个的需求。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gantt</span><br><span class="line">dateformat YYYY-MM-DD</span><br><span class="line">Title The expected refining schedule</span><br><span class="line">section DS1</span><br><span class="line">Oil 3 (25,000): done, 0h, 100h</span><br><span class="line">Oil 4 (24,000): crit, 96h</span><br><span class="line">Oil 8 (24,000): crit, 176h</span><br><span class="line">section DS2</span><br><span class="line">Oil 1 (16,000): done, 0h, 48h</span><br><span class="line">Oil 2 (26,000): done, 78h</span><br><span class="line">oil 11 (82,300): crit, 246h</span><br><span class="line">section DS3</span><br><span class="line">Oil 5 (15,000): done, 0h, 60h</span><br><span class="line">Oil 4 (17,000): done, 68h</span><br><span class="line">oil 6 (18,000): done, 72h</span><br><span class="line">oil 10 (43,055): crit, 172h</span><br><span class="line">section DS4</span><br><span class="line">Oil 7 (22,000): done, 0h, 35h</span><br><span class="line">Oil 8 (103,000): active, 165h</span><br><span class="line">oil 9 (107,638): crit, 172h</span><br></pre></td></tr></table></figure>
<p><img src="/2021/02/09/Typora-Markdown-Intros/gantt.JPG"></p>
<center>
Figure 13. Gantt图绘制结果
</center>
<hr>
<h2 id="实践练习">实践练习！</h2>
<ul>
<li>一句话：尝试-&gt;熟练 就能发现word / WPS 有多难以使用。</li>
<li>读者可以尝试使用Markdown写一份笔记。要求包含：
<ul>
<li>封面的设计（比如居中 / 强制分页 / 字体变换 / 图片插入）</li>
<li>目录（toc插入 / 强制分页）</li>
<li>正文（标题 / 强调 / 分点 / 超链接 / 引用 / 表格 / 代码块(optional) / LaTeX(optional) ）</li>
</ul></li>
</ul>
<center>
<font size="5"> Amat Victoria Curam. 2021.2.10</font>
</center>
<p>​</p>
]]></content>
      <categories>
        <category>tutorial</category>
      </categories>
      <tags>
        <tag>typesetting</tag>
      </tags>
  </entry>
  <entry>
    <title>Vision Transformers</title>
    <url>/2021/11/28/Vision-Transformers/</url>
    <content><![CDATA[<h1 id="vit">ViT</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​ 去年的一个工作<a href="#refs">[1]</a>，Vision Transformer的成功带动了变形金刚在视觉邻域的应用。CNN-based的backbone可能就快败在NAS以及ViT衍生模型手下了。为了回顾transformer以及加深理解，我复现了这篇论文<a href="#refs">[2]</a>（其中的ViT-Lite以及CCT）。这个工作是对ViT进行轻型化，并且作者也提出了使用卷积加入inductive bias的方法。论文提出的网络复现起来很简单，毕竟不是什么大型网络以及复杂架构，但是要复现其结果感觉还是挺吃经验的。复现见：<a href="https://github.com/Enigmatisms/Maevit">[Github🔗:Enigmatisms/Maevit]</a></p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><img src="/2021/11/28/Vision-Transformers/train.png"></th>
<th style="text-align: center;"><img src="/2021/11/28/Vision-Transformers/test.png"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">最终（无mixup）训练集准确率（约99.8%）</td>
<td style="text-align: center;">最终（无mixup）测试集准确率（约94.5%）</td>
</tr>
</tbody>
</table>
<center>
Figure 1. CIFAR-10实验，官方实现显示的最终acc约为94.7%
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-a-few-points">II. A Few Points</h2>
<h3 id="inductive-bias">2.1 Inductive Bias</h3>
<p>​ 按照Wikipedia的定义，归纳偏置其实就是 为了处理没有见过的数据而在学习器上做的假设。</p>
<blockquote>
<p>The <strong>inductive bias</strong> (also known as <strong>learning bias</strong>) of a learning algorithm is the set of assumptions that the learner uses to predict outputs of given inputs that it has not encountered.</p>
</blockquote>
<p>​ 维基以奥卡姆剃刀原理作为了其中一个例子。事实上，奥卡姆剃刀原理这种归纳偏置实际上是 权重正则化的底层思想：模型不应该过于复杂。</p>
<blockquote>
<p>A classical example of an inductive bias is <a href="https://en.wikipedia.org/wiki/Occam&#39;s_razor">Occam's razor</a>, assuming that the simplest consistent hypothesis about the target function is actually the best. Here <em>consistent</em> means that the hypothesis of the learner yields correct outputs for all of the examples that have been given to the algorithm.</p>
</blockquote>
<p>​ ViT论文中提到：</p>
<blockquote>
<p>We note that Vision Transformer has much less image-specific inductive bias than CNNs. In CNNs, locality, two-dimensional neighborhood structure, and translation equivariance are baked into each layer throughout the whole model.</p>
</blockquote>
<p>​ 此处所说的inductive bias实际上是卷积神经网络的特性。由于卷积核每次操作都是针对某个位置领域的像素（或特征）进行运算，卷积操作也就包含了一个这样的假设：一个像素（特征）的信息一般与其周围的像素（特征）存在一定的关联性（当然，如果你非要对每个图像位置，取出其周围的像素，过MLP，然后说MLP也有这样的inductive bias，那我也没办法）。</p>
<p>​ 相比之下，Transformer看什么都具有全局眼光。Transformer 这种从NLP过来的结构，本来用于处理语句token的embeddings，语言这种东西就会存在长距离的关联关系，如果要使用卷积（比如一维卷积），可能层数得非常深才能使感受野足够大。于是，卷积层的领域信息综合这种inductive bias在transformers中是找不到的。所以说，ViT-Lite的作者希望自己能把更多传统CNN模型的inductive bias融合到ViT模型中（毕竟patch化以及插值是唯二利用率空间邻域信息的操作）实际上做的工作非常浅层：</p>
<ul>
<li>我在输入Transformer前，让生成embeddings的网络具有卷积层不就行了吗？看起来像小打小闹。</li>
</ul>
<h3 id="两篇论文的思想">2.2 两篇论文的思想</h3>
<p>​ 论文思想其实并没有什么好说的，就是Transformer模型在视觉中的应用：</p>
<div class="note danger no-icon"><p>ViT将图像进行了分块操作（patch），每个patch进行tokenize，形成了一串embeddings序列。而CVT以及CCT实际上是将tokenize的分块操作变成了卷积操作，以此引入inductive bias，CCT做得更加彻底，使得positional embeddings不是很必要（但是从我自己的复现实验上看，结论好像有点不同？）</p>
</div>
<div class="note warning no-icon"><p>Embeddings 过多个transformer layer（自注意力 + Feed forward）。当然，在embeddings输入之前，可以加positional embeddings信息。</p>
</div>
<div class="note info no-icon"><p>ViT遵循BERT的模式，输出class token进行分类。而CVT CCT使用 sequential pooling（实际上。。。就是一种注意力pooling机制，使得不定长的sequence可以输出一个单个的embeddings进行分类），相当于是隐式使用class token了。</p>
</div>
<div class="note success no-icon"><p>一层线性层完成分类。（ViT imagenet预训练时使用的MLP稍微深一丢丢）。</p>
</div>
<p>​ 值得一提的是，原论文名字叫做：An Image is Worth 16X16 Words....。可以从中看出其“patchify”过程，实际上是固定patch个数的。这使得ViT不适用于不同的数据集：</p>
<ul>
<li>CIFAR10大小只有32 * 32，那么一个patch只有四个像素，能有多少信息？不会要我上采样吧</li>
<li>MNIST更不用说了</li>
<li>ImageNet？真是谁有钱谁work啊，不是人人都能训的动image net这种贵物的。我们将这种人称之为：卡怪。ViT是一个大模型，参数很多（ViT-base效果不太可，ViT-胡歌效果才SOTA，但是胡歌（huge）版参数已经超ResNet-1001了，我没理解错的话，ResNet-1001是个千层面网络）。</li>
<li>CCT就相对轻型很多了，而且可以适用于小数据集。我自己做实验使用的就是CIFAR-10。</li>
</ul>
<hr>
<h2 id="iii.-训练tricks">III. 训练tricks</h2>
<h3 id="写在前面">3.1 写在前面</h3>
<p>​ 我自己本身很反感调参。在我看来，<strong><u>人工智能训练师</u></strong>就是初中毕业就能干的活，但不管怎么样，打不过的时候，该加入还是要加入，至少了解使自己恶心的事物到底恶心在哪，才有机会去改变吧。由于之前一直被设备以及这种恶心感限制，一直没怎么了解训练tricks，这次花了一点时间稍微涉及了一点点。</p>
<blockquote>
<p>人工智能训练师和驯兽师没有区别，训练的客体都是能力未知的对象，训练主体都不需要特别高的智力。乐观地说，人类还是有机会理解自己的创造的，但调参怪没有这个机会。悲观地说，你猜世界上有多少炼丹师是调参怪？</p>
</blockquote>
<h3 id="adamw">3.2 AdamW</h3>
<p>​ 之前在自建网络解决一个二分类问题时，遇到了很严重的过拟合。当时Google到的其中一种方案是：使用weight-decay，在优化器里直接设置即可。Weight decay 实际上就是 L2正则化（in SGD），很简单： <span class="math display">\[
\begin{align}
&amp;L_{\text{final}}=L+L_{\text{L2 Reg}}=L+\alpha\sum_{i=1}^nw_i^2\\
&amp;\frac {d L_{\text{final}}}{dw_i}=\text{grad}+2\alpha w_i\\
&amp;w_{t+1,i}=w_{t,i}-\text{lr}\times (\text{grad}+2\alpha w_i)
\end{align}
\]</span> ​ 也就是说，每一次更新，权重都会根据上一次的权重进行一定的衰减。</p>
<p>​ 至少，weight decay = L2 regularization在 SGD中成立。在一些复杂的优化器，又有momentum又有平均的的（比如Adam），weight decay实际上和L2 regularization是不一样的。</p>
<p><img src="/2021/11/28/Vision-Transformers/Adamw.png"></p>
<center>
Figure 2. AdamW以及Adam的对比<a href="#refs">[4]</a>
</center>
<blockquote>
<p>We note that common implementations of adaptive gradient algorithms, such as Adam, <strong><u>limit the potential benefit</u></strong> of weight decay regularization, because the weights do not decay multiplicatively (as would be expected for standard weight decay) but by an <strong><u>additive constant factor</u></strong>. <a href="#refs">[4]</a></p>
</blockquote>
<p>​ 这个优化器在之前的某个二分类任务中我已经用过了。关于AdamW的更多信息，可以查看<a href="#refs">[5]</a></p>
<h3 id="cosineannealingwarmrestarts">3.3 CosineAnnealingWarmRestarts</h3>
<p>​ Torch自带的cosineLR好像并不是我想要的样子，因为lr_scheduler.CosineAnnealingWarmRestarts出来的是这样的结果（下图绿色）：</p>
<p><img src="/2021/11/28/Vision-Transformers/LEC.png"></p>
<center>
Figure 3. CosineAnnealingWarmRestarts以及我自定义的学习率
</center>
<p>​ 绿色的曲线其学习率是一直在回跳到最大初始学习率，这好吗？我没有在API里找到任何关于学习率变小的设置。并且，这个学习率设置还有个这样的问题：如果设置T_mult（也就是让restart频率越来越低，cosine周期越来越长的一个因子），很难控制其在一定epochs后，学习率降到最低（一般来说，最好降到最低才是最好的）。</p>
<p>​ 所以我用LambdaLR设计了一个余弦学习率曲线，波动是为了其有一定的退火能力，而我同时希望：</p>
<ul>
<li>学习率不断减小</li>
<li>波动频率不断减小，并且在指定的epoch减到最小</li>
</ul>
<p>​ 我将这个学习率称为（xxx-Decay-Cosine-Annealing-Warm-Restart），xxx可以是线性，也可以是指数。思想很简单，学习率曲线被两条曲线夹住（不是渐近线，渐近线很难求，但是可以按照渐近线理解）。一条确定学习率最大值（可以是线性衰减或者指数衰减），另一条确定学习率下界（指数衰减），可以根据初值、终值以及epochs计算所有参数。详情见：(<a href="https://github.com/Enigmatisms/Maevit/blob/master/py/LECosineAnnealing.py">LECosineAnnealing.py</a>)</p>
<p>​ Timm (Pytorch Image Models)是个好东西，里面提供了可以衰减的CosineAnnealingWarmRestarts:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> timm.scheduler <span class="keyword">import</span> CosineLRScheduler</span><br><span class="line">lec_sch_func = CosineLRScheduler(opt, t_initial = epochs // <span class="number">2</span>, t_mul = <span class="number">1</span>, lr_min = min_max_ratio, decay_rate = <span class="number">0.1</span>, warmup_lr_init = min_max_ratio, warmup_t = <span class="number">10</span>, cycle_limit = <span class="number">2</span>, t_in_epochs = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>​ 学习率曲线是这样的：</p>
<p><img src="/2021/11/28/Vision-Transformers/lr.png"></p>
<center>
Figure 4. CosineAnnealingWarmRestarts in timm
</center>
<p>​ Restart不是瞬间的，而是线性增大的（只不过很快速）。其中涉及到这么一些概念：</p>
<ul>
<li>warmup-epoch：热身阶段。一般用于train-from-the-scratch（从头训练），开始的学习率小，是因为初始化模型时，参数随机，梯度也基本上是随机的。如果学习率太大，梯度乱飞，可能导致NaN。小学习率使得梯度稳定，开始时向正确方向移动。</li>
<li>cooldown-epoch：冷静期。学习率减小到最小时（一般是周期性学习率scheduler结束），需要冷静一下，度过一段贤者时间，以小学习率训练一段时间。</li>
</ul>
<h3 id="labelsmoothingce">3.4 LabelSmoothingCE</h3>
<p>​ 分类问题，标签是硬的。而神经网络输出，是模拟量，用模拟过程拟合离散过程存在一定难度（参考：正弦波无限叠加生成方波的吉布斯效应）。有可能在网络设计得不好时，分类很难是正确的。这个时候我们可以把硬的变成软的：</p>
<ul>
<li>Label本身转化成置信度（之前在二分类任务中用过）</li>
<li>在计算loss时进行label平滑。平滑嘛，那其目的离不开：防止过拟合，本质就是正则化手段，涨点tricks了</li>
<li>Timm已经实现了这个loss，可以直接使用</li>
</ul>
<h3 id="加速">3.5 加速</h3>
<p>​ 开始时我太笨？了？5个batch就很着急地eval一次，实际上没有必要，一次eval需要花费5-6s（CIFAR-10），那么batch size（开始时用的是64）情况下782个batch共需要eval 150多次，每个epoch训练的时间增加了10分多钟，太傻了。很显然这并不是我要说的加速。</p>
<p>​ 加速有这么几种方法：</p>
<ol type="1">
<li>混合精度：我们已经知道（在我的CUDA第二篇学习博客中），双精度 非常拉，单精度还行，要是使用float16就更快了。pytorch提供一种混合精度的方式：AMP（Automatic Mixed Precision），自动确定哪些浮点可以简化。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># From [6]</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># Creates once at the beginning of training</span></span><br><span class="line">scaler = torch.cuda.amp.GradScaler()</span><br><span class="line"><span class="keyword">for</span> data, label <span class="keyword">in</span> data_iter:</span><br><span class="line">   optimizer.zero_grad()</span><br><span class="line">   <span class="comment"># Casts operations to mixed precision</span></span><br><span class="line">   <span class="keyword">with</span> torch.cuda.amp.autocast():</span><br><span class="line">      loss = model(data)</span><br><span class="line">   <span class="comment"># Scales the loss, and calls backward()</span></span><br><span class="line">   <span class="comment"># to create scaled gradients</span></span><br><span class="line">   scaler.scale(loss).backward()</span><br><span class="line">   <span class="comment"># Unscales gradients and calls</span></span><br><span class="line">   <span class="comment"># or skips optimizer.step()</span></span><br><span class="line">   scaler.step(optimizer)</span><br><span class="line">   <span class="comment"># Updates the scale for next iteration</span></span><br><span class="line">   scaler.update()</span><br></pre></td></tr></table></figure>
<ul>
<li>当然，timm实现了更好的接口（NativeScaler），就不需要调用什么scale(loss).backward(), step之类的了：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">amp_scaler(loss, opt, clip_grad=<span class="literal">None</span>, parameters = model_parameters(model), create_graph = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>cuDNN</li>
</ol>
<p>​ 之前一直不知道这个能怎么用，反正CSDN只顾授人以鱼嘛，告诉你装吧，也不告诉你装来干啥，粪坑实锤了（越用越觉得粪坑，实力坑菜逼）。cuDNN能加速一些运算，DL中，典型的卷积运算是会被加速的，cuDNN自动benchmark卷积，找到最好的卷积实现给你用。只需：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.backends.cudnn.benchmark = <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>工人阶级的力量</li>
</ol>
<p>​ 数据集加载（Dataloader），使用多个workers。这里遇到了一些这样的问题：</p>
<ul>
<li>dataloader实际上在搞多进程，多进程默认是开子进程的（fork），但是：</li>
</ul>
<blockquote>
<p>The CUDA runtime does not support the <code>fork</code> start method; either the <code>spawn</code> or <code>forkserver</code> start method are required to use CUDA in subprocesses. ---- <a href="https://pytorch.org/docs/stable/notes/multiprocessing.html">Pytorch Document</a></p>
</blockquote>
<p>​ 如果在主进程中初始化了torch.cuda程序（先于dataloader有除了model.cuda()的别的cuda操作【？为什么model可以调cuda，难道因为它是进程间共享的？】），就会报错，说不能在fork的subprocess中初始化CUDA。解决方法确实就是，用spawn方法生成新的进程：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.multiprocessing.set_start_method(<span class="string">&#x27;spawn&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>​ spawn和fork的区别：<a href="https://stackoverflow.com/questions/64095876/multiprocessing-fork-vs-spawn">stackoverflow.com: multiprocessing fork() vs spawn()</a>。这里不多讲，spawn方式生成进程貌似炸了我的显存（<strong><u>原因可能有两点：</u></strong>1. spawn本身特性，会大量复制资源，每个新启动的python3解释进程都占用部分资源 2. 在CUDA误初始化，如果是这样的话，误初始化问题解决应该不会炸显存了）。炸显存的问题，<a href="https://blog.csdn.net/YNNAD1997/article/details/113829532">这位CSDN老哥</a>也碰到了，但他貌似没有解决。</p>
<p>​ 开始时我一直没能用成fork，都使用spawn（启动很慢，而且还炸显存）。我发现官方实现可以使用fork方式，这让我感到很奇怪，查错最后发现是：RandomErase（Dataloader数据增强的transform）默认使用了CUDA，设置device为cpu就可以解决问题了。</p>
<h3 id="mixup">3.6 Mixup</h3>
<p>​ 我超。我不知道这个工作：<a href="https://arxiv.org/abs/1710.09412">[mixup: Beyond Empirical Risk Minimization]</a>。这个工作貌似是一种终极数据增强方法。</p>
<p>​ 我超。这篇论文我看了30s之后就已经感觉有点6了，mixup就是将两个训练样本叠在一起，label可以不一样，叠加是加权的，最后形成加权的label，让网络去学。作者认为：</p>
<ul>
<li>虽然普通的数据增强确实使得训练数据增多了，但是数据增强并不是在数据的真实分布附近采样，而是加了一些随机噪声，只是增强了抗干扰能力</li>
<li>简单地说，考虑一个多峰分布，mixup可以在峰与峰之间的某个位置采样，使得label和样本在另一种意义上被平滑了。Mixup的作者说到，mixup可被理解为是：</li>
</ul>
<blockquote>
<p>A form of <strong><u>data augmentation</u></strong> that encourages the model f to behave <strong><u>linearly in-between training examples</u></strong></p>
</blockquote>
<hr>
<h2 id="iv.-复现结果">IV. 复现结果</h2>
<p>​ 我怀疑我复现结果不如官方实现的原因是我并没有使用mixup策略，我使用的是传统的数据增强。我今晚（2021-12-05）尝试了一下mixup，但貌似（可能是没有用好，也可能是才训练了100个epoch，出不了结果）很拉，mixup参数与官方实现一致，就是没有直接调用timm库生成PrefetchLoader（因为没有时间去看文档）。无mixup训练的最佳结果是：训练集acc接近1，测试集acc 94.5%，过拟合还是有点严重：</p>
<p><img src="/2021/11/28/Vision-Transformers/first.png"></p>
<center>
Figure 5. 刚开始训练（MultiStepLR，并且实现有点问题）
</center>
<p><img src="/2021/11/28/Vision-Transformers/cosine.png"></p>
<center>
Figure 6. CosineAnnealingWarmRestarts
</center>
<p><img src="/2021/11/28/Vision-Transformers/lec_lr.png"></p>
<center>
Figure 7. 自定义学习率
</center>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><img src="/2021/11/28/Vision-Transformers/train.png"></th>
<th style="text-align: center;"><img src="/2021/11/28/Vision-Transformers/test.png"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">最终（无mixup版本）训练集准确率</td>
<td style="text-align: center;">最终（无mixup版本）测试集准确率</td>
</tr>
</tbody>
</table>
<h3 id="更新">12.8 更新</h3>
<p>​ 我尝试了一下Mixup（想要脱离timm库用mixup还是有点麻烦的，比如timm中的mixup把输入转换成了numpy。。。为的就是用里面的贝塞尔分布？所以不得不写一个可以把tensor转换成对应numpy格式的函数）。用mixup会使训练时的效果明显变差，但是一取消mixup，效果就很好：</p>
<p><img src="/2021/11/28/Vision-Transformers/Screenshot%20from%202021-12-07%2019-40-38.png"></p>
<center>
Figure 8. 带mixup，最后约94%
</center>
<hr>
<h2 id="reference">Reference</h2>
<p><span id="refs"></span></p>
<p>[1] <a href="https://arxiv.org/pdf/2010.11929.pdf">Dosovitskiy A, Beyer L, Kolesnikov A, et al. An image is worth 16x16 words: Transformers for image recognition at scale[J]. arXiv preprint arXiv:2010.11929, 2020.</a></p>
<p>[2] <a href="https://arxiv.org/pdf/2104.05704.pdf">Hassani A, Walton S, Shah N, et al. Escaping the big data paradigm with compact transformers[J]. arXiv preprint arXiv:2104.05704, 2021.</a></p>
<p>[3] <a href="https://arxiv.org/abs/1706.03762">Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need[C]//Advances in neural information processing systems. 2017: 5998-6008.</a></p>
<p>[4] <a href="https://openreview.net/pdf?id=rk6qdGgCZ">Fixing Weight Decay Regularization In Adam</a></p>
<p>[5] <a href="https://www.fast.ai/2018/07/02/adam-weight-decay/">AdamW and Super-convergence is now the fastest way to train neural nets</a></p>
<p>[6] <a href="https://efficientdl.com/faster-deep-learning-in-pytorch-a-guide/#4-use-automatic-mixed-precision-amp-">Faster Deep Learning Training with PyTorch – a 2021 Guide</a></p>
<p></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>Volume2D Shader Pro</title>
    <url>/2021/08/02/Volume2D-Shader-Pro/</url>
    <content><![CDATA[<h1 id="volume2d-pro">Volume2D Pro</h1>
<hr>
<h2 id="i.-preface">I. Preface</h2>
<p>​ 觉得之前的算法太菜了，只能处理方形障碍物（虽然如果要给我的游戏用也够了），所以想着升级一下算法。近期实习刚好也做了一些类似的事情，但实习期间设计的算法很难debug（bug制造机就是我），在实习末期重新设计了一下，见Github Repo：<a href="https://github.com/Enigmatisms/Volume">[Enigmatisms/Volume]</a></p>
<video src="cv_output.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<center>
Video 1. 不规则障碍物体积光算法效果
</center>
<p>​ 不得不说，叠buff式编程真的很恶心，从实习开始到现在我都处于叠buff式编程中。</p>
<details class="note primary"><summary><p>什么叫叠buff式编程</p>
</summary>
<p>叠buff式编程指的是编写的代码不能一次性通过所有测试用例，需要一点一点测试之前没有考虑到的方面（定义来自 HQY）</p>

</details>
<span id="more"></span>
<hr>
<h2 id="ii.-算法设计简介">II. 算法设计简介</h2>
<h3 id="数据表示">2.1 数据表示</h3>
<div class="tabs" id="two-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#two-unique-name-1">Edge</a></li><li class="tab"><a href="#two-unique-name-2">Object</a></li></ul><div class="tab-content"><div class="tab-pane active" id="two-unique-name-1"><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Edge</span>: <span class="keyword">public</span> std::deque&lt;Eigen::Vector3d&gt; &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    std::pair&lt;<span class="type">int</span>, <span class="type">int</span>&gt; proj_ids;           <span class="comment">// 待投影点的id</span></span><br><span class="line">    <span class="type">double</span> min_dist = <span class="number">1e9</span>;</span><br><span class="line">    <span class="type">bool</span> valid = <span class="literal">true</span>;                      <span class="comment">// 是否完全被遮挡</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>​ Edge是一个继承了<code>std::vector&lt;Eigen::Vector3d&gt;</code>的类，除了包含vector的所有特性之外，还实现了一些方法，诸如<strong><u>旋转数组二分查找</u></strong>，带奇异性的角度判定等等。Edge实际上就是每一条参与投影的边，在Edge之上有Object来进行管理。Edge是<strong><u>不断开的，面向光源的障碍物边界部分</u></strong>。</p>
<p>​ Vector3d在此处表示的是：x，y，角度（点到观测点形成的向量，求反正切的角度）。</p></div><div class="tab-pane" id="two-unique-name-2"><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Object</span> &#123;</span><br><span class="line"><span class="keyword">using</span> HeapType = std::priority_queue&lt;<span class="type">size_t</span>, std::vector&lt;<span class="type">size_t</span>&gt;, EdgeCompFunctor&gt;;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="type">int</span> id;</span><br><span class="line">    <span class="type">bool</span> valid;</span><br><span class="line">    <span class="type">double</span> min_dist;</span><br><span class="line">    std::vector&lt;Edge&gt; edges;</span><br><span class="line">    std::pair&lt;<span class="type">double</span>, <span class="type">double</span>&gt; angle_range;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>​ Object是Edge的集合体，除了Edge之外还封装了一些附加信息，用于判定：</p>
<ul>
<li>哪些Edge先参与投影</li>
<li>哪些Edge完全被遮挡等等</li>
</ul>
<p>​ Object内部有一个Edge的堆，堆结构在Volume2D中也曾使用，本次使用了双层堆，并且堆称为了临时变量（因为调试过程中发现全局堆有些问题）。</p></div></div></div>
<h3 id="边界分割">2.2 边界分割</h3>
<p>​ 之前在做点云相关工作的时候，知道：</p>
<blockquote>
<p>LaserScan内部的点都是具有方向性的，可根据两个点形成线段的法向量判定面向激光器与背向激光器的scan</p>
</blockquote>
<p>​ 和Volume 2D一样，我也不希望太多无效的边界参与投影过程，进行“Back Culling”理论上可以减少一半的计算量（障碍物面向以及背向光源的部分正常来说各占一半）。故在做边界分割时，只保留面向光源边对应的点。</p>
<p>​ 此外由于边界是使用vector进行顺序保存的，存在以下的几种情况需要考虑：</p>
<p><img src="/2021/08/02/Volume2D-Shader-Pro/cases.PNG"></p>
<center>
Figure 1. 三种不同的情况
</center>
<div class="tabs" id="fourth-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#fourth-unique-name-1">最简单的情形</a></li><li class="tab"><a href="#fourth-unique-name-2">循环添加1</a></li><li class="tab"><a href="#fourth-unique-name-3">循环添加2</a></li></ul><div class="tab-content"><div class="tab-pane active" id="fourth-unique-name-1"><p>​ 最简单的显然就是：需要添加的边从front()或者中间位置开始，最多需要添加到back()处的点。这种情况下可以直接遍历添加，无需下标循环。</p></div><div class="tab-pane" id="fourth-unique-name-2"><p>​ 第二种情况在开始撰写代码时考虑到了，觉得可能会有这种需要从front()到back()循环连接的情况。所以一开始设计Edge类就使用了双端队列（真的号用）。因为已知：同一个Object上由于中间有不可视（背向光源）的段，可能会将一条完整的边界分割为若干段面向光源的edges，那：front()处加入的点留在对应的edge种，而back()对应的edges则需要反向加入到front()对应edge的头部。也就像这样：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (Edge::const_reverse_iterator rit = to_add.<span class="built_in">crbegin</span>(); rit != to_add.<span class="built_in">crend</span>(); rit++)</span><br><span class="line">	front.<span class="built_in">push_front</span>(*rit);</span><br></pre></td></tr></table></figure></div><div class="tab-pane" id="fourth-unique-name-3"><p>​ 第三种情况开始没有考虑到（不周啊），头部只有一个点加入。我的逻辑是不会保存孤立点的（形成Edge至少要两个点），而如果front()确实应该加入，但遍历时，front()联系的边都是背向边，那么可能会错误地丢弃front()。最后是多加入了几个判断才完成这部分。</p></div></div></div>
<h3 id="内外投影">2.3 内外投影</h3>
<h4 id="内外投影简介">2.3.1 内外投影简介</h4>
<p>​ 已知，我的算法对于Edge的管理基于类Object，其逻辑是：</p>
<ul>
<li>内投影：首先选择离光源最近的物体，计算该物体内部的遮挡（内部的形状复杂时）</li>
<li>外投影：此物体如何影响别的物体，如何判定遮挡关系</li>
</ul>
<p>​ 为什么要区分内外投影呢？内投影与外投影有什么关系呢？在我最初的构想中，区别挺大的，但仔细思考后发现，内外都会有如下的情况发生：</p>
<p><img src="/2021/08/02/Volume2D-Shader-Pro/proj.PNG" style="zoom:67%;"></p>
<center>
Figure 2. 两种内部遮挡情况
</center>
<p>​ 尤其是第一种，开始时我认为第一种情况是不会出在内投影的情况中的，我开始认为：内部不会有切分一条边为两条的情况。（我对应的切分函数<code>breakEdge</code>开始是给外部投影实现的），但事实上是，都有可能。</p>
<h4 id="两个设计">2.3.2 两个设计</h4>
<h5 id="proj_ids">proj_ids</h5>
<p>​ proj_ids是每一个Edge都携带的结构，是一个<code>std::pair&lt;int, int&gt;</code>。使用这个pair可以快速查找，此edge有哪些是需要参与后续内外投影的点。示意图如下：</p>
<p><img src="/2021/08/02/Volume2D-Shader-Pro/examples.PNG"></p>
<center>
Figure 3. proj_ids 使用
</center>
<p>​ 图中蓝色点是投影形成的点，在判断外部遮挡时，显然应该由外侧点（意味着范围更大）来进行投影（也就是红色点）。也就是说，蓝色点只保存，不参与后续的投影，但是红色点与后续投影有很大的关系。蓝色点不参与计算可以减少部分计算负担。</p>
<h5 id="eigenvector3d">Eigen::Vector3d</h5>
<p>​ 为什么不好好地使用Eigen::Vector2d，反倒要使用Vector3d，保存一个角度？首先我对问题做了一个这样的假设：</p>
<blockquote>
<p>我们的每一个edge，上面每一个点的角度（相对于观测点的反正切角度）都不同，并且由于做了背面剔除，在非奇异（atan函数角度从<span class="math inline">\(-\pi\)</span>到<span class="math inline">\(\pi\)</span>的奇异跃迁）情况下，是一个按角度递增的数组。存在奇异的情况下，是一个旋转数组，front()必然大于back()</p>
</blockquote>
<p>​ 顺序化或者旋转顺序化的数据结构可以使用二分查找或是旋转数组二分查找，在障碍物表面特别不平（比如激光点云）时，可以显著加快交点搜索速度。此处我们使用旋转数组二分查找，查找投影关系：</p>
<ul>
<li>主投影边src上的点，如何投影到被投影边dst上，src的front() / back() 角度对应到dst的哪两个点之间？</li>
<li>使用这两个点以及已知的src投影光线，进行交点计算</li>
</ul>
<h4 id="主要函数-projedge2edge">2.3.2 主要函数 projEdge2Edge</h4>
<p>​ <code>projEdge2Edge</code>是用于投影的主要函数，此函数适用于内外投影。其主要逻辑是：</p>
<div class="note info"><p>首先规定：主投影边（产生遮挡的边）为src，dst则为被遮挡的边。一般来说，主投影边的min_dist（内部点到光源的最小距离）会比dst的min_dist更小，但是也有例外。见下图。</p>
</div>
<center>
<img src="/2021/08/02/Volume2D-Shader-Pro/special.PNG" style="zoom:50%;">
</center>
<center>
Figure 4. 按照最小距离建立堆产生的问题
</center>
<p>​ 上图首先选中更长的边（蓝色线连接的长边），因为最小距离长边对应最小（观测点选得好就会这样）。那么场边会先于两个实际上应该判定为更近的小障碍物进行投影，这样就会出现问题。比如：</p>
<p><img src="/2021/08/02/Volume2D-Shader-Pro/Screenshot from 2021-08-02 02-13-46.png" style="zoom:60%;"></p>
<center>
Figure 5. 边异常消失问题
</center>
<p>​ 可能原因是，由于开始的实现是：只要dst在src的角度范围内（角度上完全覆盖），那么dst就会被设为valid = false（完全覆盖不需要再投影）。但是如果src选错，就会出现如上问题。</p>
<p>​ 本函数的逻辑为：</p>
<ul>
<li>首先判定src可用投影点数为（proj_ids中有多少个大于等于0者），如果有两个，可能出现breakEdge的情况（投影产生新的Edge）</li>
<li>如果只有一个可用点，需要判定（实际逻辑比下面简介的复杂得多，因为情况太多了）：
<ul>
<li>src / dst首尾两点到观测点的连线夹角是否小于90度？不小于则可能是反方向的障碍物，不应该参与</li>
<li>判定src是否完全覆盖dst。为了避免atan角度奇异性，这里使用了基于内积的相对判定方法。具体实现不讲了。</li>
<li>如果可能存在完全覆盖，需要反向筛查（查找dst首尾两点会被src内部那两对点“夹住”），如果存在这样的点对，才能认为是完全覆盖的。</li>
</ul></li>
<li>根据计算结果求解交点（省略了很多逻辑，不想讲，逻辑太复杂了，包括奇异处理，裕量处理，一些意想不到的情况）</li>
</ul>
<h4 id="交点求解">2.4 交点求解</h4>
<p>​ 求解两对点对应的两条直线的交点，只需要一些数学上的处理。首先我们知道，不能使用斜截式，因为 <strong><u>在本问题中，可能存在斜率无穷大的直线，导致病态</u></strong>。而另一方面，我们知道线段上一点可以使用线段的法向量表示：</p>
<blockquote>
<p>直线上一点(x, y)到直线上已知一点<span class="math inline">\((x_0,y_0)\)</span>的向量会垂直于法向量</p>
</blockquote>
<p>​ 那么由此，交点可以列两个方程。假设光线发射点为<span class="math inline">\((x_0, y_0)\)</span>，交点位置为<span class="math inline">\((x,y)\)</span>，障碍物的edges对应两点为<span class="math inline">\((x_1,y_1),(x_2,y_2)\)</span>，光线的方向向量为<span class="math inline">\((v_x,v_y)\)</span>那么有： <span class="math display">\[
\begin{align}
&amp; (u_x,u_y)=(x_1-x_2,y_1-y_2) \\
&amp; (-v_y,v_x)\cdot(x-x_0,y-y_0)=0\tag{eq 1}\\
&amp; (-u_y,u_x)\cdot(x-x_1,y-y_1)=0\tag{eq 2}
\end{align}
\]</span> ​ 由(eq 1), (eq 2)组成两个方程，可以解出<span class="math inline">\((x, y)\)</span>，只需判定对应齐次方程系数矩阵行列式是否很小（不可逆），如果不可逆，直接返回被投影点更近的那个点，如果可逆，那么解出的<span class="math inline">\((x,y)\)</span>就是结果。</p>
<h4 id="其他">2.5 其他</h4>
<p>​ 还有很多！逻辑是真的很复杂，情况很多，我不想写这个，要一一解释太麻烦了。</p>
<hr>
<h2 id="iii.-效果一览">III. 效果一览</h2>
<video src="cv_output.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<center>
Video 1. 不规则障碍物体积光算法效果
</center>
<video src="cv_output2.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<center>
Video 2. 更多障碍物下的表现
</center>
<p>​ 边界计算结果使用截图的方式记录了一下：</p>
<p><img src="/2021/08/02/Volume2D-Shader-Pro/Screenshot%20from%202021-08-02%2016-49-37.png"></p>
<center>
Figure 6. 边界计算（demo1），图中绿色点是观测点，黄色是计算最后需要绘制的边
</center>
<p><img src="/2021/08/02/Volume2D-Shader-Pro/Screenshot%20from%202021-08-02%2016-50-01.png"></p>
<center>
Figure 7. 边界计算（demo2），图中绿色点是观测点，黄色是计算最后需要绘制的边
</center>
<hr>
<h2 id="iv.-库的使用">IV. 库的使用</h2>
<p>​ 本项目已经上传至Github，见Github库<a href="https://github.com/Enigmatisms/Volume">[Enigmatisms/Volume]</a>，里面有非常详细的说明，不过是英文的。怎么说呢，关于这个问题，我想到了一个绝妙的解决办法，可惜今晚很困，写不完（老费马了）。如果有细节方面的疑问，欢迎直接联系我。</p>
<hr>
<h3 id="reference">Reference</h3>
<p>​ 关于<code>EdgeCompFunctor</code>这个还是有必要说一下的：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">EdgeCompFunctor</span>&#123;</span><br><span class="line">    <span class="built_in">EdgeCompFunctor</span>(<span class="type">const</span> std::vector&lt;Edge&gt;&amp; _egs): <span class="built_in">egs</span>(_egs) &#123;&#125;</span><br><span class="line">    <span class="type">const</span> std::vector&lt;Edge&gt;&amp; egs;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">operator</span><span class="params">()</span> <span class="params">(<span class="type">const</span> <span class="type">size_t</span>&amp; e1, <span class="type">const</span> <span class="type">size_t</span>&amp; e2)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> egs[e1].min_dist &gt; egs[e2].min_dist;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>​ std::priority_queue接收一个自定义的比较函数，由于C++高版本的匿名函数特性很不错，一般都使用匿名函数来填充这个自定义比较函数，但也可以使用较为老式的Functor写法。而此处，我更改了在Volume2D算法中使用的“保存Edge*”的实现，因为已知保存在堆中的指针没有办法正确指向vector。原因我哥已经帮我解释了：</p>
<blockquote>
<ul>
<li>因为vector的内部存储的地址是会变的</li>
<li>比如resize的时候 它会构造一个新的数组 把原来的数据复制进去 然后销毁之前的数组 这样地址就变了</li>
<li>如果直接存指针 是会失效的</li>
</ul>
</blockquote>
<p>​ 这种携带了一个常引用，初始化EdgeCompFunctor时需要传入edges这个vector常应用的写法来自于<a href="https://stackoverflow.com/questions/8372918/c-std-list-sort-with-custom-comparator-that-depends-on-an-member-variable-for">[stackoverflow/C++ std list sort with custom comparator that depends on an member variable for the object instance]</a>。显然，保存索引比保存指针优雅多了。</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>algos</tag>
      </tags>
  </entry>
  <entry>
    <title>【笔记】两篇双目相关论文</title>
    <url>/2021/09/04/%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%A4%E7%AF%87%E5%8F%8C%E7%9B%AE%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/</url>
    <content><![CDATA[<h1 id="stereo">Stereo!</h1>
<hr>
<p>​ 最开始的时候，我在人机所的工作是搞双目开发，但是当时还完全不懂深度学习，觉得这就是个玄学玩意（事实上我现在还是这么觉得，只不过有些简单的网络，具有很好的理论解释，我觉得还挺妙的）。但是当年（也就是2020）的KITTI榜就已经被深度学习刷爆了啊，前100目测98个非传统方法。现在我对深度学习有了一定了解，也有了很多实践的经验，所以想着挑战一些更难的问题领域，一些不一样的应用场景（毕竟老研究奇奇怪怪的网络结构，复现不同的CV基础网络结构就跟调参一点区别没有）。</p>
<p>​ 本文没有任何附带的实现，我只把这两篇CVPR2021论文只作为回归双目研究的起始“研读性”文章，不尝试复现，或者咱们不找借口，我之后理解得更透彻再来复现😝。</p>
<span id="more"></span>
<hr>
<h2 id="ii.-a-decomposition-model-for-stereo-matching1">II. <strong>A Decomposition Model for Stereo Matching</strong>[1]</h2>
<p>​ 加速了。作者能加速10-100倍，并且把复杂度降得很低，使用的思想我之前思考过，但是我之前并不知道怎么做，只是有个类似的想法：</p>
<div class="note primary"><p>​ 如果我只需要在一个较小的图像上进行双目匹配（下采样图像），在上采样的过程中使用另一个网络进行refine，只需要对部分像素进行refine，是不是能提速？</p>
</div>
<p>​ 产生这个想法的原因很简单，之前在尝试孙剑老师的“上古”论文（BP）时，对于无纹理区域的匹配效果不太好。大面积无纹理区域在下采样图像中就应该被解决。</p>
<h3 id="主要思想">2.1 主要思想</h3>
<p>​ 首先把网络总结构放一下：</p>
<p><img src="/2021/09/04/%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%A4%E7%AF%87%E5%8F%8C%E7%9B%AE%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/arch.PNG"></p>
<center>
Figure 2. Decomposition model 网络架构
</center>
<p>​ 读完还是觉得这篇文章里有些<strong><u>很魔法</u></strong>的东西，但是也有很不错的思想。文章的方法主要可以分为以下四步：</p>
<div class="note danger"><ol type="1">
<li>最底层使用full cost volume（可以认为是双目匹配里面的内存暴力法）以及cost regularization（文中使用了一个如Figure 3所示的网络，对cost volume又重新映射了一边）。文章称cost regularization的作用是“rectify cost volume”，但是我半天没看明白这和rectify的关系（双目就有rectification操作，难不成是用Conv3d做了一个深度rectification？）。在这样固定大小的左右视图上进行full cost volume匹配的开销是完全可以接受的。</li>
</ol>
</div>
<div class="note warning"><ol start="2" type="1">
<li>【稀疏的【损失细节】】检测。也就是使用一个无监督的网络，输入是：特征金字塔上一层（经过下采样的一层）的特征图的上采样结果，和特征金字塔本层特征图。无监督地学出可能因为下采样操作而丢失的特征（对应的position）。无监督学习，就是nice。</li>
</ol>
</div>
<div class="note info"><ol start="3" type="1">
<li>稀疏匹配。既然在上一步操作中，我们已经清楚有些地方就是没有匹配好，那么这一步我可以对那些没有匹配好的【损失细节】进行稀疏的匹配。由于稀疏匹配对应的特征们分布不规则并且大小不固定，使用cost volume搜索对应的方法是不好的。论文使用了一种agreement思想，使用cross correlation（相当于找到最大“卷积”响应点），转换结果为softmax，再求期望，这个想法不错。</li>
</ol>
</div>
<div class="note success"><ol start="4" type="1">
<li>视差融合。也就是稀疏视差图融合到稠密视差图上的操作。这个操作又分为两步：</li>
</ol>
<ul>
<li>视差图上采样。要把上一层视差金字塔的结果用上我总要上采样吧，但是做固定上采样不好玩，我们来搞一个CARAFE[2] ，一种更骚的上采样方法，具有【content-aware】能力，很玄乎吧，这个还好。最玄乎的是它做了一个大concatenation（我很讨厌无端的concat操作，把不相关的信息拼接在一起会让信息失去其原有的物理意义，这是个人粗浅的见解，会在稍后进行说明），对concat的结果进行了几次卷积，得到一个mask（也就是content-aware的权重），通过这个pixel-wise的权重将上一层上采样视差和本层融合。</li>
</ul>
</div>
<p><img src="/2021/09/04/%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%A4%E7%AF%87%E5%8F%8C%E7%9B%AE%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/conv3d.PNG"></p>
<center>
Figure 3. cost regularization
</center>
<h3 id="gradient-flow">2.2 Gradient Flow</h3>
<p>​ 我们需要考虑梯度流的问题，也就是说：我到底需要优化谁？我的loss最终作用在哪些单元？在没有看附录之前，就应该思考这样的问题。</p>
<p>​ 首先我们发现，这篇文章不是pixel2pixel的匹配，而是特征到特征的匹配（可能深度学习上了就是这样的），特征提取在文章中说的是：</p>
<blockquote>
<p>As shown in Figure 2, we first use <strong><u>U-Net</u></strong> to obtain deep features Fl on each level l for the stereo matching.</p>
</blockquote>
<p>​ 我当时反应了一下，之前读过一篇做风格迁移的文章（对应博客<a href="https://enigmatisms.github.io/2021/04/21/CNN-Style-Transfer论文复现/">【CNN Style Transfer论文复现】</a>，截止到9.5我都还没有填坑），文章直接使用了一个预训练好的VGG-19，固定参数不优化，提取特征。本文是这样吗？并不是，特征提取网络是需要进行优化的。那么与loss直接相关的待优化参数最后除了特征提取网络之外，还有什么吗？</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><img src="/2021/09/04/%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%A4%E7%AF%87%E5%8F%8C%E7%9B%AE%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/part1.PNG"></th>
<th style="text-align: center;"><img src="/2021/09/04/%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%A4%E7%AF%87%E5%8F%8C%E7%9B%AE%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/part2.PNG"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">步骤II</td>
<td style="text-align: center;">步骤I</td>
</tr>
</tbody>
</table>
<p>​ 这两个步骤虽然在网络中，但是其参数并不直接根据整个架构对应的输出以及loss进行优化。毕竟：</p>
<ul>
<li>步骤II对应的操作是自监督的，应该完全可以独立训练</li>
<li>步骤I也是可以独立的（看实现），假如使用的方法是独立于输入的传统cost volume法，那完全可以。否则的话可能会收到U-Net输出的影响，内部的参数也需要参与优化。</li>
</ul>
<p>​ 在附录中，作者主要讨论的是U-Net生成的特征图作为自变量时的求导。</p>
<h3 id="一些问题">2.3 一些问题</h3>
<h4 id="detailed-loss-detection">2.3.1 Detailed Loss Detection</h4>
<p>​ 无监督的loss听起来很棒，但是我总感觉作者用学习的方式解决了一个NP-hard的问题（应该是NP-hard），我甚至有点怀疑可行性（虽然我在RM灯条检测里面也这么干过）。</p>
<p>​ 如果需要人工标注lost detail mask的话，那工作量太大了，作者希望使用这样一个无监督loss，使得两个集合的差异最大：<strong><u>属于lost detail的特征点集合（A） 与 不属于前一个集合的特征点集合（B）</u></strong>（是一个覆盖）</p>
<p>​ 差异体现在：集合A的平均特征误差应该较大（低精度上采样后无法恢复的区域），集合B的平均特征误差小。那么作者使用了这个loss： <span class="math display">\[
\begin{equation}\label{dld}
\mathcal{L}^{DLD}=|FA_l|-\alpha\frac{\sum_{(h,w)\in FA_l}\Vert F_l(h, w)-F_{l-1}&#39;(h,w)\Vert_2}{\vert FA_l \vert}
\end{equation}
\]</span> ​ 其中<span class="math inline">\(FA_l\)</span>为特征金字塔第l层的fine-grained（细粒度）特征，<span class="math inline">\(F_{l-1}&#39;\)</span>则是上采样的上一层特征。这个式子非常容易理解，但是... 从一个集合中挑选一个子集使得对于这个集合和子集定义的某个损失最小，感觉就是一个NP-hard的问题，毕竟暴力穷举之外貌似没有别的方法。并且，在这里优化问题遇到的是 <u><strong>分支的处理</strong></u>，我优化的是一个决策？（应不应该认为这个特征属于<span class="math inline">\(FA_l\)</span>），我记得好像TF由于是静态图的缘故不方便设置分支？另一方面，我又觉得解决方案可能类似分类问题，输出是模拟的，但是计算cross entropy loss的时候转换成了long型（硬的）的index。</p>
<h4 id="sparse-matching">2.3.2 Sparse Matching</h4>
<p>​ 这个想法我觉得还挺不错的。我得到左右视图的lost details，现在要进行匹配了。由于occlusion存在一定一致性（并且由于存在对极约束），还是可以将lost details在一个方向左右滑动。那么对于这样的：两个信号滑动求最大匹配的问题，显然可以使用cross correlation。作者由此产生了一个三维空间的概率volume（注意不是分布，因为这是按照第三个维度也就是disparity归一化的）。 <span class="math display">\[
\begin{align}
&amp; P_l(h,w,d)=\frac{e^{C_l(h,w,d)-C_l^{max}(h,w)}}{\sum_{d=0}e^{C_l(h,w,d)-C_l^{max}(h,w)}}\\
&amp; C_l(h,w,d)=\text{cross correlation}(F_{\text{left}}(h,w),F_{\text{right}}(h,w-d))\\
&amp; C_l^{max}(h,w)=\max_d C_l(h,w,d)
\end{align}
\]</span> ​ 最后，每个稀疏点的视差就由期望决定了（作者为什么把这个叫做regress？） <span class="math display">\[
\begin{equation}\label{reg}
\hat{D}_l(h,w)=\sum_{d=0}P_l(h,w,d)\times d
\end{equation}
\]</span></p>
<h4 id="supervised-loss">2.3.3 Supervised Loss</h4>
<p>​ 简单地提一下论文使用的有监督loss。无监督loss在lost detail detection阶段使用了，用于判定哪些是丢失细节，见公式<span class="math inline">\(\eqref{dld}\)</span>。而计算视差图的过程中，我们有特征提取网络，Fusion网络，底层full cost volume对应的网络需要训练，这些都是基于disparity真值训练的。</p>
<p>​ 多层的disparity就需要用到多层的真值，那么多层真值可以使用降采样来得到。然后作者使用了一系列的smooth L1 Loss。好玄乎哦，实际上就是Huber Loss。</p>
<hr>
<h2 id="iii.-smd-nets-stereo-mixture-density-networks3">III. SMD-Nets: Stereo Mixture Density Networks[3]</h2>
<p>​ 个人认为这篇文章没有那么魔法，读起来觉得还挺有道理的。最主要的思想就是：使用双模态描述结果。之前读的对比学习相关的文章，里面就提到过不同的模态数的优缺点：</p>
<ul>
<li>单模态：计算十分方便，建模简单，并且也具有广泛的应用范围，但表征能力有限。</li>
<li>完全生成式模型（终极多模态）：表征能力极其强，但是计算量一般都很大（比如对抗网络）</li>
<li>模态数少一些的多模表征：折衷。</li>
</ul>
<p>​ 本文使用双模态描述前景和背景，并且网络结构 / 输入不那么魔法，也具有一定的超分辨率能力（虽然感觉方法有点普通？）。</p>
<p><img src="/2021/09/04/%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%A4%E7%AF%87%E5%8F%8C%E7%9B%AE%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/smd.PNG"></p>
<center>
Figure 4. SMD-Nets的网络结构
</center>
<h3 id="主要思想-1">3.1 主要思想</h3>
<p>​ 主要可以分为以下三步：</p>
<p><span id="quest"></span></p>
<div class="note danger"><ol type="1">
<li>前端使用了一个经典的双目视觉网络作为骨架，用于提取特征。就如Figure 4最左边，先下采样再上采样的典型结构（常用于Semantic/Detection/Mono/Stereo）。我不是特别了解这个网络提取出来的特征是否与原输入图像保持了空间一致性，虽然卷积可能可以做到这一点，但具体是如何保证的【一个特定区域】对应的【特征图元素】一定在特征图对应的位置上？而且看起来，深度学习的引入产生了很多特征-特征匹配的方法。</li>
</ol>
</div>
<p></p>
<div class="note warning"><ol start="2" type="1">
<li>超分辨率：插值操作，插值操作只是为了能够得到任意精度位置的特征向量。个人对于第二步的理解是，作者对于每一个点都计算了双模态分布的参数，形成了一个双模态分布的二维结构（图像）。对每一个特征向量，都过一遍MLP，最后得到五个参数:</li>
</ol>
<ul>
<li><span class="math inline">\((\mu_1,b_1),(\mu_2,b_2)\)</span>是分布的均值（期望）与不确定度</li>
<li><span class="math inline">\(\pi\)</span>是两个模态的选择参数（相当于前景背景mask）</li>
</ul>
</div>
<div class="note info"><ol start="3" type="1">
<li>输出：根据模态选择参数，从两个模态中的均值中选择对应的视差值。</li>
</ol>
</div>
<h3 id="some-points">3.2 Some points</h3>
<p>​ 这篇论文我倒是没有什么特别想说的，感觉想法倒是挺简单的（简单不代表我能一下想到）。虽然我个人存在一些疑问，感觉作者也没有解释清楚（要怪就怪神经网络不可解释？）：</p>
<ul>
<li>前景(foreground)与背景(background)的区别在哪？disparity明显很大的叫foreground（虽然我感觉作者就是叫着玩的）？作者更被没有说两个mode的生成方式有何不同。为什么能恰好产生这种，在关键区域有互补性的两个模态呢？又为什么只使用两个模态呢？</li>
<li>当然，这确实可以用不可解释性来说。毕竟像<span class="math inline">\(\pi\)</span>这种学出来的东西，真的就说不清楚其深层次的原理...</li>
</ul>
<p>​ 另外，我不知道别的网络是否进行稠密的训练，本文中，网络并不进行稠密的disparity训练（可以说是半稠密？）。首先对生成好的特征图进行采样，对采样得到的（稍微稀疏一些）点进行训练。由于作者需要更多地聚焦于边缘点的处理，所以作者使用了一种不同的采样方法：</p>
<ul>
<li>生成边缘点mask，具体的方式也就是：首先检测深度不连续点（根据4-连通性），对检测结果进行膨胀
<ul>
<li>在边缘点mask内采样一半的稀疏训练点样本</li>
</ul></li>
<li>在全图的非边缘点区域进行均匀的采样，采样得到另一半样本。</li>
</ul>
<p>​ 整个框架是有监督的，并且没有金字塔结构。其使用的backbone模型，PSM内部也是有一个大的cost volume的。</p>
<hr>
<h2 id="iv.-dl立体匹配">IV. DL立体匹配</h2>
<p>​ 深度学习用在立体匹配中？知道能用，但是具体的实现是什么样的呢？基于特征向量的匹配的流程具体是什么呢？完全不知道了。所以我在这里补充一篇综述性论文[4]，帮自己补一补领域知识。只不过，这篇文章包含了很多方法，我在此只讨论基础的DL-based方法。</p>
<h3 id="pipeline">4.1 Pipeline</h3>
<p>​ 主要流程仍然大体相同：</p>
<p><img src="/2021/09/04/%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%A4%E7%AF%87%E5%8F%8C%E7%9B%AE%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/flow.PNG"></p>
<center>
Figure 5. 双目配准网络一般的流程
</center>
<p>​ 那么典型的几个网络结构，论文也贴心地列了出来（这篇论文真的很适合入门了解行业啊）：</p>
<p><img src="/2021/09/04/%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%A4%E7%AF%87%E5%8F%8C%E7%9B%AE%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/nets.PNG"></p>
<center>
Figure 6. 双目配准网络的一些典型结构
</center>
<p>​ 视差图生成网络的训练输入可以通过采样而来，也可以通过直接卷积而来。</p>
<ul>
<li>采样的方法是：在输入图像中均匀“播撒”一些点（对应于一种稀疏的训练方式），切取点以及其领域的信息作为对应视图的输入。如果是有监督的结构，那么就在另一个视图中查找：
<ul>
<li>disparity图真值对应位置的patch（作为正样本）</li>
<li>其他disparity值对应的patch作为负样本</li>
</ul></li>
<li>直接卷积：每个点对应的卷积输出就已经是特征了。但是这种方法如何保证左右特征一致？一种简单的想法就是直接共用完全相同的encoder（孪生网络）。</li>
<li>当然也可以直接跳过特征描述，直接端到端生成一个cost出来</li>
</ul>
<p>​ 这种基于DL特征的描述，实际上是对人工描述子的升级，卷积操作对每个点都会有个特异的表征输出，假设我们的卷积就是奇数大小的kernel并且以其中心为anchor，那么在(x,y)位置的卷积显然就会得到以(x,y)为中心的领域特征描述，能保证<a href="#quest">[3.1中(1)里提出问题的解决]</a>。这一环节，我们的目的不是只得到特征（然后神奇海螺：什么也不做），而是使用特征来衡量两个像素位置是否存在关系，比如使用L1或者L2距离来判定特征的相似度，越相似说明两个位置匹配度越高。</p>
<p>​ 根据loss函数可以计算出一个cost volume，为了方便起见，我只讨论3D cost volume。3D cost volume每一个(x, y)位置都对应了一串可能匹配的cost，我们需要根据我们选定的策略来计算一个最好的disparity。方法有很多。我确实是开了眼了，学到了，见下一小节。</p>
<h3 id="cost-volume-regularization">4.2 Cost Volume Regularization</h3>
<p>​ 有了cost volume之后，紧接着就要进行<strong><u>cost volume regularization</u></strong>。但是这是个什么操作，与regularization又是什么关系？</p>
<p>​ 我们知道，正则化（regularization）在深度学习中是被用来防止过拟合的，因为引入正则化惩罚之后，原本起伏不平的超平面，会变得平滑。这是因为正则化项要么限制了描述超平面的参数个数，要么限制了其取值，使之描述力下降（不那么活跃）。也就可以认为，正则化项<span class="math inline">\(\approx\)</span>平滑项。</p>
<p>​ 巧了，双目视觉通常也有平滑项（虽然我感觉SMD-Nets一定程度上在鄙视平滑假设）。我们希望网络的输出不要那么起伏不平的，一个深度差不多的平面就不要因为噪声而有太大的小范围波动了吧。所以需要施加平滑项，当然还存在一些其他的约束项，比如：</p>
<ul>
<li>(x, y)已知与(x+d, y)完美配上了，那么(x+1, y) 对应的视差必定不可能小于d-1（右视图匹配不交叉）</li>
<li>保证深度不连续边缘锐利性的一些约束项</li>
</ul>
<p>​ 那么施加约束项/平滑项就是在做正则化！目的就是优化输出图像，所以叫regularization。一般来说，cost volume regularization伴随最终视差图的产生，这是因为regularization之后，full cost就求出来了啊。当然是选full cost最小的。故可以将cost volume regularization看作是视差图求解。</p>
<p>​ <img src="/2021/09/04/%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%A4%E7%AF%87%E5%8F%8C%E7%9B%AE%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/agg.PNG"></p>
<center>
Figure 7. 最终disparity的计算
</center>
<p>​ 论文贴心地把几种常用的regularization方法可视化了出来：</p>
<ul>
<li>滢者通吃！（误，在这里简单地cue一下我的女朋友）。谁小选谁。</li>
<li>考虑空域特性：2D卷积，综合空域信息。</li>
<li>考虑不同的disparity上的信息：基于RNN的正则化</li>
<li>3D卷积：全域正则化（这个结构在两篇论文的regularization中都有）</li>
</ul>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] Yao C, Jia Y, Di H, et al. A Decomposition Model for Stereo Matching[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 6091-6100.</p>
<p>[2] Wang. Carafe: Content-aware reassembly of features. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), 2019</p>
<p>[3] Tosi F, Liao Y, Schmitt C, et al. SMD-Nets: Stereo Mixture Density Networks[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 8942-8952.</p>
<p>[4] Laga H, Jospin L V, Boussaid F, et al. A survey on deep learning techniques for stereo-based depth estimation[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2020.</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>stereo</tag>
      </tags>
  </entry>
  <entry>
    <title>优雅线代与美妙优化</title>
    <url>/2021/04/03/%E4%BC%98%E9%9B%85%E7%BA%BF%E4%BB%A3%E4%B8%8E%E7%BE%8E%E5%A6%99%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h1 id="矩阵分析-优化">矩阵分析 &amp; 优化</h1>
<p>​ 最近接触了一些有趣的 机器学习 / 控制算法，其中的数学原理非常有意思，大多数都涉及到了矩阵分解以及线性代数解析解的求取。推导这些理论可以帮助深入理解矩阵分解（以及分解后子矩阵的数学意义）以及 矩阵分析和优化理论的数学联系，这些理论都非常优雅而且美妙。</p>
<p><img src="/2021/04/03/%E4%BC%98%E9%9B%85%E7%BA%BF%E4%BB%A3%E4%B8%8E%E7%BE%8E%E5%A6%99%E4%BC%98%E5%8C%96/decomp.jpg"></p>
<center>
Figure 1. 矩阵分解的真谛：图为 上三角分解
</center>
<p>​ 本文将包括以下四个部分：</p>
<ul>
<li>卡尔曼滤波的最小二乘解释</li>
<li>最小二乘的几何解释</li>
<li>谱聚类的矩阵分析</li>
<li>PCA的矩阵分析</li>
</ul>
<span id="more"></span>
<hr>
<h2 id="kf最小二乘解释">KF最小二乘解释</h2>
<p>​ Kalman Filter，作为一种“最小二乘”滤波器，其应用极其广泛。个人使用KF设计过：</p>
<ul>
<li>目标跟踪算法（Adaptive Robust KF）<a href="https://github.com/Enigmatisms/Algorithms-Plus/tree/master/cpp/KF">[Github🔗：Algorithm_Plus/KF]</a></li>
<li>语音信号处理（白噪声滤波）：<a href="https://github.com/Enigmatisms/AudioDSP">[Github🔗: AudioDSP]</a></li>
</ul>
<p>​ 虽然说，KF是“最小二乘”的迭代式滤波器，但自己从来没有里结果其中的数学原理，也即：<strong>(1) 最小二乘最优性是如何得到的</strong>？<strong>(2)为什么KF是迭代式的</strong>？而关于KF的深入分析（包括参数整定，自适应化，收敛性谈，将会在另一篇博文中细讲<a href="https://enigmatisms.github.io/2021/03/07/%E5%8D%A1%E5%B0%94%E6%9B%BC%E8%BF%9B%E9%98%B6%E4%B8%8E%E7%B2%92%E5%AD%90%E6%BB%A4%E6%B3%A2%E5%AE%9E%E7%8E%B0/">【卡尔曼进阶与粒子滤波实现】</a>）。</p>
<h3 id="kf最小二乘性">KF最小二乘性</h3>
<p>​ 我们将最为一般的KF迭代公式重写如下（实际上个人认为实现KF最难的地方就是记公式）： <span class="math display">\[
\begin{align}
&amp; \breve{x}(k)=A\hat{x}(k-1)+Bu(k)+w(k) \label{transit}\\
&amp; \breve{P}(k)=A\hat{P}(k-1)A^T+Q       \label{covup}\\
&amp; z(k)=H\breve{x}(k)+v(k) \label{obs}\\
&amp; K=\breve{P}(k)H^T(H\breve{P}(k)H^T+R)^{-1}\label{gain}\\
&amp; \hat{x}(k)=\breve{x}(k)+K(z(k)-H\breve{x}(k)) \label{xcor}\\
&amp; \hat{P}(k)=\breve{P}(k)-KH\breve{P}(k)\label{covcor}
\end{align}
\]</span> ​ 其中，“<span class="math inline">\(\breve{ }\)</span>”表示先验，“<span class="math inline">\(\hat{ }\)</span>”表示后验。也就是说：</p>
<table>
<thead>
<tr class="header">
<th>先验（前两行）</th>
<th>后验（前两行）</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\breve{x}(k)\)</span> 迭代k的状态（先验均值）</td>
<td><span class="math inline">\(\hat{x}\)</span>(k) 后验均值</td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\breve{P}\)</span>(k) 状态k的协方差（先验协方差）</td>
<td><span class="math inline">\(\hat{P}\)</span>(k) 后验协方差</td>
<td></td>
</tr>
<tr class="odd">
<td>Q 状态转移噪声协方差</td>
<td>R 观测噪声协方差</td>
<td></td>
</tr>
<tr class="even">
<td>A 状态转移矩阵，H观测矩阵</td>
<td>B 控制矩阵 <span class="math inline">\(u(k)\)</span>系统控制量（外界输入）</td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(w(k),v(k)\)</span> 噪声（一般讨论白噪声）</td>
<td>K 卡尔曼增益</td>
<td></td>
</tr>
</tbody>
</table>
<p>​ 光看这个迭代式根本不知道为什么KF会得出最小二乘最优来，在《概率机器人》一书上，作者使用的是概率分布的转移以及推导来看待KF的迭代优化过程，并没有从最小二乘的角度看待这个问题。下面我们尝试从最小二乘角度来分析KF。</p>
<p>​ 考虑一个拟合问题，拟合曲线时，数据点都是给定的（而且一般有噪声）。个人认为这是个平滑问题（因为使用者有unlimited access to all the data【随便写段英文】），根据<a href="https://www.intechopen.com/books/smoothing-filtering-and-prediction-estimating-the-past-present-and-future">Smoothing, Filtering and Prediction</a>所说，平滑 / 滤波 / 预测是针对三个不同的时间点：处理过去的数据（已经接收并且存储），处理当下的数据（比如确定更准确的测量值），处理未来的可能数据（预测）。而KF的一种常用领域-控制，是有实时性要求的，要求至少需要达到【滤波】的标准，最好能进行【预测】。而一般的拟合，基本都是一次性计算所有的点，所以着导致了一般的拟合问题 <strong><u>不是增量性的（也即有新的数据点，需要全部重新计算，比如loss与梯度）</u></strong>。</p>
<p>​ KF显然并不是这样的，KF需要实时更新，并且不能依赖太久远的历史信息（低阶的马尔可夫性）。KF的预测输出期望能与观测贴合（但这也不完全一定，由于观测是存在一定的噪声的）。根据论文"<strong><em>Robust Estimation with Unknown Noise Statistics</em></strong>"，我们可以把KF问题重写成如下形式： <span class="math display">\[
\begin{equation}\label{optim}
\begin{pmatrix}
I\\
H
\end{pmatrix}\breve{x}(k)=
\begin{pmatrix}
A\hat{x}(k-1)\\
z(k)
\end{pmatrix} +
\begin{pmatrix}
w(k)\\
v(k)
\end{pmatrix}=
\begin{pmatrix}
A\hat{x}(k-1)\\
z(k)
\end{pmatrix} + E(k)
\end{equation}
\]</span></p>
<p>​ 假设我们求解噪声矩阵<span class="math inline">\(E(k)\)</span>的协方差，那么它应该是这样的： <span class="math display">\[
\begin{equation}\label{ecov}
\mathbb{E}(E(k)E(k)^T)=\begin{pmatrix}
\breve{P}(k) &amp; \mathbf{0}   \\
\mathbf{0} &amp; R(k)
\end{pmatrix}
\end{equation}
\]</span></p>
<p>​ 协方差为什么长成这样呢？很显然：<span class="math inline">\(w(x)\)</span>自己的协方差就是状态转移协方差（注意不是噪声协方差Q，因为Q需要进行状态转移），而<span class="math inline">\(v(x)\)</span>的协方差是噪声协方差。而<span class="math inline">\(w(x),v(x)\)</span>默认是相互独立的，故非对角线矩阵块为0。接下来，对这个协方差进行矩阵分解： <span class="math display">\[
\begin{equation}
Cholesky(\mathbb{E}(E(k)E(k)^T))=SS^T
\end{equation}
\]</span></p>
<p>​ 此后所做的事情有点奇怪，矩阵<span class="math inline">\(S\)</span>被单独使用了（协方差矩阵的矩阵LU分解代表了什么意义？）。实际上，这里是要使linear transform之后的噪声协方差为单位阵（也就是说，此处做了一个白化变换）。我们看公式<span class="math inline">\(\eqref{optim}\)</span>，<span class="math inline">\(E(k)\)</span>是系统的噪声，而系统高斯噪声并不为单位阵，问题并非标准问题，也可以说是：输入没有进行标准化。那么对于<span class="math inline">\(\eqref{optim}\)</span>而言，等号左右乘以<span class="math inline">\(S^{-1}\)</span>实际上就是在做白化变换： <span class="math display">\[
\begin{align}
&amp;S^{-1}\begin{pmatrix}
I\\
H
\end{pmatrix}\breve{x}(k)=
S^{-1}\begin{pmatrix}
A\hat{x}(k-1)\\
z(k)
\end{pmatrix} +
S^{-1}\begin{pmatrix}
w(k)\\
v(k)
\end{pmatrix}=
S^{-1}\begin{pmatrix}
A\hat{x}(k-1)\\
z(k)
\end{pmatrix} + S^{-1}E(k)\label{optim2}
\end{align}
\]</span></p>
<p><span class="math display">\[
\begin{equation}\label{lsp}
X(k){x}(k)+\xi(k)=Y(k)
\end{equation}
\]</span></p>
<p>​ 这就是个标准的最小二乘问题，由于此处<span class="math inline">\(\mathbb{E}\{\xi(k)\xi(k)^T\}\)</span>是单位阵。有没有发现此处我们已经不写<span class="math inline">\(\breve{x}\)</span>了？虽然从推导式<span class="math inline">\(\eqref{optim}\)</span>来说，此处确实应该是先验<span class="math inline">\(\breve{x}\)</span>，但是此问题的解（由于涉及到本次观测<span class="math inline">\(z(k)\)</span>进行的后验修正）已经是后验了，那么可以根据pseudo逆理论求得<span class="math inline">\(x(k)\)</span>的解： <span class="math display">\[
\begin{align}
&amp;\hat{x}(k)=\mathop{\text{arg min}}_{x}\Vert Y(k)-X(k)x(k)\Vert^2 \\
&amp;x^*(k)=(X^T(k)X(k))^{-1}X^T(k)Y(k)\label{optim3}
\end{align}
\]</span> ​ 从而得到了后验估计。这就是KF的优化表达式，而我们能从中推出KF的迭代性质吗？</p>
<h3 id="kf迭代性质">KF迭代性质</h3>
<p>​ 分析不难得到如下关系： <span class="math display">\[
\begin{equation}
X^T(k)X(k)=
(I\quad H^T)(S^{-1})^T(S^{-1})
\begin{pmatrix}
I\\
H
\end{pmatrix}=(I\quad H^T)(SS^T)^{-1}
\begin{pmatrix}
I\\
H
\end{pmatrix}
\end{equation}
\]</span></p>
<p>​ 而<span class="math inline">\(SS^T\)</span>是公式<span class="math inline">\(\eqref{ecov}\)</span>中的协方差矩阵，那么可以进一步得到： <span class="math display">\[
\begin{equation}
X^T(k)X(k)=
(I\quad H)
\begin{pmatrix}
P^{-1}(k) &amp; \mathbf{0} \\
\mathbf{0} &amp; R^{-1}(k)
\end{pmatrix}
\begin{pmatrix}
I\\
H
\end{pmatrix}
\end{equation}
\]</span></p>
<p>​ 展开以上式子可以得到： <span class="math display">\[
\begin{equation}
(X^T(k)X(k))^{-1}=(P^{-1}+H^TR^{-1}H)^{-1}=P+H^{-1}R(H^{-1})^{T}
\end{equation}
\]</span></p>
<p>​ 诶，只需要顺着这样的分解下去，不难发现（真的不难，所以费篇幅在这推公式了），优化结果<span class="math inline">\(\eqref{optim3}\)</span>与之前的后验更新式<span class="math inline">\(\eqref{xcor}\)</span>是完全一致的。而协方差的先验后验更新实际上是类似的，这里就不再详细推导了。妙啊兄弟们，这样我们就推出了最小二乘与KF的关系。</p>
<hr>
<h2 id="最小二乘的几何解释">最小二乘的几何解释</h2>
<p>​ 上DIP（数字图像处理）的时候，老师突然抛出一个问题来：</p>
<p>​ <img src="/2021/04/03/%E4%BC%98%E9%9B%85%E7%BA%BF%E4%BB%A3%E4%B8%8E%E7%BE%8E%E5%A6%99%E4%BC%98%E5%8C%96/proj.JPG"></p>
<center>
Figure 2. 观测 误差 与真值的空间表示
</center>
<div class="note default"><p>​ 为什么说，观测平面需要和误差正交？（也就是说观测平面的法向量和误差的方向是重合的？）</p>
</div>
<p>​ 惊讶，竟然没有人说上来为什么（可能大家都比较谦虚吧）。</p>
<p>​ 从几何<strong>直观</strong>上非常好理解为什么。显然，观测<span class="math inline">\(\hat{x}\)</span>是由真值的投影<span class="math inline">\(\breve{x}\)</span>与误差<span class="math inline">\(e\)</span>投影的结合，而如果投影平面（观测面）正好与误差是正交的，那么误差的投影将会是0。而在最小二乘意义下，误差的平均投影长度是最小的。</p>
<p><img src="/2021/04/03/%E4%BC%98%E9%9B%85%E7%BA%BF%E4%BB%A3%E4%B8%8E%E7%BE%8E%E5%A6%99%E4%BC%98%E5%8C%96/err.JPG"></p>
<center>
Figure 3. 误差投影 投影后影响观测（实际观测是绿色 + 紫色）
</center>
<p>​ 那么要求最优的投影面，实际上是要优化这个问题： <span class="math display">\[
\begin{equation}\label{f17}
\left\{
\begin{array}{ll}
\text{min }\Vert \pmb{e}-(\pmb{a}^T\pmb{e})\pmb{a}\Vert^2\\
\text{s.t. }\pmb{a}^T\pmb{a}=1
\end{array}
\right.
\end{equation}
\]</span></p>
<p>​ 什么意思？意思就是，假设<span class="math inline">\(\pmb{a}\)</span>是投影平面的单位法向量，那么<span class="math inline">\(\pmb{a}^T\pmb{e}\)</span>就是误差在单位法向量上的投影，而<span class="math inline">\(\pmb{e}-(\pmb{a}^T\pmb{e})\pmb{a}\)</span>就是误差在观测平面上的投影。需要使得这个投影最短。</p>
<p>​ 那么解这个问题，实际上最后会求出：需要对误差的协方差<span class="math inline">\(\pmb{e}\pmb{e}^T=\Sigma\)</span>进行矩阵分解，求最大特征值对应的特征向量，就是<span class="math inline">\(\pmb{a}\)</span>。而这个特征向量实际上对应了误差的主方向（PCA部分中会提到这个思想），如果只有一个观测的话，则就是误差的方向。至于为什么，<strong><u>很简单</u></strong>，公式<span class="math inline">\(\eqref{f17}\)</span>留给读者作为练习。</p>
<hr>
<h2 id="谱聚类矩阵分析">谱聚类矩阵分析</h2>
<p>​ 谱聚类（spectrum clustering）是一种很美妙的聚类理论，它包含了<strong><u>图论</u></strong>， <strong><u>矩阵分析</u></strong>，<strong><u>优化理论</u></strong>以及<strong><u>机器学习理论</u></strong>，综合性的一个算法，理解这个算法可以帮助对以上四个方面的理论都有进一步的认识。</p>
<h3 id="laplace算子">Laplace算子</h3>
<p>​ 这是我DIP课程中刚讲的空域滤波器kernel，虽然之前就知道Laplace长什么样，但是从来没有从DSP的角度去思考，也没有思考其数学原理。Laplace算子用 <strong><u>求二阶导</u></strong>，这是为什么呢？小编也不知道，小编也觉得很有趣。一个典型的Laplace kernel长这样： <span class="math display">\[
\begin{equation}
\begin{pmatrix}
0 &amp; -1 &amp; 0 \\
-1 &amp; 4 &amp; -1 \\
0 &amp; -1 &amp; 0
\end{pmatrix}
\end{equation}
\]</span></p>
<p>​ 从DSP的角度考虑Laplace算子的设计，这也就是一个高通滤波器嘛（求边缘使用），而对于直流分量这种显然是低频的信号成分来说，它是要被高通滤波器滤除的。于是高通滤波器不能保留任何直流的能量，需要保证对于平滑区域（比如ones），卷积结果为0。而图分析（graph）中，对于离散的图而言也有Laplace算子，并且其物理意义非常明确：<strong><u>求图上的最小割</u></strong>。首先推一下离散的二阶导，使用一个简单的一阶导表达式： <span class="math display">\[
\begin{equation}\label{de_1}
\frac{df}{dx}=f&#39;(x)=f(x)-f(x-1)
\end{equation}
\]</span></p>
<p>​ 而需要求二阶导，也就需要在本函数的基础上再求一阶导： <span class="math display">\[
\begin{equation}\label{de_2}
\frac{d^2f}{dx^2}=f&#39;&#39;(x)=f&#39;(x)-f&#39;(x-1)=f(x)-2f(x-1)+f(x-2)
\end{equation}
\]</span></p>
<p>​ 接下来分析无向带权图上的Laplace矩阵。</p>
<p>​ 首先定义<span class="math inline">\(W\)</span>为权重矩阵（无向带权图的邻接矩阵，注意<span class="math inline">\(w_{i,i}=0\)</span>），<span class="math inline">\(W\)</span>就刻画了节点之间的联系程度（或者cost）。在聚类问题中，我们设定，假设两个样本点之间的关系越紧密，特征越类似，对应节点之间的边权也就越大。那么聚类实际上就是在这样的图上寻找一个最小割（最小权的边集合），使得经过这个cut之后可以分为k个指定类。</p>
<p>​ 此外，定义<span class="math inline">\(D\)</span>为度矩阵，与普通的度定义不同（这个度是有权的），<span class="math inline">\(D\)</span>为对角矩阵，元素<span class="math inline">\(d_{i,j}\)</span>的意义是： <span class="math display">\[
\begin{equation}
d_{i,j}=\left\{
\begin{array}{l}
\sum_{j=1}^nw(i,j),\text{ if }i=j \\
0,\text{ otherwise}
\end{array}
\right.{}
\end{equation}
\]</span></p>
<p>​ D衡量的实际是一个节点与其他所有节点的联系紧密程度。则有了这两个矩阵，我们接下来定义<span class="math inline">\(L=D-W\)</span></p>
<p>​ 也就是度矩阵减去邻接矩阵，看起来非常抽象？直接看L是难以得到其物理意义的，需要有其他向量的帮助</p>
<h5 id="性质1-向量差异">性质1 向量“差异”</h5>
<p><span class="math display">\[
\begin{equation}
\text{Given vector }x,\text{ }Lx=
\begin{pmatrix}
\sum_{j\neq1}w_{1j} &amp; -w_{12} &amp; ... &amp; -w_{1n}\\
-w_{21} &amp; \sum_{j\neq2}w_{2j} &amp; ... &amp; -w_{2n}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
-w_{n1} &amp; -w_{n,2} &amp; ... &amp; \sum_{j\neq n}w_{nj}
\end{pmatrix}
\begin{pmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{pmatrix}
\end{equation}
\]</span></p>
<p>​ 将上式展开可以得到： <span class="math display">\[
\begin{equation}\label{diff1}
\begin{pmatrix}
\sum_{j\neq1}w_{1j} &amp; -w_{12} &amp; ... &amp; -w_{1n}\\
-w_{21} &amp; \sum_{j\neq2}w_{2j} &amp; ... &amp; -w_{2n}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
-w_{n1} &amp; -w_{n,2} &amp; ... &amp; \sum_{j\neq n}w_{nj}
\end{pmatrix}
\begin{pmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{pmatrix}=
\begin{pmatrix}
\sum_{j\neq 1}w_{1j}(x_1-x_j)\\
\sum_{j\neq 1}w_{2j}(x_1-x_j)\\
\vdots\\
\sum_{j\neq 1}w_{nj}(x_n-x_j)\\
\end{pmatrix}
\end{equation}
\]</span></p>
<p>​ 证明就是暴力展开。可以发现一个x时，对x做线性变换实际上求了x各个元素之间的差异。</p>
<h5 id="性质2-标量输出">性质2 标量输出</h5>
<p><span class="math display">\[
\begin{equation}\label{diff2}
x^TLx=\sum_{i=1}^n\sum_{j=1}^nw_{ij}(x_i-x_j)^2
\end{equation}
\]</span></p>
<p>​ 根据矩阵乘法，对公式<span class="math inline">\(\eqref{diff1}\)</span>进行左乘x操作再展开很容易就能得到。此处，<span class="math inline">\(x^TLx\)</span>的意义实际上就是：根据每个节点的关联关系 <strong><u>加权</u></strong> 的向量内部差异。但是这个向量<span class="math inline">\(x\)</span>到底是什么？</p>
<h5 id="向量x意义的讨论">向量x意义的讨论</h5>
<p>​ 我们讨论问题的背景是聚类，聚类中除了每对节点之间的特征差异之外，最显著的差异就是 <strong><u>聚类对应的类别差异</u></strong>了。那么x恰好可以作为一个指示向量，给定一个k=2簇的聚类问题，设： <span class="math display">\[
\begin{equation}\label{indicate}
x_i=\left\{
\begin{array}{ll}
1, \text{ if }\pmb{x}\in\mathbb{C}_1\\
-1,\text{ if }\pmb{x}\in\mathbb{C}_2
\end{array}
\right.
\end{equation}
\]</span></p>
<p>​ 那么<span class="math inline">\(Lx\)</span>实际上就是不同节点之间label的差异，比如两个点为同一个簇，则<span class="math inline">\(Lx\)</span>对应分量为0，否则为一个非0的值（正数）。现在要找一种方式割开这个点集（也就是找一个x），使得两个类之间的联系是最小的。那么实际上，切开两类的割对应的值就是两类之间被丢弃的（割开）类间联系，实际可以对应于<span class="math inline">\(x^TLx\)</span>。在不同的formulation下，<span class="math inline">\(x\)</span>可以有不同形式，但是其意义基本一致：割。</p>
<p>​ k=2时，完全可以使用一个向量进行运算（<span class="math inline">\(\pm1\)</span>），而涉及到多类时，可能<span class="math inline">\(x\)</span>就会是一个矩阵了（因为不存在一种赋值方式使得任意两类不同的结点的cost相减是相同的，举个例子：0为A，1为B，2为C，虽然AB，BC之间相差1，但是AC之间差2）。</p>
<h4 id="二类cut">二类Cut</h4>
<p>​ k=2聚类直接使用如<span class="math inline">\(\eqref{indicate}\)</span>所定义的向量x即可。</p>
<div class="note info"><p><strong>说了这么久矩阵分析，还没正经地开始分析呢。</strong></p>
<p>可以看一下<span class="math inline">\(x^TLx\)</span>的取值范围应该是什么？与矩阵L的特征值有什么关系？</p>
</div>
<p>​ 由于矩阵的特征向量是相互正交的，它们实际上张成了一个与x所在线性空间等价的一个空间。从而可以知道，由于x存在于特征向量张成的线性空间中，x可在以特征向量为基时被特征向量的线性组合表示： <span class="math display">\[
\begin{equation}
x^TLx=(\sum_{i=1}^na_i\pmb{v}_i)^TL(\sum_{i=1}^na_i\pmb{v}_i),\text{ where }\pmb{v}_i\text{ is the eigen vec of }L
\end{equation}
\]</span></p>
<p>​ 由于特征向量的定义，那么上式实际上就等于： <span class="math display">\[
\begin{equation}
x^TLx=\sum_{i=1}^na_i^2\lambda_i,\text{ where }\lambda_i\text{ is the eigen value of }L
\end{equation}
\]</span></p>
<p>​ <span class="math inline">\(x^TLx\)</span>中的x并非是没有约束的，在二分类问题中，x是正负1的向量，而<span class="math inline">\(\pmb{v}_i\)</span>为归一化之后的特征向量，故<span class="math inline">\(a_i\)</span>的最大值不可能小于<span class="math inline">\(1/\sqrt{n}\)</span>，既然如此，设<span class="math inline">\(\max(a_i)=a_m\)</span>，<span class="math inline">\(a_m\)</span>必然会作用到其中一个特征值上。那么可以发现，如果要求最小的话，显然让<span class="math inline">\(a_m\)</span>作用到最小特征值上就可以让<span class="math inline">\(x^TLx\)</span>等价地最小。那么求第j小也就相当于使用第j小特征值，那么对应的解向量也就是<span class="math inline">\(v_{\text{min jth}}\)</span>。其实特征值最大最小性在之前就已经提过：</p>
<p>​ 最大化类间方差时，就需要使用到协方差矩阵最大特征值对应的特征向量。而求平面 / 线段的normal时，就需要使用到最小特征值，不过这里的最小特征值可以有两种方法解释，以求线段的法线为例：</p>
<ul>
<li>最小二乘得到线段的最优估计过程也就等价得到了法线的最优估计，那么最小二乘问题本身对应着最小特征值 以及其对应的特征向量</li>
<li>以矩阵特征向量的方向性来说，线段对应的方向向量就是最大特征值对应的特征向量（元素主方向），而与之正交的（次要方向，特征向量也是相互正交的，就跟方向向量与法线向量正交一样）法向量就是最小特征值对应的特征向量。</li>
</ul>
<p>​ 那么此处需要选择最小的几个特征向量作为“割”。取多少个（k）特征向量，相当于割出多少个簇，相当于割上k-1次，每一次可以得到新的簇。比如，举个例子： <span class="math display">\[
\begin{equation}
\begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; \sqrt{\frac{1}{2}} &amp; \sqrt{\frac{1}{2}} &amp; 0 \\
0 &amp; -\sqrt{\frac{1}{2}} &amp; \sqrt{\frac{1}{2}} &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{pmatrix}
\end{equation}
\]</span></p>
<p>​ 这是四个特征向量，已经按照从左到右特征值逐渐减小的顺序排列了。假设我们最终需要得到簇k = 3，那么可以知道需要选择两个最小特征值对应的特征向量进行cut。</p>
<ul>
<li>首先自然选取的是最后一个，这说的意义是：需要把最后一个结点单独割开，其他的结点暂时不管。</li>
<li>倒数第二个特征向量，两个正数，说明第二，第三个点是同一类的，割为一类。那么最后得到：<span class="math inline">\(\{1,\{2,3\},4\}\)</span></li>
</ul>
<hr>
<h2 id="pca矩阵分析">PCA矩阵分析</h2>
<h3 id="直观理解">直观理解</h3>
<p>​ 仿佛在之前从来没有认真想过，PCA为什么要选取k个最大特征值对应的特征向量进行降维？之前对于PCA的理解只是停留在：</p>
<div class="note warning"><p>​ 矩阵分解可以得到其主方向，主方向的保留可以保留矩阵的更多信息。</p>
</div>
<p>​ 但是这只是直观上的理解，“信息”保留的多少并没有得到数学上的推导，只能算作对PCA理论的通俗理解。所以PCA为什么要选取最大k个特征值对应的特征向量？</p>
<p>​ 首先，PCA分解的是什么？经过【去中心化】【标准差归一化的】数据，数据在经过如上的白化处理之后，需要进行<span class="math inline">\(\pmb{x}\pmb{x}^T\)</span>操作，得到其协方差矩阵，维度 d * d，d为特征空间的维数，降维实际上就是要组合特征。那么协方差矩阵<span class="math inline">\(\Sigma\)</span>有什么特殊之处？ <span class="math display">\[
\begin{equation}\label{svd}
\text{SVD}(\Sigma)=USU^T
\end{equation}
\]</span></p>
<p>​ 直接进行SVD分解，由于<span class="math inline">\(\Sigma\)</span>的对称性，可以得到如公式<span class="math inline">\(\eqref{svd}\)</span>所示的分解式，其中S是对角矩阵。如果说其他矩阵的分解结果没有那么直观的物理意义的话，PCA则完全不一样。对协方差的矩阵分解有非常清晰的物理意义：<span class="math inline">\(S\)</span>是“标准”的协方差，也就是在没有经过旋转的方差。可以给一个简单的高斯函数的例子。</p>
<p><img src="/2021/04/03/%E4%BC%98%E9%9B%85%E7%BA%BF%E4%BB%A3%E4%B8%8E%E7%BE%8E%E5%A6%99%E4%BC%98%E5%8C%96/gauss.JPG"></p>
<center>
Figure 4. 独立情况下的协方差与一般协方差 高斯
</center>
<p>​ 而<span class="math inline">\(U\)</span>的意义则是：对方差进行旋转。那么也就是说，分解得到了：独立时的协方差矩阵<span class="math inline">\(S\)</span>以及协方差矩阵<span class="math inline">\(S\)</span>如何旋转得到当前的<span class="math inline">\(\Sigma\)</span>。而恰好，<span class="math inline">\(S\)</span>对角元素对应了特征值。特征值大等价于独立时的方差大，而<span class="math inline">\(U\)</span>特征向量则是：<strong><u>对于d个特征的线性组合向量</u></strong>（比如<span class="math inline">\((1\;\;3\;-2)^T\)</span>，其意义就是新的组合特征：一份特征一 加 三份特征二再减去两份的特征三），在对应特征向量也就是独立情况下，按照特征向量组合的特征在这个空间下的方差就是特征值。</p>
<hr>
<h3 id="特征分量差异期望最大">特征分量差异期望最大</h3>
<p>​ 那么我们希望投影之后，数据之间还能有比较好的区分度（如果全部投影到一个点上了，那么就说明投影后的大部分信息都损失了），于是要选择方差大的方向投影。可以这样具体地看：对于一个特征（特征空间的一个分量），假设有两个样本<span class="math inline">\(\pmb{x}_1\)</span>与<span class="math inline">\(\pmb{x}_2\)</span>，样本(1 * d)在经过一个一维的线性变换之后变成了一个标量（也就是求新特征的一个维度，综合（线性组合）原来所有维度的信息），设为<span class="math inline">\(z_1,z_2\)</span>，那么为了使得任意两个样本产生的新特征差异期望尽可能大 <span class="math display">\[
\begin{align}
&amp;z_1=F^T\pmb{x}_1\\
&amp;z_2=F^T\pmb{x}_2\\
&amp;\text{max } \mathbb E((z_1-z_2)^2)=\mathbb E(F^T(\pmb{x}_1-\pmb{x}_2)(\pmb{x}_1-\pmb{x}_2)^TF)\label{obj}\\
&amp;\text{s.t. }\Vert F\Vert=1
\end{align}
\]</span></p>
<p>​ 由于F是确定性的变换，所以实际只需要对内部的<span class="math inline">\((\pmb{x}_1-\pmb{x}_2)((\pmb{x}_1-\pmb{x}_2))^T\)</span>进行期望求取即可，可知这个实际上就是协方差矩阵<span class="math inline">\(\Sigma\)</span>。那么公式<span class="math inline">\(\eqref{obj}\)</span>实际上变成了下式（注意F有约束） <span class="math display">\[
\begin{equation}
\text{max } \mathbb{E}(F^T\Sigma F)
\end{equation}
\]</span></p>
<p>​ 也就是求这个二次型（标量结果）的最大。由特征向量构成等价线性空间基的性质以及特征值存在一定取值范围，可知差异最大就是要选取最大的特征值。也就是说，选取前k个最大的特征值是完全能够保证新特征在特征空间下，样本间两两差异的期望最大。</p>
<p>​ 啊，其实这个解释多么接近正确答案啊。我在4.17晚上复习LDA的时候，突然想到了如何正确地从数学角度而非直观角度解释为什么需要选择最大特征值对应的特征向量。LDA中（可见于博文<a href="https://enigmatisms.github.io/2021/03/02/%E7%BA%BF%E6%80%A7-%E6%A0%91%E5%9E%8B%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%BA%AF%E7%90%86%E8%AE%BA%E5%88%86%E6%9E%90/">[线性/树型分类器的纯理论分析]</a>），LDA巧妙变换了类间方差和类内方差的表示形式。而PCA中，实际上也是相求方差最大！并且还是<strong><u>类内方差</u></strong>，因为我们希望降维后的数据能够有最好的区分度，保留的信息量最大，也就对应着方差最大，个体差异大代表了丰富性。假设降维到1维，也即需要寻找一个线性组合向量<span class="math inline">\(w_{k\times 1}\)</span>，使得投影后（线性组合后）的特征向量<span class="math inline">\(y=w^T\pmb{x}_{k\times 1}\)</span>方差最大，也即： <span class="math display">\[
\begin{equation}\label{max2}
\text{max }\sum^{n}(y_i-\overline y)^2\rightarrow \text{max }\sum^{n}(w^T\pmb{x}_i-w^T\overline {\pmb{x}})^2
\end{equation}
\]</span></p>
<p>​ 那么把非随机变量<span class="math inline">\(w\)</span>提出来有： <span class="math display">\[
\begin{align}
\label{max3}
&amp;\text{max }\sum^{n}(y_i-\overline y)^2\rightarrow \text{max }\sum^{n}w^T(\pmb{x}_i-\overline {\pmb{x}})(\pmb{x}_i-\overline {\pmb{x}})^Tw\rightarrow \\
&amp;\text{max }w^T\sum^{n}(\pmb{x}_i-\overline {\pmb{x}})(\pmb{x}_i-\overline {\pmb{x}})^Tw
\end{align}
\]</span></p>
<p>​ 像LDA一样，把<span class="math inline">\(\sum^{n}(\pmb{x}_i-\overline {\pmb{x}})(\pmb{x}_i-\overline {\pmb{x}})^T\)</span>设为类内散度矩阵<span class="math inline">\(S_w\)</span>，其意义就是对原空间下方差的一种度量。这样我们可以求<span class="math inline">\(\eqref{max3}\)</span>定义的最大化问题了，但是还有个小小的问题：<span class="math inline">\(w\)</span>的模长可以无限大，导致<span class="math inline">\(\eqref{max3}\)</span>无限大。那么我们只需要限定<span class="math inline">\(w\)</span>是单位向量，模长为1即可（实际上，这恰好符合之后矩阵分解<span class="math inline">\(w\)</span>为特征向量的特性）： <span class="math display">\[
\begin{equation}\label{max4}
\text{max }w^TS_bw\\
\text{s.t. } \Vert w\Vert=1
\end{equation}
\]</span></p>
<p>​ 则根据Lagrange乘子，可以写为： <span class="math display">\[
\begin{equation}\label{lag}
\text{max }w^TS_bw - \lambda (w^Tw-1)\\
\end{equation}
\]</span></p>
<p>​ KKT条件，对<span class="math inline">\(w\)</span>求导，使用分子布局（结果转置，那分子布局和分母布局没有什么不同）： <span class="math display">\[
\begin{equation}\label{res}
S_bw=\lambda w
\end{equation}
\]</span></p>
<p>​ 也就是说，<span class="math inline">\(w\)</span>为一个特征向量（我们的线性组合是个特征向量，<span class="math inline">\(S_b\)</span>的特征向量，<strong><u><span class="math inline">\(S_b\)</span>恰好是原来样本的协方差矩阵</u></strong>）。而根据<span class="math inline">\(\eqref{res}\)</span>，等式左右左乘以<span class="math inline">\(w^T\)</span>，得到：<span class="math inline">\(w^TS_bw=\lambda w^Tw\)</span>，根据<span class="math inline">\(w^Tw=1\)</span>，可知，<span class="math inline">\(w^TS_bw=\lambda\)</span>。又由于需要让<span class="math inline">\(w^TS_bw\)</span>最大，那么<span class="math inline">\(\lambda\)</span>作为特征值需要选择最大的。在多维的情况下，最大的被选走了，就按照特征值大小排序，依次选取次大的特征值对应的特征向量即可。</p>
<p>​ 这样就可以明白，为什么PCA要选择最大的特征值对应的特征向量作为降维组合方式了。很可惜的是，在<span class="math inline">\(\eqref{obj}\)</span>式分析时，并没有这样去思考，但是原来的想法已经非常接近这个我认为最有解释力的答案了。</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title>位姿变换与六轴仿真</title>
    <url>/2021/10/31/%E4%BD%8D%E5%A7%BF%E5%8F%98%E6%8D%A2%E4%B8%8E%E5%85%AD%E8%BD%B4%E4%BB%BF%E7%9C%9F/</url>
    <content><![CDATA[<h1 id="axis6">Axis6</h1>
<hr>
<p>​ 稚晖君牛逼。看了他的六轴机器人之后，我感觉自己没学过自动化。为了证明自己是自动化专业的学生，我尝试学习以及手推了一下正逆运动学公式，手写了一个六轴机器人的控制、仿真（rviz以及Gazebo: for those who doesn't know how to pronounce: <code>ɡəˈziːboʊ</code>，重音在前），代码放在了<a href="https://github.com/Enigmatisms/Axis6">[Github🔗:Enigmatisms/Axis6]</a>。本文包含如下内容：</p>
<ul>
<li>位姿变换/正逆运动学的一些基本知识</li>
<li>Gazebo的配置使用</li>
<li>仿真效果视频（<del>高清无码</del>）</li>
</ul>
<p>​ 这里放两张图：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><img src="/2021/10/31/%E4%BD%8D%E5%A7%BF%E5%8F%98%E6%8D%A2%E4%B8%8E%E5%85%AD%E8%BD%B4%E4%BB%BF%E7%9C%9F/rviz.png" style="zoom:85%;"></th>
<th style="text-align: center;"><img src="/2021/10/31/%E4%BD%8D%E5%A7%BF%E5%8F%98%E6%8D%A2%E4%B8%8E%E5%85%AD%E8%BD%B4%E4%BB%BF%E7%9C%9F/gazebo.png"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">rviz仿真结果</td>
<td style="text-align: center;">Gazebo仿真结果</td>
</tr>
</tbody>
</table>
<center>
Figure 1. 仿真效果图
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-前置知识">II. 前置知识</h2>
<h3 id="位姿变换左右乘">2.1 位姿变换左右乘</h3>
<p>​ 这个问题个人之前一直没有搞清楚，也没有静下心来推过。</p>
<p>​ 给定空间中一个点p以及一个位姿变换<span class="math inline">\(T=[R\quad t]\)</span>（非齐次），点p经过位姿变换的结果应该是： <span class="math display">\[
\begin{equation}\label{basic}
p&#39;=Rp+t
\end{equation}
\]</span> ​ 那么现在有这样一个问题，如果我想对点p进行多次变换？或者是进行一次<strong><u>两个位姿变换合成</u></strong>对应的变换？应该怎么做？假设我们有两个位姿变换：<span class="math inline">\(T_1 = [R_1\quad t_1]\)</span>以及<span class="math inline">\(T_2 = [R_2\quad t_2]\)</span>，乍一看应该这么做： <span class="math display">\[
\begin{equation}\label{composite}
p&#39;=R_2(R_1p+t_1)+t_2=R_2R_1p+R_2t_1+t_2
\end{equation}
\]</span> ​ 上面这个公式，思想非常直白。不是要多次变换吗？不是要合成吗？那就直接先变换一次，再对结果变换一次就行了。但是<strong><u>实际上，对于位姿变换合成问题而言，这是错的结果</u></strong>。首先，我在这里给出结论： <span class="math display">\[
\begin{align}
&amp;p&#39;=R_1(R_2p+t_2)+t_1=R_1R_2p+(R_1t_2+t_1)\tag{合成变换}\\
&amp;p&#39;=R_2(R_1p+t_1)+t_2=R_1R_2p+R_2t_1+t_2\tag{变换的复合}
\end{align}
\]</span> <div class="note danger"><center>
合成变换，与变换的复合是两回事。
</center>
</div></p>
<p>​ 很多时候，我们接触的都会是合成变换。举一个例子：点云配准。假设点云A到点云B的位姿变换为T（点云A对应的激光器坐标系 需要经过变换T才能变换到点云B对应的激光器坐标系位置），已经存在一个粗糙的初始位姿变换：<span class="math inline">\(T_0\)</span>，这个变换可以是里程计或者一些算法给出的，需要 <strong><u>精配准</u></strong> 来修正这个位姿变换，使之更符合实际观测，那么假设这个精配准模块求出，点云在位姿<span class="math inline">\(T_0\)</span>下，还需要进行的变换<span class="math inline">\(\Delta T\)</span>，最后合成<span class="math inline">\(T_0\)</span>与<span class="math inline">\(\Delta T\)</span>得到最终的变换。 ​ 合成变换与变换复合的本质区别是：<strong>讨论的坐标系不同</strong>。变换的复合具有非常简单的思想，正如函数的复合，对输出进行一次新的变换。<strong><u>两次变换都是在同一个坐标系下讨论的</u></strong>，可以认为：</p>
<div class="note info"><p>参与变换复合的两个变换，是两个互不相关的，在同一个坐标系下讨论的绝对位姿变换，之间没有相对性。</p>
</div>
<p>​ 而合成变换，则具有相对性。仍然以上面的点云配准为例子，<span class="math inline">\(\Delta T\)</span>变换是在<span class="math inline">\(T_0\)</span>变换的基础上进行的，是在<span class="math inline">\(T_0\)</span>对应的坐标系下的一个变换，而<span class="math inline">\(T_0\)</span>是相对于另一个坐标系（比如全局坐标系或者子地图坐标系而言）。也就是说：</p>
<div class="note info"><p>参与合成变换的两个变换，具有关联关系，其中的一个变换是基于另一个变换确定的坐标系来讨论的。</p>
</div>
<p>​ 既然如此，那么在两种情况下的【合成的】变换分别是什么？ <span class="math display">\[
\begin{align}
&amp;T=T_1T_2\tag{合成变换}\\
&amp;T=T_2T_1\tag{变换的复合}
\end{align}
\]</span> ​ 只简单说一下合成变换为什么是右乘：显然，因为<span class="math inline">\(T_2\)</span>是在<span class="math inline">\(T_1\)</span>变换后的坐标系下的一个相对变换，其中的平移量相当于直接被<span class="math inline">\(T_1\)</span>预先变换了一次（平移就相当于是一个点）。整个式子可以看成是：<span class="math inline">\(T_2\)</span>变换被<span class="math inline">\(T_1\)</span>预先变换了一次，由于是<span class="math inline">\(T_1\)</span>来变换（动词）<span class="math inline">\(T_2\)</span>，则显然<span class="math inline">\(T_1\)</span>应该放在左边。</p>
<p>​ 所以要回答左右乘问题，其中一个角度应该是：</p>
<ul>
<li>左乘对应了绝对变换，右乘对应了追加变换，是在前一变换对应坐标系下讨论的。</li>
</ul>
<h3 id="左右乘讨论的衍生">2.2 左右乘讨论的衍生</h3>
<p>​ 为了方便理解，我画了一个图：</p>
<p><img src="/2021/10/31/%E4%BD%8D%E5%A7%BF%E5%8F%98%E6%8D%A2%E4%B8%8E%E5%85%AD%E8%BD%B4%E4%BB%BF%E7%9C%9F/transform.png"></p>
<center>
Figure 2. 位姿变换示意图
</center>
<p>​ 坐标系1经过位姿变换T变换到坐标系2，那么对于两个系中定义的一些点，其坐标变换公式是什么？假设点p在坐标系i下的坐标是<span class="math inline">\(p_i\)</span>：（为了方便起见，这两个坐标都是齐次坐标） <span class="math display">\[
\begin{align}
&amp;p_1=Tp_2\label{p1}\\
&amp;p_2=T^{-1}p_1\label{p2}
\end{align}
\]</span> ​ 从坐标系1变到坐标系2是变换T，而坐标系1点变换到坐标系2就是<span class="math inline">\(T^{-1}\)</span>。这也可以用左右乘推出的公式来讨论：假设两个坐标系都是相对于一个绝对的坐标系，两个坐标系相对绝对坐标系的变换分别为<span class="math inline">\(T_1, T_2\)</span>，那么对于点p，两个坐标系对应的坐标转换到绝对坐标系下应该是相等的，因为描述的都是绝对坐标系下的点<span class="math inline">\(p^{*}\)</span> <span class="math display">\[
\begin{equation}
T_1T_{1-p}p^*=T_2T_{2-p}p^*
\end{equation}
\]</span> ​ 因为<span class="math inline">\(T_{1-p}p^*=p_1\)</span>且<span class="math inline">\(T_{2-p}p^*=p_2\)</span>，而上式是由右乘（相对变换）得到的，可以推出公式<span class="math inline">\(\eqref{p1}\)</span>，<span class="math inline">\(\eqref{p2}\)</span>来。</p>
<h3 id="正逆运动学">2.3 正逆运动学</h3>
<p>​ 关于D-H坐标与正逆运动学，这个人的博客讲得很清楚（非常推荐，他的博客写得不错，上一个我觉得写得不错的博客是苏剑林的）：</p>
<div class="note success"><center>
<a href="http://gaoyichao.com/Xiaotu/?book=math_physics_for_robotics&title=inverse_kinematics">无处不在的小土</a>
</center>
</div>
<p>​ 关于正逆运动学的原理以及D-H坐标表示，我就不赘述了，上面链接的博客已经有了。我实现的六轴机器人，正逆运动学的思想是从以上博客以及Wikipedia中学来的，使用的是一个类似PUMA 560的简单带球腕六轴机器人，但是所有的关节中，link twist都与常见模型相反，所以运动学不得不自己推。</p>
<p>​ 在此我只简述一下正逆运动学的思想：</p>
<div class="tabs" id="class"><ul class="nav-tabs"><li class="tab active"><a href="#class-1">正运动学</a></li><li class="tab"><a href="#class-2">逆运动学</a></li></ul><div class="tab-content"><div class="tab-pane active" id="class-1"><p>实际上就是，给定各个关节的位姿，求解机器人手臂末端的位姿。这是个很容易的任务，就是疯狂地进行位姿变换合成。由于使用D-H坐标描述，使得描述机器人的参数最简，并且也描述了两个关节确定的坐标系之间的相对变换，所以可以轻易地使用位姿变换合成： <span class="math display">\[
\begin{equation}
T_6^0=T_1^0T_2^1T_3^2T_4^3T_5^4T_6^5
\end{equation}
\]</span> 每个关节相对于下一个关节的位姿变换，在正运动学篇已经进行了详细的讨论，在简单的问题中，也不过就是使用link length, link offset, link twist, link angle计算变换矩阵。</p></div><div class="tab-pane" id="class-2"><p>可以把这个问题看作是解方程：已知期望的末端位置，需要求解出每个关节的位姿（比如角度，平移）。复杂问题下，是需要引入优化的方式来求解的（可能没有简单的闭式解），而在一些简单的情形下，可以进行 <strong><u>解耦</u></strong>，也就是找到前后不相关联的位姿变换，分解问题为子问题，子问题下就有可能求解出闭式解。带有球腕的问题就是一个典型的简化情形。</p></div></div></div>
<p>​ 我所使用的六轴机器人模型，参数定义如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// link offset / link length / link twist / link angle</span></span><br><span class="line"><span class="type">const</span> std::vector&lt;LinkInfo&gt; init_links = &#123;</span><br><span class="line">    <span class="built_in">LinkInfo</span>(<span class="number">0.5</span>, <span class="number">0</span>, M_PI_2,  <span class="number">0.134140</span>), </span><br><span class="line">    <span class="built_in">LinkInfo</span>(<span class="number">0.1</span>, <span class="number">0.8</span>, <span class="number">0</span>, <span class="number">0.012189</span>), </span><br><span class="line">    <span class="built_in">LinkInfo</span>(<span class="number">0.1</span>, <span class="number">0</span>, M_PI_2, <span class="number">-0.036790</span>), </span><br><span class="line">    <span class="built_in">LinkInfo</span>(<span class="number">0.8</span>, <span class="number">0</span>, M_PI_2, <span class="number">1.596749</span>), </span><br><span class="line">    <span class="built_in">LinkInfo</span>(<span class="number">0</span>, <span class="number">0</span>, M_PI_2, <span class="number">-0.222030</span>),</span><br><span class="line">    <span class="built_in">LinkInfo</span>(<span class="number">0.4</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1.459867</span>)  </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>​ 小土的博客中，使用的是<span class="math inline">\(-\pi / 2\)</span>的link twist，而我这里使用的是<span class="math inline">\(\pi/2\)</span>。开始我的底部三个关节的求解，完全按照<span class="math inline">\(-\pi/2\)</span>去推的，这当然会有问题，之后手推了一下<span class="math inline">\(\pi/2\)</span>的情况。</p>
<p>​ 顶部三个关节如何求解，小土的博客并没有说，但是思想大致还是一样的：将末端点变换到第四个关节对应的坐标系下，使用投影法求解。</p>
<h3 id="多解问题可行域">2.4 多解问题&amp;可行域</h3>
<p>​ 以底部的三个关节以及对应机械臂为例：</p>
<p><img src="/2021/10/31/%E4%BD%8D%E5%A7%BF%E5%8F%98%E6%8D%A2%E4%B8%8E%E5%85%AD%E8%BD%B4%E4%BB%BF%E7%9C%9F/two.png"></p>
<center>
Figure 3. 位姿变换示意图
</center>
<p>​ 黑色和蓝色分别表示了两种不同解下的机械臂情形。对于同一个球腕位置（也就是右上角的交汇点），可能有两个解，两个解都是需要求出来的，不同的关节会形成解组。比如<span class="math inline">\(\theta_1\)</span>以及<span class="math inline">\(\theta_2\)</span>分别对应joint 2的两个相差<span class="math inline">\(\pi\)</span>的解角度。选取谁？需要根据“能耗最小原则”：哪个解与上一时刻对应的角度最接近，说明运动到对应的状态所需能量损耗最小，机器人应该更倾向于选取这个解。多解问题存在于球腕与底部角度上。</p>
<p>​ 给定末端姿态以及末端的位置，机械臂各个关节也不一定有解，比如：超出长度范围，或是没办法同时满足姿态和位置等等，这些都可能会使得求解结果成NaN，只需要限制在解为NaN时放弃本次控制。</p>
<hr>
<h2 id="iii.-gazebo仿真">III. Gazebo仿真</h2>
<p>​ 我想尝试一下除了rviz之外的可视化方法，rviz版本也已经在Axis6这个库里实现了，这个版本的可视化核心就在tf的使用，也没什么困难的，可视化时碰到的大多数问题实际上都是坐标系或者变换求解错误的问题。除了rviz之外，我能想到也就只有寥寥几个可视化工具：OpenGL以及其封装的Pangolin，Gazebo。由于我从来没有用过Gazebo，故想尝试一下这个新东西。</p>
<p>​ 构建Gazebo机械臂主要有以下三步：</p>
<ul>
<li>编写urdf（或者xacro）描述机器人，以及相应的gazebo文件（.sdf或者.gazebo以及.world）</li>
<li>构建机器人控制器（transmission），使用gazebo_ros以及gazebo_ros_control进行控制</li>
<li>调参。这一步都能放进来确实是我没想到的。</li>
</ul>
<h3 id="描述机器人">3.1 描述机器人</h3>
<p>​ ROS wiki上对于描述机器人以及模型的文件是这么说的：</p>
<blockquote>
<p>Xacro (XML Macros) Xacro is an XML macro language. With xacro, you can construct shorter and more readable XML files by using macros that expand to larger XML expressions.[1]</p>
</blockquote>
<blockquote>
<p>Xacro is just a scripting mechanism that allows more modularity and code re-use when defining a URDF model. When using it, what is actually uploaded to the parameter servers (per default as the "robot_description" parameter) actually is a URDF, as that gets generated from the xacro file in the launch file (by expanding the xacro macros used).[2]</p>
</blockquote>
<p>​ 这里主要给出四个部分的例子，主要看注释：以下两个部分来自于<code>src/axis6/urdf/axis6.xacro</code></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!--        此处定义的是机械臂          --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">name</span>=<span class="string">&quot;world&quot;</span>/&gt;</span></span><br><span class="line"><span class="comment">&lt;!--上面这个link（机械臂）是一个固定的轴，每个urdf都需要带，相当于世界坐标系--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--定义一个机械臂，这里是六轴机器人的底座--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">name</span>=<span class="string">&quot;base&quot;</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--collision属性没有写上来，其定义方式与visual类似，定义的是碰撞箱--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">visual</span>&gt;</span> <span class="comment">&lt;!--视觉效果，定义的是我们能观察到的样子--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">origin</span> <span class="attr">xyz</span>=<span class="string">&quot;0 0 0.75&quot;</span> <span class="attr">rpy</span>=<span class="string">&quot;0 0 0&quot;</span>/&gt;</span> <span class="comment">&lt;!--rpy对应轴是xyz--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">geometry</span>&gt;</span> <span class="comment">&lt;!--定义基础模型：一个长方体，width depth height是xyz--&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">box</span> <span class="attr">size</span>=<span class="string">&quot;0.4 0.4 1.5&quot;</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">geometry</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">material</span> <span class="attr">name</span>=<span class="string">&quot;grey&quot;</span>/&gt;</span> <span class="comment">&lt;!--调用material.xacro中定义的颜色--&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">visual</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">inertial</span>&gt;</span>	<span class="comment">&lt;!--惯性力学信息--&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--可以认为，此处定义了一个等效几何体，位置与姿态都给出了，并且给了多轴方向上的质量分布--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">origin</span> <span class="attr">xyz</span>=<span class="string">&quot;0 0 0.75&quot;</span> <span class="attr">rpy</span>=<span class="string">&quot;0 0 0&quot;</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">mass</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;mass&#125;&quot;</span>/&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--一种遵循shell类似语法的变量调用--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">inertia</span></span></span><br><span class="line"><span class="tag">      <span class="attr">ixx</span>=<span class="string">&quot;1.0041666666666669&quot;</span> <span class="attr">ixy</span>=<span class="string">&quot;0.0&quot;</span> <span class="attr">ixz</span>=<span class="string">&quot;0.0&quot;</span></span></span><br><span class="line"><span class="tag">      <span class="attr">iyy</span>=<span class="string">&quot;1.0041666666666669&quot;</span> <span class="attr">iyz</span>=<span class="string">&quot;0.0&quot;</span></span></span><br><span class="line"><span class="tag">      <span class="attr">izz</span>=<span class="string">&quot;0.13333333333333336&quot;</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">inertial</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">link</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!--此处定义的是关节信息，关节是连接机械臂（以及两个不同坐标系）的结构--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">joint</span> <span class="attr">name</span>=<span class="string">&quot;joint0&quot;</span> <span class="attr">type</span>=<span class="string">&quot;continuous&quot;</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--joint是机器人机械臂位姿变换的基础，可以认为joint定义的是child link的坐标系--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">parent</span> <span class="attr">link</span>=<span class="string">&quot;world&quot;</span>/&gt;</span>		<span class="comment">&lt;!--父系，或者上一个机械臂--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">child</span> <span class="attr">link</span>=<span class="string">&quot;link1&quot;</span>/&gt;</span>		<span class="comment">&lt;!--子系，连接的下一个机械臂--&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--关节相对于上一个坐标系，其原点平移偏置以及z轴的相对旋转--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">origin</span> <span class="attr">xyz</span>=<span class="string">&quot;0 0 1.5&quot;</span> <span class="attr">rpy</span>=<span class="string">&quot;0 0 0&quot;</span>/&gt;</span>  	</span><br><span class="line">    <span class="comment">&lt;!--使用child link的哪一个轴或者哪一个方向作为关节转轴--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">axis</span> <span class="attr">xyz</span>=<span class="string">&quot;0 0 1&quot;</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--电机的力矩以及速度限制（不超过以下两个设置值，这两个参数在【3.3调参】中很重要）--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">limit</span> <span class="attr">effort</span>=<span class="string">&quot;50&quot;</span> <span class="attr">velocity</span>=<span class="string">&quot;50&quot;</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">joint</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>​ 以下部分来自于<code>src/axis6/urdf/axis6.sdf</code>:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- URDF需要转为gazebo能理解的sdf类型 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">gazebo</span> <span class="attr">reference</span>=<span class="string">&quot;link1&quot;</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--设置重力为0，注意此处有Gazebo的bug[3]--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">gravity</span>&gt;</span>0<span class="tag">&lt;/<span class="name">gravity</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--关闭内部碰撞检测，也有bug[3]--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">self_collide</span>&gt;</span>0<span class="tag">&lt;/<span class="name">self_collide</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--两个摩擦系数--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mu1</span>&gt;</span>0.0<span class="tag">&lt;/<span class="name">mu1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mu2</span>&gt;</span>0.0<span class="tag">&lt;/<span class="name">mu2</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--还有kp,kd两个参数，用于定义模型的硬度，之前好像是这样的</span></span><br><span class="line"><span class="comment">	假如kp与kd很接近，那么模型会变软，可能陷到地里，kp&gt;&gt;kd时很硬。</span></span><br><span class="line"><span class="comment">	不过我也没有深究过--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">material</span>&gt;</span>Gazebo/Black<span class="tag">&lt;/<span class="name">material</span>&gt;</span> <span class="comment">&lt;!--颜色--&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">gazebo</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>​ 定义机械臂的重力为0经常出现bug，一会儿说你有 <code>multiple conflicting &lt;gravity&gt; tag</code> 然后给你强制设为<code>&lt;gravity&gt;true&lt;/gravity&gt;</code>，又存在这个bug[3]，导致gravity以及self_collide两个标签都不能被正确设置。</p>
<p>​ 以下部分来自于<code>src/axis6/world/axis6.world</code>:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">world</span> <span class="attr">name</span>=<span class="string">&quot;default&quot;</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--引入外部的模型（如果找不到，有些可能会在加载时在网上下载）--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">include</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">uri</span>&gt;</span>model://ground_plane<span class="tag">&lt;/<span class="name">uri</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">include</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!--...省略部分--&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Global light source --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">include</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">uri</span>&gt;</span>model://sun<span class="tag">&lt;/<span class="name">uri</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">include</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--最后的我的消重力方式：直接让世界没有重力，嗯，很暴力--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">gravity</span>&gt;</span>0 0 0<span class="tag">&lt;/<span class="name">gravity</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">world</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="传输控制">3.2 传输控制</h3>
<p>​ 定义好这些文件后，写一个launch文件，如果编写正确，就能在Gazebo中生成出定义的机器人。但此时机器人是死的，没办法控制。使用gazebo_ros以及相关模块进行控制，这几个包都是需要自己下的，建议直接：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install ros-version-gazebo-ros*</span><br></pre></td></tr></table></figure>
<p>​ transmission定义的实际上是一个个电机：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">transmission</span> <span class="attr">name</span>=<span class="string">&quot;tran5&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">type</span>&gt;</span>transmission_interface/SimpleTransmission<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--定义在关节5上的电机--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">joint</span> <span class="attr">name</span>=<span class="string">&quot;joint5&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">hardwareInterface</span>&gt;</span>hardware_interface/EffortJointInterface</span><br><span class="line">      <span class="tag">&lt;/<span class="name">hardwareInterface</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">joint</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--电机--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">actuator</span> <span class="attr">name</span>=<span class="string">&quot;motor5&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">hardwareInterface</span>&gt;</span>hardware_interface/EffortJointInterface</span><br><span class="line">      <span class="tag">&lt;/<span class="name">hardwareInterface</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">mechanicalReduction</span>&gt;</span>1<span class="tag">&lt;/<span class="name">mechanicalReduction</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">actuator</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">transmission</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>​ 需要配置一个相应的电机config文件(<code>src/axis6/config/axis6_control.yaml</code>)：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">axis6:</span></span><br><span class="line">  <span class="comment"># Publish all joint states -----------------------------------</span></span><br><span class="line">  <span class="attr">joint_state_controller:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">joint_state_controller/JointStateController</span></span><br><span class="line">    <span class="attr">publish_rate:</span> <span class="number">50</span>  </span><br><span class="line">  </span><br><span class="line">  <span class="comment"># Position Controllers ---------------------------------------</span></span><br><span class="line">  <span class="attr">joint0_position_controller:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">effort_controllers/JointPositionController</span></span><br><span class="line">    <span class="attr">joint:</span> <span class="string">joint0</span></span><br><span class="line">    <span class="attr">pid:</span> &#123;<span class="attr">p:</span> <span class="number">15.0</span>, <span class="attr">i:</span> <span class="number">0.001</span>, <span class="attr">d:</span> <span class="number">1.2</span>&#125;</span><br><span class="line"><span class="comment"># ...</span></span><br></pre></td></tr></table></figure>
<p>​ 2-5行是不可少的，此项配置了整个关节状态发布器。剩余的就一个个配置，配置其类型（位置控制电机，速度控制电机）以及pid参数（<strong>很难调</strong>）。</p>
<p>​ 在加入这些信息之后，再生成Gazebo仿真，使用rostopic list命令可以看到一些新的topic（实际上是gazebo模型subscribe的，但因为没有配置ros端，暂时无publisher），可以直接使用如下命令进行简单测试：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rostopic pub &lt;topic_name：比如/axis6/joint1_state_controllers/command&gt; &lt;topic_type:一般是std_msgs::Float64&gt; &quot;data: &lt;控制量，比如:1.0&gt;&quot; </span><br></pre></td></tr></table></figure>
<p>​ 剩下的事情就是写一个控制节点，发布对应消息就能进行控制了，这里就不赘述了。</p>
<h3 id="调参">3.3 调参</h3>
<p>​ 仿真，顾名思义，一定要真。即使我把摩擦关了，碰撞检测关了，重力关了，控制也并没有想象的那么简单。问题主要是：</p>
<ul>
<li>机械臂的质量以及质量分布设计得不合理（比如末端很重）</li>
<li>PID参数 + 电机limit（见xacro文件按）设置的不合理。</li>
</ul>
<p>​ 导致以下三个问题（折磨了我一下午）：</p>
<ul>
<li>电机驱动力不够 + pid参数过小时，又慢又超调</li>
<li>电机驱动力充足 + pid参数较大时，机械臂抖动严重（末端尤为严重）</li>
<li>电机驱动力充足 + pid参数过大时，可能会炸开。。。机械臂直接飞了，这也太真实了</li>
</ul>
<p>​ 解决方案当然就是一个个电机调：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">joint0_position_controller:</span></span><br><span class="line">	<span class="attr">pid:</span> &#123;<span class="attr">p:</span> <span class="number">15.0</span>, <span class="attr">i:</span> <span class="number">0.001</span>, <span class="attr">d:</span> <span class="number">1.2</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="attr">joint1_position_controller:</span></span><br><span class="line">	<span class="attr">pid:</span> &#123;<span class="attr">p:</span> <span class="number">10.0</span>, <span class="attr">i:</span> <span class="number">0.001</span>, <span class="attr">d:</span> <span class="number">0.8</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="attr">joint2_position_controller:</span></span><br><span class="line">	<span class="attr">pid:</span> &#123;<span class="attr">p:</span> <span class="number">5.0</span>, <span class="attr">i:</span> <span class="number">0.001</span>, <span class="attr">d:</span> <span class="number">0.1</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="attr">joint3_position_controller:</span></span><br><span class="line">	<span class="attr">pid:</span> &#123;<span class="attr">p:</span> <span class="number">1.5</span>, <span class="attr">i:</span> <span class="number">0.001</span>, <span class="attr">d:</span> <span class="number">0.04</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="attr">joint4_position_controller:</span></span><br><span class="line">	<span class="attr">pid:</span> &#123;<span class="attr">p:</span> <span class="number">1.1</span>, <span class="attr">i:</span> <span class="number">0.001</span>, <span class="attr">d:</span> <span class="number">0.08</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="attr">joint5_position_controller:</span></span><br><span class="line">	<span class="attr">pid:</span> &#123;<span class="attr">p:</span> <span class="number">0.25</span>, <span class="attr">i:</span> <span class="number">0.0001</span>, <span class="attr">d:</span> <span class="number">0.0002</span>&#125;</span><br></pre></td></tr></table></figure>
<p>​ 从最底部的关节开始（它应有的驱动能力最大，因为负载最大），关节号越高，其后的机械臂越少（载荷越小），那么显然，limit中的effort以及velocity应该越小，PID参数越小，机械臂也尽可能在末端变轻。</p>
<hr>
<h2 id="iv.-效果展示">IV. 效果展示</h2>
<p>​ 最后的效果也就是：末端可以三轴方向平移，以及绕某一轴旋转。我复用了之前写的键盘控制函数（在LiDARSim2D库内）（多按键触发），故运动是可以合成的：</p>
<p>​ rviz：使用tf以及visualization_msg::Marker进行可视化：</p>
<video src="rviz.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<center>
Video 1. rviz仿真结果
</center>
<p>​ Gazebo：花了好几个穿模的长方体（随便画的，没必要搞机械设计了）:</p>
<video src="gazebo.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<center>
Video 2. Gazebo仿真结果
</center>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="http://wiki.ros.org/xacro">ROS wiki: xacro</a></p>
<p>[2] <a href="https://answers.ros.org/question/202162/urdf-or-xacro/">URDF or Xacro?</a></p>
<p>[3] <a href="https://github.com/ignitionrobotics/sdformat/issues/71">Incorrect URDF to SDF conversion of gravity and self_collide tags #71</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>运动学</tag>
        <tag>Gazebo</tag>
      </tags>
  </entry>
  <entry>
    <title>关于变形金刚的一些思考</title>
    <url>/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[<h1 id="transformer">Transformer</h1>
<hr>
<h2 id="i.-引入">I. 引入</h2>
<p>​ 在NLP（Natural Language Processing 而不是 Non-Linear Programming）问题中，经常涉及到sequence to sequence的问题，在这种问题上最广为人知的应用就是【机器翻译】：</p>
<blockquote>
<p>Watch out everybody, the potato is really hot. Nice.</p>
<p>大家快看外面有一个特别性感的土豆。好棒啊。</p>
</blockquote>
<p>​ 而RNN及其变体如GRU/LSTM，既然属于RNN范畴，那就免不了<strong><u>串行</u></strong>以及自递归（auto-regression）。在数字信号处理课程中学的知识：自递归对应了IIR，时域上比FIR复杂一些。由于这两个显著的弱点，导致其慢并且长距离下的语义解析能力差，Vaswani等人提出了一种新的 基于注意力机制的可并行处理框架 - the 变形金刚。在此基础上，Juho-Lee等人构建了一种对集合数据具有置换不变性的网络（集合无序，输入顺序不影响输出）。因为从小就是看变形金刚系列电影长大的（？），我实现了这两篇论文中提到的神经网络结构，用在了Set Transformer论文中的Toy Problem - Max regression 上。结果如下图，本文是对Transformer相关理论以及实现的总结，实现已经挂在Github上了，见<a href="https://github.com/Enigmatisms/Set-Transformer">Github🔗：Enigmatisms/Set-Transformer</a>。</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/1.png" style="zoom:75%;"></p>
<center>
Figure 1. Set Transformer Max Regression Problem实验结果
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-attention机制的理解">II. Attention机制的理解</h2>
<h3 id="与rnn的关系">2.1 与RNN的关系</h3>
<p>​ RNN中的典型结构（我也不记得叫什么了），总之是一个有记忆能力的Gate。神经元的上一个输出，可以作为本次输入的一部分，那么这可以被简单地表示成： <span class="math display">\[
\begin{equation}\label{rnn}
y[n]=a\times h[n]+b\times x[n],\text{ where }h[n]=y[n-1]
\end{equation}
\]</span> ​ 显然，一个简单的记忆单元可以被表示成一个<strong><u>离散一阶系统</u></strong>，那就是一个惯性环节嘛。这也就是一个自递归单元。很可惜，这样的系统阶数越高，表示力才越强，但作为代价的是，需要系统提供存储单元，并且对于一个k阶系统，前k个值如果没有完全计算完成，那么第k+1个值是无法得到的，这也就阻止了并行，这太不优雅了，虽然可能 一定程度上模仿了人类的理解方式：顺序读，再处理顺序输入的信息。</p>
<p>​ 我个人不是很了解RNN，因为个人觉得这个网络结构就是不是特别优雅（虽然看起来很有道理），加上我偏CV，一般也用不到RNN。我在想，RNN能做到以下的事情吗？</p>
<blockquote>
<p>另外，在常规接当种中我也们发现，免疫相对功能较低人的群，以及60岁上以的人群，他们接踵产生后的免效疫没有果18-59岁的好，但是这类人群又是恰恰感的染后高危人群</p>
</blockquote>
<p>​ 上面这段话的内容，存在一些颠倒的字词，人可能没有太大的阅读障碍，但是依赖顺序输入的网络表现会如何？</p>
<p>​ 与之相比，Transformer是一种FIR，它无需依赖记忆单元，在输入时也没有顺序要求（Attention is All You Need一文中使用三角函数Position encoding），于是可以很方便地进行并行。并且Transformer使用的注意力机制，就是模仿人类理解信息时，有所侧重的特性。</p>
<h3 id="单头细节">2.2 单头细节</h3>
<p>​ Query，Key，Value（Q K V）的物理含义应该如何理解？假设问题的背景是机器翻译，那么有两种情况：</p>
<ul>
<li>Q是输入语言，(K,V)是目标语言对应的信息。输入的每一个token，变为Q之后查应该对应目标语言中的哪一个词。</li>
<li>Q是目标语言，(K,V)是输入语言信息。目标语言查自己应该如何选择目标token才能使得最类似输入</li>
</ul>
<p>​ 个人认为在Transformer中，应该是用第一种方式来处理问题。那么Q，K，V在其中的作用个人认为分别是：</p>
<ul>
<li>Q：输入embedding信息，用于与目标语言的信息进行比较</li>
<li>K：<strong><u>目标语言</u></strong>构建的，<strong><u>方便源语言（Q）进行比较</u></strong>的，包含目标embedding信息的张量</li>
<li>V：用于输出的目标embedding信息部分</li>
</ul>
<p>​ 考虑batch的情况下，一般的张量shape（以Q为例），大概是这样的：<span class="math inline">\((N_{\text{batch}},M_{\text{seq-len}},K_{\text{embedding-dim}})\)</span>​​。也就是，三维张量已经足够表示：batch size，序列长度，以及embedding维度。有的时候，Q与K的shape会相同，以下以QK处于同一个线性空间为例，那么Q/K所在的空间内可以形成Gram矩阵：</p>
<blockquote>
<p>在线性代数中，内积空间中一族向量的格拉姆矩阵（Gramian matrix 或 Gram matrix, Gramian）是<strong><u>内积的对称矩阵</u></strong>，其元素由<span class="math inline">\(G_{ij}=(v_j|v_i)\)</span>​​给出。</p>
</blockquote>
<p>​ 之前在CNN style transfer中接触过，这个矩阵用于衡量两组向量的相似程度。因为内积可以用于衡量相似度。使用内积就会有一种使用agreement概念的感觉。最后的输出是： <span class="math display">\[
\begin{equation}\label{qkv}
Att(Q,K,V,\omega)=\omega(\frac{QK^T}{\sqrt{k}})V
\end{equation}
\]</span> ​ <span class="math inline">\(QK^T\)</span>就是Gram矩阵，要注意KV的对应性。可以这么说：假如<span class="math inline">\(Q_i\)</span>与<span class="math inline">\(K_j\)</span>的相似度高，那么<span class="math inline">\(V_j\)</span>​应该有更大的权值。<span class="math inline">\(\omega\)</span>​是非线性函数，论文中使用的是softmax，变换为多元素的概率，进行概率加权。</p>
<p>Softmax沿着哪一个维度做？已知QK的计算是：<span class="math inline">\(QK^T\)</span>也就是<span class="math inline">\((n\times k)\times(k\times n)\)</span>，最后生成<span class="math inline">\((n\times n)\)</span>​​矩阵</p>
<details class="note primary"><summary><p>每一个Query token与key匹配的关系有两个选择：</p>
</summary>
<ul>
<li>一个query可以选择多个key，也就是选择不同key的概率是归一的，那么就是行和为一（）</li>
<li>一个key对应了多个query，那么就是列和为1（列方向求和）（这个在2.2节开头就已经说过了，属于方式2，应该是不对的）。</li>
</ul>

</details>
<p>​ 个人更加倾向于，一个query可以对应多个key，也就是一个query可以找到多个value？也就是每一个query字，与所有value字的注意力，对应的概率应该和为1。</p>
<h3 id="单头理解-多头化">2.3 单头理解 &amp; 多头化</h3>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/single.PNG" style="zoom:60%;"></th>
<th style="text-align: center;"><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/multi.PNG" style="zoom:50%;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">单头QKV注意力块</td>
<td style="text-align: center;">多头QKV注意力块</td>
</tr>
</tbody>
</table>
<p>​ 单头QKV可以理解成：源数据经过特征提取得到Q，目标空间由V对应的元素展成（span），并且提供一个与Q中元素相同维度的比较信息（K）。源信息（Q）与部分目标信息（K）元素两两求相似，通过相似度转化为的概率对V进行加权输出。</p>
<p>​ 多头则是指：Q K V并不直接进行内积运算。一是因为可能是大矩阵，直接内积计算时间长，二是因为这样学习得出的内容太单一。多头注意力就是希望通过多重低维度映射的方法，使得不同的head能够学习到不同的源 / 目的数据关系，<strong><u>这是产生多重语义理解的一步。</u></strong></p>
<hr>
<h2 id="iii.-set-transformer">III. Set Transformer</h2>
<h3 id="inducing-point-isab">3.1 Inducing Point &amp; ISAB</h3>
<p>​ ISAB中的Inducing Points与PMA中的seeds实际上是一回事，叫法不同。从论文中摘录的框图说明了ISAB的实现结构。它的提出是为了解决SAB平方复杂度导致的问题。比如当集合特别大的时候，会因为平方级别的复杂度计算很长时间。</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/isab.PNG"></p>
<center>
Figure 2. Attention Blocks
</center>
<p>​ SAB的时间复杂度为什么是<span class="math inline">\(O(n^2)\)</span>？SAB作为自注意力网络块，Multi-head attention输入的Q K V都是X，也就是说：对于一个输入X，不考虑其batch大小，假设其为（<span class="math inline">\(n\times k\)</span>），n为集合大小（或者在NLP中，token的数量），k为embedding的大小。那么根据内积： <span class="math display">\[
\begin{equation}\label{self_att}
Att(X,X,X,\omega)=\omega(\frac{XX^T}{\sqrt{k}})X
\end{equation}
\]</span> ​ 过程大概是：<span class="math inline">\((n\times k)\times(k\times n)\times(n\times k)\)</span>​。第一个QK阶段就已经需要n平方次计算了。这个就是<span class="math inline">\(O(n^2)\)</span>复杂度的。所以作者希望，可以固定某一维度的大小，以降低复杂度。</p>
<p>​ MAB是<span class="math inline">\(Att(X,Y,Y,\omega)\)</span>形式的，那么当MAB的输入是：<span class="math inline">\((I,X,X)\)</span>，最终的计算会成为：<span class="math inline">\((m\times k)\times(k\times n)\times(n\times k)\)</span>。在QK阶段，内积运算只进行<span class="math inline">\((mn)\)</span>次，复杂度是<span class="math inline">\(O(mn)\)</span>，当输入为大集合时，可能可以显著减小计算负担。所以两层MAB的交替输入，第一层输出<span class="math inline">\((m\times k)\)</span>作为第二层MAB的Y，X本身作为第二层的X，可以最后重新映射回到<span class="math inline">\((n\times k)\)</span>维度。</p>
<p>​ 作者自己也说（我觉得作者这个类比很不错，很直观），ISAB就像一个编码器，或者说常见的Detection / Segmentation的两头大中间小结构：</p>
<blockquote>
<p>This is analogous to low-rank projection or autoencoder models, where inputs (X) are first projected onto a low-dimensional object (H) and then reconstructed to produce outputs.</p>
</blockquote>
<h3 id="实现细节维度">3.2 实现细节：维度？</h3>
<p>​ 开始时，我实现了一版这一样的MAB，请看：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MAB</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, batch_size, head_num, dk_model, dv_model, use_layer_norm</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.att = Multihead(batch_size, head_num, dk_model, dv_model, use_layer_norm)</span><br><span class="line">        self.ff = nn.Sequential(</span><br><span class="line">            nn.Linear(dv_mode, dv_model),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.layer_norm = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> use_layer_norm == <span class="literal">True</span>:</span><br><span class="line">            self.layer_norm = nn.LayerNorm(dv_model)</span><br><span class="line">        self.remap = nn.Linear(dk_model, dv_model)</span><br></pre></td></tr></table></figure>
<p>​ Multihead这个模块就是根据<em>Attention is All You Need</em>这篇文章来的（至少我觉得我是这么实现的）。但是发现，这没办法实现维度变换。为什么？我发现我在解决中位数问题时，遇到了这样的难题：</p>
<ul>
<li>一个训练用例，显然是<span class="math inline">\(\{x_1,x_2,...,x_n\}\)</span>​​，x是标量，使用SAB时，内积还是标量，用处不大。</li>
<li>低维数据能向高维转移吗？自己实现的这一版SAB，输出就是：(batch_size, token_num_Q, embedding_dim_V)，如果内部不对数据做变换，那么输出的embedding维度就是1</li>
</ul>
<p>​ 不管是在Transformer论文还是在Set Transformer论文中，提到Multi-head一定做的是这个事情：首先将Q K V变换到低维度上（以Q为例） <span class="math display">\[
\begin{equation}
Q_i=QW_q^i,\text{ where } W_q^i\text{ has shape }(N_{batch},d_q,d_q/M)
\end{equation}
\]</span> ​ 将变换后的Q K V输入到single-head attention模块中。巧了，我就是这么做的，只不过感觉会引起维度问题。所以我们需要：</p>
<ul>
<li>可以设置输入输出维度（设置输出维度极为重要，就像我们用CNN输出多少个Channel一样，应该是可调的）</li>
<li>输入时对较小的维度进行升维，以便进行Multi-head操作、</li>
</ul>
<div class="note warning"><p>​ 所以Transformer在实现时，到底应该如何操作？Q K V看起来很简单的三个维度设置，需要统一维度吗？</p>
</div>
<p>​ 个人认为，在Set transformer中，多头注意力机制模块应当完全不需要对输入进行变换，直接使用。这样才可以模块独立。而不同的Block之间的连接，有赖于Feed forward层，或者说，有些Block的输出（比如MAB），就会经过FFN。</p>
<p>​ row-wise feed forward 层，一般来说也就是一个单层的线性网络（不过要记得激活，<strong><u>开始时忘记</u></strong>加ReLU了，既然是层，那就要有激活，除非是输出）。可以认为，此处就是一个类似残差块的东西。虽然在Attention is All You Need中，FFN是这样定义的： <span class="math display">\[
\text{FFN}(x)=\max(0,xW_1+b_1)W_2+b_2
\]</span> ​ 相当于nn.Linear + nn.ReLU + nn.Linear。但是在Set transformer中，实现的貌似叫做 row-wise（all you need中叫做position-wise）。但是为什么要这么做？作者没有给出明确的答案，而是说：</p>
<blockquote>
<p>It could reduce to applying a residual block on X. In practice, it learns more complicated functions due to linear projections of X inside attention heads.</p>
</blockquote>
<p>​ 感觉挺无力的，这些深度学习新的网络架构看起来好像确实没什么可以解释的，数学上也不好说。残差连接在这似乎也与其被提出时所要解决的问题对应的目的不同，因为不会有什么梯度爆炸。</p>
<h3 id="多头注意力的实现">3.3 多头注意力的实现</h3>
<p>​ 多头注意力是我在本文中最觉得困惑的部分。因为官方的实现与自己的论文 / All you need是不一样的。不管是在Transformer 还是 Set Transformer论文中，提到的多头的实现方式时，总会将以下公式列出来： <span class="math display">\[
\begin{align}
&amp;\text{output}=\text{cat}[O_1,O_2,...,O_h]\cdot W_o,\text{ where }O_i \label{out}\\
&amp;O_i=Att(Q_i,K_i,V_i,w)\\
&amp;Q_i=QW_Q^i,K_i=KW_K^i,V_i=VW_V^i,
\end{align}
\]</span> ​ 也就是：对Q K V 每一项分别使用多个权重<span class="math inline">\(W\)</span>​​，从原来的embedding dimension k映射到一个更低的维度（实现低维多输入，低维上的注意力）。​公式<span class="math inline">\(\eqref{out}\)</span>​​​​是两篇论文中都有的，但是作者并没有这样实现。作者直接使用了split（fron Github juho-lee/set_transformer）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Q_ = torch.cat(Q.split(dim_split, <span class="number">2</span>), <span class="number">0</span>)</span><br><span class="line">K_ = torch.cat(K.split(dim_split, <span class="number">2</span>), <span class="number">0</span>)</span><br><span class="line">V_ = torch.cat(V.split(dim_split, <span class="number">2</span>), <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>​ 相当于，本来应该使用线性映射到低维的Q K V，直接在embedding dimension维度切开，成为head number份。这和你的论文里写的也不一样啊，为什么呀大哥。此后，官方实现有些更迷惑的操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">A = torch.softmax(Q_.bmm(K_.transpose(<span class="number">1</span>,<span class="number">2</span>))/math.sqrt(self.dim_V), <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>​ 连起来就是：首先embedding直接split成块，拼接到第一个维度上（一般来说是batch维度），相当于原来batch size为n现在变成了<span class="math inline">\(h\times n\)</span>，batch之间不会有相互作用。计算内积之后，再拆分回到原来的shape。所以我也不是很懂为什么不按部就班实现。。。可能这就是强者吧。我的实现，只能说按着论文来的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Qs = Q.split(self.dk, dim = -<span class="number">1</span>)</span><br><span class="line">Ks = K.split(self.dk, dim = -<span class="number">1</span>)</span><br><span class="line">Vs = V.split(self.dv, dim = -<span class="number">1</span>)</span><br><span class="line">heads = [self.singleHeadQKVAtt(Qs[i], Ks[i], Vs[i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.head_num)]</span><br><span class="line"><span class="comment"># 或者不使用split</span></span><br><span class="line">Qs = [Q @ self.Wqs[i].repeat(batch_size, <span class="number">1</span>, <span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.head_num)]</span><br><span class="line">Ks = [K @ self.Wqs[i].repeat(batch_size, <span class="number">1</span>, <span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.head_num)]</span><br><span class="line">Vs = [V @ self.Wvs[i].repeat(batch_size, <span class="number">1</span>, <span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.head_num)]</span><br><span class="line"><span class="comment"># each head outputs (n, token_num, token_num) @ (n, token_num, dv_model / head)</span></span><br><span class="line">heads = [self.singleHeadQKVAtt(Qs[i], Ks[i], Vs[i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.head_num)]</span><br></pre></td></tr></table></figure>
<p>​ split本质上与线性映射没有什么区别，甚至split实现会简单很多，并且少一些参数。</p>
<hr>
<h2 id="iv.-复现结果">IV. 复现结果</h2>
<ul>
<li>学习率设置</li>
</ul>
<h3 id="学习率">4.1 学习率</h3>
<p>​ 测试的问题是Set Transformer中的Max Regression问题，找一个集合的最大数，本来想实现中位数的，但是发现中位数简直没办法直接训练出东西来。训练参数：batch size = 64，一个集合32个数，也就是每次的X是<span class="math inline">\(64 \times 32\)</span>​矩阵。模型非常难训练，主要体现在：</p>
<ul>
<li><p>我使用exponential learning rate scheduler，初始学习率1e-3，gamma大概为0.9999（衰减慢），正常情况下，在初始的几百个样本，loss下降非常快。到loss约等于2时，可能一直卡在这直到结束，最后的acc也就20%。</p></li>
<li><p>有很小的概率，学习率减到很小时，跳出局部最优解。acc继续上升，但是由于ExpoLR让学习率变得很小了，训练很慢，训练完也只能让模型acc到50%。</p></li>
<li><p>官方实现可以在较大学习率时跳出局部最优。所以最后学得很快，训练结束时到了90%。</p></li>
</ul>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/2.png"></p>
<center>
Figure 3. 测试用例acc（每次测试10个集合）
</center>
<p>​ 上图中，在15k个epoch突然飙起来的橙色曲线是官方实现思路的MAB，很快就收敛了。深蓝色曲线则是我说的那个exponential LR训练结果。</p>
<p>​ 之后我换成Multi Step LR，开始200个epoch学习率很大，loss下降很快，[200,1000]内的学习率是上一阶段的1/10，此后则是1/100。看起来真的是学习率过大。此后其他的曲线都是学习率精调得到的结果。</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/4.png"></p>
<center>
Figure 4. 测试用例loss（每次测试10个集合）
</center>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/5.png"></p>
<center>
Figure 5. 训练用例loss
</center>
<p>​ 可以看到，灰色的曲线是最后一次的训练结果。也就是说，我的实现比官方实现训练次数多了好几倍，达到的acc之比官方高了个4%。</p>
<hr>
<h2 id="v.-funny-thing-about-transformer">V. Funny Thing about Transformer</h2>
<p>​ 谁让Vaswani起了一个倍具争议的名字呢？</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/a1.PNG"></p>
<p>​ 实名赞同楼上：</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/a3.PNG"></p>
<p>​ 赞同，但是我要提方案：</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/a2.PNG"></p>
<p>​ 我有些疑问：</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/a4.PNG"></p>
<p>​ 实名反对楼主：</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/a5.PNG"></p>
<p>​ 反对反对（nm啊，这名字真的很踢馆）</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/a6.PNG"></p>
<p>​ 我来折衷：</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/a7.PNG"></p>
<p>​ 注意力？小马宝莉（My Little Pony简称MLP）最强：</p>
<p><img src="/2021/08/20/%E5%85%B3%E4%BA%8E%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/a8.PNG"></p>
<p>​ 你们搞NLP的还挺有意思的。</p>
<hr>
<h2 id="reference">Reference</h2>
<ul>
<li><p><a href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need[C]//Advances in neural information processing systems. 2017: 5998-6008.</a></p></li>
<li><p><a href="http://proceedings.mlr.press/v97/lee19d.html">Lee J, Lee Y, Kim J, et al. Set transformer: A framework for attention-based permutation-invariant neural networks[C]//International Conference on Machine Learning. PMLR, 2019: 3744-3753.</a></p></li>
<li><p><a href="https://github.com/juho-lee/set_transformer">Github: juho-lee/set_transformer</a></p></li>
<li><p><a href="https://spaces.ac.cn/archives/4765/comment-page-1#Attention%E5%AE%9A%E4%B9%89">苏剑林的科学空间:《Attention is All You Need》浅读（简介+代码）</a></p></li>
</ul>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>前端小学习</title>
    <url>/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="front-end">Front-End</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​ 某天我回过头来看自己大一写的游戏，越玩越觉得制作尽量细节拉满（确实，不过估计是因为我大一非常闲，可以整天泡在写游戏里）。虽然如此，我还是觉得Pygame不适合做这个游戏，并且我觉得大一时的代码设计思想还不成熟，非常乱，想重构这个游戏。思来想去，用Unity（写了个弹珠打砖块游戏）觉得不爽，并且C#语言风格与C++类似，不想重复，遂想用一些（感觉上）完全不一样的语言去做这件事，最后确定用前端写网页游戏。前端说有趣，也还挺有趣的（毕竟我之前一直想当建筑设计师，搞设计的热情还是有的），但总感觉少了点深度思考（可能因为我接触的太简单）。为了在实践中学习前端，我将之前用Pygame实现的用户登录界面用JS升级了一下（只是功能升级，并没有更好看，见<a href="https://github.com/Enigmatisms/JSen">Github:Enigmatisms/JSen</a>），本文记录在做这个小小项目过程中遇到的一些问题。</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><img src="/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/5.png" style="zoom: 40%;"></th>
<th style="text-align: center;"><img src="/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/home.png"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Ethians Alpha 1.0 主菜单</td>
<td style="text-align: center;">一个（个人认为的）人性化的登录/注册网页</td>
</tr>
</tbody>
</table>
<center>
Figure 1. 目标 与 现阶段 发展不平衡之间的矛盾
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-html碎片知识">II. HTML碎片知识</h2>
<p><img src="/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/joke.png"></p>
<center>
Figure 2. href="html是编程语言!!!.com"
</center>
<p>​ 众所周知，HTML是编程语言（误）。作为一种标记语言，当然要去记其中的标记以及js中如何调用这些元素。这里只举一些简单的例子：</p>
<h3 id="控件元素">2.1 控件元素</h3>
<p>​ html5中有一些很有趣的"控件"，比如<code>button</code> （按键），<code>input</code> 文本输入框，<code>file</code>文件上传框等等。这些元素有共性，也有特殊的用法。比如button和input都可以 <code>focus</code> 以及 <code>blur</code>：</p>
<ul>
<li>focus：聚焦。对于input来说，focus函数会使得文本输入框像是被选中了一样（如果网页中存在focus之后的text输入框，那么键盘输入会直接出现在这个输入框中）。button的focus... 可能就是单纯的定位吧（使得网页翻页到button所在位置）。举个例子：可以写一个这样的功能，使得用户输入用户名后按<code>enter</code>键可以直接跳转到密码输入框上 ---&gt; 密码输入框.focus()</li>
<li>blur：focus的反义。举个例子：用户填写信息之后希望放弃本次填写，第一次<code>ESC</code>使得输入框不再被选中，第二次直接返回上一级。</li>
</ul>
<p>​ 对应的，有一些事件驱动的函数，比如<code>onkeyup</code>（用户按键抬起时的行为），<code>onclick</code>（点击时的行为），<code>onblur</code>（用户取消选中时的行为）。当然这很多都是和JS相关的。</p>
<p>​ 不同之处比如：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">value</span>=<span class="string">&quot;&quot;</span> <span class="attr">placeholder</span>=<span class="string">&quot;Username&quot;</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;password&quot;</span> <span class="attr">value</span>=<span class="string">&quot;&quot;</span> <span class="attr">placeholder</span>=<span class="string">&quot;Password&quot;</span>/&gt;</span></span><br></pre></td></tr></table></figure>
<p>​ text可以指定自己的类型，指定为password可以自动回显成:black_circle:，好，很有精神。</p>
<h3 id="name-class-id">2.2 name / class / id</h3>
<p>​ 怎么说呢，只能简单区分一下，因为我还没有遇到这三个的坑（触及本质的那种）。</p>
<ul>
<li>name：重名是完全可以的，一个html中可以有多个name属性为同一个值的元素。可以在js中使用：<code>getElementsByName</code>，注意element用了复数形式，返回的是一个NodeList（可以下标索引）。name方便了同种类型元素的类似操作。比如我写的那个 <strong><u>自动评教脚本</u></strong>。</li>
<li>id: 这玩意貌似是每个html文件唯一的，毕竟js方法是：<code>getElementById</code>：唯一表示了一个元素的存在（特化元素的好方法）。</li>
<li>class: 为什么要用class呢？感觉name处理了重复性，id处理了唯一性，class好像没事干。同一class可以有不同的name，同一name也可以有不同的class，class属性目前我在css中遇到过，css不方便定义一个name的样式，但是可以定义一个id的样式，而如果需要多元素统一样式，可以使用class。</li>
</ul>
<h3 id="span-div">2.3 span &amp; div</h3>
<div class="tabs" id="span-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#span-unique-name-1">span</a></li><li class="tab"><a href="#span-unique-name-2">div</a></li></ul><div class="tab-content"><div class="tab-pane active" id="span-unique-name-1"><p>​ &lt;span&gt;是内联元素，内部可以填充文本。内联元素的好处就是：我不换行显示。这样可以创建一些有name/id/class的文本而不换行（注意&lt;p&gt;也是换行的块级元素）。我把它用在了用户名或密码输入不符合要求时的提示信息显示上：</p>
<p><img src="/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/log5.png"></p>
<center>
Figure 3. span的应用（红色字体只会在输入不符要求时出现）
</center></div><div class="tab-pane" id="span-unique-name-2"><p>​ &lt;div&gt;元素是一个容器，非常常用，常见于网页的组织（相同功能的放一起，可以认为就是花括号了）。它是块级元素（这意味着它通常都是另起一行，并且结束后会换行的），所以不引入一些魔法（比如CSS组织）可能没办法让其不换行显示（可能只是我不知道而已）:</p>
<p><img src="/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/div.png"></p>
<center>
Figure 3. 很多div
</center></div></div></div>
<h2 id="iii.-css碎片知识">III. CSS碎片知识</h2>
<p>​ 我从来没有系统学过CSS（或者是HMTL，都是要用的时候学一点算一点）。虽然如此，我觉得其中有些内容还是有必要搞清楚的，毕竟也不能只会而不知道为什么。</p>
<center>
<img src="/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/css.jpg" style="zoom:80%;">
</center>
<center>
Figure 4. Game of Front-end Thrones
</center>
<h3 id="定位">3.1 定位</h3>
<p>​ css每个元素可以指定<code>position</code>，我接触过的只有其中三个（准确来说是四个，第四个<code>static</code>没有显式用过）：</p>
<ul>
<li><code>relative</code>：relative会保持正常的文档flow，比如写如下的代码：</li>
</ul>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">span</span><span class="selector-class">.relative</span> &#123;</span><br><span class="line">  <span class="attribute">position</span>: relative;</span><br><span class="line">  <span class="attribute">left</span>: <span class="number">0px</span>;</span><br><span class="line">  <span class="attribute">border</span>: <span class="number">3px</span> solid blue;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-tag">span</span><span class="selector-class">.test</span> &#123;</span><br><span class="line">  <span class="attribute">position</span>: relative;</span><br><span class="line">  <span class="attribute">left</span>: <span class="number">0px</span>;</span><br><span class="line">  <span class="attribute">border</span>: <span class="number">3px</span> solid blue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 根据以上的CSS代码在body中放置两个同级的span：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;relative&quot;</span>&gt;</span>This div element has position: relative;<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;test&quot;</span>&gt;</span>This div element has position: relative;<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>​ 结果是这样的：</p>
<p><img src="/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/rel.png"></p>
<center>
Figure 5. 双relative
</center>
<p>​ 说明文档flow（元素的先后位置关系）没有被破坏。</p>
<ul>
<li><code>absolute</code>则是绝对定位：它会将元素从文档flow中取出，比如将上面<code>span.text</code>的position属性改为<code>absolute</code>会得到这样的结果：</li>
</ul>
<p><img src="/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/abs.png"></p>
<p>​ 本来<code>span.test</code>这个inline元素应该跟随在<code>span.relative</code>的后面，但是由于<code>test</code>从flow中单独提取出来了，它相对于其最邻近的relative父级元素（本例子中就是&lt;body&gt;）定位。</p>
<p>​ 注意，如果需要使用absolute定位，其定位方式是相对于 <strong><u>最邻近的relative 父级元素</u></strong>。</p>
<h3 id="显示">3.2 显示</h3>
<p>​ <code>display</code>可以有这样四种常用的选项：<code>none</code>, <code>inline-block</code>，<code>inline</code>, <code>block</code></p>
<ul>
<li><code>none</code>：元素不被渲染，不占空间。不像<code>visibility: hidden</code>一样，<code>hidden</code>的元素虽然看不见，但是也占位置</li>
<li><code>inline-block</code>:
<ul>
<li>与<code>inline</code>不同之处在于：它可以设置行内元素的width height以及margin（相当于一个不添加换行符的小block）</li>
<li>与<code>block</code>不同之处在于：已经说了，它不会换行显示</li>
</ul></li>
</ul>
<h3 id="子元素选择">3.3 子元素选择</h3>
<p>​ 这里只简单记录使用到的一些语法（我其实也并没有仔细去学的打算，前端学习工作的优先级很低）</p>
<ul>
<li><code>#</code> 可以直接指定id，比如<code>#first</code> 将会指定<code>id = first</code>元素的样式</li>
<li><code>.</code>是class selector，可以不指定元素：比如下代码块第一行，也可以指定元素：比如第二行</li>
</ul>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.classname</span> &#123;...&#125;		<span class="comment">/* 表示所有 class = &quot;classname&quot;的元素*/</span></span><br><span class="line"><span class="selector-tag">span</span><span class="selector-class">.classname</span> &#123;...&#125;		<span class="comment">/* 表示 span的class = &quot;classname&quot;的元素*/</span></span><br></pre></td></tr></table></figure>
<p>​ 有些有趣的例子可以看这篇文章说的: <a href="https://css-tricks.com/multiple-class-id-selectors/">Difference between "#header .class" &amp; "#header.class"</a></p>
<h2 id="iv.-js碎片知识">IV. JS碎片知识</h2>
<h3 id="浏览器端js与服务器端js">4.1 浏览器端js与服务器端js</h3>
<p>​ 本人还并没有开始Node.js的学习，只是了解了以下浏览器端JS的写法。开始时我还不知道这两者有什么区别，直到遇上了这么一个问题：</p>
<blockquote>
<ul>
<li>Log 5.0希望可以从本地加载用户数据，以便sign in时可以比对用户。</li>
<li>Sign up时可以写出到本地文件</li>
</ul>
</blockquote>
<p>​ 查了好久，都没有发现有什么接口可以帮我读出或者写入到本地文件的。最后面向Google，有人说：浏览器上运行的JS出于安全性考虑，是不允许写入和读取本地数据的，如果需要实现文件操作，最好使用一个服务器host的文件。实际上这就不是很前端了。</p>
<p>​ 而Node.js 本质上是后端语言（只不过可以使用JS这个前端语言编辑），Node.js常用于服务器端，它没有：</p>
<ul>
<li>BOM（Browser Object Model）：对浏览器进行访问和操作的模型。也就是说，<code>window</code>这个没有了</li>
<li>DOM （Document Object Model）： <code>document</code>以及其下属元素也没有了</li>
</ul>
<p>​ 原来本人上手用浏览器端js，但想做一些后端的事情。</p>
<div class="note danger"><p>学习语言这样的东西时，我延续了Python/C++的学习方式：上手就是自行设计项目并通过实践来学习。这种学习方式有的时候可能并不好，特别是在其前驱知识不牢固的情况下。不看理论、教程、文档可能只能让我们明白 <strong><u>如何解决问题</u></strong> 而不是 <strong><u>如何分析问题并设计方法</u></strong>。</p>
</div>
<h3 id="本地服务器小坑">4.2 本地服务器小坑</h3>
<p>​ 我们已知浏览器出于安全考虑，不能随便加载本地文件这一事实。加载本地文件不一定要是进行数据的读入或者写出，比如最基本的 <strong><u>跨模块调（引）用</u></strong> 都属于一种加载本地文件的行为。比如我有两个文件：<code>a.js</code> 以及<code>b.js</code>，其中：</p>
<ul>
<li><code>a.js</code>相当于一个utility模块，定义了很多有趣的常用函数</li>
<li><code>b.js</code>相当于一个客户模块，需要使用<code>a.js</code>的函数</li>
<li><code>c.html</code>调用了<code>b.js</code>模块（作为网页的行为）</li>
</ul>
<p>​ 那么这涉及到import与export。但是由于基于本地文件的import, export是不允许的（本质是加载本地文件），如果直接在本地使用文件打开，会报如下的错误：</p>
<p><img src="/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/error.png"></p>
<center>
Figure x. CORS错误 无法加载特定的本地文件
</center>
<p>​ 但是如果我使用服务器，将<code>c.html</code>定义的网站挂在上面，再使用服务器对应的url访问网页时并不会有文件访问限制。这实际上涉及到两个协议以及一个policy：</p>
<div class="note info"><p>​ 双击html文件可以直接打开为网页，此处使用的是file protocol，打开网页时浏览器url显示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">file:///&lt;path to your file&gt;</span><br></pre></td></tr></table></figure>
</div>
<div class="note success"><p>​ 使用服务器也可以加载网页，此时使用http(s)协议，按照个人的理解，一次http请求访问大概是这样的流程：</p>
<ul>
<li>域名解析：用户输入url，url经过DNS服务转为IP返回给用户</li>
<li>三次握手：由于http（是应用层的）在传输层上使用TCP/IP协议，故需要握手建立连接</li>
<li>网站服务器通过http协议回传html、css、javascript等文件到本地</li>
<li>本地浏览器解析html等文件，渲染网页</li>
</ul>
</div>
<p>​ 虽然乍一看，两种方式并没有本质上的区别，都是通过某种方式获得网页文件，在本地进行渲染，那么对于文件访问这种事情，本来不应该有区别的。但本地访问却受到如上图所说的 CORS policy限制：</p>
<blockquote>
<p><strong><u>C</u></strong>ross-<strong><u>O</u></strong>rigin <strong><u>R</u></strong>esource <strong><u>S</u></strong>haring (CORS) is an HTTP-header based mechanism that allows a server to indicate any origins (domain, scheme, or port) other than its own from which a browser should permit loading resources.[1]</p>
</blockquote>
<p>​ 与之相对的一个概念叫做：Same-origin policy，关于same origin policy，这篇文章讲得很清楚: <a href="https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy">MDN Web Docs: Same Origin Policy</a>. 这个policy的大概意思是说，【协议（比如同http或者同https）】【端口】【host】三者必须相同。而本地打开的文件，并没有host，也没办法做到host相同。并且有人这么说：</p>
<blockquote>
<p>Chrome doesn't believe that there's any common relationship between any two local files.[2]</p>
</blockquote>
<p>​ 除了在浏览器中直接disable此安全设置，否则没办法直接绕开（事实上，我觉得绕开也非常不优雅）。假如不绕开，那就只有一个选择了，使用服务器host我们的网页。于是我写了一个http server：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Use to create local host</span></span><br><span class="line"><span class="keyword">import</span> http.server</span><br><span class="line"><span class="keyword">import</span> socketserver</span><br><span class="line">PORT = <span class="number">8080</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NoCacheHTTPRequestHandler</span>(</span><br><span class="line">    http.server.SimpleHTTPRequestHandler</span><br><span class="line">):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">send_response_only</span>(<span class="params">self, code, message=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().send_response_only(code, message)</span><br><span class="line">        self.send_header(<span class="string">&#x27;Cache-Control&#x27;</span>, <span class="string">&#x27;no-store, must-revalidate&#x27;</span>)</span><br><span class="line">        self.send_header(<span class="string">&#x27;Expires&#x27;</span>, <span class="string">&#x27;0&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    NoCacheHTTPRequestHandler.extensions_map.update(&#123;<span class="string">&quot;.js&quot;</span>: <span class="string">&quot;application/javascript&quot;</span>,&#125;)</span><br><span class="line">    httpd = socketserver.TCPServer((<span class="string">&quot;&quot;</span>, PORT), NoCacheHTTPRequestHandler)</span><br><span class="line">    httpd.timeout = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            httpd.handle_request()</span><br><span class="line">        <span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">            httpd.server_close()</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>​ 实际上代码并不是我写的，代码是我从两个Stackoverflow回答中整理出来的（非常抱歉，这两个回答我也不记得来源了，太久远了）。其中第一个回答只是python3的http request server（stackoverflow上有人回答了用python2设置的本地http服务器，下面就有个哥们把他代码改成python3了）。然而我发现初版代码有个很大的问题：这tm打开服务器就关不掉了，我记得当时作者调用了个这玩意：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">httpd.serve_forever()</span><br></pre></td></tr></table></figure>
<p>​ <code>Ctrl + C</code>根本关不掉，而平台又是windows，没办法<code>Ctrl + Z</code>再<code>kill %1</code>，非常烦。于是我google（如何才能让http server不阻塞呢？（因为我发现server每次<code>Ctrl + C</code>没有反应是因为阻塞在一个奇怪的循环里）），最后找到别人写的<code>NoCacheHTTPRequestHandler</code>，再设置一下timeout就可以很方便关闭了。</p>
<p>​ 为什么要关闭呢？这里有个我没明白原理的坑：每次我不关闭server，或者没有完全关闭（可能只是挂起了），在修改js代码后刷新网页或者重新访问是不会更新行为的。我怀疑是它端口一直开着，使用的是cache过的网页，故js代码更新并不会引起网页行为的更新。</p>
<h3 id="export-import">4.3 export &amp; import</h3>
<p>​ 我一开始以为export以及import的使用就会像我每天早上起床一样简单（确实很简单），但实际上export与import只在解决完http服务器问题之后才开始用（本地file协议根本是不允许的，两个js文件origin都是null，没办法互相访问，除非在html中使用丑陋的全局变量）。</p>
<p>​ 但是export与import我遇到了default 以及non-default (name imports) 问题。</p>
<p>​ 首先，import export必须要在 <code>module</code>中使用。module与一般的js文件不同，在引入html时，需要定义（<strong><u>type=</u></strong>）：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;module&quot;</span> <span class="attr">src</span>=<span class="string">&quot;xxx.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>​ 比如在我的练手小项目里：<code>common.js</code>定义了一些多个js文件可以共用的函数，其中一个js文件如<code>signin_modules.js</code>调用了<code>common.js</code>中的一些函数或类，html文件直接加载的是<code>signin_modules.js</code>，那么<code>signin_modules.js</code>就必须是一个module。我开始觉得很疑惑，为什么<code>signin_modules.js</code>是module？不应该是<code>common.js</code>是一个 <strong><u>模块</u></strong> 才对么？实际上，<code>signin_modules.js</code>（使用import的js）是top level module，其他的被引用文件都是底层module。import处定义了module，被引用的文件会自动变为lower level modules。如果不加<code>type=module</code>将会报错：</p>
<blockquote>
<p>SyntaxError: import declarations may only appear at top level of a module.</p>
</blockquote>
<p>​ 其次，是named以及default的区别。</p>
<div class="tabs" id="onetab-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#onetab-unique-name-1">named import/export</a></li><li class="tab"><a href="#onetab-unique-name-2">default import/export</a></li></ul><div class="tab-content"><div class="tab-pane active" id="onetab-unique-name-1"><p>​ named import因为带有变量（或者自定义类型）名，故可以同时调入/调出多个元素。但要记住，named一定需要使用花括号包住！</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123;bar, fool&#125; <span class="keyword">from</span> <span class="string">&quot;module name&quot;</span></span><br></pre></td></tr></table></figure>
<p>​ 不管是引入一个还是多个，都需要使用花括号包住。</p></div><div class="tab-pane" id="onetab-unique-name-2"><p>​ default import/export 的好处就是不需要提供名字，但这也导致了每个module只能有一个default import/export。default情况下不要使用花括号。当然，也可以把default写出来：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> some_value;			<span class="comment">// default可有可无，但花括号一定无</span></span><br></pre></td></tr></table></figure></div></div></div>
<p>​ 搞错了default/named的结果（并且还不知道这个机制），就是会找不到模块中的错误（之前搞错了一直以为模块中定义有问题）。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS">MDN Web Docs: Cross-Origin Resource Sharing (CORS)</a></p>
<p>[2] <a href="https://coderedirect.com/questions/104753/origin-null-is-not-allowed-by-access-control-allow-origin-in-chrome-why">Code Redirect: "Origin null is not allowed by Access-Control-Allow-Origin" in Chrome. Why?</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>JavaScript</tag>
        <tag>前端开发</tag>
      </tags>
  </entry>
  <entry>
    <title>协方差 &amp; 特征值的交集</title>
    <url>/2021/03/12/%E5%8D%8F%E6%96%B9%E5%B7%AE-%E7%89%B9%E5%BE%81%E5%80%BC%E7%9A%84%E4%BA%A4%E9%9B%86/</url>
    <content><![CDATA[<h1 id="eigens-covs">Eigens &amp; Covs</h1>
<hr>
<p>​ 线性代数确实很有趣，但是展开成<span class="math inline">\(\sum\)</span>的形式就没有趣了。本文意在分析矩阵特征值在某些场合下的应用以及一些线性代数结论（特别是矩阵/向量求导）（烦人的分子分母布局）。</p>
<p><img src="/2021/03/12/%E5%8D%8F%E6%96%B9%E5%B7%AE-%E7%89%B9%E5%BE%81%E5%80%BC%E7%9A%84%E4%BA%A4%E9%9B%86/stitch.jpg"></p>
<center>
Figure 1. 2D-2D单应匹配
</center>
<span id="more"></span>
<hr>
<h2 id="矩阵特征量与法向量估计">矩阵特征量与法向量估计</h2>
<p>​ 对于一个给定矩阵A而言，其特征方程是： <span class="math display">\[
\begin{equation}\label{eigen}
\begin{array}{l}
A\pmb{x}=\lambda\pmb{x}\\
(I-\lambda A)\pmb{x}=\pmb{0}
\end{array}
\end{equation}
\]</span> ​ 以上两个式子定义实际是同一个意思，只不过写法不同。如何理解特征（eigen）量呢？对于特征向量<span class="math inline">\(\pmb{x}\)</span>，在矩阵A的映射下（线性变换），会导致<span class="math inline">\(\pmb{x}\)</span>的方向完全不变（可能反向）。而另一方面，空间变换与矩阵运算的联系也有着紧密的联系，比如3 * 3矩阵就能完全表征二维平面上的平移以及旋转。实际上 3 * 3矩阵能表示任何的透视（perspective）变换： <span class="math display">\[
\begin{equation}
(x&#39;,y&#39;,z&#39;)^T=\begin{pmatrix}
a_{11} &amp; a_{12} &amp; a_{13} \\
a_{21} &amp; a_{22} &amp; a_{23} \\
a_{31} &amp; a_{32} &amp; a_{33}
\end{pmatrix}\begin{pmatrix}
x \\
y \\
z
\end{pmatrix}
=A\pmb{x}
\end{equation}
\]</span> ​ 那么对A可以求其特征量。这些特征量表征的是什么呢？为了简单以及便于人类进行空间想象，以下讨论主要集中于二维矩阵与三维矩阵的讨论。</p>
<h3 id="二维直线法向量估计">二维直线法向量估计</h3>
<p>​ 实际上，在二维的情况下，估计法向量与估计直线是同一个问题。假设有一堆点，如下图所示，存在噪声并且由于实际表面是个曲面，需要选择一个合理的范围，利用范围内点的信息进行法向量估计：</p>
<p><img src="/2021/03/12/%E5%8D%8F%E6%96%B9%E5%B7%AE-%E7%89%B9%E5%BE%81%E5%80%BC%E7%9A%84%E4%BA%A4%E9%9B%86/normal.JPG"></p>
<center>
Figure 2. 2D法向量估计
</center>
<p>​ 我们需要估计一条直线（法向量形式）： <span class="math display">\[
\begin{equation}\label{normal}
a^T\pmb{x}-b=0
\end{equation}
\]</span> ​ 那么对于n个离散的点<span class="math inline">\((x_i,y_i)\rightarrow\pmb{x}_i\)</span>，如果能找到参数<span class="math inline">\(a,b\)</span>使得： <span class="math display">\[
\begin{equation}\label{res1}
|b-a^T\pmb{x}|
\end{equation}
\]</span> ​ 这是由需要估计的参数直线<span class="math inline">\(\eqref{normal}\)</span>决定的，那么可以将<span class="math inline">\(\eqref{res1}\)</span>化为模平方的形式，这也就是我们需要优化的目标，实际上点的信息已经包含在直线中了，虽然没有写成常见的直线拟合最小二乘表示： <span class="math display">\[
\begin{equation}\label{cost}
C=\sum_i(b-a^T\pmb{x})^T(b-a^T\pmb{x})
\end{equation}
\]</span> ​ 加上约束，可以得到一个带约束优化问题。约束是：<span class="math inline">\(a^Ta=1\)</span>。也就是说希望法向量是单位向量： <span class="math display">\[
\begin{equation}
\left\{
\begin{array}{ll}\label{obj}
\text{min }\sum_i(b-a^T\pmb{x})^T(b-a^T\pmb{x}) \\
\text{s.t. } a^Ta=1
\end{array}
\right.\rightarrow
\text{min }\sum_i(b-a^T\pmb{x})^T(b-a^T\pmb{x}) + \lambda(a^Ta-1)\\
\end{equation}
\]</span> ​ 也就是又用Lagrange乘子法将有约束问题转化为无约束问题了。对KKT条件进行讨论，等式约束的KKT条件就不用说了。对<span class="math inline">\(a\)</span>求导，有（这里有必要穿插一下矩阵与向量的求导知识）。如果x是一个 n * 1的列向量，那么一个关于x的标量函数关于x求导，求出将会是一个行向量。进一步地，可以证明（见<a href="#app">【Appendix】</a>）： <span class="math display">\[
\begin{equation}\label{lemma}
\begin{array}{ll}
\text{if }\alpha=x^TAx,\text{where }A\text{ is }n \times n \\
\text{then } \frac{\partial\alpha}{\partial x}=x^T(A+A^T)
\end{array}
\end{equation}
\]</span> ​ 那么根据公式<span class="math inline">\(\eqref{lemma}\)</span>，并且对<span class="math inline">\(\eqref{obj}\)</span>进行关于a（2 * 1列向量）求导，此处求导的结果是： <span class="math display">\[
\begin{equation}\label{der}
2\lambda a^T-2bn\overline{x}^T+\sum_{i=1}^n2a^T(x_ix_i^T)
\end{equation}
\]</span> ​ 而对b求导实际上也能得到重要的结论：即<span class="math inline">\(b=a^T\overline{x}\)</span>，那么带入到公式<span class="math inline">\(\eqref{der}\)</span>中就会有： <span class="math display">\[
\begin{equation}\label{der2}
2\lambda a^T+2a^T\sum_{i=1}^n(x_ix_i^T)-(\overline{x}\overline{x}^T)=2\lambda a^T+2a^T\sum_{i=1}^n(x_i-\overline{x})(x_i-\overline{x})^T
\end{equation}
\]</span> ​ 而<span class="math inline">\(\eqref{der2}\)</span>的右半部分求和式实际上是点集的协方差，最后也就得到了（忽略负号给<span class="math inline">\(\lambda\)</span>代来的影响）： <span class="math display">\[
\begin{equation}\label{eig}
\left(\sum_{i=1}^n(x_i-\overline{x})(x_i-\overline{x})^T\right)a=\lambda a
\end{equation}
\]</span> ​ 也就是说，<span class="math inline">\(\lambda\)</span>为点集协方差矩阵的一个特征值，而<span class="math inline">\(a\)</span>则为对应的特征向量。也就是说，<span class="math inline">\(a\)</span>（法向量）的解实际上是点集协方差的一个特征向量，但是对于二维问题而言，特征向量有两个（一个最大特征向量，一个最小特征向量）。那么显然，根据<span class="math inline">\(\eqref{eig}\)</span>以及<span class="math inline">\(b=a^T\overline{x}\)</span>，带入到目标函数<span class="math inline">\(\eqref{obj}\)</span>中可以得到： <span class="math display">\[
\begin{equation}
L=0+\sum_{i=1}^n[a^T(x_i-\overline{x})][a^T(x_i-\overline{x})]^T=n\lambda
\end{equation}
\]</span> ​ 可以知道，<span class="math inline">\(\lambda\)</span>应该选择最小特征值。那么<span class="math inline">\(a\)</span>的解就是最小特征值对应的特征向量。感觉这个过程就十分的精妙，主要是要完全利用KKT条件，一个都不能漏，并且有意识地构造协方差 / 均值以及<span class="math inline">\(x^Tx / xx^T\)</span>两种形式。<strong><u>不难发现</u></strong>，这种表示形式可以自然推广到三维空间中去，此时求取的不再是直线的法向量，而是平面的法向量。</p>
<hr>
<h2 id="d图像配准闭式解">2D图像配准闭式解</h2>
<p>​ 考虑一个2D问题，两幅图像的配准。假设我们通过SIFT算子 + RANSAC优化，得到了准确的特征点配对关系，那么如何求这个单应矩阵呢？</p>
<div class="note warning"><p>​ 实际上，纯2D-2D匹配并不能称为单应矩阵（单应矩阵是同一物体3D-3D投影变换的表征）</p>
</div>
<p>​ 考虑简单的仿射变换，假设仿射变换矩阵为<span class="math inline">\(H\)</span>，给定source点集与target点集： <span class="math display">\[
\begin{equation}
P=(p_1,p_2,...p_n),Q=(q_1,q_2,...,q_2),P,Q\in \mathbb{R}^{3\times n}
\end{equation}
\]</span> ​ 那么假设<span class="math inline">\(HP=Q\)</span>,也即点集<span class="math inline">\(P\)</span>经过变换<span class="math inline">\(H\)</span>后直接成了<span class="math inline">\(Q\)</span>，那么为了使变换后的投影误差最小，考虑最小二乘问题： <span class="math display">\[
\begin{equation}
L=\Vert HP-Q\Vert^2=tr[(HP-Q)^T(HP-Q)]\Longleftrightarrow tr[(HP-Q)(HP-Q)^T]
\end{equation}
\]</span> ​ 那么根据矩阵迹的求导（以下性质将在<a href="#app">【Appendix】</a>中进行简要的分析）</p>
<table>
<colgroup>
<col style="width: 6%">
<col style="width: 45%">
<col style="width: 47%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">性质</th>
<th>结论（分母布局）</th>
<th>分子布局</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">轮换性</td>
<td><span class="math inline">\(tr(ABC)=tr(BCA)\)</span></td>
<td><span class="math inline">\(tr(ABC)=tr(BCA)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">线性1</td>
<td><span class="math inline">\(\frac{\partial tr(A^TB)}{\partial A}=B\)</span></td>
<td><span class="math inline">\(\frac{\partial tr(A^TB)}{\partial A}=B^T\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;">线性2</td>
<td><span class="math inline">\(\frac{\partial tr(AB)}{\partial A}=B^T\)</span></td>
<td><span class="math inline">\(\frac{\partial tr(AB)}{\partial A}=B\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">二次型1</td>
<td><span class="math inline">\(\frac{\partial tr(ABA^T)}{\partial A}=A(B+B^T)\)</span></td>
<td><span class="math inline">\(\frac{\partial tr(ABA^T)}{\partial A}=(B+B^T)A^T\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;">二次型2</td>
<td><span class="math inline">\(\frac{\partial tr(A^TBA)}{\partial A}=(B+B^T)A\)</span></td>
<td><span class="math inline">\(\frac{\partial tr(A^TBA)}{\partial A}=(B+B^T)A^T\)</span></td>
</tr>
</tbody>
</table>
<p>​ 可以得到： <span class="math display">\[
\begin{equation}\label{H}
\frac{\partial \text{ tr}[(HP-Q)(HP-Q)^T]}{\partial H}=2HPP^T-2QP^T=0
\end{equation}
\]</span> ​ 则可以得到：<span class="math inline">\(H=QP^T(PP^T)^{-1}\)</span>是解。其中<span class="math inline">\((PP^T)^{-1}\)</span>是伪逆，由于其行列式可能为0。可以用SVD分解得到，正常情况则使用LDLT进行分解即可。</p>
<hr>
<h2 id="appendix">Appendix</h2>
<p><span id="app"></span></p>
<h3 id="向量矩阵求导法则以及基本结论证明">向量矩阵求导法则以及基本结论证明</h3>
<p>​ 这里涉及的都是基本的线性代数（以及高数中的多元函数Jacobian求解），但是自己从来认真推过。向量矩阵求导主要分析其中几个公式：</p>
<h4 id="基本法则">基本法则</h4>
<ul>
<li>标量对行向量求导，结果是行向量（朴素结论）</li>
<li>标量对列向量求导，结果是列向量（朴素结论）</li>
<li>标量对矩阵，结果是同样大小的矩阵，并且每个元素与求导矩阵对应（朴素结论）</li>
</ul>
<h4 id="行列求导">行列求导</h4>
<p>​ 行向量对列向量求导，结果显然是个雅可比，由于求导元素是列向量，那么雅可比矩阵是按列组织的： <span class="math display">\[
\begin{equation}
d(y_1,y_2,...,y_n)/d
\begin{pmatrix}
x_1\\
x_2\\
\vdots \\
x_m
\end{pmatrix}=
\begin{pmatrix}
\frac{\partial y_1}{\partial x_1} &amp; \frac{\partial y_2}{\partial x_1} &amp; ... &amp; \frac{\partial y_1}{\partial x_1}\\
\frac{\partial y_1}{\partial x_2} &amp; \frac{\partial y_2}{\partial x_2} &amp; ... &amp; \frac{\partial y_1}{\partial x_2} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
\frac{\partial y_1}{\partial x_m} &amp; \frac{\partial y_2}{\partial x_m} &amp; ... &amp; \frac{\partial y_1}{\partial x_m}
\end{pmatrix}
\end{equation}
\]</span> ​ 则反之，如果是列向量对行向量求导，那么将会是上矩阵的转置。注意，上式我写的是分母布局，之后我将完全使用分子布局，因为比较自然。分子布局与分母布局的区别是：</p>
<ul>
<li>分子布局：如果f是个列向量，x是个标量，那么<span class="math inline">\(\frac{\partial f}{\partial x}\)</span>为列向量（自然表达）</li>
<li>分母布局：如果f是个标量，x是个列向量，那么<span class="math inline">\(\frac{\partial f}{\partial x}\)</span>是个列向量（感觉不太自然嗷）</li>
</ul>
<p>​ 也就是说，列向量对标量求导是不变形的，矩阵对标量求导也是不变形的（那么自然，行向量对标量求导也不变形，这就是一个比较自然的表达）。接下来讨论的公式都基于几个共同点：</p>
<ul>
<li>向量<span class="math inline">\(\pmb{x}\)</span>是列向量（n * 1）
<ul>
<li>矩阵A是m * n矩阵或是n * n矩阵79</li>
</ul></li>
</ul>
<p><span class="math display">\[
\begin{equation}
\frac{\partial A\pmb{x}}{\partial \pmb{x}}=A\tag{prop 1}
\end{equation}
\]</span></p>
<p>​ 这个很显然，讨论<span class="math inline">\(A\pmb{x}\)</span>时只需要将A按行分块，<span class="math inline">\(A\pmb{x}\)</span>每个元素都是<span class="math inline">\(\pmb{a}_j\pmb{x}\)</span>（标量），那么一个列向量<span class="math inline">\(A\pmb{x}\)</span>中的每个标量元素对列向量求导，得到一个行向量： <span class="math display">\[
\begin{equation}
\pmb{a}_j\pmb{x}=\sum_{i=1}^na_{ji}x_i
\end{equation}
\]</span> ​ 显然，对这个标量求导得到<span class="math inline">\(\pmb{a}_j\)</span>本身。 <span class="math display">\[
\begin{equation}
\frac{\partial \pmb{x}^TA\pmb{x}}{\partial \pmb{x}}=\pmb{x}^T(A+A^T)\tag{prop 2}
\end{equation}
\]</span> ​ 展开之后易于证明，由于<span class="math inline">\(\pmb{x}^TA\pmb{x}\)</span>是标量，标量对列向量求导是行向量，可以得到，行内的第j个元素为： <span class="math display">\[
\begin{equation}
\sum_{i=1}^na_{ji}x_i+\sum_{j=1}^na_{ji}x_j
\end{equation}
\]</span> ​ 上式前半部分是行向量<span class="math inline">\(\pmb{x}^T\)</span>与矩阵<span class="math inline">\(A^T\)</span>的某一列进行相乘，后半部分则与<span class="math inline">\(A\)</span>的某一列相乘。<span class="math inline">\(\text{prop 2}\)</span>的证明又是比较容易的，可以根据基本的求和式与矩阵运算性质得到，关于矩阵行列求导操作，就只提这两个。</p>
<h3 id="矩阵迹的求导法则">矩阵迹的求导法则</h3>
<p>​ 迹是针对n * n矩阵而言的（对角线之和），假设<span class="math inline">\(A_{n\times k},B_{k\times n}\)</span>，则<span class="math inline">\(\text{tr}(AB)\)</span>有： <span class="math display">\[
\begin{equation}\label{tr}
\text{tr}(AB)=\sum_{i=1}^n\sum_{j=1}^ka_{ij}b_{ji}
\end{equation}
\]</span> ​ 那么假设<span class="math inline">\(\text{tr}(AB)\)</span>对A求导，由分子布局，将A看成一个行向量，每个行元素为一个列向量。可以知道，分子布局下，标量对行求导，得到列向量，列向量的元素将由原来行向量内的元素决定。那么由于原来行向量（1 * k）元素是一个个的列向量（n * 1），那么求导后的每个分量是个行向量（1 * n），也即最后的结果是（k * n）的，下面证明这就是矩阵B。</p>
<p>​ 我们假设当前正在对行向量<span class="math inline">\(A\)</span>的元素<span class="math inline">\(\pmb{a}_p\)</span>进行求导，<span class="math inline">\(\pmb{a}_p=(a_{1p},a_{2p},...,a_{np})^T\)</span>是A矩阵的第p列。那么由公式<span class="math inline">\(\eqref{tr}\)</span>，迹中与<span class="math inline">\(a_{ip}\)</span>有关的只有： <span class="math display">\[
\begin{equation}
\sum_{i=1}^na_{ip}b_{pi}
\end{equation}
\]</span> ​ 对其求导，由于上式是一个标量而<span class="math inline">\(\pmb{a}_p\)</span>是一个列向量，应该得到一个行向量结果 <span class="math display">\[
\begin{equation}
\sum_{i=1}^na_{ip}b_{pi}\mathop{\Longrightarrow}^{d\pmb{a}_p}(b_{p1},b_{p2},...,b_{pn})
\end{equation}
\]</span> ​ 也就是说，矩阵迹对<span class="math inline">\(A\)</span>矩阵的第p个列求导，得到B的第p行。那么由此可以得到<span class="math inline">\(d\text{ tr}(AB)/dA=B\)</span>。（注意，这和我们上面所列表格不一致，表格是分母布局的，分母布局下这里确实是<span class="math inline">\(B^T\)</span>）。分母布局和分子布局恰是转置关系，那么公式<span class="math inline">\(\eqref{H}\)</span>在分子布局下应该是不变的（因为减号前后都进行了转置）。</p>
<p></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title>滤波＆卡尔曼</title>
    <url>/2021/05/31/%E6%BB%A4%E6%B3%A2%EF%BC%86%E5%8D%A1%E5%B0%94%E6%9B%BC/</url>
    <content><![CDATA[<h1 id="filtering-kalman">Filtering &amp; Kalman</h1>
<hr>
<h2 id="i.-引入">I. 引入</h2>
<p>​ 2021赛季充分认识到滤波的美妙之处。虽然只前学了DSP，但是在进行实际系统控制的时候，很少有意识地进行滤波或者平滑。2020赛季中设置过一个静止目标滑动平均，在此前没有做过非常大量的滤波。</p>
<p><img src="/2021/05/31/%E6%BB%A4%E6%B3%A2%EF%BC%86%E5%8D%A1%E5%B0%94%E6%9B%BC/disp-1622393689154.png"></p>
<center>
Figure 1. 单方向ARKF滤波预测
</center>
<p>​ 本文是对近段时间使用的滤波方法进行的一个比较肤浅的总结，包括：</p>
<ul>
<li>ARKF（自适应抗差KF）</li>
<li>MEE &amp; CMEE（约束最小误差熵KF）</li>
<li>ESKF（Error State KF）</li>
</ul>
<span id="more"></span>
<hr>
<h2 id="ii.-arkf">II. ARKF</h2>
<h3 id="理论分析">2.1 理论分析</h3>
<h4 id="抗差">2.1.1 抗差</h4>
<p>​ ARKF[1]是很老的工作了，大创答辩的时候老师还特地问我为什么要引那么老的文献（1999，比我还大）（小声：但人家简单有效啊）。我已经在<a href="https://enigmatisms.github.io/2021/04/03/%E4%BC%98%E9%9B%85%E7%BA%BF%E4%BB%A3%E4%B8%8E%E7%BE%8E%E5%A6%99%E4%BC%98%E5%8C%96/">[优雅线代与美妙优化]</a>一文中说了，卡尔曼滤波是怎么与最小二乘联系起来的。这里简单回顾一下： <span class="math display">\[
\begin{equation}\label{lsp}
W(k){x}(k)+\xi(k)=Y(k)
\end{equation}
\]</span> ​ 其中<span class="math inline">\(W(k)\)</span>（实际是上面那篇博客中提到的<span class="math inline">\(X(k)\)</span>，但是<span class="math inline">\(X\)</span>用于表示非状态矩阵，容易与<span class="math inline">\(x\)</span>发生冲突）以及<span class="math inline">\(Y(k)\)</span>的意义直接看上面提到的博文吧。<span class="math inline">\(\xi(k)\)</span>则是状态转移噪声 / 观测噪声concatenation的白化变换。我们提到，KF实际上是根据<span class="math inline">\(\eqref{lsp}\)</span>进行MSE最小化的过程。</p>
<p>​ 但是MSE在很多问题下的表现并不好，特别是外点很多的时候。想想在最小二乘直线拟合的时候，一个外点就能让直线拟合出来的参数变得比原来离谱很多，这是由于误差函数的性质决定的：MSE对偏差大的数据产生的cost是平方级别的cost，而Huber则是线性的cost。</p>
<center>
<img src="/2021/05/31/%E6%BB%A4%E6%B3%A2%EF%BC%86%E5%8D%A1%E5%B0%94%E6%9B%BC/huber.png" style="zoom:72%;">
</center>
<center>
Figure 2. Huber函数和MSE
</center>
<p>​ 这就决定了Huber函数存在一定的外点鲁棒性，对于外点多的数据，Huber函数的KF将会更加稳定。但是很可惜，由于Huber函数的表达式比MSE复杂，并且原始Huber函数是存在非线性的（if判定，虽然导数以及原函数是连续的），我个人没有推出其解析解（我也没推，我也不会Mathematica），所以对于公式<span class="math inline">\(\eqref{lsp}\)</span>定义的“状态转移”，由于公式<span class="math inline">\(\eqref{lsp}\)</span>展开是： <span class="math display">\[
\begin{equation}\label{optim}
\begin{pmatrix}
I\\
H
\end{pmatrix}\breve{x}(k)=
\begin{pmatrix}
A\hat{x}(k-1)\\
z(k)
\end{pmatrix} +
\begin{pmatrix}
w(k)\\
v(k)
\end{pmatrix}=
\begin{pmatrix}
A\hat{x}(k-1)\\
z(k)
\end{pmatrix} + E(k)
\end{equation}
\]</span> ​ 其中'<span class="math inline">\(\breve{}\)</span>'表示先验，'<span class="math inline">\(\hat{}\)</span>'表示后验，我们需要估计的是公式<span class="math inline">\(\eqref{optim}\)</span>中的<span class="math inline">\(\breve{x}(k)\)</span>（也就是KF需要估计的当前状态，实际就是公式<span class="math inline">\(\eqref{lsp}\)</span>的<span class="math inline">\(x(k)\)</span>），那么<span class="math inline">\(x(k)\)</span>可以写为： <span class="math display">\[
\begin{equation}\label{optim2}
x(k)^*=\mathop{\arg \min}_{x(k)}\sum \Phi(y_i-w_i^Tx(k))
\end{equation}
\]</span></p>
<p>​ 此处，<span class="math inline">\(w_i^T\)</span>是公式<span class="math inline">\(\eqref{lsp}\)</span>中提到的矩阵<span class="math inline">\(W(k)\)</span>的第i行。<span class="math inline">\(\Phi(·)\)</span>是鲁棒核函数，此处可以为Huber。普通卡尔曼滤波则此处为<span class="math inline">\((·)^2\)</span>函数，平方则是存在闭式解的，甚至可以不用化为求和式，只需要简单用pseudo逆就可求出。</p>
<p>​ 而由于<span class="math inline">\(y_i,w_i\)</span>都是已知的，具有具体的意义，只剩下未知的待估计位姿<span class="math inline">\(x(k)\)</span>，那么只需要求解公式<span class="math inline">\(\eqref{optim2}\)</span>定义的优化问题即可。这步在Kalman滤波中称为：抗差（Robust）化，因为解抗差最小二乘问题得到的解将更加稳定。</p>
<h4 id="自适应">2.1.2 自适应</h4>
<p>​ 朴素KF的噪声协方差不是自适应的，而是开始就设置好的。Q和R两个矩阵，一个代表状态转移噪声协方差，另一个代表观测噪声协方差，都是固定的（非自适应，固定就意味着高斯噪声假设）。这两个矩阵的意义比较明确：反映了不同的物理过程的噪声大小。比如：</p>
<ul>
<li>若要让结果倾向于数学模型（状态转移模型），那么状态转移噪声应该显著小于观测噪声。</li>
<li>如果要让结果倾向于观测（观测模型），那么观测噪声应该显著小于状态转移噪声。</li>
</ul>
<p>​ 但是实际使用中，关于【状态转移 / 观测两者谁更可靠】的问题是非常不好回答的。我可以凭借先验知识来判定，状态转移更好还是观测更好，但是这也仅限于“定性判定”，此后的KF甚至还需要进行调参，才能得到较好的收敛结果。此外，两个噪声协方差的固定性限制了我们可以处理的噪声种类（只能是高斯噪声），显然限制了KF在某些问题下的泛化。自适应的过程可以认为是：</p>
<div class="note info"><p>使得KF可以处理的噪声类型摆脱高斯噪声限制</p>
</div>
<p>​ 作者使用的是中值偏差（median deviation）。说实在的，这个median deviation公式可以说是很奇怪了： <span class="math display">\[
\begin{equation}\label{med}
\hat{d}(k)=\text{median}\vert \frac{r(i)-\text{median}(r(i))}{0.6745}\vert
\end{equation}
\]</span> ​ 其中，<span class="math inline">\(r(i)\)</span>是滑动窗口内的一个新息（innovation），其实就是偏差：<span class="math inline">\(z(i)-Hx(i)\)</span>。所以这做的是什么？相当于是：计算误差协方差时（尤其是方差计算），本身是可以通过标准差（standard deviation）计算出来的，但是可以计算标准差的替代品（别的deviation）。而此处，新息的最优估计也使用了鲁棒核函数： <span class="math display">\[
\begin{equation}\label{innov}
r^*(k)=\mathop{\arg\min}_{\hat{r}(k)}\sum^{k}_{i=k-N+1}\Psi\left(\frac{r(i)-\hat{r}(k)}{\hat d(k)}\right)
\end{equation}
\]</span> ​ 即，已知一个滑动窗口内的所有新息的信息<span class="math inline">\(r(i)\)</span>，根据中值偏差进行的re-scale操作加权 + Huber鲁棒核函数，优化这个问题，得到新息的最优估计，根据新息计算噪声水平。</p>
<h3 id="代码">2.2 代码</h3>
<p>​ 代码可见<a href="https://github.com/Enigmatisms/Algorithms-Plus/tree/master/cpp/KF">[Github🔗:Algorithm-Plus/KF]</a>。其中<code>KFTest.cc</code>是对一个带有运动噪声的小球进行的仿真，使用的就是ARKF。当前效果已经比传统KF稳定了很多（不过同时也结合了很多简单滤波器）。</p>
<video src="arkf_simulation.mp4" preload="metadata" controlslist="nodownload" controls playsinline poster>
</video>
<hr>
<h2 id="iii.-mee-cmee">III. MEE &amp; CMEE</h2>
<p>​ [2]。这是KF最近的工作，使用EE（Error Entropy）替换原来的MSE / Robust MSE准则。实际上，这些人关于KF的想法就是：</p>
<ul>
<li>粒子滤波太慢了，但是它很棒，可以处理任意的分布</li>
<li>KF不太行，因为其噪声要求是高斯的，而且不自适应</li>
</ul>
<p>​ 理解此论文的内容需要有一定的理论储备。</p>
<h3 id="error-entropy-kernel">3.1 Error Entropy &amp; Kernel</h3>
<h4 id="简单介绍">3.1.1 简单介绍</h4>
<p>​ 这篇论文[3]详细地介绍了MEE的思想以及其与M-estimation的关系，我结合这篇论文简单说一下吧（这篇论文做的modification就不说了）。</p>
<p>​ 此处使用的Entropy有别于通常说的香农熵（Shannon），这个熵被称为Renyi entropy，与香农熵的区别如下： <span class="math display">\[
\begin{align}
&amp; H_s(X)=-\sum\log(P_i(x))P_i(x)\label{shannon} \\ 
&amp; H_a(X)=\frac{1}{1-a}\log(\sum P^a(x))\label{renyi}
\end{align}
\]</span> ​ 公式<span class="math inline">\(\eqref{shannon}\)</span>是香农熵，而公式<span class="math inline">\(\eqref{renyi}\)</span>是Renyi熵。这两个式子让我想到了在DIP课上学到的两个滤波器，一个是普通的均值滤波器，另一个则是逆谐波均值滤波器（阶数可变那种）。香农熵就是Renyi熵在a趋近于1的一个特例。MEE中常用的是a=2（称为quadratic Renyi entropy）。论文[3]做作者提到的EE做的事实际上是：</p>
<blockquote class="blockquote-center">
<p>The concept of ‘close’, implicitly or explicitly employs a distance function or similarity measure.</p>

</blockquote>
<p>​ 也即，EE定义的是一种相似 / 接近的度量。而由于EE在计算时引入了概率，普通的<strong><u>误差（或者说是偏差）</u></strong>是没有概率的归一、范围性质的，不能直接参与运算。核函数就起到了一个映射为概率的作用，我们可以理解为这是一个sigmoid / softmax： <span class="math display">\[
\begin{align}
&amp; H_2(e)=-\log V(e) \label{h2}\\
&amp; V(e)=\frac 1 {L^2} \sum_{j=1}^N\sum_{i=1}^Nk_{\sigma}(e_i-e_j) \label{kernel}\\
&amp; k_{\sigma}(x)=\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{x^2}{2\sigma^2}\right)
\end{align}
\]</span> ​ 最后的Renyi EE就如公式<span class="math inline">\(\eqref{h2}\)</span>所定义。最小化Renyi EE就是要最大化公式<span class="math inline">\(\eqref{kernel}\)</span>定义的<span class="math inline">\(V(e)\)</span>，也即误差的QIP（quadratic information potential）。KF本质求解的加权最小二乘问题，ARKF为自适应加权鲁棒最小二乘问题。而其中的e，以我个人对论文的理解，应该表示的是新息。但是论文[2]里面实际说的是，<span class="math inline">\(e\)</span>是滤波器输出与“期望输出”的偏差。嗯？期望输出是什么东西？其实是最优滤波器的输出，<span class="math inline">\(e\)</span>是最优滤波器与当前参数滤波器输出的差异。</p>
<p>​ 所以可以知道：</p>
<div class="note info"><p>​ MEE准则是在优化最优滤波器和当前参数滤波器输出之间误差的误差熵。</p>
</div>
<p>​ 然后我发现了有趣的东西：论文[4]是人机所老师们的文章，完全介绍了MEE-KF。而论文[2]对MEE-KF的介绍并不透彻，甚至看完之后我还不是很清楚如何实现。论文[4]则说得将一些细节说的更加清楚。</p>
<h4 id="parzen窗与renyi-entropy">3.1.2 Parzen窗与Renyi Entropy</h4>
<p>​ 没想到还能和Parzen窗联系起来，当时没往这方面想。Parzen窗是一种核密度估计方法（非参数地估计概率密度函数，在我大三下学期的《模式识别与机器学习》课程中学了）。实际上公式<span class="math inline">\(\eqref{kernel}\)</span>定义的就是一个Parzen窗操作，怎么理解？</p>
<ul>
<li>首先，进行Renyi entropy计算需要计算IP（information potential）</li>
<li>IP的计算需要依赖概率密度函数，这可以用Parzen窗估计出来</li>
</ul>
<p>​ 首先，Parzen窗法是这样的： <span class="math display">\[
\begin{equation}\label{parzen}
\hat{p}(x)=\frac 1N \sum_{i=1}^N G_{\sigma}(x-e_i)
\end{equation}
\]</span> ​ 相当于在一堆<span class="math inline">\(\{e_i\}\)</span>（已经采样得到的error）上放一个Gauss分布函数，再进行归一化，得到密度估计。通过采样得到的<span class="math inline">\(\{e_i\}\)</span>可以估计出error的分布，从而计算信息势<span class="math inline">\(V_a(e)\)</span>。二阶离散情况下计算为： <span class="math display">\[
\begin{equation}\label{potential}
\hat{V}_2(e)=\frac 1N \sum_{i=1}^N\hat{p}(e_i)=\frac 1{N^2} \sum_{i=1}^N \sum_{j=1}^N G_{\sigma}(e_i-e_j)
\end{equation}
\]</span> ​ 但上述公式还存在一些奇怪的地方，比如说<span class="math inline">\(\hat{V}_2(e)=\frac 1N \sum_{i=1}^N\hat{p}(e_i)\)</span>。明明正常情况下，二阶信息势应该是： <span class="math display">\[
\begin{equation}\label{v2}
V_2(x)=\int p^2(x)dx\rightarrow\sum_{i=1}^N p^2(x)
\end{equation}
\]</span> ​ 此处直接把二次项去掉了，相当于对<span class="math inline">\(p(x)\)</span>按其自身的加权平均变成了直接平均。可能是一种近似计算方法吧，因为平方确实会麻烦一些，将会写成以下形式： <span class="math display">\[
\begin{equation}\label{right}
V_2(x)=\sum_{i=1}^N p^2(x)=\frac 1{N^2}\sum_{i=1}^N
\left(\sum_{j=1}^NG_{\sigma}(e_i-e_j)\right)
\left(\sum_{j=1}^NG_{\sigma}(e_i-e_j)\right)
\end{equation}
\]</span> ​ 这显然是与公式<span class="math inline">\(\eqref{potential}\)</span>有一定差别的。相当于公式<span class="math inline">\(\eqref{right}\)</span>是将其中一个内求和式近似为了1（这合理吗？虽然论文说的就是：<code>one can obtain an estimate of the second order (α = 2) information potential</code>），感觉Parzen窗（一次近似）+ 均匀分布（第二次近似）是两次近似啊？还是我理解错了？但是确实这样的近似会让Renyi Entropy更方便计算。之后的推导就<strong><u>非常复杂</u></strong>了。之后开单独的一篇进行分析，我可能自己也会尝试实现一下，既然有闭式解那么可能实现起来并不会太复杂吧（？飘了）。</p>
<h3 id="约束与闭式解">3.2 约束与闭式解</h3>
<p>​ 说实在的，我觉得这个略有点“强行创新”的感觉。不知道怎么说这个比较好，可能是我太菜了没看明白。论文[2]做的事情是增加了一个约束（还是等式约束）： <span class="math display">\[
\begin{equation}\label{const}
\mathop{\arg\max}_{\pmb{w}}\hat{V}_2(e_n)\text{ subject to }\mathbf{C}^T\pmb{w}_n=\mathbf{f}
\end{equation}
\]</span> ​ 后面这个约束是用来干什么的呢？什么实际问题下会有这样的约束呢？就抓住这样一点小的改动就可以有一篇论文嘛？虽然后序的推导还是很有意思的，作者通过约束 + 变换求出了对应的拉格朗日乘子的取值。其中需要设置的是约束参数<span class="math inline">\(\mathbf{C}\)</span>以及<span class="math inline">\(\mathbf{f}\)</span>。</p>
<p>​ 仔细一看，还是我们学校的老师（陈霸东教授）作为其中一位作者。当然也有可能是因为，论文长度只有5页（因为是篇brief），有些推导不是特别的详细。但可能我还是觉得，就多讨论了一个约束的情况，没什么太大的意思吧。</p>
<hr>
<h2 id="iv.-eskf">IV. ESKF</h2>
<p>​ 我在做机队的某项定位任务的时候用到了ESKF（Error-State KF）[5]，对机器人的轮速 / IMU / UWB（定位信号）进行融合。ESKF与普通KF最根本的区别在于：</p>
<ul>
<li>普通KF的状态就是可以直接使用的，具有明确物理含义的状态，比如速度 / 位置 / 角度。</li>
<li>ESKF的状态是误差，状态转移 / 观测都是有关误差的（比如位置误差 / 速度误差），相当于是一个对误差进行滤波得到结果，每次使用滤波估计出的系统误差进行原状态的计算。</li>
<li>可以理解为：KF是位置式的控制（每次滤波得到的都是最终结果），而ESKF都是增量式的控制（每次滤波得到的是状态应有的变化值）。</li>
</ul>
<div class="note primary"><p>​ 状态总是由两部分组成：实际状态（true state）= <strong>理想状态（nominal state）</strong>+ <strong>噪声状态（error state）</strong></p>
</div>
<p>​ KF对实际状态进行滤波，ESKF对噪声状态进行滤波，而理想状态进行无误差假设，直接更新。关于ESKF的使用，这里就不赘述了，因为我也赘述不出来：</p>
<p><img src="/2021/05/31/%E6%BB%A4%E6%B3%A2%EF%BC%86%E5%8D%A1%E5%B0%94%E6%9B%BC/eskf.jpg"></p>
<center>
Figure 3. ESKF 95页论文中的 状态变量截图
</center>
<p>​ 涉及到大量的四元数 / 运动学 / 机器人学知识，常用于定位，因为它有很显著的优点：</p>
<ul>
<li>error-state很小（因为是误差），相当于使用相对量进行计算，一般不会出现奇异 / 万向锁之类的问题。</li>
<li>另一方面，由于其很小（一般都在0附近，并且范围不太大），对于复杂的运动学问题（特别是非线性系统），Taylor展开后高阶项一般都是可以忽略的，性质很好。</li>
</ul>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] Durovic Z M, Kovacevic B D. Robust estimation with unknown noise statistics[J]. IEEE Transactions on Automatic Control, 1999, 44(6): 1292-1296.</p>
<p>[2] Peng S, Ser W, Chen B, et al. Robust constrained adaptive filtering under minimum error entropy criterion[J]. IEEE Transactions on Circuits and Systems II: Express Briefs, 2018, 65(8): 1119-1123.</p>
<p>[3] Liu W, Pokharel P P, Principe J C. Error entropy, correntropy and m-estimation[C]//2006 16th IEEE Signal Processing Society Workshop on Machine Learning for Signal Processing. IEEE, 2006: 179-184.</p>
<p>[4] Chen B, Dang L, Gu Y, et al. Minimum error entropy Kalman filter[J]. IEEE Transactions on Systems, Man, and Cybernetics: Systems, 2019.</p>
<p>[5] Sola J. Quaternion kinematics for the error-state Kalman filter[J]. arXiv preprint arXiv:1711.02508, 2017.</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>线性代数</tag>
        <tag>控制理论</tag>
      </tags>
  </entry>
  <entry>
    <title>我贫瘠的数学世界【1】- SAM与优化方法</title>
    <url>/2022/01/30/%E6%88%91%E8%B4%AB%E7%98%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B8%96%E7%95%8C%E3%80%901%E3%80%91-SAM%E4%B8%8E%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h1 id="bfgsam">BFGSAM</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​ 很长一段时间没有静下心来看过有很强理论性的内容了，我十分担心自己会丧失理论上的思考能力以及数学计算能力。正好之前在看某篇论文时，看到其中提到一种叫做SAM（sharpness aware minimization）的方法，说是效果还行，此前保存了SAM论文，但没去细读。最近寒假由于电脑故障没办法工作，很闲，便重新了解了一些数值优化方面的知识（比如拟牛顿族），并读了读SAM（虽然读完感觉？？？这怎么这么魔法）</p>
<ul>
<li><a href="https://arxiv.org/pdf/2010.01412.pdf">ICLR 2021: Foret, Pierre, et al. "Sharpness-aware minimization for efficiently improving generalization." <em>arXiv preprint arXiv:2010.01412</em> (2020).</a></li>
<li><strong><u>《我这种菜鸡哪有资格觉得DL顶会论文魔法》系列</u></strong>（下图图源论文）</li>
</ul>
<p><img src="/2022/01/30/%E6%88%91%E8%B4%AB%E7%98%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B8%96%E7%95%8C%E3%80%901%E3%80%91-SAM%E4%B8%8E%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/sam.png"></p>
<span id="more"></span>
<hr>
<h2 id="ii.-条件数与quasi-newton">II. 条件数与quasi-Newton</h2>
<h3 id="条件数与稳定性">2.1 条件数与稳定性</h3>
<p>​ 条件数（condition number）：</p>
<blockquote>
<p>The <strong>condition number</strong> of a <a href="https://en.wikipedia.org/wiki/Function_(mathematics)">function</a> measures how much the output value of the function can change for a small change in the input argument.</p>
</blockquote>
<p>​ 这个概念也就是一个衡量输入输出关系的指标：输入发生小的改变是否会使得输出发生大的改变？如果会，那么优化结果将有很大的抖动。比如在深度学习中，观察loss曲线，loss波动非常大，可能因为条件数太大，需要使得输入的变化在合理范围内减小（控制学习率）。</p>
<p>​ 这里我们不对一般的优化问题进行讨论，只讨论矩阵情况。矩阵中，条件数是： <span class="math display">\[
\begin{equation}
\kappa(A)=\frac {\sigma_{\max}(A)}{\sigma_{\min}(A)}
\end{equation}
\]</span> ​ 其中<span class="math inline">\(\sigma_{\max}\)</span>代表矩阵A的最大奇异值（如果是非奇异矩阵，就是最大特征值），<span class="math inline">\(\sigma_{\min}\)</span>是最小特征值。经常我们在奇异值分解时，取出其对角值，判定最大特征值与最小特征值之比，如果过大就进行一些保护操作，实际上就是在保护大条件数时的解情况。</p>
<p>​ 条件数确定了一个问题的前后向稳定性：</p>
<blockquote>
<p>算法的“前向误差”是结果与真解之间的差别，即<span class="math inline">\(\Delta y=y^{*}-y\)</span>。“后向误差”是满足<span class="math inline">\(f(x+\Delta x)=y^{*}\)</span>的最小<span class="math inline">\(\Delta x\)</span>，也就是说后向误差说明算法的所解决的问题。前向误差和后向误差通过条件数发生关系：前向误差的幅度最多是条件数乘以后向误差的幅度。[2]</p>
</blockquote>
<h3 id="preconditioning">2.2 Preconditioning</h3>
<p>​ 假设我们已经知道，某个问题的条件数很大（ill-conditioned），但我们又不得不解这个问题，应该怎么办？使用preconditioner（怎么翻译，不知道，日语翻译是“前処理行列”，好吧人家都是中文）</p>
<blockquote>
<p>In mathematics, <strong><u>preconditioning</u></strong> is the application of a transformation, called the <strong><u>preconditioner</u></strong>, that conditions a given problem into a form that is more suitable for numerical solving methods.[3]</p>
</blockquote>
<p>​ 此处简单翻译一下英文维基（因为没有中文，而英文讲得挺清楚的）：</p>
<ul>
<li>首先假设我们有一个病态线性问题：</li>
</ul>
<p><span class="math display">\[
\begin{equation}
Ax=b
\end{equation}
\]</span></p>
<ul>
<li>可以用一个 <strong><u>preconditioner矩阵</u></strong> <span class="math inline">\(P\)</span> 使得<span class="math inline">\(P^{-1}A\)</span>使得条件数小于A：</li>
</ul>
<p><span class="math display">\[
\begin{equation}
AP^{-1}(Px)=b
\end{equation}
\]</span></p>
<ul>
<li>我们认为：<span class="math inline">\(AP^{-1}\)</span>是一个新的矩阵<span class="math inline">\(Q\)</span>，也就得到：<span class="math inline">\(Qy=b\)</span>这个问题，首先解这个问题得到<span class="math inline">\(y\)</span>后再根据<span class="math inline">\(Px=y\)</span>解出<span class="math inline">\(x\)</span></li>
</ul>
<p>​ 很巧妙的方法。进一步了解这种方法的应用以及其work的机制，参见reference。</p>
<h3 id="quasi-newton法简介">2.3 Quasi-Newton法简介</h3>
<p>​ 拟牛顿（quasi-Newton）法，顾名思义就是牛顿法的近似。牛顿法需要用到二阶导，在更加一般的情况下---海森（Hessian）阵。但并不是所有函数都容易求二阶导，要么是因为其解析表达式太复杂，要么是因为维度太高，二阶导的时空开销都是至少<span class="math inline">\(O(n^2)\)</span>的。此时我们可以使用一些方法来近似海森矩阵，用近似的海森矩阵计算更新方向。在此我将简介一些更为熟知的拟牛顿迭代方法（的好处）：BFGS（族），DFP，SR1。</p>
<p>​ BFGS（四个人名字貌似）是一种很好用的拟牛顿迭代算法，相比于DFP以及SR1，这个算法可能有一定优势（要不然为什么Google ceres solver里的线搜索只提供LBFGS以及BFGS？难不成因为写起来简单？），并且其存在一种对内存以及算力更加友好的实现（Limited-BFGS），这个更友好的实现可以摆脱普通BFGS的<span class="math inline">\(O(n^2)\)</span>时间复杂度，使得时间复杂度变为<span class="math inline">\(O(mn)\)</span>，一般来说m都小于n。</p>
<div class="tabs" id="span-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#span-unique-name-1">BFGS</a></li><li class="tab"><a href="#span-unique-name-2">DFP</a></li><li class="tab"><a href="#span-unique-name-3">SR1</a></li></ul><div class="tab-content"><div class="tab-pane active" id="span-unique-name-1"><ol type="1">
<li>维持对称正定性。(2) 一种奇妙的自我矫正能力。(3) 对于大型稀疏问题非常有效</li>
</ol>
<blockquote>
<p>BFGS is the most effective quasi-Newton correction... Also, BFGS has self-correcting properties: if <span class="math inline">\(H_k\)</span> incorrectly approximates the curvature of the objective function and this estimate slows down the iteration, then the (inverse) Hessian approximation will tend to correct itself in the next few steps. [4]</p>
</blockquote></div><div class="tab-pane" id="span-unique-name-2"><ol type="1">
<li>第一个提出的quasi-Newton方法，是BFGS update的对偶。（2）在解决二次问题时，迭代产生共轭方向（与共轭梯度法重合）。(3) 对于大型问题，效率非常低。</li>
</ol>
<blockquote>
<p>This formula, like BFGS, is a rank 2 formula update and it has nice properties as well, however it is not as fast. It is less effective than BFGS at self-correcting of the Hessians. Likewise, DFP could fail for general nonlinear problems, it can stop at a saddle point, it is sensitive to inaccurate line searches and it’s Hessian updates are sensitive to round-off errors and other inaccuracies. [4]</p>
</blockquote></div><div class="tab-pane" id="span-unique-name-3"><p>​ SR1如其名（Symmetric Rank-1），DFP与BFGS都是秩-2算法。</p>
<blockquote>
<ul>
<li>The matrices generated are very good approximations to the (inverse) Hessian matrices, often better than BFGS.</li>
<li>The drawback of the method is that sometimes <span class="math inline">\((s_k − H_ky_k)^Ty_k\approx0\)</span> and there may not be a symmetric rank one formula that satisfies the secant condition. Hence instabilities and breakdown may occur.</li>
</ul>
</blockquote></div></div></div>
<p>​ 秩-1算法（SR-1）得到的海森矩阵可能比秩-2算法的海森矩阵更好，但是它无法保证更新矩阵的正定性，线搜索将是非精确线搜索[5]（来自台湾一个叫做，国立中正大学的课件，这大学名字感觉一看就知道在纪念谁）。</p>
<h4 id="bfgs法推导">2.4 BFGS法推导</h4>
<p>​ 中文维基的话呢，就是简单告诉你：算法就是这样，至于推导，自己推去吧。英文维基则没有过程。推导并不难（别在开始时抄错公式就行，我因为抄错公式而花了一个半小时用各种方法推而没有结果，果然努力是不值钱的，方向错了一点用都没有）。</p>
<p>​ 首先，拟牛顿法都基于这一个假设：更新方向<span class="math inline">\(\pmb{p}_k\)</span>与海森近似阵<span class="math inline">\(B_k\)</span>，梯度的关系正如牛顿法中海森梯度与更新方向的关系如下，当然，我们也可以将这里视为对梯度的preconditioning： <span class="math display">\[
\begin{equation}
B_k\pmb{p}_k=-\nabla f(x_k)
\end{equation}
\]</span> ​ 由于<span class="math inline">\(\pmb{p}_k\)</span>只是一个方向，可将其写为<span class="math inline">\(\pmb{p}_k=\alpha(x_{k+1}-x_k)\)</span>。注意拟牛顿条件： <span class="math display">\[
\begin{align}\label{quasi}
&amp;f(x_k+\Delta x)\approx f(x_k)+\nabla f(x_k)\Delta x + \frac 12\Delta x^TB\Delta x\rightarrow\\
&amp;\text{Approx linearity: }\nabla f(x_k+\Delta x) \approx \nabla f(x_k)+ B\Delta x\rightarrow\\
&amp;B_{k+1}(x_{k+1}-x_k)=\nabla f(x_{k+1})-\nabla{f(x_k)}\\
&amp;\text{let: } y_k=\nabla f(x_{k+1})-\nabla{f(x_k)}, s_k=x_{k+1}-x_k\\
&amp;\text{thus, }B_{k+1}s_k=y_k\label{update}
\end{align}
\]</span> ​ 则更新<span class="math inline">\(B_k\)</span>（或者称为correction），<strong><u>必须要使得<span class="math inline">\(B_{k+1}\)</span>满足公式<span class="math inline">\(\eqref{update}\)</span></u></strong>。在BFGS中，为了满足对称且正定（positive definiteness），人为使得更新公式如下： <span class="math display">\[
\begin{equation}\label{new}
B_{k+1}=B_k+\alpha u_ku_k^T+\beta v_kv_k^T
\end{equation}
\]</span> ​ 注意其中<span class="math inline">\(u,v\)</span>均是列向量。只要公式<span class="math inline">\(\eqref{new}\)</span>满足更新公式<span class="math inline">\(\eqref{update}\)</span>即可。注意公式<span class="math inline">\(\eqref{new}\)</span>后有两个更新项，只有一个时将是秩1算法。在这里，我们就地取材，使得<span class="math inline">\(u_k=y_k,v_k=B_ks_k\)</span>。求<span class="math inline">\(\alpha,\beta\)</span>。</p>
<p>​ 则带入公式<span class="math inline">\(\eqref{update}\)</span>，整理后可以得到： <span class="math display">\[
\begin{align}
&amp;(B_k+\alpha u_ku_k^T+\beta v_kv_k^T)s_k=y_k\rightarrow\\
&amp;(\alpha u_ku_k^T+\beta v_kv_k^T)s_k=y_k-B_ks_k\rightarrow\\
&amp;(\alpha u_k^Ts_k)u_k+(\beta v_k^Ts_k)v_k=y_k-B_ks_k\rightarrow\\
&amp;\text{for: }u_k=y_k,v_k=B_ks_k\\
&amp;\text{let: }\alpha u_k^Ts_k=1,\beta v_k^Ts_k=-1\\
&amp;\alpha=\frac 1{y_k^Ts_k},\beta=-\frac{1}{s^T_kB_k^Ts_k}=-\frac{1}{s^T_kB_ks_k}
\end{align}
\]</span> ​ 则可以得到更新公式。</p>
<hr>
<h2 id="iii.sam">III.SAM</h2>
<p>​ 这篇论文我也不是很想细讲，不知道是因为我没有深入理解还是这篇论文本身就有那么一点魔法，个人感觉此文最后得出的算法貌似很trivial。SAM（sharpness aware minimization）是一种新的误差函数，此误差函数可以提升网络的泛化能力（<strong><u>使得最优值附近较为平滑</u></strong>）。</p>
<p>​ 一般的提升泛化能力方法可以分为这么几种：</p>
<ul>
<li><p>限制活动参数数量：weight decay（限制部分参数的存在）、Dropout（参数随机存在）以及比较新的stochastic depth（随机扔层，多用在attention结构中）</p></li>
<li><p>loss方面：比如分类问题中的label smoothing loss，使得one-hot变成了 0.9或者0.8 hot，label不再是硬的，或者说是从分类问题转化为回归问题，从“数字信号学习”变为“模拟信号学习”。</p></li>
<li><p>数据处理方面：数据增强（传统），Random Erase，mixup/cutmix（现代数据增强）。</p></li>
</ul>
<p>​ 在loss方面，如果说label smooth算是杰出的一个泛化能力增强尝试的话，个人觉得这还是不够的。毕竟这就不优雅。本来人家猫就是猫，我能很明确告诉你这就是猫，100%概率，但label smooth偏要说这是90%的置信度，强行软化。</p>
<p>​ SAM则着重于优化网络学习结果计算的loss形状。假设我们把loss值函数看作是： <span class="math display">\[
\begin{equation}
l=L(x;\theta)
\end{equation}
\]</span> ​ 其中x是输入数据，<span class="math inline">\(\theta\)</span>是网络参数。我们大可以将上式看作是关于<span class="math inline">\(\theta\)</span>的函数（可以认为输入给定），那么我们希望对于任意给定输入，loss都能保持一定的平滑性，正如我们希望 <strong><u>超平面是存在平滑性的</u></strong>，以免发生过拟合。那么如何保证此“平滑性”？</p>
<p>​ <del>首先，我们知道，根据某个xx理论 显然 不难得到 易于证明 QED</del>。首先，作者将问题写成了这样（这里我跳过了作者抛出的一个theorem），假设我们现在已经有了一个参数<span class="math inline">\(w\)</span>（这是个向量但我不想打<code>\pmb&#123;&#125;</code>，为了方便），我们需要找一个有更强泛化能力的参数<span class="math inline">\(w^*\)</span>，那么<span class="math inline">\(w\)</span>局部最大loss可以写为： <span class="math display">\[
\begin{align}
&amp;[\mathop{\max}_{|\epsilon|_2\leq\rho}L_s(w+\epsilon)-L_s(w)]+L_s(w)+\lambda\Vert w\Vert^2\label{div}\\
&amp; L_s^{SAM}:=\mathop{\max}_{|\epsilon|_2\leq\rho}L_s(w+\epsilon)
\end{align}
\]</span> ​ 其中<span class="math inline">\(\rho\)</span>是个超参数。作者将局部最大loss拆分为<span class="math inline">\(\eqref{div}\)</span>就是为了说明：方括号里的项实际上包含了局部变化率信息（越大说明sharpness越高），剩余部分就是plain loss with regularizer。</p>
<p>​ 作者进一步认为： <span class="math display">\[
\begin{align}
\epsilon^*(w)=\mathop{\arg\max\;}_{|\epsilon|_2\leq\rho}L_s(w+\epsilon)\mathop{\approx}^{Taylor}\mathop{\arg\max\;}_{|\epsilon|_2\leq\rho}L_s(w)+\epsilon^T\nabla_wL_s(w)=\mathop{\arg\max\;}_{|\epsilon|_2\leq\rho}\epsilon^T(w)\nabla_wL_s(w)
\end{align}
\]</span></p>
<p>​ 感觉如果直接求解<span class="math inline">\(\arg\max\epsilon^T(w)\nabla_wL_s(w)\)</span> 只是求解在对应参数点<span class="math inline">\(w\)</span>，与<span class="math inline">\(L_s\)</span>梯度内积最大的参数偏移值。这么看来，貌似<span class="math inline">\(\epsilon\)</span>的方向与<span class="math inline">\(\nabla L_s(w)\)</span>一致，范数取最大值（<span class="math inline">\(\rho\)</span>）即可？作者最后确实也是这么解的： <span class="math display">\[
\begin{equation}\label{max}
\epsilon^*(w)=\rho\text{ sign}(\nabla_wL_s(w))|\nabla_wL_s(w)|^{q-1}/\left(\Vert\nabla_wL_s(w) \Vert^q_q\right)^{1/p}
\end{equation}
\]</span> ​ 作者说p=q=2是最优参数。但... 为什么要用 sgn函数？这里... 作者写复杂了。<span class="math inline">\(|...|\)</span>是 element-wise absolute操作，sgn + |...| 相当于是先取每个元素的值，归一化后再将原来的方向加上。</p>
<p>​ 由于公式<span class="math inline">\(\eqref{max}\)</span>求出了最终的<span class="math inline">\(\epsilon\)</span>，那么我们的<span class="math inline">\(L_s^{SAM}(w)\)</span>梯度可以求出如下，由于<span class="math inline">\(L_s^{SAM}(w)\approx L_s(w+\epsilon^*(w))\)</span>: <span class="math display">\[
\begin{align}
&amp;\nabla_wL_s^{SAM}(w)\approx \nabla_wL_s(w+\epsilon^*(w))=\frac{d(w+\epsilon^*(w))}{dw}\nabla_w{L_s(w)}|_{w=w+\epsilon^*(w)}\rightarrow\\
=&amp;\nabla_w{L_s(w)}|_{w=w+\epsilon^*(w)}+\left[\frac{d(\epsilon^*(w))}{dw}\nabla_w{L_s(w)}|_{w=w+\epsilon^*(w)}\right]
\end{align}
\]</span> ​ 最后，作者甚至将上式方括号内的项省略掉，直接一步： <span class="math display">\[
\begin{equation}
\nabla_wL_s^{SAM}(w)\approx \nabla_w{L_s(w)}|_{w=w+\epsilon^*(w)}
\end{equation}
\]</span> ​ 个人感觉很暴力。因为假设这样，假设在SGD背景下进行迭代，每一次将直接取负梯度方向优化，而SAM则是首先计算本参数所在位置的梯度，之后设置一临时向量，其值是梯度归一化结果乘以ρ，计算实际更新方向时，当前参数加临时向量位置evaluate得到梯度后当作方向。而ρ是个魔法参数，也不自适应，甚至我都不知道ρ是否鲁棒，是否会出现ρ“条件数大”的情况。作者相当于在此处：</p>
<div class="note warning"><p>​ 每次不在参数位置获得梯度，而在参数附近的一个魔法位置获得梯度。作者的理论也很魔法，核心部分竟然是一个一阶泰勒展开的极值（内积最大值结果），作者将其说成是 <strong><u>dual norm problem</u></strong>，好家伙，一下成了泛函分析问题了，逼格++。</p>
</div>
<p>​ 虽然本文引用量100+，但个人始终感觉<strong><u>不太对劲</u></strong>（很魔法），有机会将尝试一下本算法。不过按道理来说，如果这个方法很成功，就像AdamW &gt; Adam这样，SAM一定会被Pytorch进行官方实现的，引用量比肩ResNet、transformer也说不定，<strong><u>可惜并没有</u></strong>。</p>
<p>​ 个人水平实在有限，没办法读出本文的深意，也没办法从中获得启发，如果有读者对此文产生兴趣并有自己的深入理解，笔者愿意深入探讨。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://en.wikipedia.org/wiki/Condition_number">Wikipedia: Condition number</a></p>
<p>[2] <a href="https://en.wikipedia.org/wiki/Numerical_stability">Wikipedia: Numerical stability</a></p>
<p>[3] <a href="https://en.wikipedia.org/wiki/Preconditioner">Wikipedia: Preconditioner</a></p>
<p>[4] <a href="http://people.math.sfu.ca/~elushi/project_833.pdf">Yang D., Enkeleida L., Qingguo L., Investigation of quasi-Newton methods for unconstrained optimization</a></p>
<p>[5] <a href="https://www.cs.ccu.edu.tw/~wtchu/courses/2012s_OPT/Lectures/Chapter%2011%20Quasi-Newton%20Methods.pdf">Chapter 11 Quasi-Newton Methods</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>优化理论</tag>
      </tags>
  </entry>
  <entry>
    <title>概率图模型</title>
    <url>/2021/11/10/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="crf-mrf">CRF &amp; MRF</h1>
<hr>
<h2 id="i.-introduction">I. Introduction</h2>
<p>​ 本文是早期被挂在<a href="https://github.com/Enigmatisms/Algorithms-Plus">Github🔗: Enigmatisms/Algorithm Plus</a>上的一篇学习总结。写这篇学习笔记的时候博客还没有诞生，也刚刚熟练掌握Typora。本文相当于是考古post，虽然古老，但我发现当年的我学习热情也还是挺高的，这篇笔记可以说是写得不错的一个概率图模型入门文章了（开始自夸，尽管UGM部分没写完）。</p>
<p>​ 可能我最近还是要重新学一下概率图模型:</p>
<blockquote>
<p>一个概率图模型，上面的所有结点构成了所有随机变量的联合分布。需要表达的就是联合分布。--早期HQY的理解</p>
</blockquote>
<p>​ 之前应该只是清楚了其中的一些概念，但是并没有产生深入的理解，比如MRF与置信传播的原理以及具体的应用方式等等（虽然已经是很老的传统方法了）。方法老归老，思想本质有启发意义就是好的。</p>
<span id="more"></span>
<hr>
<h2 id="ii.-dgm">II. DGM</h2>
<h3 id="dgm-中三种典型结构的理解">2.1 DGM 中三种典型结构的理解</h3>
<p>​ DGM(Directed Graph Model)。又叫贝叶斯网络。</p>
<pre class="mermaid">
graph LR

A[A Intelligence]--&gt;B[B GPA]
A--&gt;C[C Innovative prop.]

</pre>
<h4 id="结构一-tail-to-tail-单父多子">2.1.1 结构一 Tail to Tail (单父，多子)</h4>
<ul>
<li>当观测到A，B与C之间独立（不存在关系，<strong><u>没有可以有信息推断</u></strong>）</li>
<li>没有观测到A，B，C之前可以有隐含的关系，不独立</li>
</ul>
<p>举个例子：</p>
<ul>
<li>A智力，B成绩，C创新力。当不知道A时，我们可以隐含地推定，当一个人成绩高，说明他创新能力高的概率很大（概率推断），反之亦然</li>
<li>而如果GPA，创新力只受到智力一个因素的影响时，已知A，那么GPA和创新力就毫无关系了。因为这两个因素B,C已经确定了，再进行概率推断已经没有意义了（信息量为0）.<strong><u>如果这个例子不好理解，那么还有一个例子：</u></strong></li>
<li>A 今天下雨，B明天下雨，C今天地面湿。其中，A（下雨）有80%可能导致积水（C），20%可能导致不积水（<span class="math inline">\(\overline C\)</span>），50%下雨（B）。那么A未知时，地面湿时（假设C发生），可以反推A是否发生，再反推B是否发生，反过来也一样。</li>
<li>但是如果A发生了，那么C与B只与A当前事实有关，<strong><u>已经不会受到来自B或者C的推断影响了！（影响消除）</u></strong>。</li>
<li>A的观测会导致B,C的相互独立（信息的互不影响性）</li>
</ul>
<h4 id="结构二-head-to-tail-典型的因果关系">2.1.2 结构二 Head to Tail （典型的因果关系）</h4>
<pre class="mermaid">
graph LR

A[A Diffculty]--&gt;B[B Grade]
B--&gt;C[C Recommendation]

</pre>
<p>B为关键结点。当：</p>
<ul>
<li>B没有被观测，A和C是可以有推断关系（信息关联性）的，不独立</li>
<li>B被观测：A与C独立，A已经不影响C的发生了</li>
</ul>
<p><strong><u>可以用马尔可夫链的想法来理解！</u></strong>历史事件的无后效性！当 当前不确定时，<strong>由于历史状态可以确定当前状态</strong>，那么相当于历史可以影响未来（下一状态）。而当前状态已知的话，历史信息已经不起作用力，下一状态完全由当前状态决定。</p>
<p>例子：</p>
<ul>
<li>不知道成绩的情况下，如果考试的难度大，那么每个人在考好的情况下获得推荐的概率都大。</li>
<li>但是知道了成绩的话，收益就和风险没关系了。你考得好就能获得推荐，考不好就不行。</li>
</ul>
<h4 id="结构三-head-to-head-汇点">2.1.3 结构三 Head to Head （汇点）</h4>
<pre class="mermaid">
graph LR

A[A Difficulty]--&gt;C[C Grade]
B[B Intelligence]--&gt;C

</pre>
<p>C为关键节点。当：</p>
<ul>
<li>C没有被观测：那么A和B互相不影响（因为缺少信息判断A与B的相互影响性），结果未知，原因互相产生的影响不可知。<strong><u>条件独立</u></strong></li>
<li>C被观测到：A与B存在联系的结果，可以A-&gt;B推断或者反之。</li>
</ul>
<p>例子：</p>
<ul>
<li>考试成绩不清楚的时候，每个人的智力 / 考试难度两者之间如果也未知，知道其中一个也推不出另一个来。</li>
<li>但是如果已知成绩，比如：成绩普遍很好。那么由B，比如某个人的智力不行，但是成绩好，可以推定A（难度低），反之，如果成绩普遍很差，由B（高智力），可以推知A（难度高）。</li>
</ul>
<p><strong><u>以上这三种有向图结构，可以方便进行条件独立判定以及信息关联性的快速区分，判定两个随机变量之间是否存在关联时可以应用。</u></strong>联系例子即可。</p>
<ul>
<li>每个节点：都是一个随机变量，一般未知，需要从信息中推断</li>
<li>每个有向弧：都是条件概率。A发生时，C存在概率发生，则A-&gt;C有弧。</li>
</ul>
<h3 id="条件独立与马尔可夫链">2.2 条件独立与马尔可夫链</h3>
<p>条件独立： <span class="math display">\[
\begin{equation}
P(X,Y|Z)=P(X|Z)P(Y|Z)
\end{equation}
\]</span> ​ 在Z发生的情况下，X，Y同时发生的概率为分别概率的积。可以写成另一种形式： <span class="math display">\[
\begin{equation}
P(X|Y,Z)=\frac{P(X,Y,Z)}{P(Y,Z)}=\frac{P(X,Y|Z)P(Z)}{P(Y|Z)P(Z)}=\frac{P(X,Y|Z)}{P(Y|Z)}=P(X|Z)
\end{equation}
\]</span> ​ 这最能直接说明条件独立的意义：给定条件Y,Z，若X,Y条件独立，Y条件不影响X事件，可以直接从条件中删除。而CRF中的有向边表征了条件概率，对应地，结点间关系（以上三种模式）表征了条件独立性。</p>
<p>​ 如果两个结点之间的中间结点已经完全确定，已经没有 <strong><u>不通过中间已经观测结点</u></strong> 的直连路径或者间接路径了，此时两个结点条件独立。而条件独立可以用于理解Markov链： <span class="math display">\[
\begin{equation}
P(x_t)=P(x_1)P(x_2|x_1)P(x_3|x_1,x_2)...P(x_t|x_1,x_2,...x_{t-1})
\end{equation}
\]</span> ​ 这个是普通的链式法则。而由于一阶马尔可夫假设：历史不影响未来，过去的状态与未来条件独立。那么可以简化链式法则为： <span class="math display">\[
\begin{equation}
P(x_t)=P(x_1)P(x_2|x_1)P(x_3|x_2)...P(x_t|x_{t-1})=P(x_1)\prod_{i=1}^tP(x_{i}|x_{i-1})
\end{equation}
\]</span> ​ 这可以大大简化运算以及储存难度。</p>
<h3 id="使用例子理解dgm-马尔可夫毯">2.3 使用例子理解DGM / 马尔可夫毯</h3>
<p>朴素贝叶斯就是个很典型的DGM例子。朴素（naive）就naive在：</p>
<blockquote>
<p>基于特征条件独立假设的分类器。</p>
</blockquote>
<p>​ 特征条件独立这个假设很强了，一般做不到。但是在DGM中可以表示为：</p>
<pre class="mermaid">
graph TB

A[Label]--&gt;B[Feature 1]
A--&gt;C[Feature 2]
A--&gt;D[Feature 3]
A--&gt;E[...]

</pre>
<p>​ 给定Label后，所有的Features毫无关联（Tail to Tail 结构）。</p>
<h4 id="马尔可夫毯">2.3.1 马尔可夫毯</h4>
<p>​ 马尔可夫毯说的是这样一个集合：集合<span class="math inline">\(\Pi(t)\)</span>表征了，当我们对集合<span class="math inline">\(\Pi(t)\)</span>内的所有随机变量进行观测，那么会导致结点t与剩下的结点之间完全条件独立（<strong>啊，被孤立了，相当于<span class="math inline">\(\Pi(t)\)</span></strong>把t墙了）。例子：</p>
<pre class="mermaid">
graph LR

A(1)--&gt;B(2)
A--&gt;C(3)
B--&gt;D(5)
C--&gt;D
B--&gt;E(4)
C--&gt;F(6)
E--&gt;G(7)
D--&gt;F
D--&gt;G
F--&gt;G

</pre>
<p>​ 那么对于结点5，其马尔可夫毯为？</p>
<ul>
<li>首先2，3给定之后，由于2，3为5的父结点，2，3的观测导致5与1的独立</li>
<li>此后是5与4的独立：有赖于2的给定。</li>
<li><strong><u>观测本身会导致被观测变量与其父节点或者子结点独立！</u></strong>不确定性消除。故5建立6，7的观测，6，7要给定。</li>
<li>但是给定了7，在5，7，4形成了一个Head to Head 结构。会导致5和4的不独立，那么需要给定4以消除不确定性的方式终结。</li>
<li>最后的毯子是：<span class="math inline">\({\{2,3,4,6,7\}}\)</span></li>
</ul>
<h4 id="dgm到底能干什么">2.3.2 DGM到底能干什么</h4>
<p>​ 多个变量错综复杂的因果关系，相互有影响。一个变量的改变可能导致整个网络（说到网络就会形成一个高维结构了，之所以是高维，指的是这个图可能不是平面图，不一定表达的就是二维关系）内部的变量发生连锁变化。那么为了解决有条件独立 / 条件概率联系起来的多个网络变量，需要使用这个方法。</p>
<h4 id="有向图的概率表示">2.3.3 有向图的概率表示</h4>
<p>由条件概率的定义，联合概率可以由边缘 / 条件表示。在有向图中，由于有向图对条件概率进行建模（每一条边就是一个条件概率关系），那么使用有向图如何表示概率？举个例子：</p>
<pre class="mermaid">
graph LR

A((X1))--&gt;B((X2))
B--&gt;C((X3))
B--&gt;D((X4))
C--&gt;E((X5))
D--&gt;E

</pre>
<p>​ 如果需要使用有向图关系表示<span class="math inline">\(\{x_1,x_2,x_3,x_4,x_5\}\)</span>的联合概率分布，如何写出这个表达式？（给定顶层结点，也就是起源结点<span class="math inline">\(x_1\)</span>的初始分布<span class="math inline">\(P(x_1)\)</span>），则表达式为： <span class="math display">\[
\begin{equation}
P(x_1,x_2,x_3,x_4,x_5)=P(x_1)P(x_2|x_1)\rightarrow?
\end{equation}
\]</span> ​ 之后，<span class="math inline">\(x_3\)</span> <span class="math inline">\(x_4\)</span>是乘法关系还是加法关系？首先可以肯定，接下来的概率表达式是<span class="math inline">\(P(x_4|x_2)\)</span>与<span class="math inline">\(P(x_3|x_2)\)</span>（由于<span class="math inline">\(x_2\)</span>的存在，导致<span class="math inline">\(x_1\)</span>，<span class="math inline">\(\{x_3,x_4\}\)</span>条件独立），个人认为，此处<span class="math inline">\(x_5\)</span>的产生是<span class="math inline">\(\{x_3,x_4\}\)</span>共同作用的结果。比如说，考试：<span class="math inline">\(\{x_3,x_4\}\)</span>分别表示难度以及学生智力，<span class="math inline">\(x_5\)</span>为分数。产生分数必须要有前两个因素，故此处虽然是两个通路，但是仍然是乘法原则起作用（与事件）（<strong><u>可能隐含表达了，DGM中子结点需要所有父结点成立而产生</u></strong>） <span class="math display">\[
\begin{equation}
P(x_1,x_2,x_3,x_4,x_5)=P(x_1)P(x_2|x_1)P(x_3|x_2)P(x_4|x_2)P(x5|x_3,x_4)
\end{equation}
\]</span> ​ 一个更加复杂的例子：</p>
<pre class="mermaid">
graph LR

A((X1))
B((X2))
C((X3))
D((X4))
E((X5))
F((X6))
G((X7))
A--&gt;D
A--&gt;E
B--&gt;D
C--&gt;D
C--&gt;E
D--&gt;F
D--&gt;G
E--&gt;G

</pre>
<p>​ 可以立即得到联合分布：（不仔细推了） <span class="math display">\[
\begin{equation}
P(x_1,...x_7)=P(x_1)P(x_2)P(x_3)P(x_4|x_1,x_2,x_3)P(x_5|x_1,x_3)P(x_6|x_4)P(x_7|x_4,x_5)
\end{equation}
\]</span></p>
<p>​ 这样的联合概率求解规律是可以推广的。</p>
<hr>
<h2 id="iii.-无向图模型ugm">III. 无向图模型（UGM）</h2>
<h3 id="基本概念">3.1 基本概念</h3>
<p>​ 区别于有向图模型（DGM），无向图模型不是对因果关系进行建模。</p>
<p>​ 无向图和有向图的区别是什么？有向图表征了因果关系，并且连接有方向性，导致了处理图像这样的问题时，<strong><u>不方便进行建模</u></strong>。</p>
<pre class="mermaid">
graph LR

1--&gt;4
2--&gt;5
3--&gt;6
1--&gt;2
2--&gt;3

4--&gt;5

5--&gt;6

4--&gt;7
5--&gt;8
6--&gt;9
7--&gt;8
8--&gt;9

</pre>
<p>​ 可以看出，在对有向图进行建模时，如果要进行条件独立分析（比如我们要单独分析5与其他的结点的条件独立性）。需要寻找马尔可夫毯，那么在有向图中，除了<span class="math inline">\(\{2,4,6,8\}\)</span>之外，实际上还有别的结点，而<span class="math inline">\(\{2,4,6,8\}\)</span>是1阶邻域，在图像处理中比较常见求一阶邻域与中心点间的关系。而此处，要加入<span class="math inline">\(\{3,7\}\)</span>结点（Head to Head，由于给定了8，5与7不再条件独立，需要给定7，3的话同理）。那么显然我们加入了奇怪的点，导致分析存在一些问题，并且与有向图网络的生成方向还存在关系。</p>
<p>​ 而使用无向图的话，由于结点之间是平等的，在无向图中的马尔可夫毯直接就是<span class="math inline">\(\{2,4,6,8\}\)</span>。</p>
<p>​ 无向图中，存在三种独立性：</p>
<ol type="1">
<li>全局独立性（全局马尔可夫性）</li>
</ol>
<pre class="mermaid">
graph LR

A((1))---B((2))
B---D((4))
A---C((3))
C---D
E((5))---A
D---F((6))

</pre>
<p>​ 当我们删除结点<span class="math inline">\(\{2,3\}\)</span>时，可知集合<span class="math inline">\(\{1,5\}\)</span>以及<span class="math inline">\(\{4,6\}\)</span>之间完全没有联系了。删除两个结点之间的连通性结点，产生两个连通支，则这两个连通支 <strong>独立</strong>。</p>
<ol start="2" type="1">
<li>局部独立性（局部马尔可夫性）</li>
</ol>
<pre class="mermaid">
graph TB

a((1))
b((2))
c((3))
d((4))
e((5))
f((6))
g((7))
a---b
a---c
a---d
a---e
c---f
e---g
b---f
d---g

</pre>
<p>​ 可知，当我们把2，3，4，5删去之后，1结点与所有其他结点完全没有联系了。<strong><u>1被孤立了，因为其马尔可夫毯已经被删除了。</u></strong>那么，1与其他结点条件独立。写为表达式可以如下：</p>
<p>​ 设<span class="math inline">\(V_k\)</span>为我们探索的结点，<span class="math inline">\(V_M\)</span>为<span class="math inline">\(V_k\)</span>的马尔可夫毯的节点集合，而<span class="math inline">\(V_S\)</span>为<span class="math inline">\(V_i\in \{V\}/\{V_M\cup V_k\}\)</span>，则可知： <span class="math display">\[
\begin{equation}
V_k\perp V_S|V_M
\end{equation}
\]</span> ​ 即给定马尔可夫毯，则对应结点和除其本身以及马尔可夫毯结点之外的所有结点条件独立。</p>
<ol start="3" type="1">
<li>成对独立性（成对马尔可夫性）</li>
</ol>
<p>​ u，v为两个没有直连边的结点。去掉u，v之外的其他点，<strong><u>u，v条件独立。</u></strong></p>
<h3 id="团块clique的概念">3.2 团块（Clique）的概念</h3>
<p>​ 如果一个结点集合内，任意两个结点之间存在连边，那么称这是一个团（Clique）。</p>
<p>​ 最大团：在一个团C外部任意找一个结点，加入此团后都会破坏团的性质（此结点与至少一个结点之间不存在连边）。也即外部已经不能再加入结点使团变大了。</p>
<p>​ 无向图模型中一般会涉及到大量结点，那么要表示这些结点的联合概率就十分麻烦。可以使用最大团来进行描述，将 <strong><u>无向图中的联合概率分布表示为极大团的势函数（Potential Function）</u></strong>的积。也即： <span class="math display">\[
\begin{equation}
P(x)=\frac{1}{Z}\prod_{i=1}^n\psi_i(x_i)
\end{equation}
\]</span> ​ 上式中，<span class="math inline">\(\psi_i(x)\)</span>表示极大团<span class="math inline">\(x_i\)</span>的势函数，而Z则是归一化因子，为了使<span class="math inline">\(P(x)\)</span>满足概率的归一化性质。归一化因子又叫做：配分函数（Partition Function），但是如何进行计算呢？举个例子（例子来自CSDN，但是感觉讲的不太清楚，我自己理解一下：）</p>
<div class="note info"><p>2021.11.15补充：当时还会看粪坑CSDN呢。PS：参考的文献都没有记录。</p>
</div>
<pre class="mermaid">
graph TB

A((x1))
B((x2))
C((x3))
D((x4))
E((x5))
A---B
A---C
B---C
C---D
C---E

</pre>
<p>​ 可知，图中存在三个极大团：<span class="math inline">\(\{x_1, x_2, x_3\}\)</span>，<span class="math inline">\(\{x_3,x_5\}\)</span>，<span class="math inline">\(\{x_3, x_4\}\)</span> (注意一个结点可以存在于多个极大团中！)。那么整个联合概率分布可以写为： <span class="math display">\[
\begin{equation}
P(x_1, x_2, x_3,x_4,x_5)=\frac 1Z\psi_1(x_1,x_2,x_3)\psi_2(x_3,x_5)\psi_3(x_3,x_4)
\end{equation}
\]</span> ​ 那么Z应如何计算？需要对每个结点进行遍历。下式为每个结点所在极大团的势函数： <span class="math display">\[
\begin{align}
    &amp; x_1:\psi_1(x_1,x_2,x_3)\\
    &amp; x_2:\psi_1(x_1,x_2,x_3)\\
    &amp; x_3:\psi_1(x_1,x_2,x_3)\psi_2(x_3,x_5)\psi_3(x_3,x_4)\\
    &amp; x_4:\psi_3(x_3,x_4)\\
    &amp; x_5:\psi_2(x_3,x_5)
\end{align}
\]</span> ​ 对每个结点进行求和归一化。为什么要这么做？为什么是对每一个结点结点所在团的势函数？而不是求每一个结点对应的某一个其他函数进行累加求和？</p>
<div class="note danger"><p>2021.11.15 补充：诶？我最后在这里写了一个开放性思考题？应该是原来我没想清楚，但是最后也没去想。</p>
</div>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title>特龙智慧-GMapping</title>
    <url>/2021/10/22/%E7%89%B9%E9%BE%99%E6%99%BA%E6%85%A7-GMapping/</url>
    <content><![CDATA[<h1 id="特龙智慧">特龙智慧</h1>
<hr>
<p>​ 我在大二上学期购买了《概率机器人》一书，当时还没有学概率论，所以我看不懂（但是我大受震撼）。大二下的暑假曾经学了一段时间，但是没有深入，到第五章就结束了。直到现在，大四了，项目有这方面的需求了，才重新开始看特龙(Sebstian Thrun)这本口碑很好的书。尽管这本书是2006年出版的，其中的很多思想在现在的我看来，都还很有指导意义。非常后悔，自己没能在之前花精力啃下这本SLAM以及移动机器人著作。</p>
<p>​ GMapping（以及相关的粒子滤波SLAM方法）或多或少都有他的参与，最近也刚好读了相关的论文，并且仔细研读了其代码（OpenSLAM上的💩山，literally），故我把这些笔记整理成了一篇文章：</p>
<ul>
<li>本文作者并没有特龙，但是估计是相关团队的文章：<a href="https://ieeexplore.ieee.org/abstract/document/4084563/">Improved Techniques for Grid Mapping with Rao-Blackwellized Particle Filters</a></li>
<li>上面这篇论文可以说是：<a href="https://ieeexplore.ieee.org/abstract/document/1250629/">IROS2003:An Efficient FastSLAM Algorithm for Generating Maps of Large-Scale Cyclic Environments from Raw Laser Range Measurements</a>的升级版（这篇论文的建议分布是“学”出来的）。</li>
</ul>
<p><img src="/2021/10/22/%E7%89%B9%E9%BE%99%E6%99%BA%E6%85%A7-GMapping/Screenshot%202021-10-22%20194809.png"></p>
<center>
Figure 1. 这人有一个以自己名字命名的实验室，还曾拒绝过出任Google副总裁...
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-gmapping-论文分析">II. GMapping 论文分析</h2>
<h3 id="大致思想">2.1 大致思想</h3>
<p>​ gmapping是一篇基于粒子滤波的配准工作，其主要创新点只有一点：就是得到了一个改进的粒子滤波建议分布（improved proposal distribution），这篇文章既没有涉及到回环检测、后端优化，也没有深入分析前端的配准算法。其主要贡献就是：改进粒子滤波在某些传感器上的表现。</p>
<p>​ 我们考虑激光雷达，一般来说，激光雷达的测距精度很高，在配准算法具有很好的表现情况下时，可以认为配准也有比较好，配准结果噪声较小。因为粒子滤波的主要思想是：</p>
<div class="note info"><ul>
<li>我先建模一个易于获取的建议分布（proposal）</li>
<li>再建模一个【近似的】建议分布与目标分布之间的差别w（权重）（根据贝叶斯理论，一般是乘性的因子）</li>
</ul>
</div>
<p>​ 可见，如果目标分布（贝叶斯后验）很好获得，那么我们可以直接将目标分布当作建议分布，并且使得这差别权重都相等，为1。但是一般来说，需要粒子滤波解决的问题都不会有简单的目标后验，故建模一个好的建议分布是非常必要的：</p>
<div class="note primary"><ul>
<li>一个好的建议分布可以使得【近似的】差别权重对于其近似性的要求降低</li>
<li>好的建议分布可以提高采样的质量</li>
</ul>
</div>
<p>​ 传统意义上，建议分布一般会使用odometry的运动模型分布，比如沿着运动方向的与垂直运动方向两个方向为主轴的高斯分布。在粒子的更新阶段（也即从建议分布采样阶段），我们根据控制<span class="math inline">\(u_t\)</span>，确定<span class="math inline">\(x_t^{(i)}=u_t *x_{t-1}^{(i)}\)</span>，并且根据<span class="math inline">\(u_t\)</span>，确定一个带噪声的<span class="math inline">\(x_t^{(i)}\)</span>，人工加噪相当于是从运动模型分布中采样了。但是，gmapping这篇论文说：odometry较之于LiDAR配准来说，一般都大了一些，如果我们可以在建议分布中也用上观测的值，说不定可以得到更加符合目标分布的建议分布。</p>
<blockquote>
<p>When using the odometry model as the proposal distribution in such a case, the importance weights of the individual samples can differ signifificantly from each other since only a fraction of the drawn samples cover the regions of state space that have a high likelihood under the observation model</p>
</blockquote>
<p>​ 举一个例子：假设我们有一条长走廊，长走廊较为理想。那么对于配准来说，长走廊情况下的配准协方差沿着走廊方向的分量更大，但是垂直走廊方向很小，而另一方面，odometry在两个方向上可能都有较大的协方差。如果我们使用odometry的协方差，在更新采样环节可能会采到次优的位置，但如果此时结合配准误差、里程计协方差，可以将：</p>
<ul>
<li>垂直长走廊方向的协方差降下来，沿着长走廊方向的协方差则可以由odometry主导。</li>
</ul>
<p>​ 从这样的分布中采样，可以得到更好的结果。</p>
<p>​ 此外，还有另一个问题。为什么你在实现PF时，使用完全随机的采样策略效果并不好？这篇论文中的一个解释我觉得非常有道理：</p>
<blockquote>
<p>However, if the observation likelihood is <strong><u>peaked</u></strong> the number of pose samples <span class="math inline">\(x_j\)</span> that has to be sampled from the motion model is high, since a dense sampling is needed for sufficiently capturing the <strong><u>typically small areas of high likelihood</u></strong>. This results in a similar problem than using the motion model as the proposal: a high number of samples is needed to s<strong><u>ufficiently cover the meaningful region of the distribution</u></strong>.</p>
</blockquote>
<p>​ 之前也没有想得太深，只是觉得角度上的采样不足，于是增大了角度采样。现在想想，整个后验分布确实就是一个具有突出峰值的分布，在实验过程中也发现了这一点（实验是<a href="https://enigmatisms.github.io/2021/10/15/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%902%E3%80%91/">上一篇博客</a>中的粒子滤波，更新过程中发现，收敛时的粒子分布的确呈尖峰形状）。</p>
<h3 id="如何结合观测">2.2 如何结合观测</h3>
<p>​ PF更新公式如下： <span class="math display">\[
\begin{equation}
w_t=w_{t-1}\frac{
\eta p(z_t|x_{1:t}, z_{1:t-1})p(x_t|x_{t-1},u_{t-1})
}{
\pi(x_t|x_{1:t-1},z_{1:t},u_{1:t-1})
}
\end{equation}
\]</span> ​ 朴素情况下，建议分布就是运动状态转移分布：<span class="math inline">\(p(x_t|x_{t-1},u_{t-1})\)</span>，我们将其替换：考虑到配准信息也可以使用，那么gmapping使用了一个这样的策略：</p>
<ul>
<li>首先我根据scan-matcher确定一个ROM（region of meaning，有意义的区域），也即是配准认为可能的分布位置</li>
<li>在这个有意义的区域内进行<strong><u>多次采样</u></strong>。多次采样的结果，使用scan-matcher得到<span class="math inline">\(p(x_t|x_{1:t},z_{1:t-1})\)</span>（似然），而由于控制已知（均值已知），参数一般也已知，那么分布就已知，则在选取的点可以计算<span class="math inline">\(p(x_t^{(j)}|x_{t-1},u_{t-1})\)</span></li>
<li>我们需要计算的improved proposal是：<span class="math inline">\(p(x_t|m^{(i)}_{t-1},x_{t-1},z_t,u_{t-1})\)</span>。这个的物理意义是：在第i个粒子对应的map <span class="math inline">\(m^{(i)}_{t-1}\)</span>下，由<span class="math inline">\(x_{t-1}\)</span>由控制量<span class="math inline">\(u_{t-1}\)</span>转移，观测到<span class="math inline">\(z_t\)</span>的条件下，在<span class="math inline">\(x_t\)</span>位置的概率。看起来这个非常像后验，但是其计算是近似的。</li>
</ul>
<p>​ 但是实际上，在RBPF中，更新公式有所不同。因为RBPF是专门针对SLAM设计的一种粒子滤波，在滤波过程中，各种概率分布需要包含地图信息。针对RBPF的权重更新公式如下： <span class="math display">\[
\begin{equation}\label{rbpf}
w_t=w_{t-1}\frac{
\eta p(z_t|x_{t}, m_{t-1})p(x_t|x_{t-1},u_{t-1})
}{
p(x_t|x_{t-1},z_t,u_{t-1},m_{t-1})
}
\end{equation}
\]</span> ​ 上式的分母可以使用贝叶斯理论展开： <span class="math display">\[
\begin{align}
&amp;p(x_t|x_{t-1},z_t,u_{t-1},m_{t-1})=\frac{p(z_t|x_t,x_{t-1},u_{t-1},m_{t-1})p(x_t,x_{t-1},u_{t-1},m_{t-1})}
{p(z_t,x_{t-1},u_{t-1},m_{t-1})}\\
&amp;p(x_t,x_{t-1},u_{t-1},m_{t-1})=p(x_t|u_{t-1},m_{t-1},x_{t-1})p(u_{t-1},m_{t-1},x_{t-1})=p(u_{t-1},m_{t-1},x_{t-1})p(x_t|x_{t-1},u_{t-1})\tag{条件独立性-1}\\
&amp;p(z_t|x_t,x_{t-1},u_{t-1},m_{t-1})=p(z_t|x_{t},m_{t-1})\tag{条件独立性-2}
\end{align}
\]</span> ​ 故，分母可以展开成为： <span class="math display">\[
\begin{equation}
\frac{p(z_t|x_t,m_{t-1})p(x_t|x_{t-1},u_{t-1})}
{p(z_t|x_{t-1},u_{t-1},m_{t-1})}
\end{equation}
\]</span> ​ 带入公式<span class="math inline">\(\eqref{rbpf}\)</span>中可以得到<span class="math inline">\(w_t=w_{t-1}p(z_t|x_{t-1},u_{t-1},m_{t-1})\)</span>。则进一步可以写为（别看公式很长，其实完全就是贝叶斯，“很好”推的！）： <span class="math display">\[
\begin{align}
&amp;p(z_t|x_{t-1},u_{t-1},m_{t-1})=\int p(z_t,x&#39;|x_{t-1},m_{t-1},u_{t-1})dx&#39;=\\
&amp;\int \frac {p(x&#39;,z_t,x_{t-1},m_{t-1},u_{t-1})}{p(x&#39;|x_{t-1},m_{t-1},u_{t-1})p(x_{t-1},u_{t-1},m_{t-1})}p(x&#39;|x_{t-1},m_{t-1},u_{t-1})dx&#39;=\\
&amp;\int p(z_t|m_{t-1},x&#39;,x_{t-1},u_{t-1})p(x&#39;|x_{t-1},m_{t-1},u_{t-1})dx&#39;\stackrel{\text{独立性}}{\longrightarrow}\\
&amp;\int p(z_t|x&#39;,m_{t-1})p(x&#39;|x_{t-1},u_{t-1})dx&#39;\propto\\
&amp;\sum_{i=1}^Kp(z_t|m_{t-1}^{(i)},x_j)p(x_j|x_{t-1}^{(i)},u_{t-1})\label{approx}
\end{align}
\]</span> ​ 公式<span class="math inline">\(\eqref{approx}\)</span>将最后的转换完成了，这个公式使得我们不必计算复杂的条件概率，而可以使用：机器人运动学模型分布与观测模型分布的加权组合，更新每一个粒子（<strong><u>运用好独立性假设以及边缘化，可以推出很多有意思的公式</u></strong>）。</p>
<p>​ 论文中的更新迭代策略是这样的：</p>
<ul>
<li>根据里程计信息，作为初值，进行配准，得到带有观测信息的<span class="math inline">\(u_{t-1}^*\)</span></li>
<li><span class="math inline">\(x_{t-1}+u_{t-1}^*\)</span>周围（一个球内）采样，每个采样点<span class="math inline">\(x_s\)</span>都可以根据里程计的高斯分布以及配准的似然域计算点权（<span class="math inline">\(p(z|x)p(x|x&#39;,u)\)</span>），注意，所有点的点权之和，就是更新公式的<span class="math inline">\(p(z_t|x_{t-1},u_{t-1},m_{t-1})\)</span>。</li>
<li>根据采样的点可以计算高斯分布，最后得到的粒子从这个高斯分布中采样。</li>
</ul>
<div class="note danger"><p>​ 非常奇怪的是，<strong><u>网上所有GMapping的实现</u></strong>，都没有实现多点采样生成高斯分布再进行重新采样的步骤。</p>
</div>
<hr>
<h2 id="iii.-gmapping-代码流程">III. GMapping 代码流程</h2>
<h3 id="processscan">3.1 processScan</h3>
<p>​ processScan是核心函数：</p>
<h5 id="运动模型">3.1.1 运动模型</h5>
<p>​ 首先从运动模型中采样（<code>drawFromMotion</code>函数，此函数的原理在《概率机器人上》）</p>
<h5 id="计算移动距离">3.1.2 计算移动距离</h5>
<p>​ 计算移动距离：<code>m_linearDistance</code>, <code>m_angularDistance</code></p>
<ul>
<li>保证平移距离不过大，过大则认为位置发生了突变</li>
<li>当移动距离过大，或是长时间没有更新，那么就需要进行一次配准</li>
</ul>
<h5 id="scanmatch">3.1.3 scanMatch</h5>
<p>​ scanMatch首先根据plainReading（也就是点云原始数据）进行配准，配准使用搜索算法，在<code>optimize</code>函数中。注意代码里有bug：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (bestScore&gt;=currentScore)</span><br></pre></td></tr></table></figure>
<p>​ 六个方向移动，直到达到最大分数或者迭代次数，每次减小步长</p>
<p>​ score的计算,在之后的函数中说. 配准函数针对了每一个粒子,每个粒子都进行了一次优化</p>
<p>​ <code>likelihoodAndAScore</code>函数 进行似然计算：大概做了这样的事情：</p>
<ul>
<li>skip是跳过处理的一种实现，指的是：激光线太多，信息冗余，可以跳过一个激光线计算似然域</li>
<li>首先把激光器的位姿投影到世界坐标系下，此后对于每一条需要处理的激光线，也转到世界坐标系下，并且确定一个位于空域的点位置（激光线截短一截）</li>
<li>在一个领域内，查找最适合的障碍物点（因为激光测距会存在噪声），障碍物点需要满足：该点占用概率大于阈值，对应空域点占用概率小于阈值</li>
<li>求均值，并求激光点世界坐标位置与该均值的距离（越小说明越应该是这个障碍点）</li>
<li>求似然。这样求出的似然域是较为平滑的，故在scanMatch的optimize中，计算score也是用了类似的平滑函数</li>
</ul>
<p>​ <code>computeActiveArea</code>：是一个更新地图操作，因为地图是基于占用栅格的，未知区域也是需要表征的，限制范围可以节约内存资源。computeActiveArea更新了地图大小（每个粒子）：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//this allocates the unallocated cells in the active area of the map</span></span><br><span class="line"><span class="comment">//cout &lt;&lt; &quot;activeArea::size() &quot; &lt;&lt; activeArea.size() &lt;&lt; endl;</span></span><br><span class="line">map.<span class="built_in">storage</span>().<span class="built_in">setActiveArea</span>(activeArea, <span class="literal">true</span>);</span><br></pre></td></tr></table></figure>
<p>​ 在此前，先根据scanMatch计算的位姿，计算了占用栅格（每条激光线经过的每个点），将占用栅格加入到map中，等待对地图进行更新。</p>
<h3 id="updatetreeweights">3.2 updateTreeWeights</h3>
<p>​ updateTreeWeights只做了三件事：</p>
<ul>
<li>归一化权重</li>
<li>轨迹树重置</li>
<li>权重沿着树传播</li>
</ul>
<p>​ 轨迹树会不会做的是这样一件事情呢？初始时粒子都在同一位置，在迭代过程中，也可能出现两个粒子位姿一致的情况吗？会有一个parent对应了很多child的情况吗，轨迹树的child会怎么来？</p>
<p>​ propagateWeights就是一层一层将叶子节点的weight向上传播（因为在scanMatch中会重新衡量叶子节点的weight，而上层weight（相当于之前的位姿）是逐层累加的）。</p>
<p>​ 但是resample计算使用的是当前叶子节点的权重，与上层的权重无关。那么这样逐层累加的weight，其作用是什么？<code>weightSum</code>在另一个类中被使用了。看代码时没有注意继承关系，以为只有<code>GridSlamProcessor</code>是主要模块，最后发现openslam版本中，还有一个类叫做：<code>GridSlamProcessorThread</code>，内部实现了一些父类没有实现的回调函数，在这个类中定义的<code>onScanmatchUpdate</code>函数中，用到了weightSum：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(part-&gt;weightSum&gt;bestWeight)&#123;</span><br><span class="line">    bestIdx=idx;</span><br><span class="line">    bestWeight=part-&gt;weightSum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 算法选择权重综合最大的一个粒子（故与历史信息相关了），取该粒子对应的map作为当前地图，根据最大权重的粒子更新地图，并且选择最优粒子的位姿当作自身当前位姿。</p>
<p>​ 不过根据算法的逻辑，每次计算了底层叶子节点的weight之后，上层需要根据底层来的值修改权重累加，但是非叶子节点的weightSum并没有用（weightSum本身就没有被用过多少次），只有叶子节点（当前最新的particles）对应的weightSum才有价值，故propagateWeights以及相应函数其实是没有作用的。</p>
<h3 id="重采样">3.3 重采样</h3>
<p>​ resmapleIndexes函数：这里的重采样策略使用的也是《概率机器人》上的低方差重采样。故可能出现：两个粒子重复的情况。返回的是被采样到的粒子的下标。在这个函数的内部，由于使用的策略是低方差采样，下标是有顺序的，故采样的结果也是有顺序的。 ​ 而<code>new TNode</code>在整个项目中出现在：</p>
<ul>
<li><code>gridslamprocessor_tree.cpp</code> 的<code>integrateScanSequence</code>中，没有实际调用</li>
<li><code>gridslamprocessor_tree.cpp</code> 的 <code>getTrajectory</code>中，在GSP构造时使用，所以对代码逻辑的影响应该不大</li>
<li><code>gridslamprocessor.hxx</code> 的<code>resample</code>函数中用到过，此处的使用对代码逻辑有实际的影响</li>
</ul>
<p>​ 建立以及更新权重轨迹树的流程与作用：</p>
<ul>
<li>根据权重进行低方差采样，结果被保存在<code>m_indexes</code>之中，注意<code>m_indexes</code>是顺序化的，比如：原来有8个粒子，id从0-7，重采样之后成为：1 1 1 4 4 4 7 7，那么在轨迹树中，0，2，3，5，6均会被删除（假设没有其他关联，整条与这几个节点有关的树枝均会被切除）</li>
<li>轨迹树实际上就是重采样树，0 1 2 3 4 5 6 7 这8个节点，按照上面的重采样例子会生成如下图所示的树：</li>
</ul>
<pre class="mermaid">
graph TD

A(root)
A1(0)
A2(1)
A3(2)
A4(3)
A5(4)
A6(5)
A7(6)
A8(7)
B(1-1)
C(1-2)
D(1-3)
E(4-1)
F(4-2)
G(4-3)
H(7-1)
I(7-2)
A---A1
A---A2
A---A3
A---A4
A---A5
A---A6
A---A7
A---A8
A2---B
A2---C
A2---D
A5---E
A5---F
A5---G
A8---H
A8---I

</pre>
<center>
Figure 2. GMapping权重树结构示例
</center>
<p>​ 重采样得到点就相当于子节点，重采样前的节点是父节点。</p>
<ul>
<li>删除所有重采样后没有结果的点，比如假设上述例子又发生了一次重采样，(7-1)(7-2)权重过小，那么(7-1)(7-2)(7)都会被删除</li>
<li>对重采样后的新particles，根据当前的点云信息，更新地图（activeArea重新计算），但是权重会被重置为0。那么这个为0的权重，将会在scanMatch函数中被修改（计算完likelihood之后，权重会被设置为likelihood），并且在weightSum中也累加一份。</li>
</ul>
<hr>
<h2 id="iv.-流程总结">IV. 流程总结</h2>
<p>​ 我已经发现了：openslam的代码又臭又长，还不能编译，令人根本不知道processScan这个函数究竟在什么情况下被使用，貌似因为下载的是最原始的版本。</p>
<div class="note danger no-icon"><p>​ addScan函数（貌似是ROS封装），在转换scan信息之后，调用processScan函数。此函数首先从motion model中采样，此后判定是否需要进行配准。</p>
</div>
<div class="note warning no-icon"><p>​ 如果需要配准，通常情况下是超时或者超出距离阈值，则需要调用scanMatch函数，此函数内部使用被称之为【爬山法】的搜索方法进行匹配，得到修正后的位姿（<strong><u>但是貌似没有实现GMapping中的生成高斯分布</u></strong>）。</p>
</div>
<div class="note info no-icon"><p>​ 此后需要计算似然，使用似然域法，在领域内搜点获得一个平滑似然。计算得到的似然作为新的权重，并且将此权重累加到weightSum上去。</p>
</div>
<div class="note success no-icon"><p>​ 计算地图更新，也就是重新计算activeArea，需要向栅格图原始数据（PointAccumulator）的容器中增加新的栅格（或者对原有栅格进行访问）。</p>
</div>
<div class="note primary no-icon"><p>​ 重采样步骤，重采样的过程中，会对轨迹树进行重建。方法在上文已经阐述过了，注意propagateWeights是没有太大意义的操作，我直接忽略了。</p>
</div>
<hr>
<h2 id="v.-效果">V. 效果</h2>
<p>​ 2007啊！他们太强了。不过也不能说完美，有如下几个问题：</p>
<ul>
<li>5cm grid 精度可以适应大多数的需求，所以2D SLAM方向做的人越来越少了（基本满足需求了），而我尝试使用更高精度grid的时候（比如2.5cm），配准将发生错误（我猜是grid太小了，导致了激光器模型的稀疏性问题）</li>
<li>同时，grid变小将会占用过多的内存（1cm大小的格子跑Intel数据集貌似可以跑到10GB内存占用，真的无法想象当年他们那个条件怎么做实验的）</li>
<li>丢帧将会导致非常严重的问题，当点云频率很高的时候，丢帧将直接导致配飞（很奇怪，里程计不是用上了吗？）</li>
<li><strong><u>貌似没有实现2007年论文的improved proposal思想</u></strong>。</li>
</ul>
<p>​ 以下测试的地图均为5cm大小grid，intel数据包由于点云帧率低，我的i5上可以开8倍速播放包，而我自己做的仿真数据集只能2倍速（否则丢帧直接死掉），粒子个数均为15个，其他参数都是默认参数。</p>
<p><img src="/2021/10/22/%E7%89%B9%E9%BE%99%E6%99%BA%E6%85%A7-GMapping/Screenshot%20from%202021-10-22%2017-55-33.png"></p>
<center>
Figure 3. Intel 实验室数据集
</center>
<p><img src="/2021/10/22/%E7%89%B9%E9%BE%99%E6%99%BA%E6%85%A7-GMapping/Screenshot%20from%202021-10-22%2017-57-36.png"></p>
<center>
Figure 4. hqy仿真数据集【1】
</center>
<p><img src="/2021/10/22/%E7%89%B9%E9%BE%99%E6%99%BA%E6%85%A7-GMapping/Screenshot%20from%202021-10-22%2017-59-28.png"></p>
<center>
Figure 5. hqy仿真数据集【2】
</center>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>概率论</tag>
        <tag>SLAM</tag>
      </tags>
  </entry>
  <entry>
    <title>线性/树型分类器的纯理论分析</title>
    <url>/2021/03/02/%E7%BA%BF%E6%80%A7-%E6%A0%91%E5%9E%8B%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%BA%AF%E7%90%86%E8%AE%BA%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="纯理论分析">纯理论分析</h1>
<hr>
<h2 id="preface">Preface</h2>
<p>​ 周志华老师的《机器学习》看到了第五章，可总感觉看得太快了（可惜起步太晚了，大三下才系统地学ML）。个人认为走马观花地看完全没有用处，最好是能自己将所有碰到的轮子都写一遍（理想情况），但人的精力毕竟有限，开学了时间也比较紧张，实现这一步就先跳过吧，而细致的理论分析与理解是完全必要的。LDA之前实现过<a href="https://github.com/Enigmatisms/Algorithms-Plus/blob/master/py/LDA/lda_learn.py">Github Algorithm-Plus🔗</a>，决策树倒是连理论都没怎么细看，只调过库。为了不当调库侠，有写轮子的能力，个人将对这两章进行一下梳理，写一下自己的理解。</p>
<p><img src="/2021/03/02/%E7%BA%BF%E6%80%A7-%E6%A0%91%E5%9E%8B%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%BA%AF%E7%90%86%E8%AE%BA%E5%88%86%E6%9E%90/melon.jpg"></p>
<center>
Figure 1. 西瓜
</center>
<p>​ LDA（消歧义：Linear Discriminant Analysis，不是Latent Dirichlet Allocation）和决策树都是两个非常简单但是又很优雅的分类器。</p>
<span id="more"></span>
<hr>
<h2 id="lda的数学推导">LDA的数学推导</h2>
<p>​ <blockquote class="blockquote-center">
<p>同类样本的类内方差最小，而不同类样本的类间方差最大</p>

</blockquote></p>
<p>​ LDA是给定标签下的有监督降维方式，希望找到更低维度上的投影，可以满足上述属性。而对于高维而言，协方差是描述样本关系的指标。协方差的定义如下（大二下学的，回忆一下）：描述n维随机变量<span class="math inline">\(X=(X_1,X_2,...X_n)\)</span>每个分量之间存在的关系，协方差可以定义为： <span class="math display">\[
\begin{equation}
C = \begin{pmatrix}
c_{11} &amp; c_{12} &amp; ... &amp; c_{1n} \\
c_{11} &amp; c_{12} &amp; ... &amp; c_{1n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
c_{n1} &amp; c_{n2} &amp; ... &amp; c_{nn} \\
\end{pmatrix}
\end{equation}
\]</span> ​ 其中，<span class="math inline">\(c_{ij}\)</span>是两个分量<span class="math inline">\(X_i,X_j\)</span>的协方差<span class="math inline">\(Cov(X_i, X_j) = E[(X_i-E_i)(X_j-E_j)]\)</span>。协方差存在一些性质，比如说： <span class="math display">\[
\text{let }Cov(X)=\Sigma\\
Cov(AX+b)=A\Sigma A^T
\]</span> ​ 证明就省略了，根据期望的性质，推导还是比较简单的。</p>
<h3 id="二分类">二分类</h3>
<p>​ 假设有两类样本，<span class="math inline">\(D_1\)</span>以及<span class="math inline">\(D_2\)</span>，<span class="math inline">\(D_1\)</span>的样本中心（根据矩法可以求出来）为<span class="math inline">\(\mu_1\)</span>，对应地<span class="math inline">\(D_2\)</span>有<span class="math inline">\(\mu_2\)</span>，那么假设存在一个低维过原点的超平面（由于是平行投影，是否过原点不影响结果，但原点较好讨论），这个超平面方程为：<span class="math inline">\(w^Tx=0\)</span>，那么投影在这个超平面上的数据点应该有什么形式？中心点应该有什么形式？协方差是否改变？<span class="math inline">\(w^Tx=0\)</span>确实是降了1维（因为有一个约束方程），但如何使用<span class="math inline">\(w\)</span>进行投影？</p>
<p>​ 实际上，每个样本点<span class="math inline">\(x_i\)</span>都在：<span class="math inline">\(w^Tx+b_i=0\)</span> 这个超平面上，去掉这个相对原点的偏移，就可以得到每一个样本点在低维上的投影。实际是这样操作的：设<span class="math inline">\(x_i\)</span>是超平面<span class="math inline">\(w^Tx = 0\)</span>外一点，那么显然，<span class="math inline">\(x_i\)</span>可以表示为超平面上的投影点<span class="math inline">\(x_i&#39;\)</span>与法向量<span class="math inline">\(w\)</span>的加权组合（因为已经构成基了），比如： <span class="math display">\[
\begin{equation}
x_i=x_i&#39;+\lambda_iw
\end{equation}
\]</span> ​ 那么<span class="math inline">\(\lambda_i\)</span>显然就是<span class="math inline">\(x_i\)</span>在单位法向量<span class="math inline">\(w_e\)</span>上的投影，那么可以知道： <span class="math display">\[
x_i&#39;=x_i-\frac{w^Tx_iw}{\Vert w\Vert^2}
\]</span> ​ 但这是个什么呢？样本中心间的距离又是什么？可以求出样本中心应该在： <span class="math display">\[
\begin{equation}\label{proj}
x_c&#39;=\frac 1N\sum_{i=1}^N\left(x_i-\frac{w^Tx_iw}{\Vert w\Vert^2}\right)
\end{equation}
\]</span> ​ 显然公式<span class="math inline">\(\eqref{proj}\)</span>是可以进行化简的，对于内积部分（后半部分），需要将内积展开为累加，进行累加次序交换： <span class="math display">\[
\begin{array}{l}
\frac 1N\sum_{i=1}^N\frac{w^Tx_iw}{\Vert w\Vert^2}=
\frac 1{N{\Vert w\Vert^2}}\sum_{i=1}^N \left(\sum_{j=1}^nw_jx_{ij} \right)w\\
=\frac 1{\Vert w\Vert^2}\sum_{j=1}^n\frac 1n\sum_{i=1}^N w_jx_{ij}w\\
=\frac w{\Vert w\Vert^2}\sum_{j=1}^nw_j\mu_i
=\frac{w^T\mu w}{\Vert w\Vert^2}
\end{array}
\]</span> ​ 前半部分的化简十分简单。那么投影后的两个集合中心的差向量应该是： <span class="math display">\[
\begin{equation}\label{diff}
\pmb{d}=\mu_1-\mu_2-\frac{w^T(\mu_1-\mu_2)w}{\Vert w\Vert^2}
\end{equation}
\]</span> ​ 实际上，Fisher的处理方法与我的处理方法完全不同，我是真的求了一个这样的投影，但不管是Fisher还是西瓜书上的推导，均值全部都是：<span class="math inline">\(w^T\mu\)</span>，这让我觉得很奇怪，如果是这样的话，均值的维度不就是1了吗？但实际上维度只应该减1啊？以上都是我看了第一部分产生的想法，但实际上二分类LDA并不是投影到n-1维空间中（特征分量数为n），二分类的LDA直接投影到一维空间上。二分类只需要在一条直线上找到数据的投影即可，在这条直线上判定投影后的新数据离哪一类数据中心最近。</p>
<p>​ 由于这是一下从n维降到1维，所以几何直观上并不好理解。个人觉得这样的降维跨度太大了。</p>
<h4 id="为什么要投影到一条直线上">为什么要投影到一条直线上？</h4>
<p>​ 由于二分类输出的指示结果为 <span class="math inline">\(p_1,p_2,\text{ where } p_1+p_2=1\)</span>，也就是说分为两个类，落在两个类内的概率满足一个归一约束，那么输出就相当是在一条直线上。也就是说，LDA认为：<strong><u>输出在不同类上的概率实际上是所有输入特征经过<span class="math inline">\(w\)</span>映射的线性组合</u></strong>，二分类问题只需要得到直线上的一个值，就能根据归一约束求出分属于两个类的概率。那么：</p>
<ul>
<li>三分类问题只需要求得在二维空间上的一个点，就能求出一个样本分属于三个类的概率。也即线性组合输出了一个二维的点</li>
<li>四分类问题只需求出三维空间中的一个点，就能求出一个样本分属于四个类的概率...</li>
<li>M分类问题只需要求出M-1为空间中的一个点，就能求出一个样本分属于M个类的概率。</li>
</ul>
<p>​ 要注意特征空间（n维）和概率空间（M维）的不同。LDA实际上就是在正态分布以及同方差的假设下，认为只要线性组合n个特征，就能求出M维空间中的一个概率解。这也就解释了，为什么我一开始的理解是有问题的。问题的关键就在于：输出分类的概率是输入特征的线性组合。<strong><u>不能简单地想着投影，而要想为什么要这样投影，这样投影如何帮助求得分类概率。</u></strong></p>
<p>​ 那么数学上就比较好理解了：给定一条直线<span class="math inline">\(y=w^Tx\)</span>，说是要投影到直线上，实际上要做的是根据<span class="math inline">\(w\)</span>对样本的不同属性进行线性组合：<span class="math inline">\(w^Tx\)</span>。那么也就有： <span class="math display">\[
\begin{align}\label{class2}
&amp; \mu_1&#39;=w^T\mu_1 \tag{center of projected class 1} \\
&amp; \mu_2&#39;=w^T\mu_2 \tag{center of projected class 2} \\
&amp; \sigma_1=w^T\Sigma_1 w \tag{projected within-class cov 1}\\
&amp; \sigma_2=w^T\Sigma_2 w \tag{projected within-class cov 2}
\end{align}
\]</span> ​ 那么根据类内方差最小，类间方差最大的思想： <span class="math display">\[
\begin{equation}\label{obj1}
\text{max } \frac{\Vert {w^T\mu_1 - w^T\mu_2} \Vert^2}{w^T(\Sigma_1+\Sigma_2)w}
\end{equation}
\]</span> ​ 分子展开维转置乘积之后，可以定义两个散度矩阵： <span class="math display">\[
\begin{align}
&amp; S_b=(\mu_1-\mu_2)(\mu_1-\mu_2)^T &amp; \tag{within-class scatter matrix} \\
&amp; S_w=\Sigma_1+\Sigma_2 &amp; \tag{between scatter matrix}
\end{align}
\]</span> ​ 使用这两个散度矩阵，定义问题<span class="math inline">\(\eqref{obj1}\)</span>带有广义瑞利商的形式。解问题<span class="math inline">\(\eqref{obj1}\)</span>就可以得到最优的<span class="math inline">\(w\)</span>。由于<span class="math inline">\(w\)</span>的长度是不影响结果的（看的就是方向），不妨令分母为1，最大化分子，进一步化简为： <span class="math display">\[
\begin{equation}\label{obj2}
\begin{array}{ll}
\text{min } -w^TS_bw \\
\text{s.t. } w^TS_ww=1
\end{array}
\end{equation}
\]</span> ​ 请Lagrange坐到主席台上来。根据增加了一项乘子项的优化问题<span class="math inline">\(\eqref{obj2}\)</span>，KKT条件梯度为0，得到： <span class="math display">\[
\begin{equation}\label{kkt1}
S_bw=\lambda S_ww \rightarrow(\mu_1-\mu_2)=S_ww
\end{equation}
\]</span> ​ 等式<span class="math inline">\(\eqref{kkt1}\)</span>可以化简得原因是：<span class="math inline">\(S_b=(\mu_1-\mu_2)(\mu_1-\mu_2)^T\)</span>，也就是说，<span class="math inline">\(S_bw\)</span>实际方向就是<span class="math inline">\(\mu_1-\mu_2\)</span>，根据<span class="math inline">\(w\)</span>尺度任意性，直接令<span class="math inline">\(S_bw=\lambda(\mu_1-\mu_2)\)</span>省事。根据<span class="math inline">\(\eqref{kkt1}\)</span>，进行SVD分解（数值上会比较稳定）就可以得到<span class="math inline">\(w\)</span></p>
<h3 id="多分类">多分类</h3>
<p>​ 从上述理解中已经可以知道LDA的“降维分类”方式，实际上是通过原特征的线性组合，将特征空间直接变换到“概率空间”（或者是可以被变换为概率的空间）。当分类数量为M时，只需要知道M-1个类上的概率或者等价概率值就可以求出所有类上的“概率输出”值。</p>
<p>​ 也就是说：LDA的降维过程实际上是由n维特征空间变换为M-1维分类空间的过程。回顾二分类的情况，M = 2，也就是将所有样本投影到一维（直线）上：<span class="math inline">\(y=w^Tx\)</span>，直线上的值显然是一维的。这是由于参与线性组合的函数实际上是一个标量值函数（<span class="math inline">\(w^Tx\)</span>映射），要想输出高维的向量，只需要更改<span class="math inline">\(w\)</span>为一个矩阵<span class="math inline">\(W\)</span>即可。对于需要优化得到的结果，推导有些不同： <span class="math display">\[
\begin{equation}\label{div1}
S_t=\sum_{i=1}^m(x_i-\mu_t)(x_i-\mu_t)^T
\end{equation}
\]</span> ​ 定义公式<span class="math inline">\(\eqref{div1}\)</span>为全局散度，也就是每个样本点到所有样本的平均点的散度和。个人认为，由于类间差异在大多数情况下都会大于类内差异，所以<span class="math inline">\(S_t\)</span>相当于就是一个类间方差的表征（不同类的均值点到整体均值点的散度）。由于不同于二分类问题，类内散度需要重新定义了。显然类内的散度可以用类内样本与本类均值的差异来衡量： <span class="math display">\[
\begin{equation}\label{div2}
S_w=\sum_{j=1}^N(x_{ij}-\mu_i)(x_{ij}-\mu_i)^T
\end{equation}
\]</span> ​ 但是至于为什么西瓜书上要使用<span class="math inline">\(\eqref{div2}-\eqref{div1}\)</span>作为最后的类间散度矩阵，我不是很清楚。甚至我觉得，<span class="math inline">\(\eqref{div2}\)</span>的定义是多余的。类间散度实际上可以根据：</p>
<div class="note info"><p>​ 类内散度通常小于类间散度，在最优投影取得的情况下就更是这样了。所以每个样本，在类间散度很大的情况下，可以看作一个十分接近类内均值的点（如下图所示）。那么每个样本点都可以近似地被类内均值取代。</p>
</div>
<p><img src="/2021/03/02/%E7%BA%BF%E6%80%A7-%E6%A0%91%E5%9E%8B%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%BA%AF%E7%90%86%E8%AE%BA%E5%88%86%E6%9E%90/lda.JPG"></p>
<center>
Figure 2. 样本与均值的近似性
</center>
<p>​ 那么很自然，类间散度可以定义为（每个样本（近似）与全局均值的散度和） <span class="math display">\[
\begin{equation}\label{div3}
S_b=\sum_{i=1}^Mm_i(\mu_i-\mu)(\mu_i-\mu)^T
\end{equation}
\]</span> ​ 优化目标也需要更改，因为实际的输出式已经变成了如下式所示的多维线性组合矩阵<span class="math inline">\(W\)</span>，输出是多维的，那么可以简单地使用迹进行实现。 <span class="math display">\[
\begin{equation}\label{obj3}
\frac{W^TS_bW}{W^TS_bW}\rightarrow\text{ max }\frac{tr(W^TS_bW)}{tr(W^TS_bW)}
\end{equation}
\]</span> ​ 对于上式，继续根据拉格朗日乘子法可以得到： <span class="math display">\[
\begin{equation}\label{solve}
S_bW=\lambda S_wW\rightarrow {S_w}^{-1}S_bW=\lambda W
\end{equation}
\]</span> ​ 可知，<span class="math inline">\(W\)</span>是一个(n * M-1)维矩阵，而显然<span class="math inline">\(\eqref{solve}\)</span>中<span class="math inline">\(W\)</span>的每个列向量分量都是矩阵<span class="math inline">\({S_w}^{-1}S_b\)</span>的一个特征向量（符合特征向量定义，当然可能是广义特征向量），那么<span class="math inline">\(\begin{pmatrix}N-1\\n\end{pmatrix}\)</span>种不同的情况，究竟是哪N-1个特征向量组合成了最终的解<span class="math inline">\(W\)</span>？从公式<span class="math inline">\(\eqref{solve}\)</span>种可以看出，<span class="math inline">\(\lambda\)</span>越大越好（对应最大化<span class="math inline">\(\eqref{obj3}\)</span>）。那么只需要选择<span class="math inline">\({S_w}^{-1}S_b\)</span>最大的N-1个特征值（或者广义特征值）的特征向量组成解即可。</p>
<hr>
<h2 id="树型---决策树">树型 - 决策树</h2>
<blockquote class="blockquote-center">
<p>树越是向往高处的光亮,它的根就越要向下,向泥土,向黑暗的深处。—尼采</p>

</blockquote>
<p>​ emmm。这句话只因为有个“树”字就被我拿出来镇一镇文章了。决策树，利用一个个不相互影响的特征（或者我们认为影响不太大的特征，实际上有影响也是可以通过某些操作进行转化的）进行层层分类。正如猜物游戏，每次只能问一个答案只有“是”和“否”的问题，通过答案产生的分支进行推测。通过对待分类样本的层层分解可以获得最终的分类推测。本节只讨论其相关的数学原理，对于具体的生成 / 剪枝算法将不会涉及（因为这没有吸引到我）。</p>
<h3 id="信息论相关">信息论相关</h3>
<p>​ 回顾一下信息熵的两个定义： <span class="math display">\[
\begin{equation}\label{ent}
Ent(x)=-\sum_{i=1}^np_ilog(p_i)\text{ or }Ent(x)=-\int p(x)log(p(x))dx
\end{equation}
\]</span> ​ 左边为常见的离散型随机变量熵的定义，而右边则为连续变量在其PDF意义下的熵。在讲KL散度的时候已经说过了，熵是用于衡量信息编码的一个概念。一个随机事件的不确定性越大，代表信息量越大，编码这个事件所需要的二进制位数也相应越大。</p>
<p>​ 在决策树一章中，《西瓜书》提到：</p>
<blockquote class="blockquote-center">
<p>"信息熵" (information entropy) 是度量样本集合纯度最常用的一种指标。</p>

</blockquote>
<p>​ 为什么这么说呢？集合样本纯度又是指什么？纯度在此处指：同一个划分中，由于划分集合内的元素都存在相应的label，如果集合内的label越趋于一致，那么这个集合的纯度也就越高。如果用比例<span class="math inline">\(p_k\)</span>表示划分集合中，第k类样本所占的比例，那么这个集合的信息熵（纯度）表示如下： <span class="math display">\[
\begin{equation}\label{purity}
Ent(D) = -\sum_{i=1}^np_ilog(p_i)
\end{equation}
\]</span> ​ 可以看出，公式<span class="math inline">\(\eqref{purity}\)</span>定义的纯度，当某一类完全占据整个集合时熵取得最小值0。为什么要讨论信息熵或者是纯度？处于决策树的生成考虑，我们使用很多特征生成一棵决策树，但在决策树中，不同的特征地位也是不相同的，naive的情况下，每次分支只选择其中一个特征，那么要选哪一个特征作为本结点向下分支的特征？需要进行优选，优选的指标就是纯度。</p>
<p>​ 显然，如果一种划分模式可以划分出纯度较高的子结点（样本子集合），那么：</p>
<ul>
<li>全纯结点（只有一类）可以避免进一步分支，减小树结构复杂度</li>
<li>子集合越纯，说明分类效果越好（因为原集合是无序的，熵大，分类可以看作熵减过程）</li>
</ul>
<p>​ 由此我们定义信息增益：对于公式<span class="math inline">\(\eqref{purity}\)</span>定义的“纯度”，个人认为应该叫做“杂度”更好，实际上我看Wikipedia称这个为“impurity”，很显然嘛，值越大杂度越高。那么原集合的杂度为<span class="math inline">\(Ent(D)\)</span>，如何选取划分才能使得系统的杂度下降最大呢？假设我们选取的属性<span class="math inline">\(a\)</span>存在<span class="math inline">\(v\)</span>个不同的值（也就是<span class="math inline">\(v\)</span>分支），那么每个分支（a属性的每种可能取值）都会有一定样本（可以为0），记为<span class="math inline">\(D^v\)</span>。对应地，<span class="math inline">\(Ent(D^v)\)</span>指的是总体为<span class="math inline">\(D^v\)</span>时，分类的杂度。那么根据<span class="math inline">\(\vert D^v\vert / \vert D\vert\)</span> 也即每个属性样本的占比对杂度进行加权，划分后的系统杂度为： <span class="math display">\[
\begin{equation}\label{impurity}
G(D,a)=Ent(D)-\sum_{j = 1}^v\frac{|D^j|}{|D|}Ent(D^j)
\end{equation}
\]</span> ​ 公式<span class="math inline">\(\eqref{impurity}\)</span>是原系统的杂度 减去 划分后的系统杂度。这也就是<strong><u>分类，这个熵减过程到底让系统的熵减了多少</u></strong>。这被称为<strong><u>信息增益</u></strong>（information gain），实际上衡量的就是分类使系统熵减少的量。显然我们希望，熵减越大越好。那么每次从属性集合中计算 / 选择信息增益最大的属性进行分支即可。</p>
<h4 id="互信息">互信息</h4>
<p>​ 信息论中，如果需要衡量两个随机变量之间的关系，可以计算 一个随机变量携带的信息包含另一个随机变量信息的量大小，这被定义为互信息（mutual information）。可以这样认为：两个有关联的变量，给定其中一个变量的信息，另一个变量的不确定性随之减小： <span class="math display">\[
\begin{equation}\label{mut}
I(X;Y)=D_{KL}(P_{XY}||P_X \otimes P_Y),\text{ where } x\in\mathcal{X},y\in\mathcal{Y}
\end{equation}
\]</span> ​ 上式说的是：x是空间<span class="math inline">\(\mathcal{X}\)</span>中的随机变量，y是空间<span class="math inline">\(\mathcal{Y}\)</span>中的随机变量，那么互信息是联合分布<span class="math inline">\(P_{XY}\)</span>与边缘分布<span class="math inline">\(P_X\text{ and }P_Y\)</span>的外积的KL散度。多维空间不好理解的话，讨论一维变量： <span class="math display">\[
\begin{equation}\label{mut1}
I(X;Y)=\int_y\int_xp(x, y)log\left(\frac{p(x, y)}{p(x)p(y)}\right)dxdy
\end{equation}
\]</span> ​ 为什么这样可以描述相关程度呢？因为显然，X与Y独立时的联合分布为<span class="math inline">\(p(x)p(y)\)</span>，此处衡量的即是真实联合分布<span class="math inline">\(p(x, y)\)</span>与独立时的联合分布的差别。</p>
<p>​ 互信息和信息增益是存在关系的[1]。在划分时，如果对属性集合A（也就是<span class="math inline">\(a\)</span>所在的集合）取上一个期望，那么会有什么发现？也即对公式<span class="math inline">\(\eqref{impurity}\)</span>定义的信息增益取A的期望，为了方便数学变换，我们将<span class="math inline">\(\eqref{impurity}\)</span>展开： <span class="math display">\[
\begin{equation}\label{expand}
G(D,a)=-\sum_{k=1}^Jp_klog_2p_k-\sum_{v=1}^V\frac{|D^v|}{|D|}\left(-\sum_{k=1}^Jp_{D^v,k}log_2p_{D^v,k}\right)
\end{equation}
\]</span> ​ 显然公式<span class="math inline">\(\eqref{expand}\)</span>可以被表示为（原系统熵 - 给定划分下的新集合熵） <span class="math display">\[
\begin{equation}\label{ent1}
G(D,a)=Ent(D)-Ent(D|a)
\end{equation}
\]</span> ​ 进行期望的求取可以得到： <span class="math display">\[
E_A(G(D,a))=Ent(D)-Ent(D|A)
\]</span> ​ 下面证明一个有关互信息的简单结论： <span class="math display">\[
\begin{equation}\label{lemma}
I(X;Y)=Ent(X)-Ent(X|Y)
\end{equation}
\]</span> ​ 怎么说呢。推了好长时间没有推出来的原因就是：<strong><u>没有学过信息论，概念不清楚。</u></strong>比如<span class="math inline">\(\eqref{lemma}\)</span>右边的第二项，条件信息熵，定义为： <span class="math display">\[
\begin{equation}\label{cond}
Ent(X|Y)=\sum_{x\in\mathcal{X},y\in\mathcal{Y}}p(x,y)log(p(x|y)),\text{ but not }\sum_{x\in\mathcal{X}}p(x|y)log(p(x|y))
\end{equation}
\]</span> ​ 那么<span class="math inline">\(\eqref{lemma}\)</span>可以展开为： <span class="math display">\[
I(X;Y)=-\sum_{y\in\mathcal{Y}}\sum_{x\in\mathcal{X}}p(x,y)log(p(x))+\sum_{y\in\mathcal{Y}}\sum_{x\in\mathcal{X}}p(x,y)log\left( \frac{p(x,y)}{p(y)}\right)
\]</span> ​ 化简可以得到公式<span class="math inline">\(\eqref{lemma}\)</span>成立。那么可以知道，增益率对于A的期望（也就是对于属性集的概率平均）就是决策树结点与属性集的互信息。</p>
<h4 id="增益率">增益率</h4>
<p>​ 实际上，纯使用信息增益并不太好。假设某个分支结点只有一个样本，那么显然分支纯度最大（杂度最小），那么假如有一个属性分支极多，可能一下就将所有的样本分到不同结点上了（比如《西瓜书》上提到的，样本序号），这样容易产生过拟合的分支属性是没有意义的，但是只用信息增益的话实际就会选择这个分支方法。所以使用一个因子来限定分支数的影响： <span class="math display">\[
\begin{equation}\label{int}
IV(a)=-\sum_{v=1}^V\frac{|D^v|}{|D|}log\left( \frac{|D^v|}{|D|}\right)
\end{equation}
\]</span> ​ 可以发现，当分支数越多，这个值越大（不会出现单分支）。这个值称为：固有值（intrinsic value），只需要使用这个值对增益进行惩罚即可（除以此值）。</p>
<h4 id="基尼指数">基尼指数</h4>
<p>​ 针对CART决策树的，而以上所说的决策树使用信息增益作为划分属性选择的度量。基尼指数（Gini impurity）指的是：</p>
<blockquote class="blockquote-center">
<p>Gini impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset.[1]</p>

</blockquote>
<p>​ 翻译很简单：从集合中随机选择一个元素，再根据这个集合中的类别概率分布随机给这个元素进行分类，分类的错误概率就是基尼指数。 <span class="math display">\[
\begin{equation}\label{gini}
Gini(D)=\sum_{i=1}^{|\mathcal Y|}p_i\sum_{k\neq i}p_k=1-\sum_{k=1}^{|\mathcal Y|}p_k^2
\end{equation}
\]</span> ​ 显然，纯度越高的集合，内部随机取元素随机分类错误的概率（期望）越小。</p>
<h3 id="变量缺失处理的理解">变量缺失处理的理解</h3>
<p>​ 在贝叶斯决策论中提到：</p>
<ul>
<li>某一属性组合的变量可能根本不在样本中出现，但是不能直接认为这样的样本不存在。</li>
</ul>
<p>​ 而在决策树中，我们更多针对的问题是：当某一个样本某个属性值是未知的，如何处理这样的样本？丢弃是显然不可取的，这样可能损失太多的有效信息。而直接使用确实也不是办法，少掉一个属性要如何继续分支？《西瓜书》上将问题总结地很不错：</p>
<blockquote class="blockquote-center">
<p>我们需解决两个问题: (1) 如何在属性值缺失的情况进行划分属性选择 ? (2) 给定划分属性，若样本在该属性上的值缺失，如何对样本进行划分 ?</p>

</blockquote>
<p>​ 第一个问题我开始并没有什么很好的想法。而对于第二个问题，个人开始认为，假设已经知道了划分属性，可以根据其他完好样本来估计本样本在这个缺失属性上的分布，进行分布加权（事实上，这个想法类似《西瓜书》上提供的方法）。</p>
<p>​ 问题一实际上比较容易，我想得太复杂了。由于划分属性只考虑<strong><u>一个属性与分类结果的关系</u></strong>，那么完全用不着考虑多属性关系，只需要取出这个属性下对应没有缺失的样本，利用这些样本估计【属性】对【分类结果】的影响即可。以信息增益法为例，考虑<span class="math inline">\(\eqref{impurity}\)</span>定义的信息增益。假设我们讨论属性<span class="math inline">\(a\)</span>，由于有些样本属性是缺失的，在计算时将这些样本剔除再计算新集合<span class="math inline">\(\tilde{D}\)</span>的信息增益<span class="math inline">\(\tilde{G}(\tilde{D},a)\)</span>。注意，此信息增益计算出来后需要加权： <span class="math display">\[
\begin{equation}\label{weigh}
\tilde{G}(\tilde{D},a)\times\rho,\text{ what is ρ?}
\end{equation}
\]</span> ​ 其中的<span class="math inline">\(\rho\)</span>是加权因子，是什么权重呢？假设属性a在集合中有<span class="math inline">\(|\tilde{D}|\)</span>个未缺失样本，那么<span class="math inline">\(\rho=|\tilde D|/|D|\)</span>，也就是说，样本缺失越少，信息增益计算越可信。</p>
<p>​ 问题2实际上是将“让同一个样本以不同的概率划入到不同的子结点中去”（《西瓜书》言）。也可以使用没有缺失属性a的样本信息，假设某一分支分到属性a的v取值<span class="math inline">\(a^v\)</span>上： <span class="math display">\[
\tilde{r_v}=\frac{\sum_{x\in\tilde{D}_v}w_x}{\sum_{x\in {\tilde{D}}}w_x}
\]</span> ​ 也就是没有缺失属性a的样本中，有<span class="math inline">\(\tilde{r_v}\)</span>比例样本在本属性上取值为v，那么当每个样本权重为<span class="math inline">\(w_x\)</span>时，可以按照比例将缺失样本分配给不同分支（相当于按照概率（比例）割裂一个缺失样本）。</p>
<h3 id="kernelization">Kernelization</h3>
<p>​ 普通决策树的分类边界都是垂直于某个轴的（因为决策树是一种“非黑即白”的分类方法）。在某个属性（某个维度）上，只有固定的几种分法：</p>
<p><img src="/2021/03/02/%E7%BA%BF%E6%80%A7-%E6%A0%91%E5%9E%8B%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%BA%AF%E7%90%86%E8%AE%BA%E5%88%86%E6%9E%90/tree.jpg"></p>
<center>
<p>Figure 3. 决策树在单一维度上的分类边界总是垂直于轴的</p>
<p>​ 啊这？太过于“一维”了，甚至连简单的线性可分分类都需要经过如下的艰难操作：</p>
<p><img src="/2021/03/02/%E7%BA%BF%E6%80%A7-%E6%A0%91%E5%9E%8B%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%BA%AF%E7%90%86%E8%AE%BA%E5%88%86%E6%9E%90/clf.JPG"></p>
<center>
<p>Figure 4. 决策树扭来扭去</p>
<p>​ 一个简单的想法就是：不适用原属性进行分类，我们可以像PCA那样，使用属性的线性组合形成抽象属性，在这个抽象属性对应的新空间中，虽然分类边界仍然垂直于新的空间轴，但在原空间看起来，就成为一般线性分类器了。而进一步地，如果使用其他的非线性特征组合方法，也就是引入某些 <strong><u>kernel</u></strong>，甚至可以通过决策树达到任意分类边界生成的效果。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] Wikipedia, <a href="https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity">Decision tree learning</a></p>
</center></center>]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>概率论</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>编译原理小知识</title>
    <url>/2021/07/16/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%B0%8F%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<h1 id="为什么我不能乱链接">为什么我不能乱链接</h1>
<h2 id="i.-缘从何起">I. 缘从何起？</h2>
<p>​ 机队的小伙伴问了我一个问题，说是在一个<code>.hpp</code>文件中，定义了一个namespace，<code>.hpp</code>也有头文件保护，在namespace下也<strong><u>定义（声明 / 定义都在这个文件里）</u></strong>了几个函数（非类函数），<code>.hpp</code>文件中同时还有一个类的定义。那么自然这个文件会被至少两个<code>.cc</code>文件给include：</p>
<ul>
<li>类定义文件 / main函数所在的可执行文件</li>
</ul>
<p>​ 结果编译的时候报了redefined的错误，说是namespace下面的函数重复定义了。小伙伴很疑惑。我也很疑惑，开始我觉得是不应该把定义写在<code>.hpp</code>中，但想到类函数好像可以这么做啊？作为一个没有学过编译原理的自动化学生（请问自动化学生都在学些啥啊？），感到疑惑，于是查了点资料。</p>
<span id="more"></span>
<hr>
<h2 id="ii.-编译单元">II. 编译单元</h2>
<p>​ 首先，一个名词：translation unit</p>
<blockquote>
<p>A translation unit is the basic unit of compilation in C++. It consists of the contents of a single <strong><u>source file</u></strong>, <strong><u>plus</u></strong> the contents of any <strong><u>header files</u></strong> directly or indirectly included by it, <strong><u>minus</u></strong> those lines that were ignored using <strong><u>conditional preprocessing statements</u></strong>.</p>
</blockquote>
<p>​ 也即，一个translation unit包含源文件，直接或者间接include的头文件以及排除通过头文件保护排除的文件。</p>
<p>​ 而编译形成最终的可执行文件需要通过：</p>
<ul>
<li>编译+汇编（分别编译，汇编形成各自的机器指令文件）</li>
<li><strong><u>链接</u></strong>：多重符号，跨文件符号问题</li>
</ul>
<p>​ 而你现在的情况是：</p>
<ul>
<li>main.cc 文件（主函数，将会产生一个translation unit）</li>
<li>xxx.cc 文件（类定义，将会产生一个translation unit）</li>
</ul>
<p>​ 最终在链接阶段会将两个translation unit<strong><u>内容合并</u></strong>（链接过程工作的通俗说法）。但是很不巧，你的namespace下的函数<strong><u>同时进入了两个</u></strong>translation unit中。</p>
<p>​ 也就是在两个translation unit中，各被编译一次。如果两个translation unit分属不同的可执行文件（不被链接到一块儿去），那还好说。但是现在他们被链接到一起去了，也就形成了重定义，两个translation unit中各有一份定义。</p>
<p>​ 也就是说，最好的解决方案是：<strong><u>只在hpp中声明函数，在cc中定义函数，这样不会错。</u></strong></p>
<hr>
<h2 id="iii.-头文件保护">III. 头文件保护？</h2>
<p>​ 头文件保护作用与单一的translation unit中。也即，比如：</p>
<ul>
<li><code>b.h</code> 中</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;a.h&quot;</span></span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<ul>
<li><code>test.c</code> 中</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;a.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;b.h&quot;</span></span></span><br></pre></td></tr></table></figure>
<p>​ 那么两次include导致<code>a.h</code>两次代码复制到<code>test.c</code>，将由头文件保护的存在而不被编译两次。头文件保护和跨translation unit的链接没有关系，它只是防止一个translation unit内部，不因为多重间接include导致重定义。</p>
<p>​ 不仅是namespace不行，直接裸函数定义在 <code>.hpp</code> 中，之后又被多重引用 + 链接到同一个可执行文件中，也会导致问题，比如我试了试：</p>
<ul>
<li><code>name.hpp</code> 内容如下</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> __NAME_HPP</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __NAME_HPP</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">sub</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a - b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span>  <span class="comment">//__NAME_HPP</span></span></span><br></pre></td></tr></table></figure>
<ul>
<li>此后在<code>test.cc</code> , <code>main.cc</code>两个文件都 include<code>name.hpp</code>，进行编译，输出结果如下：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="language-bash">&gt;&gt; g++ ./main.cc ./test.cc -o main.exe</span></span><br><span class="line"></span><br><span class="line">~\ccMq7p5P.o:test.cc:(.text+0x0): multiple definition of `sub(int, int)&#x27;</span><br><span class="line">~\cces7mzx.o:main.cc:(.text+0x0): first defined here</span><br><span class="line">collect2.exe: error: ld returned 1 exit status</span><br></pre></td></tr></table></figure>
<p>​ 也直接报错了。</p>
<hr>
<h2 id="iv.-class可以在hpp内定义">IV. class可以在hpp内定义</h2>
<p>​ class可以在 hpp 内定义函数，同样都是被<code>定义.cc</code>， <code>主函数.cc</code>include，为什么类函数可以过编译？</p>
<p>​ 因为类函数有<strong><u>特殊性</u></strong>：声明 和 定义放在一起时，函数<strong><u>自动内联</u></strong>（inline）。inline函数在多重定义存在时，只会处理inline声明位置的定义。</p>
<p>​ 所以，另一种解决方案是：在namespace下的函数前面加上 <strong><u>inline</u></strong>。但是我个人非常不建议这么做。</p>
]]></content>
      <categories>
        <category>learning</category>
        <category>debugs</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>编译原理</tag>
      </tags>
  </entry>
  <entry>
    <title>被SCAE折磨的一天</title>
    <url>/2021/07/18/%E8%A2%ABSCAE%E6%8A%98%E7%A3%A8%E7%9A%84%E4%B8%80%E5%A4%A9/</url>
    <content><![CDATA[<h1 id="scae">SCAE</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​ 在复现完CapsNet第一版之后，想复现这篇论文（第三版CapsNet：<a href="https://arxiv.org/abs/1906.06818"><em>Stacked Capsule Autoencoders, Adam R. Kosiorek, et al.</em></a>）。复现的基础是看懂，理解其意义。本篇博客为我读这篇论文时的一些思考，其中当然还有些(很多)不够透彻的地方。要是完全透彻了我估计就可以直接动手复现了。</p>
<p><img src="/2021/07/18/%E8%A2%ABSCAE%E6%8A%98%E7%A3%A8%E7%9A%84%E4%B8%80%E5%A4%A9/2.PNG"></p>
<center>
Figure 1.Stacked Capsule Autoencoders网络结构图
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-ccae">II. CCAE</h2>
<h3 id="ccae结构">2.1 CCAE结构</h3>
<p>​ 很顶啊，CCAE上来就使用Set Transformer进行了特征学习，变形金刚牛逼：</p>
<ul>
<li>输入一堆n维向量，输出是一堆object capsules（k个）。这个capsules包含：
<ul>
<li>object—viewer 3 * 3图像仿射变换（9）</li>
<li>feature向量（未知）</li>
<li>此capsule表示的物体是否存在的概率（1）</li>
<li><strong><u>此部分为Transformer输入输出，n输入-&gt;k胶囊输出</u></strong></li>
</ul></li>
<li>每个胶囊都会进行内部的MLP，这个MLP将利用自己的特征向量（比如自己是<span class="math inline">\(\pmb{c}_k\)</span>）去推测，N个候选的part（这个part就是物体部件）的相关信息:
<ul>
<li>此后的MLP学习的是：部件 / 物体的变换，而已经学到的有：物体 / 观测者（也就是部件在图像上的pose），那么部件 / 观测者的位姿变换也就有了。</li>
<li>学习条件概率（<strong><u>这个涉及到CCAE高斯混合体的理解</u></strong>），<span class="math inline">\(a_{k, n}\)</span></li>
</ul></li>
</ul>
<p><span class="math display">\[
\begin{equation}
a_{k, n}=P(p_n|cap_k)
\end{equation}
\]</span></p>
<p>​ 也即，一个object capsule k存在时，部件n存在的概率。而之前在Set transformer实际上学习了，cap k存在的概率，那么实际上结合起来就可以得到联合概率。</p>
<p>​ 我感觉这里做了一个很妙的最大后验估计操作，理解一下：</p>
<ul>
<li>使用高斯混合模型，那么其中的高斯分布参数：均值是原有高斯分布均值经过OV,OP位姿变换得到的，而协方差已经经过MLP学习到了。我们可以通过均值和协方差写出：</li>
</ul>
<p><span class="math display">\[
\begin{equation}
p(\pmb{x}_m|k,n)=N(\pmb{x}_m|\mu_{k,n},\lambda_{k,n})
\end{equation}
\]</span></p>
<p>​ 结合这个高斯混合 + 极大似然的意义，我们再来理解一下均值和方差以及其对应下标的意义。</p>
<h3 id="ccae-mle">2.2 CCAE &amp; MLE</h3>
<p>​ 对于论文中的公式(5): <span class="math display">\[
\begin{equation}
p(\mathbf{x}_{1:M})=\prod_{m=1}^M\sum_{k=1}^K \sum_{n=1}^{N} \frac{a_ka_{k,n}} {\sum_i\left(a_i\sum_ja_{i,j}\right)} p(\mathbf{x}_m|k,n)
\end{equation}
\]</span> ​ 个人的理解是，对于给定的一张图像：</p>
<ul>
<li>一方面，我们可以通过Set Transformer 求出k个object capsules，再由这学习到的k个capsule组成n个物体部件，也就是学习一些隐含信息</li>
<li>另一方面，我们可以根据隐含信息重构物体，我们认为物体是由抽象的几个部件组成的，部件的生成与object capsules也有一定关系。那么部件以及object capsules产生的贡献可以被写为 <span class="math inline">\(p(\pmb{x}_m|k,n)\)</span>，换句话说，就是：我从图像（训练集）上学习出object capsule给定为k且存在部件为n的情况下，为目标<span class="math inline">\(\pmb{x}_m\)</span>的概率。</li>
</ul>
<p>​ 训练集可以看作是样本总体分布的抽样，那么在根据样本进行学习时，可以使用极大似然估计的方法：<strong><u>使得抽样（训练集）出现的概率最大</u></strong>，也就是： <span class="math display">\[
\begin{equation}
\max P(X)=\max\prod_{i=1}^nP(\pmb{x}_i)
\end{equation}
\]</span> ​ 在这里<span class="math inline">\(p(\pmb{x}_m|k,n)\)</span>只是条件概率，我们需要去掉条件部分，所以需要根据之前Set Transformer以及MLP的输出，可以得到： <span class="math display">\[
\begin{equation}
\frac{a_ka_{k,n}}{\sum_i\left(a_i\sum_ja_{i,j}\right)}=\frac{p(k,n)}{\sum_i\sum_jp(i,j)}=p(k,n)
\end{equation}
\]</span> ​ 那么公式5很容易从左边转化为右边。而左边和右边相等的意义是？</p>
<ul>
<li>左式是我们的目标函数（极大似然估计需要最大化的联合概率分布，由于训练集是独立同分布的）</li>
<li>右式是由特征提取 / 训练 的输出构成的：
<ul>
<li><span class="math inline">\(p(\pmb{x}_m|k,n)\)</span>是高斯混合体，高斯分布的参数一方面由Set Transformer的OV / MLP的OP对原均值进行线性变换组成，另一方面则是MLP直接输出的方差值。GM模型可以是多个高斯混合在一起形成的，所以其参数很多。</li>
<li><span class="math inline">\(a_k,a_{k,n}\)</span>是由Set Transformer / MLP分别输出的。</li>
</ul></li>
<li>那么右式由于是网络输出的结果，是存在网络参数的，可以对输出进行一定的loss变换之后，对其求导以调整网络参数。</li>
</ul>
<p>​ part capsules是什么？输入的原始数据向量就是part capsule，但是为什么叫part capsule？可能在后续的论文中会提到，下面第一次提到 part capsules，但是貌似是由别的东西来“替代”真正的 part capsules 来进行说明：</p>
<div class="note info"><p>All input points (which take the role of part capsules).</p>
</div>
<hr>
<h2 id="iii-pcae">III PCAE</h2>
<p>​ PCAE用于获得part templates，也就是学习模板。比如说：</p>
<ul>
<li>我们先通过encoder（结构是CNN特征提取 + Attention Pooling，所以Attention思想你还是得王权搞明白啊）从图像中学习一些表征（part capsule）出来：
<ul>
<li>pose，比如旋转 / 缩放 / 斜切 / 平移，出现的概率，特征向量（<strong><u>独特属性</u></strong>）</li>
<li>特征向量可以用于推测模板的颜色等等抽象信息（MLP），比如从特征向量中，直接获得模板输出的三通道强度（也就是模板图像本身的值）</li>
<li>得到模板之后，通过pose进行仿射变换</li>
<li>注意模板本身会携带一个alpha通道，相当于我们搞PS的时候，为了使图抹更加真实，调整画笔透明度，允许不同的templates叠在一起。</li>
<li>图像上每一点的输出，实际上都是不同的part按照概率 + alpha通道结合得到的（相当于一个decoder操作），使之与原图接近，或者可以说成是：对原图的极大似然估计。</li>
</ul></li>
</ul>
<p>​ 那么一套流程下来，实际上我们要得到是一个可以生成part capsule的auto encoder，之后的decoder层个人认为：只是用于计算loss或者产生一个part capsule生成好坏的evaluation方法。以上的文字叙述部分已经把PCAE的思想概括了一下，这是个人开始的理解，其中存在一些偏差：</p>
<div class="note warning"><p>此论文中的Template不是学出来的？使用的是Fixed templates？（4通道）</p>
</div>
<p>​ 就是说我对现有的part templates，学习变换（pose），独有特征（比如MLP输出颜色），出现概率。虽然我感觉论文的这三句话有点冲突：</p>
<blockquote>
<p>I. while the decoder <strong><u>learns an image template</u></strong> <span class="math inline">\(T_m\)</span> for each part</p>
<ol start="2" type="I">
<li><p>SCAE under-performs on CIFAR10, which could be because of using <strong><u>fixed templates</u></strong>, which are not expressive enough to model real data</p></li>
<li><p>Training the PCAE results in <strong><u>learning templates</u></strong> for object parts</p></li>
</ol>
</blockquote>
<p>​ 所以开始时<strong><u>晕了</u></strong>，到底是学出来的还是给定的？个人感觉学出来的templates肯定是更加不错的（只要学得好就行，作者自己也承认）。</p>
<hr>
<h2 id="iv.-ocae">IV. OCAE</h2>
<h3 id="ocae作用">4.1 OCAE作用</h3>
<p>​ OCAE：通过已经学习到的part capsule去组成object（这个和PCAE的decoder区别在哪？）。OCAE与之前的CCAE很类似，但是它受到了来自part capsule的概率影响：</p>
<p>​ OCAE与CCAE结构类似，也存在Set Transformer的encoder，那么part capsules输出的概率会影响encoder，使得Transformer忽略一些没有出现的输入（或者说part）。part capsules输出的概率会使得log likelihood（在MLE过程中）进行幂加权，使得概率小者造成的影响小</p>
<p>​ 个人感觉，由于OCAE结构上很类似CCAE，CCAE的输入是简单的星星点，那么OCAE应该是CCAE的一般化：</p>
<blockquote>
<p>We first encode all input points (which take the role of part capsules)</p>
</blockquote>
<p>​ 所以这里说的就是这个意思，CCAE是：</p>
<ul>
<li>输入是简单点而非part capsules的OCAE</li>
<li>一些part capsule 概率加权不存在的OCAE</li>
</ul>
<p>​ CCAE最后求出了part capsule的似然（作为MLE的优化目标），而PCAE自己也有关于自己生成的part capsule的似然。</p>
<h3 id="ocae-ccae-联系谈">4.2 OCAE / CCAE 联系谈</h3>
<p>​ CCAE部分，作者已经说了，CCAE的输入是简单的星座点。而一般化的OCAE，输入是上层PCAE的part capsule输出：</p>
<blockquote>
<p>In the <strong><u>first stage</u></strong>, the model predicts presences and poses of part templates directly from the image and tries to reconstruct the image by appropriately arranging the templates. In the <strong><u>second stage</u></strong>, SCAE predicts parameters of a few object capsules, which are then used to reconstruct part poses. ---<em>From Abstract</em></p>
</blockquote>
<p>​ 个人的理解就是：PCAE为first stage，其目的是得到templates，学习templates的目标函数通过<em>"reconstruct the image"</em>来完成。OCAE就是接收stage I输出的second stage，通过学习object又来反推part pose？</p>
<p>​ <strong><u>所以明确目的是多么重要！</u></strong>PCAE并没有得到用于MLE的log likelihood，论文中的公式(9),(10)都是为了构建PCAE的loss（重构图像的重构loss），可以这么说：</p>
<ul>
<li>一个普通的CNN分类网络，其输出结构可以用于直接计算loss，我们使用的也就是其输出结果</li>
<li>而PCAE，输出结果需要经过一定变换（reconstructed image），才能用于构建loss，而用于构建loss的部分，并不是我们使用的那部分。PCAE的目的是获得一个好的image template。</li>
<li>之前的部分已经说过了，CCAE（特殊化的OCAE）：
<ul>
<li>首先经过Set Transformer学习K个object capsules。</li>
<li>每个object capsule都会使用MLP（M个MLP），学出组成这个object的M个part，但这个学习过程不涉及到具体的part capsule输出，输出的是：OP，条件概率以及协方差，用于获得GMM的分布</li>
</ul></li>
</ul>
<h3 id="ocae的作用">4.3 OCAE的作用</h3>
<p>​ 为什么OCAE又要重构part？它具体重构了part的什么部分？达到了什么效果？这是本篇论文的一个重点问题，作者在一行脚注里这么说：</p>
<blockquote>
<p>Discovered objects are <em>not</em> used top-down to refine the presences or poses of the parts during inference. However, the derivatives backpropagated via OCAE <strong><u>refine the lower-level encoder</u></strong> network that infers the parts.</p>
</blockquote>
<p>​ 可能可以这么理解：</p>
<ul>
<li>PCAE学出来的part capsules，需要经过检验。这样的part组成object到底合不合适？这种合适度通过likelihood来衡量。</li>
<li>如果说，part capsules直接重建图像，是一种直接的具体的metrics，OCAE对应的likelihood就是抽象的metrics。如果要用极大似然的思想来解释：</li>
</ul>
<blockquote>
<p>It learns to discover <strong><u>further structure</u></strong> in previously identified parts.</p>
</blockquote>
<p>​ 此处的衡量metrics是part likelihood，是通过：</p>
<ul>
<li>与object capsules有关的一个条件概率分布（比如CCAE中的高斯混合分布），与object学习过程中的其他概率组成，相当于是：MLE在优化的过程中，只优化<span class="math inline">\(p(x|\theta)\)</span>的参数<span class="math inline">\(\theta\)</span>部分，而此处由BP，会将MLE的“抽样”<span class="math inline">\(x\)</span>一起进行优化，使得<span class="math inline">\(p(x|\theta)\)</span>最大。</li>
<li>虽然我感觉这样就不是MLE了，但可能可以这么理解吧：我学习的分布，参数是<span class="math inline">\(\theta\)</span>，已经能很好地表示真实情况（总体分布）了，考虑到我如此强而输入有一定噪声，那输入也进行一定的修改吧，因为学到的分布觉得你的输入有些问题。这MLE可以说是很另类的了。</li>
<li>所以总结起来就是：通过一层抽象的学习，MLE同时优化object capsule生成网络参数（<span class="math inline">\(\theta\)</span>）也反过来优化输入（输入就是part capsules）</li>
</ul>
<hr>
<h2 id="v.-sparse-regularization">V. Sparse Regularization</h2>
<p>​ 论文中说，直接使用Capsules结构，容易导致：</p>
<ul>
<li>object capsules滥用，导致难以训练 + 模型描述力下降（显然，有些object不存在于一些图片中，但是还要用对应object强行解释，这是不行的）
<ul>
<li>与之相对的，我们希望每个图像能有特定的少量object capsules（以及相应的part capsules）来描述</li>
</ul></li>
<li>mode collapse，只使用特定的一些object，发生过拟合。
<ul>
<li>与之相对的，我们希望对于整个训练集，object capsules尽量都能用上（否则相当于是出现了训练集label分布不均的情况）</li>
</ul></li>
</ul>
<p>​ 那么，作者设计了两个正则化项，用<strong><u>期望</u></strong>的思想很好理解了：</p>
<ul>
<li><span class="math inline">\(\bar{u}_k\)</span>是第k个object capsule的出现概率总和（对不同的样本）：</li>
</ul>
<p><span class="math display">\[
\begin{align}
&amp; \bar{u}_k=\sum_{b=1}^M a_{b,k}^{\text{prior}} \label{uni_b}\\
&amp; \bar{u}_b=\sum_{k=1}^K a_{b,k}^{\text{prior}} \label{uni_k}\\
\end{align}
\]</span></p>
<p>​ 则我们希望，不同的类别能用上尽可能一样数量的object capsules，假设有C类，K个object capsules，那么每一类可以用：<span class="math inline">\(K/C\)</span>个capsules来描述。而由于对于K个capsules，每个出现的概率是<span class="math inline">\(a_k^{\text{prior}}\)</span>，每一个capsule出现的期望（因为是两点分布）就是概率本身，那么根据期望的运算，一个minibatch内B个训练用例，期望capsule数量应该是公式<span class="math inline">\(\eqref{uni_b}\)</span>。则我们令<span class="math inline">\(\bar{u}_k\leftrightarrow K/C\)</span>两者足够接近即可。</p>
<p>​ 另一方面，我们希望：每个用例能仅用部分object capsules来描述。假设总体不同class均匀分布，那么一个minibatch内部，每个类别有<span class="math inline">\(B/C\)</span>类，那么每个用例object capsules的期望实际上就是公式<span class="math inline">\(\eqref{uni_k}\)</span>定义的概率和，那么可以得到论文中的第一个稀疏性先验。</p>
<p>​ 后验稀疏性很好理解，可以认为是LDA思想：类内熵最小化，类间熵最大化（也即类内的后验分布趋于一致，类间趋于不同）。</p>
<hr>
<h2 id="todos">TODOs</h2>
<p>​ 本论文看第一遍之后，感觉实现部分很模糊，论文图6感觉好像也非常粗略，前面的Attention机制也没有特别体现（只在Part Capsules到Object Capsule时有），但是前面所说的 Part Capsules特征提取部分应该也包括了Attention-based pooling。梯度阻断机制也让我觉得有点奇怪，templates方面也有相关问题没理解。那么在过段时间重读这篇论文时，希望能够在这几个问题上得到更好的理解：</p>
<details class="note primary"><summary><p>需要进一步理解的问题们：</p>
</summary>
<ul>
<li><p>Attention都在什么地方使用到了？为什么schematic图中看起来只有一处？</p>
<ul>
<li>个人认为只是没写出来罢了，只要是capsule autoencoders就逃不开attention机制，内部会有一个类似CCAE的（attention + MLP）实现，当然对于part capsules来说，可能更加复杂。</li>
</ul></li>
<li><p>Capsule在schematic图里面是输出还是网络层？个人的感觉应该是网络层，Part Capsule之上还stack了很多个Object Capsules，但是具体结构为何？</p></li>
<li><p>Templates为什么没有来自CNN或者Part Capsules的梯度流？</p>
<ul>
<li>个人感觉：Transformed templates可以组成图像，而由于capsules携带transformation信息，templates应该可以直接去transform得到，但是为何templates到 tf templates也有梯度？</li>
<li>既然Templates被标注为Trainable variables，为什么说templates是fixed的？</li>
<li>Template的color是学出来的，而color可以被认为是三通道的图像，那么templates在图像上的值不也就是学出来的了吗？</li>
</ul></li>
<li><p>Fixed Object-Part Relations是什么？在哪里起作用？</p></li>
<li><p>PCAE / OCAE的作用，虽然现在感觉自己懂了，但是总有种说不上来的“不透彻感”。</p></li>
</ul>

</details>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title>诡异bug背后的一些知识</title>
    <url>/2021/08/28/%E8%AF%A1%E5%BC%82bug%E8%83%8C%E5%90%8E%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<h1 id="untitled-no.1">Untitled-NO.1</h1>
<hr>
<p>​ 在构建2D激光雷达模拟器的时候，在某个自定义地图中碰上一个奇怪的bug。当然，我从现在完全弄明白这个问题的角度出发，这个bug一点也不奇怪，反倒是警示我要多查cppreference，使用一个STL提供的工具就要看一份文档。</p>
<center>
<a class="btn" href="https://en.cppreference.com/w/"><i class="fa fa-circle-notch"></i>CPP Reference</a>
</center>
<span id="more"></span>
<hr>
<h2 id="bug-表现">Bug 表现</h2>
<p>​ 首先我们声明一些记号：</p>
<ul>
<li><code>A</code> 是一个class，与之对应的容器是std::vector&lt;A&gt;</li>
<li>func 是一个函数，大概长这样：<code>void func(const A&amp; a, std::vector&lt;A&gt;&amp; arr)</code>。也就是，传入一个A的常引用，并且传入一个A的容器的引用。</li>
</ul>
<p>​ func的行为是：根据a，进行计算，有可能往arr尾部push新的A实例。a的来源是：a是一个常引用，但是是这样在外部定义的：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">A&amp; a_ref = arr[id];</span><br><span class="line"><span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; arr.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    <span class="built_in">func</span>(a, arr);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ for循环外部的，对arr这个vector内某一已经存在元素的引用。之后，将其传入func中，隐式转换为常引用。这实际上对应了我代码中的：阴影在物体内部的投影。比如一个object，需要先计算内部的有效遮挡边如何被内部其他边遮挡。于是A就相当于是 遮挡边class类型，以上的代码就可以认为是：a_ref是当前进行投影的边，arr中保存了这个object的所有遮挡边，使用func来判定a是否遮挡或者如何遮挡其他遮挡边。见<a href="https://github.com/Enigmatisms/LiDARSim2D/blob/master/src/lidar_sim/src/Object.cc">Enigmatisms/LiDAR2DSim🔗</a>定义的函数<code>internalOcclusion</code>。</p>
<p>​ 于是我得到了一个这样的结果：</p>
<p><img src="/2021/08/28/%E8%AF%A1%E5%BC%82bug%E8%83%8C%E5%90%8E%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9F%A5%E8%AF%86/2.png"></p>
<center>
Figure 1. GDB调试，projectEdge2Edge的输入有问题
</center>
<p>​ 其中projectEdge2Edge函数就是func，其中参数src（是一个继承了<code>std::vector&lt;Eigen::Vector2d&gt;</code>的class）就是类型A。src的内容出错了。</p>
<p>​ 当然这个问题的定位费了好阵子gdb，打conditional breakpoint才查到（不得不吹一波vscode的内置调试）。可以看到，src（一条投影边）的第一个点（<code>Eigen::Vector2d</code>）值变得奇怪（很小，不应该有）。我首先就猜测是引用失效了（废话），此后猜测 可能是push_back（在breakEdge中进行了push_back，可以说很隐蔽了，breakEdge没有直接传入src，并且src是个const，要是之前我是不会想到引用失效的）导致了引用失效。于是我做了个这样的事情：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> (heap.<span class="built_in">empty</span>() == <span class="literal">false</span>) &#123;</span><br><span class="line">    <span class="type">size_t</span> top = heap.<span class="built_in">top</span>();</span><br><span class="line">    heap.<span class="built_in">pop</span>();</span><br><span class="line">    <span class="comment">// Edge&amp; this_edge = edges[top] 	  (删除这一行)</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; edges.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">        Edge&amp; eg = edges[i];</span><br><span class="line">        Edge&amp; this_edge = edges[top] 	<span class="comment">//(加入这一行)</span></span><br><span class="line">        <span class="keyword">if</span> (eg.valid == <span class="literal">false</span> || &amp;eg == &amp;this_edge)</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        <span class="built_in">projectEdge2Edge</span>(this_edge, obs, eg, heap);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 由于projectEdge2Edge（func）在执行完push_back之后没有对src（a）有任何后续操作，所以我让引用的设置在for循环中执行，每一次都是最新的引用。这样操作之后果然好了。但是不清楚原因。</p>
<hr>
<h2 id="原因">原因</h2>
<p>​ 我先是问了我佬哥。得到的回复是：</p>
<blockquote>
<p>往vector pushback确定可能导致它的引用失效，因为它可能resize 那就换了块内存了</p>
</blockquote>
<p>​ emmm。很有道理，我又去查了一波资料[1]：</p>
<blockquote>
<p>If the new <a href="https://en.cppreference.com/w/cpp/container/vector/size">size()</a> is greater than <a href="https://en.cppreference.com/w/cpp/container/vector/capacity">capacity()</a> then all iterators and references (including the past-the-end iterator) are invalidated. Otherwise only the past-the-end iterator is invalidated.</p>
</blockquote>
<p>​ 这个capacity是什么呢？vector是动态分配大小的，之前学数据结构与算法的时候，定义动态数组，当时就需要realloc操作，我当时的实现是每次往背后多加4个空余位置。vector也是动态分配的，从它的类函数shrink_to_fit()可以看出来，据说是：每一次realloc到大于当前元素个数的最小二的幂次。那么，举个例子，当vector原来的size是4时，push_back会导致重新分配内存（应该也伴随内存的移动）。这个很好理解，毕竟加入原来分配的内存块是经过了表映射的，如果连续的空间不足，根据vector的又一特性：</p>
<blockquote>
<p>The elements are stored contiguously, which means that elements can be accessed not only through iterators, but also <strong><u>using offsets to regular pointers to elements</u></strong>.</p>
</blockquote>
<p>​ 要保证连续的话，只能整个挪动原来存储的东西。而引用？虽然我一直以为，如果是指针的话，指向的地址可能没东西了导致出错，引用应该安全的多，应该就能完全指向vector中的元素吧。可惜并不是，stackoverflow上的佬哥这么解释：</p>
<blockquote>
<ul>
<li>Reference, internally is <em>implemented</em> as a constant pointer which is automatically de-referenced.</li>
<li>The natural implementation of a reference is indeed a pointer.</li>
<li>Though a reference is in reality a pointer, but it shouldn't be used like a pointer but as an alias.</li>
</ul>
</blockquote>
<p>​ 常指针或者指针，编译器为了使得reference的设计更安全，要求必须初始化。也就是说，这个引用指向了一块具体的地址，但是由于reallocation，失效了。Nice.</p>
<hr>
<h2 id="意外收获">意外收获</h2>
<h3 id="迭代器失效">1. 迭代器失效</h3>
<p><img src="/2021/08/28/%E8%AF%A1%E5%BC%82bug%E8%83%8C%E5%90%8E%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9F%A5%E8%AF%86/3.PNG"></p>
<center>
Figure 2. 迭代器失效情况
</center>
<p>​ 我之前还写带代码还把迭代器装在一个容器里，知道很不优雅，但现在知道除了不优雅，还很危险（富贵险中求！！）。</p>
<h3 id="stdvectorbool">2. std::vector&lt;bool&gt;</h3>
<blockquote>
<p>std::vector&lt;bool&gt; is a possibly space-efficient specialization of std::vector for the type bool.</p>
</blockquote>
<p>​ 最有意思的是，cppreference说，空间节约的目的导致bool vector在内存中可能不是连续的。</p>
<p>​ 并且std::vector&lt;bool&gt;有一个新的方法（有别于其他的vector），叫做flip，可以取反内部所有元素。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] https://en.cppreference.com/w/cpp/container/vector/push_back</p>
<p>[2] <a href="https://stackoverflow.com/questions/3954764/how-are-references-implemented-internally">How are references implemented internally?</a></p>
]]></content>
      <categories>
        <category>learning</category>
        <category>debugs</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>贝叶斯学习的理解</title>
    <url>/2021/03/10/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<h1 id="bayesian">Bayesian</h1>
<hr>
<h2 id="贝叶斯分类器">贝叶斯分类器</h2>
<p>​ 个人很喜欢贝叶斯学派的理论，感觉贝叶斯理论非常具有美感。</p>
<p>​ 贝叶斯分类器是典型的生成式模型。对于分类问题的概率形式，有<span class="math inline">\(P(c|x)\)</span>是给定特征情况下，分类结果为c的概率，显然这是我们想知道的（而反过来<span class="math inline">\(P(x|c)\)</span>可能是Encoder模型所讨论的）。判别式模型直接对<span class="math inline">\(P(c|x)\)</span>进行建模，举个例子，决策树吧。决策树根据x的不同分量进行划分，每层选取信息增益或者基尼指数最大的属性进行分支。那么决策树这个判别式模型，具体是如何对<span class="math inline">\(P(c|x)\)</span>进行建模的？</p>
<span id="more"></span>
<p>​ 个人的理解是：假设样本特征<span class="math inline">\(x=\{x_1,x_2,x_3,...,x_n\}\)</span>，其中，<span class="math inline">\(x_i\)</span>的下标表示分支顺序。在根节点处，假设分支基于特征分量<span class="math inline">\(x_1\)</span>，那么在根向下一层，概率会有如下形式： <span class="math display">\[
P(c|x/\{x_1\},x_1=...)
\]</span> ​ 也就是基于<span class="math inline">\(x_1\)</span>确定后的结果进一步分支，直到无法分支为止。也就是说<span class="math inline">\(P(c|x)\)</span>中，x的每个分量逐步确定，对应到叶节点上的<span class="math inline">\(P(c|x)\)</span>也就确定了。</p>
<p>​ 而生成式模型（比如贝叶斯），建模的是联合分布或者是似然： <span class="math display">\[
\begin{equation}\label{bayes}
P(c|x)=\frac{P(x,c)}{P(x)}=\frac{P(x|c)P(c)}{P(x)}
\end{equation}
\]</span> ​ P(c)可直接根据样本估计（样本中分类为<span class="math inline">\(c_i\)</span>的占比，近似为先验概率，啊贝叶斯学派也用频率学派的结论了？）<span class="math inline">\(P(x)\)</span>为归一化常数，无需讨论。</p>
<p>​ 关于<span class="math inline">\(P(c|x)\)</span>我们要做什么？我们只希望将其计算出来（估计出来），就可以根据特征计算分类概率了。那么<span class="math inline">\(P(c|x)\)</span>分布的参数可以通过优化估计<span class="math inline">\(P(x|c)\)</span>来完成，简单的方法，就是进行极大似然估计（因为<span class="math inline">\(P(x|c)\)</span>是似然，是可以从样本中估计的）</p>
<hr>
<h2 id="朴素贝叶斯">朴素贝叶斯</h2>
<h3 id="最朴素的版本">最朴素的版本</h3>
<p>​ <span class="math inline">\(P(x|c)\)</span>好求吗？不好求，<span class="math inline">\(P(x|c)\)</span>的意义是：给定分类下，特征取值为x的概率。首先，有可能对应x根本没有在训练集样本中出现，其次，即使出现也可能因为组合爆炸导致可用样本数量少到无法正确用于估计，另外也可能产生样本某个属性值缺失的情况。</p>
<div class="note info"><p><strong>朴素贝叶斯认为</strong></p>
<p>假设样本所有的属性都是相互独立的，那么<span class="math inline">\(P(x|c)\)</span>就可以由独立条件拆开</p>
</div>
<p><span class="math display">\[
\begin{equation}\label{naive}
P(x|c)=\prod_{i=1}^nP(x_i|c)P(c)
\end{equation}
\]</span> ​ 这好吗？很好，对某个属性的分布估计是比较简单的，并且样本数据一般都是充足的。但是这又不好，因为 <strong><u>通常属性之间都不会有太好的独立性</u></strong>（但是PCA之后可以用贝叶斯，由于PCA之后的特征不相关）。由于这个强独立性假设，所以这种贝叶斯称为“朴素的（你们啊，naive）”。</p>
<h3 id="独依赖版本">独依赖版本</h3>
<p>​ 由于朴素贝叶斯 sometimes naive，导致使用者angry。为了减轻这种效应，首先进行协方差分析，找到与每一个属性关联性最强的另一个属性，讨论联合分布： <span class="math display">\[
\begin{equation}\label{ode}
P(x|c) \propto P(c)\prod_{i=1}^nP(x_i|c,x_{i,k})=P(c)\prod_{i=1}^n \frac{P(x_i,x_{i,k}|c)}{P(x_{i,k}|c)}
\end{equation}
\]</span> ​ 公式<span class="math inline">\(\eqref{ode}\)</span>最右部分个人感觉好像可以直接从样本中推出来，并且不会遇到组合爆炸效应，对独立性假设有放松作用。</p>
<h4 id="条件互信息">条件互信息</h4>
<p>​ 在<a href="https://enigmatisms.github.io/2021/03/02/%E7%BA%BF%E6%80%A7-%E6%A0%91%E5%9E%8B%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%BA%AF%E7%90%86%E8%AE%BA%E5%88%86%E6%9E%90/">[线性-树型分类器的纯理论分析]</a>中，提到了互信息，是指联合分布<span class="math inline">\(P_{X,Y}\)</span>与独立假设下边缘分布乘积<span class="math inline">\(P_XP_Y\)</span>的KL散度。那么条件互信息就是增加了一个条件概率： <span class="math display">\[
\begin{equation}\label{cmi}
I(x,y|c)=\int_y\int_x p(x,y|c)\log\frac{p(x,y|c)}{p(x|c)p(y|c)}
\end{equation}
\]</span> ​ 条件互信息就刻画了给定条件（分类为c）下，两个属性之间的关联关系。那么生成ODE结构可以以此为指导。</p>
<hr>
<h2 id="最小风险贝叶斯决策">最小风险贝叶斯决策</h2>
<p>​ 定义风险矩阵<span class="math inline">\(\Lambda\)</span>: <span class="math display">\[
\begin{pmatrix}
\lambda_{11} &amp; \lambda_{12} &amp; ... &amp;\lambda_{1n} \\
\lambda_{21} &amp; \lambda_{22} &amp; ... &amp;\lambda_{2n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\lambda_{n1} &amp; \lambda_{n2} &amp; ... &amp;\lambda_{nn} \\
\end{pmatrix}
\]</span> ​ 其中，<span class="math inline">\(\lambda_{i,j}\)</span>表示本身是第j类，但是分类结果是第i类的风险。（注意顺序啊，因为决策表的横轴一般定义为实际情况，而纵轴为决策）。那么给定一个样本x，进行分类得到c，根据c进行决策<span class="math inline">\(\alpha\)</span>，由此产生的损失是r，那么： <span class="math display">\[
\begin{align}
&amp; P(c_i|x)=\frac{P(x|c_i)P(c_i)}{\sum_{i=1}^nP(x|c_i)}\\
&amp; R(\alpha_i|x)=\sum_{j=1}^n\lambda_{i, j}P(c_i|x) \label{rsingle}\\
&amp; R_{total} = \sum_{x}R(\alpha(x)|x)    \label{rtotal} \\
&amp; E(R) =\sum_x R(\alpha(x)|x)P(x)
\end{align}
\]</span> ​ 我们实际上要最小化<span class="math inline">\(\eqref{rtotal}\)</span>，也就是对于每一个样本x，其分类函数<span class="math inline">\(\alpha(x)\)</span>需要让的总体决策风险的期望最低，因为实际上<span class="math inline">\(R_{total}\)</span>的指导意义并不大，它是局限于训练样本的，我们希望能独立于样本得到泛化能力，通过给不同特征的样本进行加权，求得期望（事实上不变成期望也没办法进行数值上的估计）。 <span class="math display">\[
\begin{equation}\label{arg}
\alpha^*=\mathop{\text{argmin}}_\alpha E(R)\leftarrow\mathop{\text{argmin}}_{i=1,2...n}R(\alpha_i|x)
\end{equation}
\]</span> ​ 每个样本都能得到最优的决策时，总体看起来决策结果也是最优的，则需要选择决策风险最小的分类结果。那么现在的问题是：会不会出现选择的决策函数<span class="math inline">\(\alpha(x)\)</span>对某些x'而言是<span class="math inline">\(R(a(x&#39;)|x&#39;)\)</span>最小，而另一些并不是最小，但总的期望却是最小的情况？<strong><u>其实个人认为这是有可能的</u></strong>，但是我还是觉得需要确定一下，之后问老师吧。我的想法是：如果固定训练集，只在训练集上讨论，那么确实是有办法让所有x的风险最小的（<strong><u>疯狂过拟合，产生奇异的分类边界</u></strong>），但是这未必是对全局都最优的，只是在训练集上的风险表现最小。</p>
<hr>
<h2 id="吉布斯采样">吉布斯采样</h2>
<p>​ 吉布斯采样（Gibbs sampling）作为一种MCMC延伸的随机采样方式，基于的理论是Markov链逐渐收敛到平稳分布（stationary distribution）时的性质。针对的问题是：</p>
<div class="note info"><p>​ 对于一个多元分布，联合概率一般难以获得，但已知一些变量的条件分布情况下，如何通过采样来估计联合概率分布？</p>
</div>
<p>​ 从联合分布采样确实是很难的事情，因为联合分布综合的信息最多。通过边缘化操作，可以得到边缘分布，通过联合分布和边缘分布可以得到条件分布。也即联合分布已经包含了一个多元分布的所有信息了。既然包含的信息越多，获取必然也就越困难。对此，Wikipedia[1]也说：</p>
<blockquote class="blockquote-center">
<p>The point of Gibbs sampling is that given a multivariate distribution it is simpler to sample from a conditional distribution than to marginalize by integrating over a joint distribution.</p>

</blockquote>
<h3 id="简单理解">简单理解</h3>
<p>​ 假设可怜的卷怪有如下几种状态：</p>
<ul>
<li>学习空间：<span class="math inline">\(X=\)</span> 概率，线代，离散</li>
<li>观测时间：$Y = $ 上午，中午，下午</li>
<li>状态空间：<span class="math inline">\(Z=\)</span> 高效，一般，不想学</li>
</ul>
<p>​ 对于联合分布<span class="math inline">\(P(X,Y,Z)\)</span>，直接讨论是极其复杂的。但是有一些先验知识却比较好获得：</p>
<ul>
<li>学习的可能：<span class="math inline">\(P(X|Y,Z)\)</span>：在给定学习状态以及当前观测时间时，卷怪可能学什么的分布。</li>
<li>观测时间：<span class="math inline">\(P(Y|X,Z)\)</span>：已知当前卷怪的状态以及ta在学什么，得到当前时间的分布。</li>
<li>状态推测：<span class="math inline">\(P(Z|X,Y)\)</span>：已知当前时间以及科目，求卷怪的学习状态。</li>
</ul>
<p>​ 以上三种条件概率都比较好讨论，比如观察半学期该卷怪的学习习惯，也就能总结出来规律，作为先验知识。Gibbs sampling就是利用Markov链以及这几种条件分布的关联性，逼近联合分布的，方法如下：</p>
<ol type="1">
<li>获取一个初始的变量，比如X = 概率，Y = 中午，Z = 不想学。这个变量不一定需要有来源的理由。将这个随机初始生成的状态变量设为<span class="math inline">\(S^0\)</span>（0时刻的状态）</li>
<li>从<span class="math inline">\(S^0\)</span>出发，根据定义的条件分布，<strong><u>每次选择一个变量进行改变</u></strong>。举个例子，<span class="math inline">\(S^0\rightarrow S^1\)</span>的状态转移时，固定中午以及不想学两个状态（对应Y,Z），根据条件概率<span class="math inline">\(P(X|Y,Z)\)</span>，从这个条件分布里采样一个可能的<span class="math inline">\(X\)</span>状态。修改此X。</li>
<li><span class="math inline">\(S^t\rightarrow S^{t+1}\)</span>也是这样做，每次选择一个变量进行修改（为了保证均匀性，可以顺序遍历所有存在条件分布的变量）。</li>
<li>Markov链收敛后（采样次数比较大），生成的样本实际是按照近似联合分布生成的。从这些样本中，可以求出所有边缘分布（假设采样足够），那么联合分布可以顺势推导出来。</li>
</ol>
<p>​ 有关Markov以及平稳分布的数学原理，见<a href>【Post:无向图模型 &amp; Markov的“家具”】</a>。</p>
<hr>
<h2 id="em算法">EM算法</h2>
<p>​ 这个算法之前一直没有搞懂其数学意义，因为不管是《西瓜书》还是Wikipedia，对于其数学性解释都极其简略。在查找资料的过程中偶然看到一篇CSDN博客[2]（可能不是[2]对应的网址，由于原网页没有被我保存），觉得说得很对。但是毕竟这是别人的推导，加上CSDN等等网站的博主都是你抄我我抄你的，个人觉得有必要自己推一遍，加深理解。</p>
<h3 id="基本流程的解释">基本流程的解释</h3>
<p>​ EM算法要解决什么问题？<strong><u>概率推理问题</u></strong>，并且还是无监督的。给定一个随机状态<span class="math inline">\(X&#39;\)</span>，但<span class="math inline">\(X&#39;\)</span>实际包含了已经被观测到的状态<span class="math inline">\(X\)</span>以及未被观测的状态<span class="math inline">\(Z\)</span>，这个Z十分烦人（称为隐变量，latent vector），存在这种未知信息的情况下，要进行模型参数<span class="math inline">\(\pmb{\theta}\)</span>的估计。一般情况下，我们是使用MLE来估计的，首先需要构造似然： <span class="math display">\[
\begin{equation}\label{likely}
L(\pmb{\theta}|X)=P(X|\pmb{\theta})\rightarrow L(\pmb{\theta}|X,Z)=P(X,Z|\pmb{\theta})
\end{equation}
\]</span> ​ 关于Z的信息是缺失的，即使我们给定参数（比如<span class="math inline">\(\pmb{\theta}\)</span>是限定某个分布的参数）也无法直接估计<span class="math inline">\(P(X,Z|\pmb{\theta})\)</span>。当然，对于公式<span class="math inline">\(\eqref{likely}\)</span>定义的似然，处理Z的一个方法是让他不存在。怎么搞呢？边缘化就好了： <span class="math display">\[
\begin{equation}\label{margin}
L(\pmb{\theta}|X)=\int_ZL(\pmb{\theta}|X,Z)dZ=\int_ZP(X,Z|\pmb{\theta})dZ
\end{equation}
\]</span> ​ 但Wikipedia这么说：</p>
<blockquote class="blockquote-center">
<p>However, this quantity is often <strong><u>intractable</u></strong> (e.g. if <span class="math inline">\(\mathbf {Z}\)</span> is a sequence of events, so that the number of values grows <strong><u>exponentially</u></strong> with the sequence length, the exact calculation of the sum will be <strong><u>extremely difficult</u></strong>).</p>

</blockquote>
<p>​ 什么意思呢？看公式<span class="math inline">\(\eqref{margin}\)</span>，我们是对Z进行积分，而Z可能是多元变量，正如上述引用所说，要是有<span class="math inline">\(Z = \{X_{n-k},...X_{n-1},X_n\}\)</span>，那在边缘化的时候我们不得不这样： <span class="math display">\[
\begin{equation}\label{awful}
L(\pmb{\theta}|X)=\int_ZP(X,Z|\pmb{\theta})dZ=\int_{X_n}\int_{X_{n-1}}...\int_{X_{n-k}}P(X,Z|\pmb{\theta})dZ
\end{equation}
\]</span> ​ 这好吗？这不好。太丑陋了，而且难以计算。所以我们需要其他算法！那么EM(Expectation Maximization)算法就是来干这个的。好，我来摘抄一下令人疑惑的基本优化过程，虽然基本优化过程的数学表达乍一看难以理解，但是意思还是比较明确的：</p>
<ol type="1">
<li>构造似然：<span class="math inline">\(Q(\pmb{\theta}|\pmb{\theta}^{(t)})\)</span>，这个似然是在：<strong><u>估计得到当前最优的条件分布<span class="math inline">\(P(Z|X,\pmb{\theta})\)</span></u></strong>下定义的，也即是：</li>
</ol>
<p><span class="math display">\[
\begin{equation}\label{estep}
Q(\pmb{\theta}|\pmb{\theta}^{(t)})=E_{P_{Z|X,\pmb{\theta}^{(t)}}}[\text{log} L(\pmb{\theta}|X,Z)]
\end{equation}
\]</span></p>
<ol start="2" type="1">
<li>优化似然：使得<span class="math inline">\(\pmb{\theta}\)</span>最大化：</li>
</ol>
<p><span class="math display">\[
\begin{equation}\label{mstep}
\pmb{\theta}^{(t+1)}=\mathop{\text{arg max}}_{\pmb{\theta}}Q(\pmb{\theta}|\pmb{\theta}^{(t)})
\end{equation}
\]</span></p>
<p>​ 个人的初步理解大概是这样的：类似于机队预判敌方位置使用的双迭代算法：</p>
<ul>
<li>构造似然的过程（称为E-step）：根据最优<span class="math inline">\(\pmb{\theta}\)</span>更新条件分布<span class="math inline">\(P(Z|X,\pmb{\theta})\)</span>并且生成目标的过程。</li>
<li>优化似然的过程（称为M-step）：根据<span class="math inline">\(P(Z|X,\pmb{\theta})\)</span>优化<span class="math inline">\(\pmb{\theta}\)</span>的过程</li>
</ul>
<p>​ 实际上，在下面一小节（【数学理论】）中，这两个过程的意义将更加清晰。个人比较笨，觉得上面<span class="math inline">\(\eqref{estep}\)</span>以及<span class="math inline">\(\eqref{mstep}\)</span>定义的公式（<span class="math inline">\(\eqref{mstep}\)</span>还好些），直接看根本不知道EM算法到底在搞什么，取什么期望，算什么分布，怎么算。</p>
<h3 id="优化目标的数学理论">优化目标的数学理论</h3>
<h4 id="jensen不等式">Jensen不等式</h4>
<p>​ 数学竞赛，啊熟悉的不等式。在函数或者多元函数里的琴生不等式说的是：对于凸函数而言，函数值的加权平均会大于加权平均的函数值。这个不再多提，很简单。而在概率（信息论）中，琴生不等式的定义如下： <span class="math display">\[
\begin{equation}\label{jensen}
\begin{array}{ll}
\psi\left( E(X)\right) \leq E(\psi(X)),\\
\text{where }\psi \text{ is convex function}
\end{array}
\end{equation}
\]</span> ​ 而琴生不等式并不是我的讨论重点，这显然也是一个非常基础的结论：凸函数映射后的随机变量取值存在的性质。但是这个结论很重要，一会儿要用到。</p>
<h4 id="重要性采样">重要性采样</h4>
<p>​ 由公式<span class="math inline">\(\eqref{margin}\)</span>的离散化形式，展开似然函数式子，并且注意，此处要符合我们在E-step中构建的似然（也就是取对数，将连乘变成连加，下式展示的是：取对数似然之前的Z边缘化操作 <span class="math display">\[
L(\pmb{\theta}|x_i)=\text{log}P(x_i|\pmb{\theta})=\text{log}\sum_ZP(x_i,Z|\pmb{\theta})
\]</span> ​ 那么，似然可以写为： <span class="math display">\[
\begin{equation}\label{like}
L(\pmb{\theta}|X)=\sum_i\text{log}P(x_i|\pmb{\theta})=\sum_i\text{log}\sum_ZP(x_i,Z|\pmb{\theta})
\end{equation}
\]</span> ​ 首先需要知道，log是个凹函数，那么凹函数琴生不等式有<span class="math inline">\(\eqref{jensen}\)</span>相反的结论，接下来就是要想办法让log换个位置，我们考虑将<span class="math inline">\(P(x_i,Z|\pmb{\theta})\)</span>拆开为： <span class="math display">\[
\begin{equation}\label{trans1}
P(x_i,z_i|\pmb{\theta})=Q(z_i)\frac{P(x_i,z_i|\pmb{\theta})}{Q(z_i)}
\end{equation}
\]</span> ​ 根据公式<span class="math inline">\(\eqref{trans1}\)</span>，可以将公式<span class="math inline">\(\eqref{like}\)</span>化成如下形式，注意，对Z进行边缘化操作实际上与取期望存在等价之处，都是消除Z的影响（消除Z的随机变量性）： <span class="math display">\[
\begin{equation}\label{equ1}
L(\pmb{\theta}|X)=\sum_i\text{log}\sum_ZP(x_i,Z|\pmb{\theta})=\sum_iQ(z_i)\text{log}\sum_Z\frac{P(x_i,z_i|\pmb{\theta})}{Q(z_i)}
\end{equation}
\]</span> ​ <span class="math inline">\(Q(z_i)\)</span>是隐变量的一种分布，但是形式暂时未知。我们可以将公式<span class="math inline">\(\eqref{equ1}\)</span>的log内部看成是对Z的期望（实际上，把<span class="math inline">\(Q(z_i)\)</span>移动到z累加式内部，就能看出来，概率<span class="math inline">\(Q(z_i)\)</span>乘以某一个值的期望形式）。这部分很像《概率机器人》[3]中，说粒子滤波时的重要性采样： <span class="math display">\[
\begin{equation}\label{imp}
E(X)=\int_xxp(x)\text{d}x=\int_xx\frac{p(x)}{q(x)}q(x)\text{d}x
\end{equation}
\]</span> ​ 也就相当于，将一个难以求取的期望，转化为另一个分布下，另一个随机变量函数的期望。而实际上，在重要性采样中，<span class="math inline">\(p(x)/q(x)\)</span>是一个经过估计的权值。关于这一点，我将会在<a href="https://enigmatisms.github.io/2021/03/07/%E5%8D%A1%E5%B0%94%E6%9B%BC%E8%BF%9B%E9%98%B6%E4%B8%8E%E7%B2%92%E5%AD%90%E6%BB%A4%E6%B3%A2%E5%AE%9E%E7%8E%B0/">【Post: 卡尔曼进阶与粒子滤波实现 】</a>中提到。</p>
<p>​ 由log的性质（log是凹函数）与琴生不等式，有： <span class="math display">\[
\text{log}\sum_Z\frac{P(x_i,z_i|\pmb{\theta})}{Q(z_i)} \geq \sum_Z\text{log}\frac{P(x_i,z_i|\pmb{\theta})}{Q(z_i)} 
\]</span> ​ 那么似然<span class="math inline">\(\eqref{equ1}\)</span>的一个下界已经找到了： <span class="math display">\[
\begin{align}
L(\pmb{\theta}|X)=\sum_iQ(z_i)\text{log}\sum_Z\frac{P(x_i,z_i|\pmb{\theta})}{Q(z_i)} \geq \\
L_{lb}(\pmb{\theta}|X)=\sum_iQ(z_i)\sum_Z\text{log}\frac{P(x_i,z_i|\pmb{\theta})}{Q(z_i)} \label{lb}
\end{align}
\]</span> ​ 如何优化？EM算法的想法实际上是：</p>
<ul>
<li>E-step：确定似然函数，求得当前Z的分布，计算得到的是<strong><u>似然函数的下界</u></strong>。</li>
<li>M-step：根据下界，优化这个下界。使下界更大，根据夹逼准则，最大值的期望也将更大。</li>
</ul>
<p>​ 那如何最大化这个下界？</p>
<h4 id="似然转化">似然转化</h4>
<p>​ 琴生不等式告诉我们，<span class="math inline">\(\eqref{equ1}\)</span>是永远大于等于<span class="math inline">\(\eqref{lb}\)</span>的，成立的条件是：X是确定变量。哦？那么此处X就是<span class="math inline">\(\eqref{lb}\)</span>log里面的部分。如果这是个常数，也即： <span class="math display">\[
\frac{P(x_i,z_i|\pmb{\theta})}{Q(z_i)} =C\rightarrow P(x_i,z_i|\pmb{\theta})=CQ(z_i)
\]</span> ​ 由于<span class="math inline">\(\sum Q(z_i)=1\)</span>（概率归一化性质），则<span class="math inline">\(P(x_i|\pmb{\theta})=C\)</span>，也就得到了这样的结论： <span class="math display">\[
\begin{equation}\label{qres}
Q(z_i)=\frac{P(x_i,z_i|\pmb{\theta})}{P(x_i|\pmb{\theta})}=\frac{P(x_i,z_i,\pmb{\theta})}{P(x_i,\pmb{\theta})}=P(z_i|x_i,\pmb{\theta})
\end{equation}
\]</span> ​ wow。这说明了什么？这说明，使得下界最大的，Z分布的估计应该是<span class="math inline">\(P(Z|X,\pmb{\theta})\)</span>。那么这样一操作，我们把似然objective写了出来，并且最大化了下界，得到了此时关于Z分布的估计。因为我们实际上不知道Z的分布，但是为了进行这个MLE，我们做了一个最大化下界操作，也就估计出了隐变量Z的分布。</p>
<p>​ 下一步当然是M-step，固定已经选择优化完的<span class="math inline">\(Q(Z)\)</span>，开始argmax <span class="math inline">\(\pmb{\theta}\)</span>。这里就有点像coordinate descent了，跟我写的灯条优化算法是类似的，固定某几个分量，优化剩余的一个分量。E-step就是固定<span class="math inline">\(\pmb{\theta}\)</span>，而M-step就是固定Q。M-step的工作是进一步优化下界。</p>
<p>​ 我们优化的是哪个式子？优化的是下界式<span class="math inline">\(\eqref{lb}\)</span>，需要进一步调整<span class="math inline">\(\pmb{\theta}\)</span>。由于<span class="math inline">\(\eqref{lb}\)</span>实际上已经完全确定了，所以M-step实际上在优化一个仅关于<span class="math inline">\(\theta\)</span>的表达式： <span class="math display">\[
\begin{equation}\label{obj}
Q^{*}_{lb}=\sum_iQ(z_i)\sum_Z\text{log}\frac{P(x_i,z_i|\pmb{\theta})}{Q(z_i)} =\sum_iP(Z|x_i,\pmb{\theta})\sum_zP(X|\pmb{\theta})
\end{equation}
\]</span> ​ 实际上这成了一个优化问题。Wikipedia上举了关于高斯分布<span class="math inline">\(\theta\)</span>参数的优化过程。这里就省略了。</p>
<h4 id="收敛分析">收敛分析</h4>
<p>​ 证明收敛？也就是需要证明，每一次的结果（似然函数）不会比前一次低即可。推导过程倒是比较直接：</p>
<ul>
<li>由于M-step才更新<span class="math inline">\(\pmb{\theta}^t \rightarrow \pmb{\theta}^{t+1}\)</span>，而更新过程保证了（因为我们希望优化下界，使得似然变大）</li>
</ul>
<p><span class="math display">\[
Q_{lb}(\pmb{\theta}|\pmb{\theta}^{t+1}) \geq Q_{lb}(\pmb{\theta}|\pmb{\theta}^{t})\rightarrow \sum_iQ(z_i)\sum_Z\text{log}\frac{P(x_i,z_i|\pmb{\theta}^{t+1})}{Q(z_i)} \geq
\sum_iQ(z_i)\sum_Z\text{log}\frac{P(x_i,z_i|\pmb{\theta}^{t})}{Q(z_i)}
\]</span></p>
<ul>
<li>而我们知道<span class="math inline">\(Q_{lb}(\pmb{\theta}|\pmb{\theta}^{t+1})\)</span>只是似然<span class="math inline">\(L(\pmb{\theta}^{t+1}|X)\)</span>的下界，所以t+1迭代的似然必然大于等于下界。</li>
<li>而由于，琴生不等式我们取了等号成立，那么下式成立：</li>
</ul>
<p><span class="math display">\[
\sum_iQ(z_i)\sum_Z\text{log}\frac{P(x_i,z_i|\pmb{\theta}^{t})}{Q(z_i)}=L(\pmb{\theta}^{t}|X)
\]</span></p>
<ul>
<li>故综上，每次更新之后，似然函数不会比原来小。EM算法是收敛的。</li>
</ul>
<hr>
<h2 id="neyman-pearson决策">Neyman-Pearson决策</h2>
<p>​ 说实话，决策这部分完全可以单独开一篇讲。决策是要做什么？举一个简单的例子，新冠。</p>
<ul>
<li>医院将阴性患者识别为阳性（TN-&gt;FP），称之为第一类错误（拒真，虚警，假阳性率，也就是实际阴性的人中，检测结果为阳性人的比例）</li>
<li>医院将阳性患者识别为阴性（TP-&gt;FN），称之为第二类错误（存伪，漏报，假阴性率）（注意此处存伪，拒真两个定义其实意思上互换没什么大问题）</li>
</ul>
<p>​ 那么作为医院，这两种判定必然存在，但是哪一种更严重？显然是第二类错误，把阳性存下来了。医院需要对检测结果存在的情况进行加权，尽量减少两类，但是两类中又各有侧重，加权地给出风险。Neyman-Pearson决策是贝叶斯决策的一种特殊情况，但是很常见：两类错误各有概率，但是我们希望：</p>
<ul>
<li>犯其中一类错误的概率能达到某个标准值（比如<span class="math inline">\(\epsilon_0\)</span>）</li>
<li>与此同时，犯另一种错误的概率越小越好</li>
</ul>
<p>​ 这就是Neyman-Pearson决策讨论的问题，其表达式可以写为（以其中一种情况为例）： <span class="math display">\[
\begin{equation}\label{np}
\begin{array}{ll}
\text{min }P_1\\
\text{s.t. } P_2=\epsilon_0
\end{array}
\end{equation}
\]</span> ​ 此处表达的意思是：当犯第二类错误的概率为<span class="math inline">\(\epsilon_0\)</span>时（达到第二类错误规定的标准），犯第一类错误概率尽可能小。</p>
<h3 id="形式变换">形式变换</h3>
<p>​ 首先我们先写出<span class="math inline">\(P_1,P_2\)</span>的表达式，假设类1对应了阴性，类2对应了阳性。那么阳性判别范围是<span class="math inline">\(R_2\)</span>，阴性判别范围是<span class="math inline">\(R_1\)</span>。 <span class="math display">\[
\begin{align}
&amp;P_1=\int_{R_2}p(x|w_1)dx\label{p1}\\
&amp;P_2=\int_{R_1}p(x|w_2)dx\label{p2}
\end{align}
\]</span> ​ 其意义是什么？P1是第一类错误犯错概率，也就是假阳性率（实际为阴性<span class="math inline">\(w_1\)</span>的样本，却在阳性判别范围内当作阳性检测出）。P2是第二类错误犯错概率，意义类似。那么由公式<span class="math inline">\(\eqref{np}\)</span>可以知道，问题是约束极小值求解问题，可以使用Lagrange法处理，那么乘子化后的objective带入公式<span class="math inline">\(\eqref{p1}\)</span>以及<span class="math inline">\(\eqref{p2}\)</span>有： <span class="math display">\[
\begin{equation}\label{obj2}
L=\int_{R_2}p(x|w_1)dx+\lambda\left( \int_{R_1}p(x|w_2)dx-\epsilon_0 \right)
\end{equation}
\]</span> ​ 而实际上，<span class="math inline">\(\eqref{obj2}\)</span>是可以拆解的（有关假阳性率部分），根据概率公式拆解： <span class="math display">\[
\begin{equation}\label{obj3}
L=1-\int_{R_1}p(x|w_1)dx+\lambda\left( \int_{R_1}p(x|w_2)dx-\epsilon_0 \right) =
1-\lambda\epsilon_0+\int_{R_1}\lambda p(x|w_2)-p(x|w_1)dx 
\end{equation}
\]</span> ​ 好，回顾熟悉的KKT条件，<span class="math inline">\(L\)</span>相对于<span class="math inline">\(\lambda\)</span>的偏导数是要为0的，实际上就是等式约束要成立，这里就不写了。而还有什么可以求导的吗？千万不要忘记自己要干什么。讨论这个决策objective，最小化它是为了找到一个最好的决策模型，也就是说，模型参数是我们想知道的！此处我们像书[4]上一样，只简单讨论模型参数【决策边界】的划定，也即参数t。对t求偏导会发生什么？ <span class="math display">\[
\frac{\partial}{\partial t}\int_{R_1}\lambda p(x|w_2)-p(x|w_1)dx =\frac{\partial R_1}{\partial t}\times[\lambda p(x|w_2)-p(x|w_1)]
\]</span> ​ 书上没写清楚，但个人认为是这样的。这是由变限积分的性质决定的。那么边界对t的偏导不好求，可以是0，也可以不是0。由KKT偏导为0要求，显然下式成立是较优的选择： <span class="math display">\[
\begin{equation}\label{cond}
\lambda = \frac{p(x|w_1)}{p(x|w_2)}
\end{equation}
\]</span> ​ 注意KKT条件产生了两个约束。而对于公式<span class="math inline">\(\eqref{obj3}\)</span>的积分，我们发现，如果可以让积分符号里面的项小于0，那么积分结果必然负的程度最大，L最小，这是最期望的情况。于是实际上我们有<span class="math inline">\(\eqref{cond}\)</span>稍微修改一下的要求：左边应该小于右边。也就是： <span class="math display">\[
\begin{equation}\label{cond2}
\lambda &lt; \frac{p(x|w_1)}{p(x|w_2)}
\end{equation}
\]</span> ​ 公式<span class="math inline">\(\eqref{obj3}\)</span>定义的积分项是在<span class="math inline">\(R_1\)</span>上的，也就是说，在<span class="math inline">\(R_1\)</span>上时，条件<span class="math inline">\(\eqref{cond2}\)</span>成立，就可以让L变小。那么，就自然可以综上所述： <span class="math display">\[
\begin{align}
&amp; \int_{R_1}p(x|w_2)dx = \epsilon_0 \tag{KKT condition 1}\\
&amp; \lambda = \frac{p(x|w_1)}{p(x|w_2)} (\large{\text{说明决策边界}}) \tag{KKT condition 2} \\
&amp; \lambda &lt; \frac{p(x|w_1)}{p(x|w_2)} (R_1\large{\text{内部要求}})  \tag{int op}
\end{align}
\]</span> ​ 理解起来还是比较简单的。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://en.wikipedia.org/wiki/Gibbs_sampling">[Wikipedia, Gibbs sampling]</a></p>
<p>[2] <a href="https://blog.csdn.net/yzheately/article/details/51164441">CSDN-EM算法-数学原理及其证明</a></p>
<p>[3] Sebastian Thrun, Wolfram Burgard, Dieter Fox <strong><em>Probabilistic Robotics</em></strong>.</p>
<p>[4] 张学工（编著），模式识别（第三版），清华大学出版社</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>概率论</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>骷髅融合者-CVPR2021</title>
    <url>/2021/10/24/%E9%AA%B7%E9%AB%85%E8%9E%8D%E5%90%88%E8%80%85-CVPR2021/</url>
    <content><![CDATA[<h1 id="骷髅融合者">骷髅融合者</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​ 想看看CVPR2021上都有关于点云配准或者点云处理都有什么样的文章，网上搜刮了几篇，骷髅融合者就是其中一篇。这篇论文的作者貌似是上海交大的本科生，嗯 本科CVPR一作，卢策吾老师团队，可以说是很nb了。本论文提出的思想，个人认为比较简单（可能是因为比较复杂的部分被PointNet++掩盖了，文中也没有使用时下最为流行的【变形金刚】）。并且看完Introduction之后，我就觉得这个思想好像在哪里见过：嗷，原来是我的灯条检测中含有这个方法的弱弱化版。</p>
<p>​ 本短篇博客只做该论文的一个简单分析，并不附带复现（如果要带复现的话，一是需要时间，二是需要了解PointNet++）。论文的地址是：<a href="https://arxiv.org/abs/2103.10814">arXiv: Skeleton Merger: an Unsupervised Aligned Keypoint Detector</a></p>
<p><img src="/2021/10/24/%E9%AA%B7%E9%AB%85%E8%9E%8D%E5%90%88%E8%80%85-CVPR2021/Screenshot%20from%202021-10-24%2001-40-07-16350111328661.png"></p>
<center>
Figure 1. Skeleton Merger 论文效果
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-论文思想">II. 论文思想</h2>
<h3 id="思想概述">2.1 思想概述</h3>
<p><img src="/2021/10/24/%E9%AA%B7%E9%AB%85%E8%9E%8D%E5%90%88%E8%80%85-CVPR2021/Screenshot%20from%202021-10-23%2023-45-48-16350111328672.png"></p>
<center>
Figure 2. Skeleton Merger 论文思想框架
</center>
<p>​ 作者使用了一种“重构误差”的思想，使用一个更简单的表征，来重构一个点云，使得原始点云与生成的点云在某个metric下最为相似。而我在RM时做的工作：无监督优化算法的灯条检测，也是类似：</p>
<ul>
<li>找两个key points（灯条的端点），使用灯条的端点根据hand-crafted重构方法，重构出灯条，使得生成的灯条与原始灯条图像的L2差距最小。（所以可以说，我大二下学期写的这个算法是本论文的弱弱化）</li>
</ul>
<p>​ 本文的思想大概可以被总结如下：</p>
<div class="note danger no-icon"><p>使用PointNet++，生成一个加权矩阵，加权后可以生成k个key points，同时，PointNet++也会输出一些全局信息。生成的key points自然形成一个完全图。</p>
</div>
<div class="note warning no-icon"><p>使用PointNet++输出的全局信息，过3层MLP，生成【activation strength】，此后我们会知道，这实际就是skeleton完全图中，每条边存在的概率。</p>
</div>
<div class="note info no-icon"><p>完全图上，每条边都可以产生一个sub-cloud（均匀采样得到，点数与长度成正比）。之后通过一个网络（decoder），学习每一个点的offset（相对于骨架的移动），使得生成的点云可以表征更加复杂的形状。</p>
</div>
<div class="note success no-icon"><p>使用Composite Chamfer Distance（CCD，一种改进的Chamfer Distance方法）作为loss函数，使得原始点云与生成点云的CCD最小【<a href="#unsup">无监督模型的生成式loss</a>】。</p>
</div>
<p>​ 本文不涉及任何网络结构以及网络设计，只是分析一下：</p>
<ul>
<li>其方法有哪些亮点</li>
<li>个人认为其方法可能存在哪些不足</li>
</ul>
<h3 id="亮点">2.2 亮点</h3>
<p>​ 本人认为，此论文突出的两个亮点就是：</p>
<ul>
<li>skeleton重构误差</li>
<li>CCD误差函数的设计</li>
</ul>
<p>​ 首先，通过skeleton重建点云，来辅助判定key points的选取效果，可以使得其达到无监督的目的。在MoCo论文分析中，实际上已经说过，无监督的loss也就主要是那么两种（据我目前所知的“主要”）：</p>
<ul>
<li>对比loss（以MoCo为代表的），主动生成匹配与不匹配的样本，最大化不同类别特征之间的差别</li>
<li>生成式loss（autoencoder思想），主要思想是：学出来的特征能够经过某种方式重构输入，特征学得越好，从直觉上来说，重构效果越好。</li>
</ul>
<p>​ 第二种方法的显著问题就是：一般会有比较大的计算开销（特别是重构图像时，长采样、反卷积结构等等）。个人感觉，本文是一种生成式的loss，但是由于：（1）key points（对应的边）具有稀疏性（2）均匀采样密度可控性，计算开销可能不会太难以接受。</p>
<p>​ 本文直接对key points形成的完全图进行重构，生成一个个的sub-cloud，但是由于有些边采样出的点，实际是不存在的，应该在其存在性上就予以抹杀（而非在offset学习阶段，强行将其拉回到某个位置），故作者引入了activation strength，每条边都将有一个对应的activation strength，相当于是边权，边权小的边对应的生成点在reconstruction过程中可能被丢弃，并且在loss计算过程中，也可能不会参与。</p>
<p>​ 此外就是CCD误差函数的设计。CCD是Chamfer distance的一个扩展，Chamfer distance可以简单地将其理解成：最邻近点距离。在一个n维metric space中给定两个集合A，B，（比如）A中的某个点<span class="math inline">\(p_i\)</span>到B中的最近点的距离，就是Chamfer distance。</p>
<p>​ 在本问题中，集合A、B分别是生成点云与原始点云。但是需要注意，Chamfer distance是单向的，那么需不需要构建成双向对称的loss函数呢？答案是否定的，本问题本身就不是一个对称的问题。作者做了一个分类：</p>
<div class="tabs" id="class"><ul class="nav-tabs"><li class="tab active"><a href="#class-1">正向loss</a></li><li class="tab"><a href="#class-2">反向loss</a></li></ul><div class="tab-content"><div class="tab-pane active" id="class-1"><p>对每一个生成点云中的点<span class="math inline">\(p_i\)</span>，计算<span class="math inline">\(p_i\)</span>在原始点云中的最近点<span class="math inline">\(q_i\)</span>，并且计算对应的Chamfer distance，使之最小化，这是在提升生成点云的fidelity（准确性），也就是说：生成点云的“大致形状”应该与原始点云类似。</p></div><div class="tab-pane" id="class-2"><p>对每一个原始点云中的点<span class="math inline">\(q_j\)</span>，计算<span class="math inline">\(q_j\)</span>在生成点云中的最近点<span class="math inline">\(p_j\)</span>。这就是不对称性的体现：即便生成点云每个点在原始点云上都有很好的对应点，<strong><u>由于生成点云可能具有稀疏性</u></strong>，反过来，原始点云的某些点可能没有办法在生成点云上找到很好的对应点。数学上来说，这就是：单射和满射。正向loss如果很小，只能保证生成点云的<strong><u>fidelity</u></strong>问题，能建立一个很好的 生成点云<span class="math inline">\(\rightarrow\)</span>原始点云的单射，但是反过来，如果原始点云的每个点也能在生成点云上有很好的对应，那么可能可以建立一个原始点云<span class="math inline">\(\rightarrow\)</span>生成点云的单射，使得 <strong><u>coverage</u></strong>问题得到解决。</p></div></div></div>
<p>​ 正向fidelity loss很简单，就是这样： <span class="math display">\[
\begin{equation}\label{fid}
L_f=\sum_k a_k\sum_i\Vert p_i-q_i\Vert^2,q_i=\mathop{\arg\min}_{q}\Vert p_i-q_i\Vert
\end{equation}
\]</span> ​ 而反向coverage loss就没有那么简单了。首先，加入反向loss也如上式一样，定义成对称的，那么最终结果将会是：我直接让所有<span class="math inline">\(a_i\)</span>训练成0得了，没有点存在，就没有loss！显然这是很有问题的。</p>
<p>​ 一方面，我们希望<span class="math inline">\(a_i\)</span> (activation strength)可以起到作用，另一方面我们又希望避免上述问题，我们也希望不会因为公式<span class="math inline">\(\eqref{fid}\)</span>内部的<span class="math inline">\(a_i\)</span>存在，使得<span class="math inline">\(a_i\)</span>倾向于变小。作者提出了两个策略：</p>
<ul>
<li>为了体现“coverage”，作者将会【一配多】，也就是说，不再寻找距离最小的一个点，而是：查到点<span class="math inline">\(q_i\)</span>后，删除<span class="math inline">\(q_i\)</span>来源的那条边（以及所有点），并且累加本边对应的activation strength到一个本地的（初始化为0的累加器）变量w上。如果w小于1，那就继续在剩余点中查找最小距离点，重复上述操作，直到w&gt;1或者没有客用边。</li>
<li>假设已经没有可用边了，而w&lt;1，则进行惩罚（<strong><u>说明我们让<span class="math inline">\(a_i\)</span>学得太小了</u></strong>），在loss上增加<span class="math inline">\(\gamma (1-w)\)</span>，论文中<span class="math inline">\(\gamma\)</span>选取20.0，比较大。</li>
</ul>
<p>​ 上述操作可以保证：<span class="math inline">\(a_i\)</span>不会因为优化CCD而变得很小。</p>
<h3 id="个人觉得存在的问题">2.3 个人觉得存在的问题</h3>
<h4 id="稀疏性问题">2.3.1 稀疏性问题</h4>
<p>​ 作者如何重建其生成点云的呢？首先：根据图结构，每条边进行均匀采样。每条线段上有若干个点。此后使用一个网络进行offset学习。这样会存在一定问题：重建的点云可能就是很稀疏，导致CCD coverage loss计算总是比较大。比如：一个圆柱型的物体，在同一高度上，绕轴不同角度可能存在很多个点，但对于本论文的方法，一个高度上就一个点，那么对于圆柱型物体，只能使用螺旋式的offset，这会使得某些位置上比较稀疏。</p>
<p>​ 要解决这个问题，可能可以在初始时同一个位置采样很多个点，之后使得这些点，在过本点，垂直图结构边的平面上扩散开来。<strong><u>我认为这样的话，学习的参数可以减少（每个点只需要学习一个参数而不是三个），也可以解决稀疏问题。</u></strong></p>
<h4 id="最邻近搜索">2.3.2 最邻近搜索</h4>
<p>​ 这只说下我的担忧：最邻近搜索快速吗？当然，可以使用一些加速的数据结构，比如8叉树，KD树等等，但是能有多快呢？不好说，我没有做过实验，但是这也就是非完全的生成式loss遇到的问题，loss构建时的稀疏性问题。所以个人认为，此处可以将最邻近loss换为别的loss。</p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
        <tag>点云</tag>
      </tags>
  </entry>
  <entry>
    <title>关于卷积的一些思考</title>
    <url>/2022/02/11/%E5%85%B3%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[<iframe src="//www.slideshare.net/slideshow/embed_code/key/EeH6ZygZvj9G5m" width="750" height="420" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%; border-radius: 2px;" allowfullscreen>
</iframe>
]]></content>
      <categories>
        <category>snippet</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title>Redmi G 2021锐龙版双系统环境工程记录</title>
    <url>/2022/02/17/Redmi-G-2021%E9%94%90%E9%BE%99%E7%89%88%E5%8F%8C%E7%B3%BB%E7%BB%9F%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<h1 id="amd-yes">AMD Yes!</h1>
<hr>
<p>新电脑 Redmi G 2021 Ryzen7 版装<strong><u>双系统</u></strong> （win11 + ubuntu 18.04 LTS）过程中遇到了一些问题，以后如果要换设备大概率还得再来一遍，本篇权当记录。不过说实话，从本篇字数来看，应该算得上一篇正规post而不是snippet了。这确实也与snippet板块的设置理念相悖，不过可能我就是那么啰嗦吧。PS：本文与AMD yes没有任何关系。</p>
<span id="more"></span>
<hr>
<h2 id="flann找不到">FLANN找不到</h2>
<p>​ 使用<code>flann</code>库时，在<code>CMakeLists</code>中是需要<code>find_package</code>操作的，但<code>flann</code>如何找？</p>
<p>​ 首先如果我们一波：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone &lt;flann仓库地址，这里不写，随便找都能找到&gt;</span><br><span class="line">cd flann/; mkdir build; cd build/</span><br><span class="line">cmake ..; make -j</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure>
<p>​ 安装<code>flann</code>库，虽然<code>flann</code>会被成功安装到<code>/usr/local/include</code>下（如果没有指定安装路径就会到这个地方），但其<code>.cmake</code>配置文件对CMake而言是不可见的，首先（1）<code>make install</code>没有自己复制<code>.cmake</code>文件，并且（2）<code>locate</code>也是没能找到<code>.cmake</code>文件（不知道为什么）</p>
<p>​ 最后的解决方案有两个:</p>
<ul>
<li>可以在<code>flann</code>库下的<code>cmake</code>文件夹下找到<code>FindFlann.cmake</code>，将其复制到<code>cmake</code>对应的配置文件夹下:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/usr/share/cmake-3.10/Modules/</span><br></pre></td></tr></table></figure>
<p>​ 这个做法很魔法，并且要手动改系统文件（需要管理员权限那种），但一劳永逸。</p>
<ul>
<li>如果有ros（对，我有），那么pcl库中自带<code>flann</code> 只需要指定pcl导入<code>flann</code>即可（CMake配置）</li>
</ul>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">find_package</span>(PCL REQUIRED COMPONENTS kdtree)</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="lz4冲突">LZ4冲突</h2>
<p>​ 服气。lz4在ROS melodic中有一份实现（lz4.h）相关，在<code>pcl</code>库中又有一份实现（存在<code>/usr/include/flann</code>下）。首先如果CMake要能找到 lz4，就需要使用<code>pkg-config</code>：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">find_package</span>(PkgConfig REQUIRED)</span><br><span class="line">pkg_check_modules(LZ4 REQUIRED liblz4)</span><br></pre></td></tr></table></figure>
<p>​ 如果没有<code>pkg-config</code>，可以使用<code>apt install</code>进行安装。</p>
<p>​ 发生冲突确实可以使用<a href="https://github.com/ethz-asl/lidar_align/issues/16#">某个Github issue</a>中提到的方案解决，但是这个方案涉及到修改<code>/usr/include</code>下的头文件，非常不优雅。个人在寒假前遇到过这个问题，当时貌似解决了，但没有记录下来，现在也回忆不起来，只能等回到学校后查看学校电脑了。</p>
<hr>
<h2 id="nvidia">Nvidia!!!</h2>
<p>​ 英伟达真折磨到我了。之前我在<a href="https://enigmatisms.github.io/2021/11/21/Nvidia-%E7%AE%80%E5%8D%95%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B/">[Nvidia 简单环境工程]</a>中提到如何安装显卡驱动，但事实证明这份教程博客非常不完全。</p>
<ul>
<li>我在实验室另一台RTX 3060上安装时遇到了无法安装CUDA 11.3的情况，可能是GPU与对应的460+ driver不适配（我忘了是不是460+了，由于CUDA 11.4对应470.95，个人猜测CUDA 11.3没到470，我也不想花时间去考证）
<ul>
<li>不能安装11.3确实有些不方便，英伟达的apex（某个auto mixed precision库）需要CUDA与pytorch版本对上... 但我11.4 + torch(cu113)真就不行，所以一直想卸了11.4装11.3 但都失败，表现在 <strong><u>安装11.3之后</u></strong> 电脑重启会黑屏，卡在登录界面，无论使用recovery还是直接启动都不行，并且在recovery的root权限命令行中使用<code>nvidia-smi</code>可能卡爆电脑。</li>
</ul></li>
<li>RTX 3060（for laptop computer）甚至都不能安装CUDA 11.4，表现类似也是黑屏，但是<code>nvidia-smi</code>在recovery root console中正常
<ul>
<li>使用博客中的<code>sudo apt-get --purge remove nvidia-*</code>并不能完全删除英伟达驱动（之前都是可以的）。执行命令导致<code>0 package to add\delete\update</code>，等于没动，原因不明</li>
<li>无论怎么删，<code>nvidia-smi</code>都阴魂不散，但如果这样卸载然后安装别的版本CUDA，又不会提示说电脑中已经有一个现有的英伟达驱动而冲突了。</li>
</ul></li>
</ul>
<p>​ 最后一直删不掉，其他指令都无效了，只能重装系统，一天半的工作白干。</p>
<p>​ 这里值得一提的是：</p>
<div class="note danger"><p>根本不应该用<code>sudo apt-get --purge remove</code>以及<code>sudo apt autoremove</code>这么暴力而且危险的方式来卸载显卡驱动。</p>
</div>
<p>​ 英伟达已经写好了:</p>
<ul>
<li>使用<code>nvdia-uninstall</code>命令可以直接干净卸载（之前我不知道这个）</li>
<li>使用<code>/usr/local/cuda-x</code>下的脚本<code>cuda-uninstaller.sh</code>可以方便地卸载CUDA</li>
</ul>
<p>​ 这两个命令运行起来几乎没有破坏性，在经历了11.3\11.4的失败之后，11.4中我直接用上述命令卸载并重装11.6，干净又卫生。</p>
<hr>
<h2 id="opencv新坑">OpenCV新坑</h2>
<p>​ OpenCV还是我的必装库。但安装opencv对我来说已经是一件很久没做过的事情了，难免忘掉很多细节。</p>
<ul>
<li><p>首先准备好<code>opencv_contrib</code>，里面还是有很多值得安装的拓展内容的</p></li>
<li><p><strong><u>准备好opencv需要安装的一些库</u></strong>：这部分可以参考 <a href="https://gist.github.com/raulqf/f42c718a658cddc16f9df07ecc627be7">[raulqf/Install_OpenCV4_CUDA11_CUDNN8.md]</a> 这个Gist。没有这些库是过不了cmake的</p></li>
<li><p><code>libEGL.so</code>消失问题：</p></li>
</ul>
<blockquote>
<p>The imported target "QT5::Gui" references the file "/usr/lib/x86_64-linux-gnu/libEGL.so" but this file does not exist.</p>
</blockquote>
<p>​ 很奇怪的一个问题，<code>libEGL.so</code>是可以被locate到的，在ubuntu的文件property中可以看到（直接用GUI查看property），<code>libEGL.so</code>要么是<strong><u>不存在</u></strong>，要么指向了一个不存在的<code>so.x</code>文件（此文件不是真正的静态库，只是一个软链接），这里提醒一下设置软链接的方式，这么久了都忘了：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo ln -s &lt;source name&gt; &lt;target name&gt;</span><br></pre></td></tr></table></figure>
<p>​ 此处我们只需要首先<code>locate libEGL.so</code>，发现有很多<code>.so.1.0</code>以及<code>.so.1.0.0</code>之类的文件，或者一些类似的，不在<code>/usr/lib/x86_64-linux-gnu/</code>下的文件，都是可以拿来使用的。创建好对应的软链接，命名为<code>libEGL.so</code>（以及<code>libGL.so</code>因为这个文件也存在相同问题）放在上述目录下即可。</p>
<ul>
<li>oracle-java 编译opencv java版：我用不到，但是它硬要我这样干。只能下载openjdk。<code>openjdk-default</code>默认版本（当前）11.0.13，但是opencv傻乎乎地要求我安装11.0.4，并且要求我安装<code>oracle-java11-installer-local</code>
<ul>
<li>但很不幸，openjdk与oracle-java版本对不上，<code>oracle-java11-installer-local</code>不能正常安装，系统需要我把对应11.0.4 <code>oracle-java11-installer-local</code>的deb包放到<code>/var/cache/oracle-java11-installer-local</code>下</li>
<li>我照做的，无误，但是系统就是不认账，一直认为我没有这么做，叔叔我啊，真的要生气了</li>
<li>一怒之下想绕开<code>oracle-java11-installer-local</code>的安装，但是系统不允许，告诉我：</li>
</ul></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1 not fully installed or removed.</span><br><span class="line">After this operation, 0 B of additional disk space will be used.</span><br><span class="line">E: Internal Error, No file name for oracle-java11-installer-local:amd64</span><br></pre></td></tr></table></figure>
<p>​ 这个问题是：装到一半由于一些问题而没装好的包，使得新的dpkg请求没办法完成。那么如何取消这样的 <strong><u> not fully installed or removed</u></strong> 的安装进程呢？</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo dpkg --force-depends --purge oracle-java11-installer-local</span><br></pre></td></tr></table></figure>
<p>​ 对于本问题的 <code>oracle-java11-installer-local</code>，这样即可。</p>
<hr>
<h2 id="rtw89-8852ae">RTW89-8852AE</h2>
<p>​ 额。刚买回电脑来的第三天（开始装ubuntu），装完发现不能联网，十分恶心（显示 <strong><u>No WiFi Adapter Found</u></strong>）。由于win11可以正常联网，网卡硬件端肯定没有问题，推测没有网卡驱动，再一查解决方案后成功解决... 不过在这里，我并不能省略 <strong><u>“一查”</u></strong> 的过程，因为有些命令我是不清楚用法的:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lspci			# 用于显示当前主机的所有PCI总线信息</span><br></pre></td></tr></table></figure>
<p>​ 执行结束后出了一大堆信息，其中有用的就只有：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">02:00.0 Network controller: Realtek Semiconductor Co., Ltd. Device 8852</span><br><span class="line">03:00.0 Ethernet controller: Realtek Semiconductor Co., Ltd. RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller (rev 15)</span><br></pre></td></tr></table></figure>
<p>​ Ethernet controller一般都是有线网络网卡。实际上有用的就是这一条命令，但搞清楚 <strong><u>就是这一条有用</u></strong> 的过程还是很曲折的。其中还遇到这么一些指令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo lshw -class network</span><br></pre></td></tr></table></figure>
<p>​ 输出如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">*-network                 </span><br><span class="line">     description: Wireless interface</span><br><span class="line">     product: Realtek Semiconductor Co., Ltd.</span><br><span class="line">     vendor: Realtek Semiconductor Co., Ltd.</span><br><span class="line">     physical id: 0</span><br><span class="line">     bus info: pci@0000:02:00.0</span><br><span class="line">     logical name: wlp2s0</span><br><span class="line">     version: 00</span><br><span class="line">     serial: &lt;xxxxxxxxxxxxxxxxxxxx&gt;</span><br><span class="line">     width: 64 bits</span><br><span class="line">     clock: 33MHz</span><br><span class="line">     capabilities: pm msi pciexpress bus_master cap_list ethernet physical wireless</span><br><span class="line">     configuration: broadcast=yes driver=rtw89_pci driverversion=5.4.0-100-generic firmware=N/A ip=&lt;xxxxxxxxxxxxxxxxxxxx&gt; latency=0 link=yes multicast=yes wireless=IEEE 802.11</span><br><span class="line">     resources: irq:85 ioport:3000(size=256) memory:d1800000-d18fffff</span><br><span class="line">*-network</span><br><span class="line">     description: Ethernet interface</span><br><span class="line">     product: RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller</span><br><span class="line">     vendor: Realtek Semiconductor Co., Ltd.</span><br><span class="line">     physical id: 0</span><br><span class="line">     bus info: pci@0000:03:00.0</span><br><span class="line">     logical name: eno1</span><br><span class="line">     version: 15</span><br><span class="line">     serial: &lt;xxxxxxxxxxxxxxxxxxxx&gt;</span><br><span class="line">     capacity: 1Gbit/s</span><br><span class="line">     width: 64 bits</span><br><span class="line">     clock: 33MHz</span><br><span class="line">     capabilities: pm msi pciexpress msix bus_master cap_list ethernet physical tp mii 10bt 10bt-fd 100bt 100bt-fd 1000bt-fd autonegotiation</span><br><span class="line">     configuration: autonegotiation=on broadcast=yes driver=r8169 firmware=rtl8168h-2_0.0.2 02/26/15 latency=0 link=no multicast=yes port=MII</span><br><span class="line">     resources: irq:24 ioport:2000(size=256) memory:&lt;xxxxxxxxxxxxxxxxxxxx&gt; memory:&lt;xxxxxxxxxxxxxxxxxxxx&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>​ 隐去了一些重要信息。在没有安装8852对应的网卡驱动前，第一项（第一个<code>*-network</code>，每一项表示一个网络控制设备）显示的是 <strong><u>unmanaged</u></strong>。此外还有一个命令（多了我也没记住）：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">iwconfig</span><br></pre></td></tr></table></figure>
<p>​ 这是什么？常用的是<code>ifconfig</code>，区别主要在于：</p>
<blockquote>
<p>iwconfig is similar to ifconfig, but is dedicated to wireless networking interfaces.[1]</p>
</blockquote>
<p>​ 好，那么在<code>lspci</code>之后，我已经知道了Realtek 8852网络控制器这个型号，接下来就是查找网卡驱动了，此处忽略google的过程，找到了Github库：<a href="https://github.com/lwfinger/rtw89">[Github: lwfinger/rtw89]</a>，直接编译安装就可以使用！</p>
<p>​ 但是在安装前一定要注意，Redmi G 2021 默认是打开了secure boot的（我一开始还被蒙在鼓里），secure boot的情况一定要按照repo中README的指示安装，否则就会不成功。我直接取消了secure boot，直接安装成功。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://wiki.debian.org/iwconfig">Debian/iwconfig</a></p>
]]></content>
      <categories>
        <category>snippet</category>
      </categories>
      <tags>
        <tag>环境工程</tag>
      </tags>
  </entry>
  <entry>
    <title>What is &#39;snippet&#39; section?</title>
    <url>/1970/01/01/What-is-snippet-section/</url>
    <content><![CDATA[<p>Snippet板块是专门为“小型博客”设置的，意在保存：</p>
<ul>
<li>字数不多但有感觉非常有记录的必要性</li>
<li>简单有趣，撰写和阅读都不费力</li>
<li>一些原markdown文档遗失、或是更适合使用pdf共享的文档</li>
</ul>
<p>Enjoy and Rejoice! ------------ 2022.2.11</p>
]]></content>
      <categories>
        <category>snippet</category>
      </categories>
      <tags>
        <tag>notification</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo NexT主题 更强的自定义页面</title>
    <url>/2022/02/18/Hexo-NexT%E4%B8%BB%E9%A2%98-%E6%9B%B4%E5%BC%BA%E7%9A%84%E8%87%AA%E5%AE%9A%E4%B9%89%E9%A1%B5%E9%9D%A2/</url>
    <content><![CDATA[<h2 id="hexo-next美化">Hexo NexT美化</h2>
<hr>
<p>​ Hexo NexT主题博客默认只有一个主页面，虽然可以在config.yml中选择以哪个板块作为主页面，但假如我想有多个不同的页面都与主页一样有页面预览，还是难以直接做到的。网上确实有一篇教程：<a href="https://finisky.github.io/customizecategorybyextension/">【Hexo添加自定义分类菜单项并定制页面布局(简洁版)】</a>，我的snippet板块第一版就是用这个教程搭建的，但之后发现存在一些问题。那么应该如何解决呢？</p>
<span id="more"></span>
<hr>
<h2 id="snippet板块与主板块关系">Snippet板块与主板块关系</h2>
<p>​ Snippet板块下的所有post，其分类（category）都是"snippet"，根据上文博客提到的代码：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> realestatePosts = locals.<span class="property">posts</span>.<span class="title function_">filter</span>(<span class="keyword">function</span>(<span class="params">x</span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> x.<span class="property">categories</span>.<span class="property">data</span>[<span class="number">0</span>].<span class="property">name</span> == filteredCategory;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>​ 这样可以筛选分类为"filteredCategory"的博文，只显示在Snippet板块。但是主板块上仍然无法阻止分类为"filteredCategory"的博客显示（主板块上不显示最合理），开始时我尝试修改<code>.njk</code>文件，但分页会出现错误。我在hexo-next开了个issue，点击下述图片以查看。解决方案是把<code>hexo-generator-index</code>替换为<code>hexo-generator-indexed</code>。</p>
<center>
<div style="background-color: rgb(245, 245, 245); border-radius: 18px; padding: 7px;">
<a href="https://github.com/theme-next/hexo-theme-next/issues/1691"><img alt="Qries" src="/2022/02/18/Hexo-NexT%E4%B8%BB%E9%A2%98-%E6%9B%B4%E5%BC%BA%E7%9A%84%E8%87%AA%E5%AE%9A%E4%B9%89%E9%A1%B5%E9%9D%A2/link.png" style="zoom: 60%"></a>
</div>
</center>
<hr>
<h2 id="强化">强化</h2>
<p>​ <a href="https://finisky.github.io/customizecategorybyextension/">【Hexo添加自定义分类菜单项并定制页面布局(简洁版)】</a>开了一个很好的头，通过这种方法确实可以生成一个新的板块，其中只留有特定分类的博文，但是多post一些博文会发现致命问题：</p>
<ul>
<li>博文排序是倒序的，越老的post排在越前面。阿哲，历史文件的现实意义？</li>
<li>博文置顶失效了。在<code>hexo-generator-indexed</code>中有个这样的功能：只需要在markdown的<code>front-matter</code>中填上:<code>sticky: x</code>（x是优先级，最小0最大100），就会根据优先级来排序，可以实现置顶功能，但是在博客的方法下失效了。我们看看博客中提到的方法代码：</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> pagination = <span class="built_in">require</span>(<span class="string">&#x27;hexo-pagination&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> filteredCategory = <span class="string">&#x27;snippet&#x27;</span>;</span><br><span class="line"></span><br><span class="line">hexo.<span class="property">extend</span>.<span class="property">generator</span>.<span class="title function_">register</span>(<span class="string">&#x27;custom&#x27;</span>, <span class="keyword">function</span>(<span class="params">locals</span>)&#123;</span><br><span class="line">  <span class="keyword">var</span> realestatePosts = locals.<span class="property">posts</span>.<span class="title function_">filter</span>(<span class="keyword">function</span>(<span class="params">x</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> x.<span class="property">categories</span>.<span class="property">data</span>[<span class="number">0</span>].<span class="property">name</span> == filteredCategory;</span><br><span class="line">  &#125;);</span><br><span class="line">  <span class="keyword">return</span> <span class="title function_">pagination</span>(<span class="string">&#x27;snippets&#x27;</span>, realestatePosts, &#123;</span><br><span class="line">    <span class="attr">perPage</span>: <span class="number">10</span>,</span><br><span class="line">    <span class="attr">layout</span>: [<span class="string">&#x27;index&#x27;</span>],</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>​ 非常plain，就是过滤了一下标签。在这里，我按照<code>hexo-generator-indexed</code>中的代码（在hexo的node_module下可以看到），借鉴其<code>generator.js</code>修改了这个博客过滤：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> pagination = <span class="built_in">require</span>(<span class="string">&#x27;hexo-pagination&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> &#123; sort &#125; = <span class="built_in">require</span>(<span class="string">&#x27;timsort&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> filteredCategory = <span class="string">&#x27;snippet&#x27;</span>;</span><br><span class="line"></span><br><span class="line">hexo.<span class="property">extend</span>.<span class="property">generator</span>.<span class="title function_">register</span>(<span class="string">&#x27;custom&#x27;</span>, <span class="keyword">function</span>(<span class="params">locals</span>)&#123;</span><br><span class="line">  <span class="keyword">var</span> posts = locals.<span class="property">posts</span>.<span class="title function_">filter</span>(<span class="keyword">function</span>(<span class="params">x</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> x.<span class="property">categories</span>.<span class="property">data</span>[<span class="number">0</span>].<span class="property">name</span> == filteredCategory;</span><br><span class="line">  &#125;).<span class="title function_">sort</span>(<span class="string">&#x27;-date&#x27;</span>).<span class="title function_">slice</span>(<span class="number">0</span>);				<span class="comment">// 复制，而非原地操作</span></span><br><span class="line">  <span class="title function_">sort</span>(posts.<span class="property">data</span>, <span class="function">(<span class="params">a, b</span>) =&gt;</span> (b.<span class="property">sticky</span> || <span class="number">0</span>) - (a.<span class="property">sticky</span> || <span class="number">0</span>));</span><br><span class="line">  <span class="keyword">return</span> <span class="title function_">pagination</span>(<span class="string">&#x27;snippets&#x27;</span>, posts, &#123;</span><br><span class="line">    <span class="attr">perPage</span>: <span class="number">10</span>,</span><br><span class="line">    <span class="attr">layout</span>: [<span class="string">&#x27;custom&#x27;</span>],</span><br><span class="line">    <span class="attr">data</span>: &#123;</span><br><span class="line">      <span class="attr">__index</span>: <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>​ 过滤之后立马调用timesort，根据日期排序，再根据posts中博客的<code>sticky</code>值排序，两处都定义了匿名函数。这样一来，博客生成的就是正确的排版。</p>
]]></content>
      <categories>
        <category>snippet</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>2D激光SLAM中的SDF表征</title>
    <url>/2022/02/21/2D%E6%BF%80%E5%85%89SLAM%E4%B8%AD%E7%9A%84SDF%E8%A1%A8%E5%BE%81/</url>
    <content><![CDATA[<h1 id="sdf-slam">SDF-SLAM</h1>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​ 在家配电脑环境工程时，真没有事干，就只能看看论文了。之前太naive了，了解得少，只知道2D地图表征常用栅格图以及点云，不常用的是隐式函数（implicit function），却忘记了还有SDF这个中间表征。查找2D-SLAM文献时，蹦出了几篇SDF相关的文章，都还算中规中矩，通俗易懂（比起什么cartographer分支定界来说，简直太友好了，不过说起来，这几篇论文中除了cartographer魔改论文之外，真的谈了后端吗？）：</p>
<ul>
<li><p>Fossel, Joscha-David, Karl Tuyls, and Jürgen Sturm. "2D-SDF-SLAM: A signed distance function based SLAM frontend for laser scanners." <em>2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>. IEEE, 2015.</p></li>
<li><p>Daun, Kevin, et al. "Large scale 2d laser slam using truncated signed distance functions." <em>2019 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)</em>. IEEE, 2019.</p></li>
<li><p>Fu, Xingyin, et al. "Improved Signed Distance Function for 2D Real-time SLAM and Accurate Localization." <em>arXiv preprint arXiv:2101.08018</em> (2021).</p></li>
</ul>
<p>​ P.S. 本文内容并不多。虽然这有三篇论文，其中值得大篇幅讲的不可能塞在这篇博客中，不值得大篇幅讲的都在这了。</p>
<span id="more"></span>
<hr>
<h2 id="ii.-iros-2015-2d-sdf-slam">II. IROS 2015: 2D-SDF-SLAM</h2>
<p>​ 本文貌似先于cartographer发表，是2D SLAM中使用SDF作为地图表征的开山鼻祖。我们说，2D SLAM主要就是两种方法：</p>
<div class="tabs" id="span-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#span-unique-name-1">Eulerian</a></li><li class="tab"><a href="#span-unique-name-2">Lagragian</a></li></ul><div class="tab-content"><div class="tab-pane active" id="span-unique-name-1"><p>​ 如果不知道我在说什么，参阅我之前的一篇英文博文<a href="https://enigmatisms.github.io/2021/11/14/A-Duality-Problem-of-Representations/">【A Duality Problem of Representations】</a>。这里的Eulerian方法指的就是使用一个静态的网格表征，比如基于（概率）栅格图的GMapping，Hector SLAM，Google's Cartographer。这种方式的好处就是：天然适合进行信息融合。</p></div><div class="tab-pane" id="span-unique-name-2"><p>​ 与Eulerian类别的方法互为对偶。你显式建模空间障碍物的分布，我就用一堆同时含有轨迹以及地图信息的粒子来代表整个空间。典型的方法就是粒子滤波。很有趣的是，要说用到PF方法的SLAM，GMapping也算是一个，所以GMapping实际上是：粒子表征含有Eulerian方法的Lagrangian方法。基于点云的方法，其实可以看作是这样的方法，因为其对地图的表征是动态的粒子。</p></div></div></div>
<p>SDF相比于以上方法，有这样一些特点：</p>
<ul>
<li>相对于grid map，其需要的内存相对小一些。SDF，特别是截断SDF，只需要表征障碍物附近即可，而grid map很多时候都是全空间的。</li>
<li>相对于grid map，SDF最后到地图需要多一步 --- marching square（cubes）算法。虽然多了这一步，SDF以此求得的地图也是sub-grid（pixel）的。</li>
<li>相对于点云表征，SDF由于从某种意义上类似于grid map，其融合更加友好。</li>
</ul>
<p>​ 本文呢，主要贡献可以这么说：</p>
<ul>
<li>提出了更好的SDF更新方法（这种更新方法与我熟知的方法大相径庭，个人认为此方法应该非常快速，但是存在一个大问题）</li>
<li>把SDF引到... 2D SLAM中来？当时来说确实可以算是radical的创新吧，但从现在的角度看来也不过如此？（嚯，垃圾hqy大放厥词）</li>
</ul>
<p>​ 本文的弊病（个人认为的）：</p>
<div class="note danger"><p>实验也太简单了。</p>
<ul>
<li><p>首先你仿真就仿真，把仿真的地图公开一下，别只公开一个啊 我们就用这个开源的Simple Two Dimensional Robot Simulator。我知道ROS已经集成了这玩意，但是这玩意怎么看都觉得有点简陋，万一你跑个巨简单的地图说，啊我这很好啊，这有什么意义呢？</p></li>
<li><p>真实的数据集也是自己采集的，而且环境很简单。没有公开数据集...</p></li>
<li><p>我说，至少也去radish上干一干GMapping啊，怎么只对比Hector SLAM</p></li>
</ul>
</div>
<p>​ 关于这篇文章的内容，我并不想多说，其SDF更新之术，我在第三节结合SSRR的论文一起说。而其配准方式，只是一个带Huber Loss的高斯牛顿法。等等，它好像也没有Huber核...。emmm，至于为什么我也不想深究这个配准后面的数学原理，是因为个人认为：</p>
<div class="note primary"><p>​ 本质上，SDF方法的优化方法与GMapping的极大后验没有什么区别。GMapping中计算这个极大后验用了一个“似然域”，这个似然域是什么东西呢？你可以简单认为在每一个激光点处都有一个2D高斯核，叠在一起（有点像GMM）。这玩意就和SDF非常像了，只不过SDF是纯纯的距离，似然域像是个SDF的近似。那么既然方法上都没有太大区别，其实也就没有必要再理解一遍这个算法过程。况且我之前还自己设计过基于SDF的配准，只不过当时不知道我设计的东西有个术语叫SDF罢了。</p>
</div>
<hr>
<h2 id="iii.-后两篇内容">III. 后两篇内容</h2>
<h3 id="ssrr-2019">3.1 SSRR 2019</h3>
<p>​ 本文是cartographer的魔改，作者自己说自己是基于cartographer，将cartographer只基于grid map拓展为了可以基于TSDF。本文我想说的不多，由于作者其实也没有介绍太多新的ideas，主要篇幅都是关于：</p>
<ul>
<li>基于TSDF表征的表征更新：如何快速而有正确地计算TSDF（local SLAM，也就是前端的内容）</li>
<li>基于分支定界法的后端（带有回环约束的图优化）</li>
</ul>
<p>​ 说起来，TSDF的更新方法确实和我理解得非常不同。个人在2021年6月份简单研究了一下普通SDF的计算，当时写了一个具有普适性的SDF计算代码（也就是说，任意给我一段折线，我都能求出其SDF），关于我原来对SDF的想法，参见<a href>【远古SDF文档】</a>。反正大概就是这个样子：</p>
<center>
<img src="/2022/02/21/2D%E6%BF%80%E5%85%89SLAM%E4%B8%AD%E7%9A%84SDF%E8%A1%A8%E5%BE%81/sdf.png" style="zoom: 80%;">
</center>
<center>
Figure 1. SDF样式. 其中，越接近折线颜色饱和度越浅，不同的颜色代表了正负号的不同
</center>
<p>​ 这样的SDF，计算当然是：对于空间每一点而言，计算其到折线段上距离的最小值（并且判定这个点在折线段的哪一边）。不考虑边的情况下，这样的想法计算量也还是挺大的，2D栅格上，每个点需要做【到不同线段的投影】，再进行一个最小值的reduce。所以个人从一开始就觉得，这种计算方法肯定比较消耗计算资源，不过这样的方法看起来是可以并行加速的（这里我想到了CUDA）。</p>
<p>​ 但论文中提出了两种截然不同的方法：</p>
<center>
<img src="/2022/02/21/2D%E6%BF%80%E5%85%89SLAM%E4%B8%AD%E7%9A%84SDF%E8%A1%A8%E5%BE%81/methods.png" style="zoom:80%;">
</center>
<center>
<span id="fig2"> Figure 2. SDF更新方法[2] </span>
</center>
<p>​ 这两种方法都避开了：一个点的SDF值需要与折线段上所有的线段发生相关计算的问题。虽然，所有线段都参与计算是最正确的方法（里面没有任何的近似）。但考虑到，激光数据进入是以点为单位的，如果转换为线段：</p>
<ul>
<li>首先，转换为线段就存在不小的计算开销以及复杂度上相同的内存开销。不管是否进行抽稀（Douglas-Peuker算法）或者近似（拟合），都会至少是<span class="math inline">\(O(n)\)</span>的计算量。并且，线段还不能直接用斜截式表示（存在奇异性）。</li>
<li>此外，转换为线段过后，如果没有做下采样操作，线段数目将非常多（虽然点云已经是一个sparse表征了），通常来说都会在100段以上。假如设grid纵横为n，线段条数为<span class="math inline">\(N\)</span>，计算资源消耗的复杂度将会是<span class="math inline">\(O(n^2N)\)</span></li>
</ul>
<p>​ 作者提出的第一种方法，称为projective ray方法，这种方法其实还是近似于grid map的思想。我用激光器光束模型来update每一个击中点附近的SDF值，简单考虑，我就认为在每一个击中点所在激光线上，我可以把激光线上点相对于击中点的距离直接当作SDF值。由于在这里，更新的每一个点都在激光线上，所以如果<span class="math inline">\(\text{range} + \Delta d\)</span>是某个grid的深度，那么<span class="math inline">\(\Delta d\)</span>就是SDF值，计算就非常简单了。但这种方法的问题也很大：</p>
<div class="note warning"><ul>
<li>求出的不是真正的SDF距离，大多数情况下都不是“到最近表面的距离”，只有在激光束垂直入射表面并且附近没有其他表面时，这种方法计算的SDF才是正确的</li>
<li>在入射角度大，或者grid分辨率很低时，SDF质量非常差。在IROS 2015 SDF文中说到：</li>
</ul>
<blockquote>
<p>Cells which are both positive and negative are in conflflict as they are updated with both positive and negative distances, which do not tend to cancel each other.</p>
</blockquote>
<p>​ 借用IROS 2015中的图，表示一下大概就是下图这样。个人认为，这种想法简直就是在用【方法的前途】换速度。</p>
<center>
<img src="/2022/02/21/2D%E6%BF%80%E5%85%89SLAM%E4%B8%AD%E7%9A%84SDF%E8%A1%A8%E5%BE%81/proj.png" style="zoom:60%;">
</center>
<center>
<span id="fig3"> Figure 3. SDF更新方法： Projective ray的弊端[1] </span>
</center>
</div>
<p>​ 而作者提出的第二种方法，看起来更加正确。在这种方法下：</p>
<ul>
<li>首先我需要evaluate每一个激光击中点的local normal（局部法向），这一步也不是那么好做，我在自研算法里有这个操作，需要进行初级分割，以免深度不连续位置导致法向量evaluate有误</li>
<li>根据局部法向，沿着局部法向的方向向内外扩展SDF，如<a href="#fig2">图二（b）</a>以及下图所示：</li>
</ul>
<center>
<img src="/2022/02/21/2D%E6%BF%80%E5%85%89SLAM%E4%B8%AD%E7%9A%84SDF%E8%A1%A8%E5%BE%81/norm.png" style="zoom:80%;">
</center>
<center>
<span id="fig4"> Figure 4. SDF更新方法：法向法[3] </span>
</center>
<p>​ 但个人觉得这种方法还是不甚优雅，在点特别稀疏的场景下，这样计算应该是会导致<strong><u>SDF稀疏</u></strong>的。毕竟你只update法线方向周围的部分点，如果点过于稀疏（1. 角度分辨率过小或2. 入射角度太大），那在垂直法向的方向上无法得到足够的coverage，就会出问题。</p>
<p>​ 这里，分支定界法我不多说，因为我并没有深入理解到其方法的精髓。在这里不得不承认，运筹学虽然学习了分支定界法，但是太流于表面，可能当时会做题（意思是现在题都做不出来了），但并没有体会到这个思想的美妙性，关于基于BB方法的后端优化，个人可能会用专门的一篇博客来讨论（有关分支定界法本身以及其在SLAM中的应用）。</p>
<h3 id="arxiv-preprint-2021">3.2 arXiv Preprint 2021</h3>
<p>​ 这篇文章，可能之所以是preprint，就是因为没有太多可以投的点吧，除了SDF更新之外，我只简单提一些本文提出的好的思想：</p>
<h4 id="free-space-update">3.2.1 Free Space Update</h4>
<p>​ 是 空域的思想吗？有点这个味道，但是并不完全。作者已经想到了，可以利用与空域的冲突性，来剔除动态障碍物，只需要在地图中建立空域概念，如果一个hit观测出现在空域中（在多数帧下显示为un-occupied，本帧发现存在障碍物），那么大概率会是动态障碍物。这个思想在我们算法里也有，并且它的free space计算方法就和我们很像：</p>
<center>
<img src="/2022/02/21/2D%E6%BF%80%E5%85%89SLAM%E4%B8%AD%E7%9A%84SDF%E8%A1%A8%E5%BE%81/free.png" style="zoom:90%;">
</center>
<center>
<span id="fig5"> Figure 5. 空域的计算方法（灰色的部分是一束激光线产生的空域）[3] </span>
</center>
<h4 id="expansion">3.2.2 Expansion</h4>
<p>​ 作者也意识到纯法向SDF更新的问题（稀疏性），所以作者用了一个“迭代取点”的方法。首先，Deming regression至少需要三个点才能生成一条直线，在入射角度过大或者距离过远的地方，一个grid内部可能找不到那么多点，作者根据hit点的邻域关系逐步expand搜索域。举个简单的例子：</p>
<ul>
<li>在某一个激光点的8-邻域内（扩展一次），只有一个点，显然两个点没办法形成regression，需要继续扩展</li>
<li>在8-邻域点对应的8-邻域内（扩展两次），找到了第三个点，那么用这三个点regress一条线并进行法向更新</li>
<li><strong><u>垂直法向</u></strong>上的更新半径，<strong><u>根据扩展的次数</u></strong>确定，越稀疏的位置，扩展次数越多，更新半径就越大。</li>
<li>这样一种方法，应该至少可以消除大部分稀疏性问题带来的影响。</li>
</ul>
<h4 id="类似view-selection">3.2.3 类似view selection</h4>
<p>​ 作者在 <strong><em>Improve Priority Strategy</em></strong> 一段中写到：</p>
<blockquote>
<p>The cells closer to the cell that gives rise to the update are put on a higher priority.</p>
</blockquote>
<p>​ SDF的标准定义就应该是：离谁近就用到谁的距离来更新。而不管是projective ray还是局部法向法，都不是按照“谁最近就用谁更新”的原则计算SDF的，那么就需要引入取舍标准：不同点计算的结果不同时，我取谁。作者这里并没有一刀切，而是用加权的方式融合。</p>
<h4 id="outlier-removal">3.2.4 Outlier removal</h4>
<p>​ emmm，简单来说就是，剔除深度不连续点。这，叔叔我啊，可早就写过了。</p>
<h4 id="子地图融合">3.2.5 子地图融合</h4>
<p>​ 这没有什么指的说的，对于这种显式或者隐式用了grid的方法，融合就是比较简单。</p>
<hr>
<h2 id="reference">Reference</h2>
<p>[1] <a href="https://www.researchgate.net/profile/Joscha-David-Fossel/publication/308298063_2D-SDF-SLAM_A_signed_distance_function_based_SLAM_frontend_for_laser_scanners/links/58e66d1fa6fdcc6800b47916/2D-SDF-SLAM-A-signed-distance-function-based-SLAM-frontend-for-laser-scanners.pdf">Fossel, Joscha-David, Karl Tuyls, and Jürgen Sturm. "2D-SDF-SLAM: A signed distance function based SLAM frontend for laser scanners." <em>2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>. IEEE, 2015.</a></p>
<p>[2] <a href="https://www.researchgate.net/profile/Oskar-Von-Stryk/publication/336088692_Large_Scale_2D_Laser_SLAM_using_Truncated_Signed_Distance_Functions/links/5e8ca2da92851c2f52884e06/Large-Scale-2D-Laser-SLAM-using-Truncated-Signed-Distance-Functions.pdf">Daun, Kevin, et al. "Large scale 2d laser slam using truncated signed distance functions." <em>2019 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)</em>. IEEE, 2019.</a></p>
<p>[3] <a href="https://arxiv.org/pdf/2101.08018.pdf">Fu, Xingyin, et al. "Improved Signed Distance Function for 2D Real-time SLAM and Accurate Localization." <em>arXiv preprint arXiv:2101.08018</em> (2021).</a></p>
]]></content>
      <categories>
        <category>learning</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>SLAM</tag>
        <tag>表征</tag>
      </tags>
  </entry>
  <entry>
    <title>远古SDF文档</title>
    <url>/2022/02/22/%E8%BF%9C%E5%8F%A4SDF%E6%96%87%E6%A1%A3/</url>
    <content><![CDATA[<iframe src="//www.slideshare.net/slideshow/embed_code/key/dUI2s72z0jLiEq" width="750" height="420" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%; border-radius: 2px;;" allowfullscreen>
</iframe>
]]></content>
      <categories>
        <category>snippet</category>
      </categories>
      <tags>
        <tag>knowings</tag>
        <tag>SLAM</tag>
      </tags>
  </entry>
  <entry>
    <title>简单的ROS跨设备控制</title>
    <url>/2022/02/22/%E7%AE%80%E5%8D%95%E7%9A%84ROS%E8%B7%A8%E8%AE%BE%E5%A4%87%E6%8E%A7%E5%88%B6/</url>
    <content><![CDATA[<h1 id="rrrros">RRRROS</h1>
<hr>
<p>​ ROS常用的进程通信机制是消息传递，是基于各个node与master的XML-RPC实现，并且可能用到TCP/UDP等传输层协议，非常地网络。这样看来，ROS进行跨设备通信应该是比较简单的。本篇主要记录一个简单的ROS跨设备应用场景，并简介其中的原理。</p>
<span id="more"></span>
<hr>
<h2 id="使用ros跨设备rviz可视化">使用ROS跨设备rviz可视化</h2>
<p>​ 你有一个工控设备，在一个轻量级机器人上。机器人没办法给你举着一个屏幕，方便你控制他的方式只有ssh。这时候，你打开了机器人身上的一个激光雷达，但突然记起来，自己没办法可视化机器人看到的东西，怎么办呢？当然，你大可以像我一样显得蛋疼去写一个用终端可视化点云的工具...，就像这样 <a href="https://github.com/Enigmatisms/tviz">Github: Enigmatisms/tviz</a>：</p>
<center>
<img src="/2022/02/22/%E7%AE%80%E5%8D%95%E7%9A%84ROS%E8%B7%A8%E8%AE%BE%E5%A4%87%E6%8E%A7%E5%88%B6/tviz.gif" style="zoom:80%;">
</center>
<center>
Figure 1. 闲得蛋疼
</center>
<p>​ 反正写完我也没用过，还是上正经方法吧。首先，如果要跨设备使用ROS，两个设备必须能够互相访问，比如：在同一个网段下。可能出现单向能ping通的情况（比如墙，或者无内网穿透）。互相可以ping通应该就没有问题。</p>
<p>​ 从这里开始，我设定如下的应用场景：</p>
<ul>
<li>主机A，是用于可视化的设备，运行rviz</li>
<li>从机B，是机器人（或者相应工控设备），直接连接了传感器但是不方便显示</li>
</ul>
<p>​ 首先，在主机A上ssh到从机B。并且修改从机<code>/etc/hosts</code>，首先查看A，B设备的ip，设为a，b：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ifconfig</span><br><span class="line">sudo vim /etc/hosts</span><br></pre></td></tr></table></figure>
<p>​ 给主机以及从机命名（随便叫），比如我叫主机 master，从机slave，<code>/etc/hosts</code>中就填写并保存，相应地，主机的<code>/etc/hosts</code>也这么修改</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">192.168.xx.a master</span><br><span class="line">192.168.xx.b slave</span><br></pre></td></tr></table></figure>
<p>​ 修改完之后，从机需要修改ROS定义的两个环境变量：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export ROS_HOSTNAME=slave</span><br><span class="line">export ROS_MASTER_URI=http://msater:11311</span><br></pre></td></tr></table></figure>
<p>​ 注意，从机的host name还是自己的name，但是master URI则是：<strong><u>主机ip + 端口（一般都是11311）</u></strong>。这里实际上是：ROS的master以及node都看ip进行通信，只有一个唯一的master（确实可以开多个roscore，但是消息不是共享的），master URI就确定了master所在的网络位置。如果不export修改ROS Master URI，一般来说:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo $ROS_MASTER_URI			# 输出都是 http://localhost:11311</span><br></pre></td></tr></table></figure>
<p>​ 修改ROS master URI就是告诉本机，master（roscore）在位于master URI的机器上。</p>
<p>​ 已经说了，按照同样的方法修改主机<code>/etc/hosts</code>，之后需要修改主机环境变量：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export ROS_HOSTNAME=master</span><br><span class="line">export ROS_MASTER_URI=http://master:11311</span><br></pre></td></tr></table></figure>
<p>​ <strong><u>注意这里，master URI</u></strong>就是主机自己的ip。之后，主机开<code>roscore &amp;</code>（一定要在主机上开，因为这是设定嘛，master URI都说了roscore在这里），再打开rviz，配置好。从机只需要能够输出ros消息即可，在主机上用<code>rostopic list</code>就能看到消息了。</p>
<ul>
<li>P.S：2D激光雷达数据传输完全没问题，就算是帧率高，点数多，也不会有太大延迟，但是图像消息就不一样了。<strong><u>如果需要跨设备图传</u></strong>，不要使用原始的<code>sensor_msgs/Image</code>消息，会非常慢，ppt级传输。可以使用<code>sensor_msgs/CompressedImage</code>，亲测很快。但是这取决于你想看流畅高刷还是高清无码，不过个人觉得，compressed image消息并没有使得画面质量有太多的下降。</li>
</ul>
]]></content>
      <categories>
        <category>snippet</category>
      </categories>
      <tags>
        <tag>ROS</tag>
      </tags>
  </entry>
</search>
