<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Event Horizon</title>
  <icon>https://enigmatisms.github.io/icon.png</icon>
  <subtitle>Technical &amp; Personal Docs.</subtitle>
  <link href="https://enigmatisms.github.io/atom.xml" rel="self"/>
  
  <link href="https://enigmatisms.github.io/"/>
  <updated>2022-05-03T04:04:18.561Z</updated>
  <id>https://enigmatisms.github.io/</id>
  
  <author>
    <name>Enigmatisms</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Rust学习 II</title>
    <link href="https://enigmatisms.github.io/2022/05/03/Rust%E5%AD%A6%E4%B9%A0-II/"/>
    <id>https://enigmatisms.github.io/2022/05/03/Rust%E5%AD%A6%E4%B9%A0-II/</id>
    <published>2022-05-03T04:01:41.000Z</published>
    <updated>2022-05-03T04:04:18.561Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;rust---ii&quot;&gt;Rust - II&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intro&quot;&gt;I. Intro&lt;/h2&gt;
&lt;p&gt;​ 变量的lifetime之前的部分，理解起来都比较简单。而一到lifetime出场，一群妖魔鬼怪也就跟着出场了。不过其实是因为之前的两天学习中，对于变量的引用，所有权的租借理解不够到位。本文仍然是在跟着Rust官方（的非官方，它自己写的）教程学习过程中，整活扩展的一些记录。&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="Rust" scheme="https://enigmatisms.github.io/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>Rust学习 I</title>
    <link href="https://enigmatisms.github.io/2022/05/03/Rust%E5%AD%A6%E4%B9%A0-I/"/>
    <id>https://enigmatisms.github.io/2022/05/03/Rust%E5%AD%A6%E4%B9%A0-I/</id>
    <published>2022-05-03T03:57:35.000Z</published>
    <updated>2022-05-03T04:04:12.549Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;rust---i&quot;&gt;Rust - I&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;intros&quot;&gt;Intros&lt;/h2&gt;
&lt;p&gt;​ Rust，好！可能主要由于所有权机制上的创新，学习时的感觉与学其他语言的感觉完全不同，于是没有像学JS一样，觉得无聊，也没有像觉像学haskell一样，觉得过于抽象。但是这样一种语言创新，必然会给学习带来障碍，毕竟编程思想是完全不同的。此外，可能我使用Rust的工具链不对，个人认为vscode对于Rust的支持明显不足（缺乏自动补全，没有函数快速查看以及定义跳转等等），第一天学的时候，只能实现一些强逻辑性算法（比如什么快排，归并排序等等），无法深入使用数据结构（给我一个数据结构我根本不知道里面有什么方法）。&lt;/p&gt;
&lt;p&gt;​ 第一天快结束时，想学习一下Rust的可视化工具Plotters，结果发现，之前从菜鸟教程了解的写法过于粗浅，基本看不懂Plotters代码，遂投身更加深入的学习。但却发现，给自己设置的小目标 --- 写一个链表，按照之前了解的语法知识，我都是写不出来的。快要放弃只是接触到了一个教程以及其官方文档：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://rust-unofficial.github.io/too-many-lists/index.html&quot;&gt;Rust unofficial - Learning Rust With Entirely Too Many Linked Lists&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://doc.rust-lang.org/std/index.html&quot;&gt;Rust-lang docs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​ 教程详细介绍了对于链表的实现，较为通俗易懂，有些难以思考的问题，其实沉下心来想也很快能想出来。本文是跟着教程实现过程中，笔者对于遇到的一些问题的处理方法以及自己的心得。由于笔者非常不喜欢依葫芦画瓢（因为这样，感觉自己完全学不到东西），所以笔者也在自己的实现中整活（超前学习），本文也记录了整活过程中遇到的坑及处理方法。本篇为Rust学习心得的第一章。&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="Rust" scheme="https://enigmatisms.github.io/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>Cartographer编译问题整理</title>
    <link href="https://enigmatisms.github.io/2022/04/11/Cartographer%E7%BC%96%E8%AF%91%E9%97%AE%E9%A2%98%E6%95%B4%E7%90%86/"/>
    <id>https://enigmatisms.github.io/2022/04/11/Cartographer%E7%BC%96%E8%AF%91%E9%97%AE%E9%A2%98%E6%95%B4%E7%90%86/</id>
    <published>2022-04-11T06:21:38.000Z</published>
    <updated>2022-04-11T06:27:04.128Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;cartographer&quot;&gt;Cartographer&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;​ 毕设工作设计到与cartographer进行定量实验比较。本人在&lt;a href=&quot;https://github.com/Enigmatisms/cartographer_tester&quot;&gt;Enigmatisms/cartographer_tester&lt;/a&gt;中整理了cartographer以及ros驱动代码，添加了自动化轨迹读取等功能，两周前在Ubuntu 18.04上已经完成了测试，但在Ubuntu 20.04上一直编译不通过，调了一下午才调出来。本文记录了cartographer在不同版本的Ubuntu上（尤其是20.04）的一些典型编译问题以及解决方案。笔者现已经通过文中所说的解决方案完成了cartographer的编译。&lt;/p&gt;</summary>
    
    
    
    <category term="snippet" scheme="https://enigmatisms.github.io/categories/snippet/"/>
    
    
    <category term="环境工程" scheme="https://enigmatisms.github.io/tags/%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="SLAM" scheme="https://enigmatisms.github.io/tags/SLAM/"/>
    
  </entry>
  
  <entry>
    <title>NeRF论文复现</title>
    <link href="https://enigmatisms.github.io/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/"/>
    <id>https://enigmatisms.github.io/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/</id>
    <published>2022-03-26T16:44:24.000Z</published>
    <updated>2022-04-16T22:51:23.619Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;nerf&quot;&gt;NeRF&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;​ 最近工程浓度太高，关于【如何设计】以及【为什么】的思考显著少于【如何实现】以及【怎么解决】。为了平衡科研与工程，我复现了最近读的一篇多视角重建论文（见上一篇博客 &lt;a href=&quot;https://enigmatisms.github.io/2022/03/13/Neural-Randiance-Field【1】/&quot;&gt;Neural Randiance Field【1】&lt;/a&gt;）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2003.08934.pdf?ref=https://githubhelp.com&quot;&gt;Mildenhall, Ben, et al. &quot;Nerf: Representing scenes as neural radiance fields for view synthesis.&quot; &lt;em&gt;European conference on computer vision&lt;/em&gt;. Springer, Cham, 2020.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​ NeRF这篇论文，读的时候觉得作者写得还是非常清晰，只要搞清楚了基本概念，流畅地读下来基本上没什么问题。但实现过程中，发现到处都是坑（坑主要来源于个人没有清晰的设计思路，不同模块间的输入输出连续性不强，导致接口经常改动，此外... 有些问题确实也挺坑的）。有别于NeRF的官方tensorflow实现，本论文复现使用Pytorch + CUDA，主要代码中约有50% CUDA，50%python。本论文主要记录复现思路，以及复现过程中遇到的主要问题。复现见&lt;a href&gt;Github repo: Enigmatisms/NeRF&lt;/a&gt;&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/dynamic.gif&quot; style=&quot;zoom:60%;&quot;&gt;
&lt;/center&gt;
&lt;center&gt;
Figure 1. blender synthetic dataset - drums 训练过程可视化（从epoch 1- epoch 400）
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="NeRF" scheme="https://enigmatisms.github.io/tags/NeRF/"/>
    
  </entry>
  
  <entry>
    <title>Neural Randiance Field【1】</title>
    <link href="https://enigmatisms.github.io/2022/03/13/Neural-Randiance-Field%E3%80%901%E3%80%91/"/>
    <id>https://enigmatisms.github.io/2022/03/13/Neural-Randiance-Field%E3%80%901%E3%80%91/</id>
    <published>2022-03-13T12:05:21.000Z</published>
    <updated>2022-03-13T17:15:48.756Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;neural-rf&quot;&gt;Neural RF&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ 深度学习的大环境下，视图合成（view synthesis）必然不会缺席（毕竟没什么数学能力也能搞，是吧）。NeRF作为其中比较杰出的工作之一，文章后续也受到很多关注，包括但不限于【NeRF++，NeRF--，Point NeRF】。本文是一篇关于NeRF及其++版本的论文理解，后续将在[Neural Randiance Field【2】]中介绍Point NeRF以及NeRF的复现：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2003.08934.pdf?ref=https://githubhelp.com&quot;&gt;Mildenhall, Ben, et al. &quot;Nerf: Representing scenes as neural radiance fields for view synthesis.&quot; &lt;em&gt;European conference on computer vision&lt;/em&gt;. Springer, Cham, 2020.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2010.07492.pdf&quot;&gt;Zhang, Kai, et al. &quot;Nerf++: Analyzing and improving neural radiance fields.&quot; &lt;em&gt;arXiv preprint arXiv:2010.07492&lt;/em&gt; (2020).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src=&quot;/2022/03/13/Neural-Randiance-Field%E3%80%901%E3%80%91/bench.gif&quot; style=&quot;zoom:100%;&quot;&gt;
&lt;/center&gt;
&lt;center&gt;
Figure 1. 拿个视频当NeRF demo是吧?（误）
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="NeRF" scheme="https://enigmatisms.github.io/tags/NeRF/"/>
    
  </entry>
  
  <entry>
    <title>远古SDF文档</title>
    <link href="https://enigmatisms.github.io/2022/02/22/%E8%BF%9C%E5%8F%A4SDF%E6%96%87%E6%A1%A3/"/>
    <id>https://enigmatisms.github.io/2022/02/22/%E8%BF%9C%E5%8F%A4SDF%E6%96%87%E6%A1%A3/</id>
    <published>2022-02-22T09:17:43.000Z</published>
    <updated>2022-02-25T00:44:11.858Z</updated>
    
    
      
      
        
        
    <summary type="html">&lt;iframe src=&quot;//www.slideshare.net/slideshow/embed_code/key/dUI2s72z0jLiEq&quot; width=&quot;750&quot; height=&quot;420&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot;</summary>
        
      
    
    
    
    <category term="snippet" scheme="https://enigmatisms.github.io/categories/snippet/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="SLAM" scheme="https://enigmatisms.github.io/tags/SLAM/"/>
    
  </entry>
  
  <entry>
    <title>简单的ROS跨设备控制</title>
    <link href="https://enigmatisms.github.io/2022/02/22/%E7%AE%80%E5%8D%95%E7%9A%84ROS%E8%B7%A8%E8%AE%BE%E5%A4%87%E6%8E%A7%E5%88%B6/"/>
    <id>https://enigmatisms.github.io/2022/02/22/%E7%AE%80%E5%8D%95%E7%9A%84ROS%E8%B7%A8%E8%AE%BE%E5%A4%87%E6%8E%A7%E5%88%B6/</id>
    <published>2022-02-22T09:16:48.000Z</published>
    <updated>2022-02-25T00:23:43.573Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;rrrros&quot;&gt;RRRROS&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;​ ROS常用的进程通信机制是消息传递，是基于各个node与master的XML-RPC实现，并且可能用到TCP/UDP等传输层协议，非常地网络。这样看来，ROS进行跨设备通信应该是比较简单的。本篇主要记录一个简单的ROS跨设备应用场景，并简介其中的原理。&lt;/p&gt;</summary>
    
    
    
    <category term="snippet" scheme="https://enigmatisms.github.io/categories/snippet/"/>
    
    
    <category term="ROS" scheme="https://enigmatisms.github.io/tags/ROS/"/>
    
  </entry>
  
  <entry>
    <title>2D激光SLAM中的SDF表征</title>
    <link href="https://enigmatisms.github.io/2022/02/21/2D%E6%BF%80%E5%85%89SLAM%E4%B8%AD%E7%9A%84SDF%E8%A1%A8%E5%BE%81/"/>
    <id>https://enigmatisms.github.io/2022/02/21/2D%E6%BF%80%E5%85%89SLAM%E4%B8%AD%E7%9A%84SDF%E8%A1%A8%E5%BE%81/</id>
    <published>2022-02-21T06:04:27.000Z</published>
    <updated>2022-02-25T00:28:25.325Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;sdf-slam&quot;&gt;SDF-SLAM&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ 在家配电脑环境工程时，真没有事干，就只能看看论文了。之前太naive了，了解得少，只知道2D地图表征常用栅格图以及点云，不常用的是隐式函数（implicit function），却忘记了还有SDF这个中间表征。查找2D-SLAM文献时，蹦出了几篇SDF相关的文章，都还算中规中矩，通俗易懂（比起什么cartographer分支定界来说，简直太友好了，不过说起来，这几篇论文中除了cartographer魔改论文之外，真的谈了后端吗？）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Fossel, Joscha-David, Karl Tuyls, and Jürgen Sturm. &quot;2D-SDF-SLAM: A signed distance function based SLAM frontend for laser scanners.&quot; &lt;em&gt;2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)&lt;/em&gt;. IEEE, 2015.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Daun, Kevin, et al. &quot;Large scale 2d laser slam using truncated signed distance functions.&quot; &lt;em&gt;2019 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)&lt;/em&gt;. IEEE, 2019.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fu, Xingyin, et al. &quot;Improved Signed Distance Function for 2D Real-time SLAM and Accurate Localization.&quot; &lt;em&gt;arXiv preprint arXiv:2101.08018&lt;/em&gt; (2021).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​ P.S. 本文内容并不多。虽然这有三篇论文，其中值得大篇幅讲的不可能塞在这篇博客中，不值得大篇幅讲的都在这了。&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="SLAM" scheme="https://enigmatisms.github.io/tags/SLAM/"/>
    
    <category term="表征" scheme="https://enigmatisms.github.io/tags/%E8%A1%A8%E5%BE%81/"/>
    
  </entry>
  
  <entry>
    <title>Hexo NexT主题 更强的自定义页面</title>
    <link href="https://enigmatisms.github.io/2022/02/18/Hexo-NexT%E4%B8%BB%E9%A2%98-%E6%9B%B4%E5%BC%BA%E7%9A%84%E8%87%AA%E5%AE%9A%E4%B9%89%E9%A1%B5%E9%9D%A2/"/>
    <id>https://enigmatisms.github.io/2022/02/18/Hexo-NexT%E4%B8%BB%E9%A2%98-%E6%9B%B4%E5%BC%BA%E7%9A%84%E8%87%AA%E5%AE%9A%E4%B9%89%E9%A1%B5%E9%9D%A2/</id>
    <published>2022-02-17T18:12:01.000Z</published>
    <updated>2022-02-17T19:11:47.776Z</updated>
    
    
    <summary type="html">&lt;h2 id=&quot;hexo-next美化&quot;&gt;Hexo NexT美化&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;​ Hexo NexT主题博客默认只有一个主页面，虽然可以在config.yml中选择以哪个板块作为主页面，但假如我想有多个不同的页面都与主页一样有页面预览，还是难以直接做到的。网上确实有一篇教程：&lt;a href=&quot;https://finisky.github.io/customizecategorybyextension/&quot;&gt;【Hexo添加自定义分类菜单项并定制页面布局(简洁版)】&lt;/a&gt;，我的snippet板块第一版就是用这个教程搭建的，但之后发现存在一些问题。那么应该如何解决呢？&lt;/p&gt;</summary>
    
    
    
    <category term="snippet" scheme="https://enigmatisms.github.io/categories/snippet/"/>
    
    
    <category term="hexo" scheme="https://enigmatisms.github.io/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>Redmi G 2021锐龙版双系统环境工程记录</title>
    <link href="https://enigmatisms.github.io/2022/02/17/Redmi-G-2021%E9%94%90%E9%BE%99%E7%89%88%E5%8F%8C%E7%B3%BB%E7%BB%9F%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B%E8%AE%B0%E5%BD%95/"/>
    <id>https://enigmatisms.github.io/2022/02/17/Redmi-G-2021%E9%94%90%E9%BE%99%E7%89%88%E5%8F%8C%E7%B3%BB%E7%BB%9F%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B%E8%AE%B0%E5%BD%95/</id>
    <published>2022-02-17T07:14:40.000Z</published>
    <updated>2022-02-17T07:17:50.067Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;amd-yes&quot;&gt;AMD Yes!&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;新电脑 Redmi G 2021 Ryzen7 版装&lt;strong&gt;&lt;u&gt;双系统&lt;/u&gt;&lt;/strong&gt; （win11 + ubuntu 18.04 LTS）过程中遇到了一些问题，以后如果要换设备大概率还得再来一遍，本篇权当记录。不过说实话，从本篇字数来看，应该算得上一篇正规post而不是snippet了。这确实也与snippet板块的设置理念相悖，不过可能我就是那么啰嗦吧。PS：本文与AMD yes没有任何关系。&lt;/p&gt;</summary>
    
    
    
    <category term="snippet" scheme="https://enigmatisms.github.io/categories/snippet/"/>
    
    
    <category term="环境工程" scheme="https://enigmatisms.github.io/tags/%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>关于卷积的一些思考</title>
    <link href="https://enigmatisms.github.io/2022/02/11/%E5%85%B3%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"/>
    <id>https://enigmatisms.github.io/2022/02/11/%E5%85%B3%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/</id>
    <published>2022-02-11T14:27:13.000Z</published>
    <updated>2022-02-11T18:02:18.015Z</updated>
    
    
      
      
        
        
    <summary type="html">&lt;iframe src=&quot;//www.slideshare.net/slideshow/embed_code/key/EeH6ZygZvj9G5m&quot; width=&quot;750&quot; height=&quot;420&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot;</summary>
        
      
    
    
    
    <category term="snippet" scheme="https://enigmatisms.github.io/categories/snippet/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
  </entry>
  
  <entry>
    <title>3D Reconstruction with Posed Mono-cam Images</title>
    <link href="https://enigmatisms.github.io/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/"/>
    <id>https://enigmatisms.github.io/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/</id>
    <published>2022-02-06T07:05:50.000Z</published>
    <updated>2022-02-08T16:04:04.327Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;re3d&quot;&gt;Re3D&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ 电脑还没到，我[#]。不得不说京东有些店是真的脑瘫，买RTX发AMD，AMD yes也别这样啊。没办法工作的情况下只能看论文，继续3D重建。3D重建有些部分与我当前工作有重合之处，我也想从中获得一些启发。本文是两篇小论文以及一本书（这本书的其中一卷）的一个小理解：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2003.10432.pdf?ref=https://githubhelp.com&quot;&gt;Murez, Zak, et al. &quot;Atlas: End-to-end 3d scene reconstruction from posed images.&quot; &lt;em&gt;European Conference on Computer Vision&lt;/em&gt;. Springer, Cham, 2020.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://proceedings.neurips.cc/paper/2021/file/0a87257e5308197df43230edf4ad1dae-Paper.pdf&quot;&gt;Bozic, Aljaz, et al. &quot;Transformerfusion: Monocular rgb scene reconstruction using transformers.&quot; &lt;em&gt;Advances in Neural Information Processing Systems&lt;/em&gt; 34 (2021)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;书（不得不说这本... 期刊？写得真不错，CV方向的基础以及前瞻，不过是当时的前瞻了，可能也比较老）: &lt;a href=&quot;https://www.nowpublishers.com/CGV&quot;&gt;Foundations and Trends® in Computer Graphics and Vision&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​ 附注：不让我工作我就打原神。&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="3D重建" scheme="https://enigmatisms.github.io/tags/3D%E9%87%8D%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>我贫瘠的数学世界【1】- SAM与优化方法</title>
    <link href="https://enigmatisms.github.io/2022/01/30/%E6%88%91%E8%B4%AB%E7%98%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B8%96%E7%95%8C%E3%80%901%E3%80%91-SAM%E4%B8%8E%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/"/>
    <id>https://enigmatisms.github.io/2022/01/30/%E6%88%91%E8%B4%AB%E7%98%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B8%96%E7%95%8C%E3%80%901%E3%80%91-SAM%E4%B8%8E%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/</id>
    <published>2022-01-30T03:04:30.000Z</published>
    <updated>2022-02-03T18:18:41.342Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;bfgsam&quot;&gt;BFGSAM&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ 很长一段时间没有静下心来看过有很强理论性的内容了，我十分担心自己会丧失理论上的思考能力以及数学计算能力。正好之前在看某篇论文时，看到其中提到一种叫做SAM（sharpness aware minimization）的方法，说是效果还行，此前保存了SAM论文，但没去细读。最近寒假由于电脑故障没办法工作，很闲，便重新了解了一些数值优化方面的知识（比如拟牛顿族），并读了读SAM（虽然读完感觉？？？这怎么这么魔法）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2010.01412.pdf&quot;&gt;ICLR 2021: Foret, Pierre, et al. &quot;Sharpness-aware minimization for efficiently improving generalization.&quot; &lt;em&gt;arXiv preprint arXiv:2010.01412&lt;/em&gt; (2020).&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;u&gt;《我这种菜鸡哪有资格觉得DL顶会论文魔法》系列&lt;/u&gt;&lt;/strong&gt;（下图图源论文）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2022/01/30/%E6%88%91%E8%B4%AB%E7%98%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B8%96%E7%95%8C%E3%80%901%E3%80%91-SAM%E4%B8%8E%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/sam.png&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="优化理论" scheme="https://enigmatisms.github.io/tags/%E4%BC%98%E5%8C%96%E7%90%86%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>Instant Neural Graphics Primitives</title>
    <link href="https://enigmatisms.github.io/2022/01/23/Instant-Neural-Graphics-Primitives/"/>
    <id>https://enigmatisms.github.io/2022/01/23/Instant-Neural-Graphics-Primitives/</id>
    <published>2022-01-23T14:29:53.000Z</published>
    <updated>2022-01-26T16:15:50.936Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;instant-ngp&quot;&gt;Instant NGP&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ 保研前是想搞3D重建来着，大概是无缘吧（xD）。最近老被安利 【5s NeRF训练】，听起来很强的样子，速度提升了好几个数量级，遂观摩了一下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.pdf&quot;&gt;&lt;strong&gt;Instant Neural Graphics Primitives with a Multiresolution Hash Encoding&lt;/strong&gt; Thomas Müller, Alex Evans, Christoph Schied, Alexander Keller arXiv:2201.05989 [cs.CV], Jan 2022&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​ 文章很有趣，对我现有工作有一定的启发价值，当然结果也很nice：&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/2022/01/23/Instant-Neural-Graphics-Primitives/robot5.gif&quot; style=&quot;zoom:125%;&quot;&gt;
&lt;/center&gt;
&lt;center&gt;
Figure 1. Hoho. Da. Nice.
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="3D重建" scheme="https://enigmatisms.github.io/tags/3D%E9%87%8D%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>Depth Completion论文三篇</title>
    <link href="https://enigmatisms.github.io/2022/01/23/Depth-Completion%E8%AE%BA%E6%96%87%E4%B8%89%E7%AF%87/"/>
    <id>https://enigmatisms.github.io/2022/01/23/Depth-Completion%E8%AE%BA%E6%96%87%E4%B8%89%E7%AF%87/</id>
    <published>2022-01-22T16:31:47.000Z</published>
    <updated>2022-01-22T16:43:28.427Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;depth-completion&quot;&gt;Depth Completion&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ 深度补全中存在多模态数据融合的问题：单目RGB图像直接进行深度估计比较困难（直接深度估计，个人感觉只能凭借常识和先验知识），而如果同时存在稀疏激光点云（散步在稠密的图像上），可以通过“传播的思想”将一些位置的深度传播出去。在返乡的高铁上没事干（事实上由于河南大雪以及湖北大雨，高铁变成了低铁，时间+2h），看了五篇论文，本文简要分析了其中三篇关于 guided深度补全的文章：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ICCV 2019: &lt;a href=&quot;https://openaccess.thecvf.com/content_ICCV_2019/papers/Xu_Depth_Completion_From_Sparse_LiDAR_Data_With_Depth-Normal_Constraints_ICCV_2019_paper.pdf&quot;&gt;Xu, Yan, et al. &quot;Depth completion from sparse lidar data with depth-normal constraints.&quot; &lt;em&gt;Proceedings of the IEEE/CVF International Conference on Computer Vision&lt;/em&gt;. 2019.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ICRA 2020 (可能写得不行 才6引): &lt;a href=&quot;https://arxiv.org/abs/2103.00783&quot;&gt;Hu, Mu, et al. &quot;Towards Precise and Efficient Image Guided Depth Completion.&quot; &lt;em&gt;arXiv e-prints&lt;/em&gt; (2021): arXiv-2103.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;AAAI 2020: &lt;a href=&quot;https://ojs.aaai.org/index.php/AAAI/article/view/6635&quot;&gt;Cheng, Xinjing, et al. &quot;Cspn++: Learning context and resource aware convolutional spatial propagation networks for depth completion.&quot; &lt;em&gt;Proceedings of the AAAI Conference on Artificial Intelligence&lt;/em&gt;. Vol. 34. No. 07. 2020.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​ 本文可能写得&lt;strong&gt;&lt;u&gt;很烂&lt;/u&gt;&lt;/strong&gt;，笔者在看这三篇论文以及写博客时，由于返乡安排太紧，只睡了3.25小时。&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="深度补全" scheme="https://enigmatisms.github.io/tags/%E6%B7%B1%E5%BA%A6%E8%A1%A5%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>Swin Transformer 复现</title>
    <link href="https://enigmatisms.github.io/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/"/>
    <id>https://enigmatisms.github.io/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/</id>
    <published>2022-01-10T14:45:34.000Z</published>
    <updated>2022-01-22T16:37:54.284Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;swin-transformer&quot;&gt;Swin Transformer&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ Swin Transformer获ICCV best paper之后，就总有很多人提起它。个人在前段时间复现了一个与ViT相关的工作（Compact Convolution Transformer），感觉实现太简单（训练难），遂想尝试一些更加复杂的工作。同时我当然也想看看best paper到底是什么水平。此论文写得很清晰，实验做得非常漂亮，思想也很有趣，不过可以说是一篇typical神经网络文章：&lt;strong&gt;&lt;u&gt;一个公式都没有&lt;/u&gt;&lt;/strong&gt;（attention公式以及复杂度计算公式不算）。个人虽然惊叹于其SOTA表现，但由于存在不可解释的魔法，也始终觉得很膈应。本文是我在复现过程中的整理的一些思路和我觉得本论文中疑难之处及其理解。复现见：&lt;a href=&quot;https://github.com/Enigmatisms/Maevit/tree/master/swin&quot;&gt;Github/Maevit(这实际是ViT的复现repo)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;​ 论文原文：&lt;a href=&quot;https://arxiv.org/abs/2103.14030&quot;&gt;Liu, Ze, et al. &quot;Swin transformer: Hierarchical vision transformer using shifted windows.&quot; &lt;em&gt;arXiv preprint arXiv:2103.14030&lt;/em&gt; (2021).&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2022/01/10/Swin-Transformer%E5%A4%8D%E7%8E%B0/intro.png&quot;&gt;&lt;/p&gt;
&lt;center&gt;
Figure 1. 艺术之国：还有一个XJTU的（MSRA nb）[1]
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="transformer" scheme="https://enigmatisms.github.io/tags/transformer/"/>
    
  </entry>
  
  <entry>
    <title>前端小学习</title>
    <link href="https://enigmatisms.github.io/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/"/>
    <id>https://enigmatisms.github.io/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/</id>
    <published>2021-12-26T12:18:03.000Z</published>
    <updated>2022-01-13T14:08:49.469Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;front-end&quot;&gt;Front-End&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ 某天我回过头来看自己大一写的游戏，越玩越觉得制作尽量细节拉满（确实，不过估计是因为我大一非常闲，可以整天泡在写游戏里）。虽然如此，我还是觉得Pygame不适合做这个游戏，并且我觉得大一时的代码设计思想还不成熟，非常乱，想重构这个游戏。思来想去，用Unity（写了个弹珠打砖块游戏）觉得不爽，并且C#语言风格与C++类似，不想重复，遂想用一些（感觉上）完全不一样的语言去做这件事，最后确定用前端写网页游戏。前端说有趣，也还挺有趣的（毕竟我之前一直想当建筑设计师，搞设计的热情还是有的），但总感觉少了点深度思考（可能因为我接触的太简单）。为了在实践中学习前端，我将之前用Pygame实现的用户登录界面用JS升级了一下（只是功能升级，并没有更好看，见&lt;a href=&quot;https://github.com/Enigmatisms/JSen&quot;&gt;Github:Enigmatisms/JSen&lt;/a&gt;），本文记录在做这个小小项目过程中遇到的一些问题。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/5.png&quot; style=&quot;zoom: 40%;&quot;&gt;&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/2021/12/26/%E5%89%8D%E7%AB%AF%E5%B0%8F%E5%AD%A6%E4%B9%A0/home.png&quot;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;Ethians Alpha 1.0 主菜单&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;一个（个人认为的）人性化的登录/注册网页&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;center&gt;
Figure 1. 目标 与 现阶段 发展不平衡之间的矛盾
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="JavaScript" scheme="https://enigmatisms.github.io/tags/JavaScript/"/>
    
    <category term="前端开发" scheme="https://enigmatisms.github.io/tags/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Vision Transformers</title>
    <link href="https://enigmatisms.github.io/2021/11/28/Vision-Transformers/"/>
    <id>https://enigmatisms.github.io/2021/11/28/Vision-Transformers/</id>
    <published>2021-11-27T23:22:16.000Z</published>
    <updated>2022-01-10T15:06:30.909Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;vit&quot;&gt;ViT&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ 去年的一个工作&lt;a href=&quot;#refs&quot;&gt;[1]&lt;/a&gt;，Vision Transformer的成功带动了变形金刚在视觉邻域的应用。CNN-based的backbone可能就快败在NAS以及ViT衍生模型手下了。为了回顾transformer以及加深理解，我复现了这篇论文&lt;a href=&quot;#refs&quot;&gt;[2]&lt;/a&gt;（其中的ViT-Lite以及CCT）。这个工作是对ViT进行轻型化，并且作者也提出了使用卷积加入inductive bias的方法。论文提出的网络复现起来很简单，毕竟不是什么大型网络以及复杂架构，但是要复现其结果感觉还是挺吃经验的。复现见：&lt;a href=&quot;https://github.com/Enigmatisms/Maevit&quot;&gt;[Github🔗:Enigmatisms/Maevit]&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/2021/11/28/Vision-Transformers/train.png&quot;&gt;&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/2021/11/28/Vision-Transformers/test.png&quot;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;最终（无mixup）训练集准确率（约99.8%）&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;最终（无mixup）测试集准确率（约94.5%）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;center&gt;
Figure 1. CIFAR-10实验，官方实现显示的最终acc约为94.7%
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="transformer" scheme="https://enigmatisms.github.io/tags/transformer/"/>
    
  </entry>
  
  <entry>
    <title>Nvidia 简单环境工程</title>
    <link href="https://enigmatisms.github.io/2021/11/21/Nvidia-%E7%AE%80%E5%8D%95%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B/"/>
    <id>https://enigmatisms.github.io/2021/11/21/Nvidia-%E7%AE%80%E5%8D%95%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B/</id>
    <published>2021-11-21T07:33:34.000Z</published>
    <updated>2021-11-21T08:29:53.397Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;ampere-pytorch&quot;&gt;Ampere Pytorch&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-introduction&quot;&gt;I. Introduction&lt;/h2&gt;
&lt;p&gt;​ 近日训练神经网络花了五六十块钱，在&lt;a href=&quot;http://www.ai-galaxy.cn/&quot;&gt;智星云&lt;/a&gt;平台上。这个云平台总的来说还是很便宜的，RTX 3090大概4元/h，之前训练胶囊网络的时候还狠吹了这个平台一波。但我最近感觉，该平台貌似有点坑：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RTX 2080Ti的训练速度比我的MX 150（比GTX 960更差一点的卡）更慢，RTX 3090没有3090的样子&lt;/li&gt;
&lt;li&gt;环境非常迷惑：比如其1080 Ti的环境，CUDA10.0 + Torch 1.4.0，直接没办法跑&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​ 于是乎我在办公室一个同事的电脑上装了整个深度学习环境。很不幸（又幸运）的是，他的显卡是RTX 3060，对应架构为安培（Ampere sm_86），不兼容低版本torch，使用不了CUDA加速。考虑到我之前有装显卡驱动搞爆系统的经历，我决定记录一下本次环境工程的过程。&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/2021/11/21/Nvidia-%E7%AE%80%E5%8D%95%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B/3060.png&quot; style=&quot;zoom:67%;&quot;&gt;
&lt;/center&gt;
&lt;center&gt;
Figure 1. 看起来很便宜 黄仁勋Yes
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="环境工程" scheme="https://enigmatisms.github.io/tags/%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>A Duality Problem of Representations</title>
    <link href="https://enigmatisms.github.io/2021/11/14/A-Duality-Problem-of-Representations/"/>
    <id>https://enigmatisms.github.io/2021/11/14/A-Duality-Problem-of-Representations/</id>
    <published>2021-11-14T13:19:26.000Z</published>
    <updated>2021-11-14T16:27:29.974Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;duality&quot;&gt;Duality&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-introduction&quot;&gt;I. Introduction&lt;/h2&gt;
&lt;p&gt;In a slide talking about 3D geometry and deep learning, I found something interesting: one question, of which I can not get rid. This is a duality question about representations:&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/2021/11/14/A-Duality-Problem-of-Representations/dual.png&quot; style=&quot;zoom:60%;&quot;&gt;
&lt;/center&gt;
&lt;center&gt;
Figure 1. Duality problem formulation
&lt;/center&gt;
&lt;p&gt;These problems lingered in my head:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Why and how we can regard probability distribution and particle filters as dual counterparts to each other?&lt;/li&gt;
&lt;li&gt;Same question for occupancy map and point clouds, as they seem to be, according to the figure above, the representations under different specifications?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So I took some time to sink in this problem. This post is therefore the summarization of my thoughts.&lt;/p&gt;</summary>
    
    
    
    <category term="Philosophy" scheme="https://enigmatisms.github.io/categories/Philosophy/"/>
    
    
    <category term="English" scheme="https://enigmatisms.github.io/tags/English/"/>
    
    <category term="Methodology" scheme="https://enigmatisms.github.io/tags/Methodology/"/>
    
  </entry>
  
</feed>
