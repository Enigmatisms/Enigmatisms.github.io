<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Event Horizon</title>
  <icon>https://enigmatisms.github.io/icon.png</icon>
  <subtitle>Technical &amp; Personal Docs.</subtitle>
  <link href="https://enigmatisms.github.io/atom.xml" rel="self"/>
  
  <link href="https://enigmatisms.github.io/"/>
  <updated>2024-12-16T09:17:23.318Z</updated>
  <id>https://enigmatisms.github.io/</id>
  
  <author>
    <name>Enigmatisms</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Write a software CUDA path tracer from scratch: the road to better parallelism</title>
    <link href="https://enigmatisms.github.io/2024/12/16/Write-a-software-CUDA-path-tracer-from-scratch-the-road-to-better-parallelism/"/>
    <id>https://enigmatisms.github.io/2024/12/16/Write-a-software-CUDA-path-tracer-from-scratch-the-road-to-better-parallelism/</id>
    <published>2024-12-16T07:02:52.000Z</published>
    <updated>2024-12-16T09:17:23.318Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;cuda-pt&quot;&gt;CUDA-PT&lt;/h1&gt;
&lt;h2 id=&quot;i.-intro&quot;&gt;I. Intro&lt;/h2&gt;
&lt;p&gt;I decide to write this blog post in English, which might potentially
help more people, I guess. It&#39;s been a while since I&#39;ve finished the
backbone of the CUDA-PT, and I think it&#39;s time to honor the original
purpose of developing this repo: write your own wheel, profile and
benchmark it, feel the challenges and understand things better. I can&#39;t
say I have done a pretty good job at benchmarking, since the commits
make it difficult to rewind back to the previous sub-optimal
implementation. Nevertheless, I&#39;ll try making my point, offering my two
cents, even if they are insignificant for those CUDA geeks.&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="CG" scheme="https://enigmatisms.github.io/tags/CG/"/>
    
    <category term="renderer" scheme="https://enigmatisms.github.io/tags/renderer/"/>
    
    <category term="GPU" scheme="https://enigmatisms.github.io/tags/GPU/"/>
    
    <category term="CUDA" scheme="https://enigmatisms.github.io/tags/CUDA/"/>
    
  </entry>
  
  <entry>
    <title>NeRF-GS Interview Preparation</title>
    <link href="https://enigmatisms.github.io/2024/04/25/NeRF-GS-Interview-Preparation/"/>
    <id>https://enigmatisms.github.io/2024/04/25/NeRF-GS-Interview-Preparation/</id>
    <published>2024-04-25T15:52:23.000Z</published>
    <updated>2024-04-25T16:06:04.869Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;nerf-3dgs&quot;&gt;NeRF-3DGS&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;​
找实习的时候也投了一些相关的岗位（三维重建、NeRF/GS等等），考虑到我本科是搞SLAM的，大四到研二上学期也断断续续做了一年半的NeRF，面相关的岗位时感觉还是比较轻松的，基本上比赛、开源项目吹吹水，回答一些简单的基础问题，做一些简单的题目就结束了，目前面试相关岗位还没碰上答不上来的问题。本部分
review NeRF 的基本工作，此前的 NeRF 项目、比赛以及 3D Gaussian
基本概念。&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="NeRF" scheme="https://enigmatisms.github.io/tags/NeRF/"/>
    
    <category term="MVS" scheme="https://enigmatisms.github.io/tags/MVS/"/>
    
    <category term="3DGS" scheme="https://enigmatisms.github.io/tags/3DGS/"/>
    
  </entry>
  
  <entry>
    <title>高性能异构计算相关知识</title>
    <link href="https://enigmatisms.github.io/2024/04/03/%E9%AB%98%E6%80%A7%E8%83%BD%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/"/>
    <id>https://enigmatisms.github.io/2024/04/03/%E9%AB%98%E6%80%A7%E8%83%BD%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/</id>
    <published>2024-04-03T14:03:34.000Z</published>
    <updated>2024-11-30T09:03:22.639Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;hpc-i&quot;&gt;HPC I&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;​ 投了几个 HPC 岗... 虽然不是科班出身，但个人觉得 HPC
还是挺有意思的（尤其是自己写 CUDA kernel
加速几百几千倍，那种成就感简直...）。HPC
的魅力之一在于，反馈非常及时：某种优化策略可能可以瞬间带来 profiling
时某一项的提高（比如 throughput, speed 等等）。我自己搞 rendering
的过程中也在不断尝试一些小的 tricks
（比如SSE啥的，毕竟多线程这种东西根本不用我写...
随便拉出一个线程池来都是自带 scheduler
的...），感觉过程中还是能学到很多东西的，对 CPU/GPU
的各种设计也能有更深的理解。&lt;/p&gt;
&lt;p&gt;​
本博客是我认为比较重要的相关知识（第一部分）以及我觉得我可以回答的一些问题。&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="HPC" scheme="https://enigmatisms.github.io/tags/HPC/"/>
    
    <category term="异构计算" scheme="https://enigmatisms.github.io/tags/%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>AdaPT - Volumetric Path Tracer I</title>
    <link href="https://enigmatisms.github.io/2023/02/18/AdaPT-Volumetric-Path-Tracer-I/"/>
    <id>https://enigmatisms.github.io/2023/02/18/AdaPT-Volumetric-Path-Tracer-I/</id>
    <published>2023-02-18T08:56:36.000Z</published>
    <updated>2023-02-18T09:06:10.385Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;ada-path-tracer-iii&quot;&gt;Ada Path Tracer III&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;​ AdaPT 进入了 volumetric path tracing
阶段。由于本人的研究方向（暂定）为散射介质渲染的研究，了解基于 particles
的（Lagrangian表征的）散射渲染是非常有必要的（烟雾渲染多有意思，虽然现在只能渲染
homogeneous 介质）。vpt相对于无介质pt的主要难点在于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;volumetric path tracing 在采样层面上多了一个维度 ---
光线传播距离将不再是无穷远，需要采样其自由程&lt;/li&gt;
&lt;li&gt;free space radiance
一致性不再成立，并且模型与表面散射模型有较大的区别。有许多额外计算需要完成&lt;/li&gt;
&lt;li&gt;direct component 更难衡量，这意味着收敛更加困难。MIS 也不那么
intuitive 了&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col style=&quot;width: 33%&quot;&gt;
&lt;col style=&quot;width: 33%&quot;&gt;
&lt;col style=&quot;width: 32%&quot;&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;渲染4000迭代（25s，约10亿光线）&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;渲染20000迭代（约50亿条光线）&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;渲染15000迭代&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/2023/02/18/AdaPT-Volumetric-Path-Tracer-I/pbr-balls-good.jpg&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/2023/02/18/AdaPT-Volumetric-Path-Tracer-I/pbr-balls-20000.png&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/2023/02/18/AdaPT-Volumetric-Path-Tracer-I/pbr-box-cloud.png&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;center&gt;
Figure 1. 无介质的收敛性明显好很多
&lt;/center&gt;
&lt;p&gt;​
话说，我写博客从来没有在一个系列上写超过两篇的文章，渲染技术系列已经三篇了，这还是头一回。&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="CG" scheme="https://enigmatisms.github.io/tags/CG/"/>
    
    <category term="renderer" scheme="https://enigmatisms.github.io/tags/renderer/"/>
    
    <category term="Taichi lang" scheme="https://enigmatisms.github.io/tags/Taichi-lang/"/>
    
  </entry>
  
  <entry>
    <title>AdaPT - Monte Carlo Path Tracer II</title>
    <link href="https://enigmatisms.github.io/2023/02/11/AdaPT-Monte-Carlo-Path-Tracer-II/"/>
    <id>https://enigmatisms.github.io/2023/02/11/AdaPT-Monte-Carlo-Path-Tracer-II/</id>
    <published>2023-02-11T14:21:14.000Z</published>
    <updated>2023-02-12T14:44:39.094Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;ada-path-tracer-ii&quot;&gt;Ada Path Tracer II&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;​ 本文为 &lt;a href=&quot;https://enigmatisms.github.io/2023/02/09/AdaPT-Monte-Carlo-Path-Tracer-I/&quot;&gt;Ada
Path Tracer I&lt;/a&gt; 的续文。在上一篇博客中，我只是说明了 Monte Carlo
积分在path tracing中的应用以及path
tracing的理论、实现流程。并没有深入讨论 PDF
如何计算、采样如何进行、PDF的选择如何影响结果以及如何使得 path tracer
具有更高的效率。笔者在本文中对上文未讨论清楚的问题进行分析。分析过程中我果真也发现自己之前的某些理解是不对的，实现时出了问题，例如在：Lambertian
BSDF的实现、MIS 对无面积光源的处理、MIS weight计算等等方面均有瑕疵。&lt;/p&gt;
&lt;p&gt;​ 本部分学习的结束标志着【基本 path tracer
实现】的完成（V1.0）。除了对BSDF进行小的修改之外（表面反射定义过于简单），下一步我将主要围绕两部分进行深入研究：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bidirectional path tracing。双向 tracer 对处理 directional /
collimated
光源十分有用，并且在caustic建模上有着更好的效果（虽然不是最好的）&lt;/li&gt;
&lt;li&gt;Volumetric path tracing。主要研究匀质介质散射吸收。&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src=&quot;/2023/02/11/AdaPT-Monte-Carlo-Path-Tracer-II/pbr-balls-multi.png&quot; style=&quot;zoom: 80%;&quot;&gt;
&lt;/center&gt;
&lt;center&gt;
Figure 1. AdaPT
2min增量式渲染（CPU，GPU时间除以8-10）：点光源/顶部面光源与球面光源
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="CG" scheme="https://enigmatisms.github.io/tags/CG/"/>
    
    <category term="renderer" scheme="https://enigmatisms.github.io/tags/renderer/"/>
    
    <category term="Taichi lang" scheme="https://enigmatisms.github.io/tags/Taichi-lang/"/>
    
  </entry>
  
  <entry>
    <title>AdaPT - Monte Carlo Path Tracer I</title>
    <link href="https://enigmatisms.github.io/2023/02/09/AdaPT-Monte-Carlo-Path-Tracer-I/"/>
    <id>https://enigmatisms.github.io/2023/02/09/AdaPT-Monte-Carlo-Path-Tracer-I/</id>
    <published>2023-02-08T17:55:18.000Z</published>
    <updated>2023-02-08T18:00:54.556Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;ada-path-tracer-i&quot;&gt;Ada Path Tracer I&lt;/h1&gt;
&lt;p&gt;​ Path
tracing背后的概率与数学理论较为复杂，如果不深入理解则很难进行正确的实现，更勿论在此基础上进行创新了。结合笔者在实现过程中的一些体会，笔者认为非Whitted光线追踪渲染器有一个这样的特点：即使是很大的逻辑错误可能也很难使用定性的方法观察出来，最后的错误输出可能与正确输出仅有很小的差别，甚至有的时候根本看不出来（例如，算法收敛慢时我可能倾向于认为是自己没有用太多的variance
reduction方法以及深入的采样技术，而不会认为我代码有逻辑错误）。故本文作为
Path Tracing
系列的第一部分文章，将尽可能深入讨论背后的理论知识以及其理解。理解是为实现、创新服务的，任何不到位的地方都将导致实现过程中的卡顿，故此处我将尽力覆盖这两周用零碎事件写&lt;a href=&quot;https://github.com/Enigmatisms/AdaPT&quot;&gt;渲染器:
AdaPT&lt;/a&gt;时所遇到的问题。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;写文档是很烦人的一件事，如果我本身很闲，不用为了各种学业、科研、个人资本等等事情考虑的话，我当然还是非常愿意写博客、写文档的。可惜写博客写文档从现在来看并没有实际的价值，只是我个人的自嗨。
--- 2023.2.8 何千越&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col style=&quot;width: 51%&quot;&gt;
&lt;col style=&quot;width: 48%&quot;&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;&quot;The cornell spheres&quot;&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;&quot;The cornell boxes&quot;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/2023/02/09/AdaPT-Monte-Carlo-Path-Tracer-I/adapt-cornell-sphere.png&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/2023/02/09/AdaPT-Monte-Carlo-Path-Tracer-I/adapt-cornell-box.png&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;center&gt;
Figure 1. Ada-Path-Tracer 渲染结果（20s内）
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="CG" scheme="https://enigmatisms.github.io/tags/CG/"/>
    
    <category term="renderer" scheme="https://enigmatisms.github.io/tags/renderer/"/>
    
    <category term="Taichi lang" scheme="https://enigmatisms.github.io/tags/Taichi-lang/"/>
    
  </entry>
  
  <entry>
    <title>Taichi-Learning-II</title>
    <link href="https://enigmatisms.github.io/2023/01/15/Taichi-Learning-II/"/>
    <id>https://enigmatisms.github.io/2023/01/15/Taichi-Learning-II/</id>
    <published>2023-01-15T13:43:34.000Z</published>
    <updated>2023-01-16T14:22:30.401Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;taichi-lang-ii&quot;&gt;Taichi Lang II&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​
深入了解Taichi语言，简单的并行算法设计无法满足我（毕竟真要说并行算法设计，Taichi所需的工作量与CUDA暂时没办法比）。Taichi中重要的两个features：稀疏数据结构（SSDS），可微编程（differentiable
programming）目前对我而言比较重要的就是SSDS，可微编程...
可微渲染可能可以用到，但是本身实在是太复杂了...
我一直觉得，不动手就学不到真正的知识，所以还是给自己布置了一道题，并且要求将SSDS以及在第一篇博客完成后学到的内容整合到此题的解答中。本文是最后一篇Taichi
入门博客，关于一些进阶的用法以及特性，以及在实现题目：flocking
simulation（鸟群模拟）中所学到的一些知识。文末附有flocking
sim的视频。&lt;/p&gt;
&lt;p&gt;​ 预计我下一步将会使用Taichi写一个带有participating media功能的path
tracer（3D，之前Rust + CUDA写了一个没开源的2D
tracer，只能看光路，不能看渲染结果（毕竟是2D）），以加深我对光线追踪算法的理解。不过这是个大项目，简单版本的也至少涉及到mesh的读取、加载、光线弹射、采样、介质实现、蒙特卡洛积分等等...
想想就刺激。&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col style=&quot;width: 50%&quot;&gt;
&lt;col style=&quot;width: 50%&quot;&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;frame 52
(红色为掠食者，白色为普通鸟)&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;frame 58
(红色为掠食者，白色为普通鸟)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/2023/01/15/Taichi-Learning-II/000052.png&quot; alt=&quot;000052&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/2023/01/15/Taichi-Learning-II/000058.png&quot; alt=&quot;000058&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;center&gt;
Figure 1. Flocking simulation with predators (64 regular boids (this is
not a typo) and 4 predators)
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="Taichi lang" scheme="https://enigmatisms.github.io/tags/Taichi-lang/"/>
    
    <category term="CUDA" scheme="https://enigmatisms.github.io/tags/CUDA/"/>
    
    <category term="LLVM" scheme="https://enigmatisms.github.io/tags/LLVM/"/>
    
  </entry>
  
  <entry>
    <title>Taichi Learning I</title>
    <link href="https://enigmatisms.github.io/2023/01/11/Taichi-Learning-I/"/>
    <id>https://enigmatisms.github.io/2023/01/11/Taichi-Learning-I/</id>
    <published>2023-01-11T03:53:43.000Z</published>
    <updated>2023-01-16T14:16:01.264Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;taichi-lang-i&quot;&gt;Taichi Lang I&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ 巨佬们的工作（胡渊明，李子懋 both from MIT CSAIL）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Taichi: A Language for High-Performance Computation on Spatially
Sparse Data Structures. ToG 2019&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​
刚好最近工作与图形学高度相关，并且一直觉得自己Python方面的技术栈太浅了（语法、代码加速了解得不够深入），于是想了解一下这个语言（与Python高度耦合）。这个语言在前年七月我刚开始做毕设的时候Dinger就在絮絮叨叨说Taichi怎么怎么香了，当时也玩了几个demo，但没有去了解语言本身。最近开始了解后觉得，要深入了解这个语言还是需要一些外围知识的辅助（比如，学了CUDA、LLVM等则会觉得接受其设计思想是一件比较容易的事情）。学这个语言的目标当然是用Taichi写一个简单的
path tracer
出来叻...。本文的主要内容有：（1）这几天学习时遇到的问题（2）一些Taichi底层原理（3）Python
decorator补充（4）自己做的一些小demo。&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/2023/01/11/Taichi-Learning-I/logo.png&quot; style=&quot;zoom: 50%;&quot;&gt;
&lt;/center&gt;
&lt;center&gt;
Figure 1. 混元形意太极 闪电五连鞭
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="Taichi lang" scheme="https://enigmatisms.github.io/tags/Taichi-lang/"/>
    
    <category term="CUDA" scheme="https://enigmatisms.github.io/tags/CUDA/"/>
    
    <category term="LLVM" scheme="https://enigmatisms.github.io/tags/LLVM/"/>
    
  </entry>
  
  <entry>
    <title>Rust C++小记录</title>
    <link href="https://enigmatisms.github.io/2022/08/20/Rust-C-%E5%B0%8F%E8%AE%B0%E5%BD%95/"/>
    <id>https://enigmatisms.github.io/2022/08/20/Rust-C-%E5%B0%8F%E8%AE%B0%E5%BD%95/</id>
    <published>2022-08-20T07:46:13.000Z</published>
    <updated>2025-10-01T09:29:48.959Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;rustc&quot;&gt;Rust/C++&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;​
很久之前（3个月前吧）写的文档了，当时还在学Rust以及零零散散地学一些C++STL库用法（哪知《effective
modern
C++》这般好书？）。Rust部分的记录还挺有趣的，C++部分就没有那么有趣了。索性就贴在此处，供日后查阅。（不过很长啊，这叫snippet？）&lt;/p&gt;</summary>
    
    
    
    <category term="snippets" scheme="https://enigmatisms.github.io/categories/snippets/"/>
    
    
    <category term="Rust" scheme="https://enigmatisms.github.io/tags/Rust/"/>
    
    <category term="C++" scheme="https://enigmatisms.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Ref NeRF复现</title>
    <link href="https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/"/>
    <id>https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/</id>
    <published>2022-08-13T08:35:58.000Z</published>
    <updated>2022-08-20T07:51:37.089Z</updated>
    
    
    <summary type="html">&lt;h2 id=&quot;ref-nerf复现&quot;&gt;Ref NeRF复现&lt;/h2&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ 科研恢复性训练。之前把CUDA加速的全并行shadow
caster写完了，算是复习了CUDA、Rust以及FFI的使用。深度学习方面就以复现Ref
NeRF为一个小任务。论文&lt;a href=&quot;https://dorverbin.github.io/refnerf/&quot;&gt;CVPR 2022 Best Student
Honorable Mention: Ref NeRF - Structured View-Dependent Appearance for
Neural Radiance
Fields&lt;/a&gt;对反射现象进行了良好的建模。之前我一直在研究折射现象的NeRF建模，就折射建模思路而言，此文对我有很大的启发。并且个人认为，基于Ref
NeRF以及mip
NeRF作为框架是比较好的选择（除此之外就是要考虑如何让训练变快了，Instant
NGP当然是不二选择）。当然，由于在复现过程中也遇到了许多问题，本文在阐述复现思路以及论文理解的同时，也会探讨踩过的坑。目前，Ref
NeRF的复现结果还没有达到令我满意的程度，只是具备雏形，毕竟融合两篇文章的idea可能导致冲突，深度学习这种玄学就更是这样了，模型炸了都不知道从哪一个先开始。复现见
&lt;a href=&quot;https://github.com/Enigmatisms/NeRF&quot;&gt;Enigmatisms/NeRF&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2022/08/13/Mip-NeRF-Ref-NeRF/ezgif-1-8207b1faa2.gif&quot;&gt;&lt;/p&gt;
&lt;center&gt;
Figure 1. Ref NeRF半成品(Shinny Blender -
Helmet)。从左至右：RGB、depth与“奇怪的法向量”
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="NeRF" scheme="https://enigmatisms.github.io/tags/NeRF/"/>
    
  </entry>
  
  <entry>
    <title>Rust CUDA混合编程</title>
    <link href="https://enigmatisms.github.io/2022/08/09/Rust-CUDA%E6%B7%B7%E5%90%88%E7%BC%96%E7%A8%8B/"/>
    <id>https://enigmatisms.github.io/2022/08/09/Rust-CUDA%E6%B7%B7%E5%90%88%E7%BC%96%E7%A8%8B/</id>
    <published>2022-08-09T06:11:59.000Z</published>
    <updated>2022-08-20T07:39:32.185Z</updated>
    
    
    <summary type="html">&lt;p&gt;​ （未完成，请勿点击）Rust FFI（foriegn function
interface）非常有吸引力，特别是当你用熟了&lt;a href=&quot;https://github.com/nannou-org/nannou&quot;&gt;nannou&lt;/a&gt;库之后（啊，nannou，比OpenCV香了不知道多少倍，OpenGL-base库牛逼！）。CUDA编程也属于很有吸引力的活动（谁会讨厌优化代码，在已经比多线程CPU快n倍的基础上看着它跑得越来越快呢）。两者放在一起只能说是让人觉得万事皆空。本文记录了在以下两个项目：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LSMv2：CUDA加速的激光雷达仿真器（simple 2D ray caster）&lt;/li&gt;
&lt;li&gt;ShadowCaster：CUDA加速的空域计算算法（2D阴影投射算法）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​
中，使用CUDA/Rust混合编程所遇到的/产生的：（1）语言方面的坑。（2）CUDA程序设计上的一些坑。（3）一些算法设计思路。&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="GPU" scheme="https://enigmatisms.github.io/tags/GPU/"/>
    
    <category term="CUDA" scheme="https://enigmatisms.github.io/tags/CUDA/"/>
    
    <category term="Rust FFI" scheme="https://enigmatisms.github.io/tags/Rust-FFI/"/>
    
  </entry>
  
  <entry>
    <title>Mip NeRF思想注入与更多的NeRF方法</title>
    <link href="https://enigmatisms.github.io/2022/05/03/Mip-NeRF%E6%80%9D%E6%83%B3%E6%B3%A8%E5%85%A5%E4%B8%8E%E6%9B%B4%E5%A4%9A%E7%9A%84NeRF%E6%96%B9%E6%B3%95/"/>
    <id>https://enigmatisms.github.io/2022/05/03/Mip-NeRF%E6%80%9D%E6%83%B3%E6%B3%A8%E5%85%A5%E4%B8%8E%E6%9B%B4%E5%A4%9A%E7%9A%84NeRF%E6%96%B9%E6%B3%95/</id>
    <published>2022-05-03T07:42:06.000Z</published>
    <updated>2022-08-24T23:20:48.138Z</updated>
    
    
    <summary type="html">&lt;p&gt;​ （未完成，请勿点击）。最近读了非常多关于NeRF的论文，毕竟这玩意从ECCV
2020被提出来之后就爆火了，变体层出不穷，基本上我能想到的卷法，都有人卷过了。低垂的果实总是被有能力又有准备的人先摘走，留下来的都是一些需要费大力气才能摘到的果实。论文不仅需要读，好的论文一定要复现，才能深入了解其精髓，西安交大人工智能学院的刘龙军副教授曾经在组会上说到：读论文不复现等于白读！大家都深以为然:&amp;gt;。而其中最有复现价值（并且难度没那么高的，不像Instant
NGP，official repo代码都看不懂）的当属：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ICCV 2021: &lt;a href=&quot;https://arxiv.org/abs/2103.13415&quot;&gt;Mip-NeRF: A
Multiscale Representation for Anti-Aliasing Neural Radiance
Fields&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ECCV 2022: &lt;a href=&quot;https://arxiv.org/abs/2111.12077&quot;&gt;Mip-NeRF 360:
Unbounded Anti-Aliased Neural Radiance Fields&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​ 其中Mip NeRF 360中的proposal
network已经成为目前个人所实现的NeRF框架的基础。本文是复现过程中的一些心得以及对其他所读的NeRF论文的总结。&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="NeRF" scheme="https://enigmatisms.github.io/tags/NeRF/"/>
    
  </entry>
  
  <entry>
    <title>Rust学习 II</title>
    <link href="https://enigmatisms.github.io/2022/05/03/Rust%E5%AD%A6%E4%B9%A0-II/"/>
    <id>https://enigmatisms.github.io/2022/05/03/Rust%E5%AD%A6%E4%B9%A0-II/</id>
    <published>2022-05-03T04:01:41.000Z</published>
    <updated>2022-05-03T04:04:18.561Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;rust---ii&quot;&gt;Rust - II&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intro&quot;&gt;I. Intro&lt;/h2&gt;
&lt;p&gt;​
变量的lifetime之前的部分，理解起来都比较简单。而一到lifetime出场，一群妖魔鬼怪也就跟着出场了。不过其实是因为之前的两天学习中，对于变量的引用，所有权的租借理解不够到位。本文仍然是在跟着Rust官方（的非官方，它自己写的）教程学习过程中，整活扩展的一些记录。&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="Rust" scheme="https://enigmatisms.github.io/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>Rust学习 I</title>
    <link href="https://enigmatisms.github.io/2022/05/03/Rust%E5%AD%A6%E4%B9%A0-I/"/>
    <id>https://enigmatisms.github.io/2022/05/03/Rust%E5%AD%A6%E4%B9%A0-I/</id>
    <published>2022-05-03T03:57:35.000Z</published>
    <updated>2022-05-03T04:04:12.549Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;rust---i&quot;&gt;Rust - I&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;intros&quot;&gt;Intros&lt;/h2&gt;
&lt;p&gt;​
Rust，好！可能主要由于所有权机制上的创新，学习时的感觉与学其他语言的感觉完全不同，于是没有像学JS一样，觉得无聊，也没有像觉像学haskell一样，觉得过于抽象。但是这样一种语言创新，必然会给学习带来障碍，毕竟编程思想是完全不同的。此外，可能我使用Rust的工具链不对，个人认为vscode对于Rust的支持明显不足（缺乏自动补全，没有函数快速查看以及定义跳转等等），第一天学的时候，只能实现一些强逻辑性算法（比如什么快排，归并排序等等），无法深入使用数据结构（给我一个数据结构我根本不知道里面有什么方法）。&lt;/p&gt;
&lt;p&gt;​
第一天快结束时，想学习一下Rust的可视化工具Plotters，结果发现，之前从菜鸟教程了解的写法过于粗浅，基本看不懂Plotters代码，遂投身更加深入的学习。但却发现，给自己设置的小目标
---
写一个链表，按照之前了解的语法知识，我都是写不出来的。快要放弃只是接触到了一个教程以及其官方文档：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://rust-unofficial.github.io/too-many-lists/index.html&quot;&gt;Rust
unofficial - Learning Rust With Entirely Too Many Linked Lists&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://doc.rust-lang.org/std/index.html&quot;&gt;Rust-lang
docs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​
教程详细介绍了对于链表的实现，较为通俗易懂，有些难以思考的问题，其实沉下心来想也很快能想出来。本文是跟着教程实现过程中，笔者对于遇到的一些问题的处理方法以及自己的心得。由于笔者非常不喜欢依葫芦画瓢（因为这样，感觉自己完全学不到东西），所以笔者也在自己的实现中整活（超前学习），本文也记录了整活过程中遇到的坑及处理方法。本篇为Rust学习心得的第一章。&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="Rust" scheme="https://enigmatisms.github.io/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>Cartographer编译问题整理</title>
    <link href="https://enigmatisms.github.io/2022/04/11/Cartographer%E7%BC%96%E8%AF%91%E9%97%AE%E9%A2%98%E6%95%B4%E7%90%86/"/>
    <id>https://enigmatisms.github.io/2022/04/11/Cartographer%E7%BC%96%E8%AF%91%E9%97%AE%E9%A2%98%E6%95%B4%E7%90%86/</id>
    <published>2022-04-11T06:21:38.000Z</published>
    <updated>2025-10-01T09:29:48.961Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;cartographer&quot;&gt;Cartographer&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;​ 毕设工作设计到与cartographer进行定量实验比较。本人在&lt;a href=&quot;https://github.com/Enigmatisms/cartographer_tester&quot;&gt;Enigmatisms/cartographer_tester&lt;/a&gt;中整理了cartographer以及ros驱动代码，添加了自动化轨迹读取等功能，两周前在Ubuntu
18.04上已经完成了测试，但在Ubuntu
20.04上一直编译不通过，调了一下午才调出来。本文记录了cartographer在不同版本的Ubuntu上（尤其是20.04）的一些典型编译问题以及解决方案。笔者现已经通过文中所说的解决方案完成了cartographer的编译。&lt;/p&gt;</summary>
    
    
    
    <category term="snippets" scheme="https://enigmatisms.github.io/categories/snippets/"/>
    
    
    <category term="SLAM" scheme="https://enigmatisms.github.io/tags/SLAM/"/>
    
    <category term="环境工程" scheme="https://enigmatisms.github.io/tags/%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>NeRF论文复现</title>
    <link href="https://enigmatisms.github.io/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/"/>
    <id>https://enigmatisms.github.io/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/</id>
    <published>2022-03-26T16:44:24.000Z</published>
    <updated>2022-04-16T22:51:23.619Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;nerf&quot;&gt;NeRF&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;​
最近工程浓度太高，关于【如何设计】以及【为什么】的思考显著少于【如何实现】以及【怎么解决】。为了平衡科研与工程，我复现了最近读的一篇多视角重建论文（见上一篇博客
&lt;a href=&quot;https://enigmatisms.github.io/2022/03/13/Neural-Randiance-Field【1】/&quot;&gt;Neural
Randiance Field【1】&lt;/a&gt;）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2003.08934.pdf?ref=https://githubhelp.com&quot;&gt;Mildenhall,
Ben, et al. &quot;Nerf: Representing scenes as neural radiance fields for
view synthesis.&quot; &lt;em&gt;European conference on computer vision&lt;/em&gt;.
Springer, Cham, 2020.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​
NeRF这篇论文，读的时候觉得作者写得还是非常清晰，只要搞清楚了基本概念，流畅地读下来基本上没什么问题。但实现过程中，发现到处都是坑（坑主要来源于个人没有清晰的设计思路，不同模块间的输入输出连续性不强，导致接口经常改动，此外...
有些问题确实也挺坑的）。有别于NeRF的官方tensorflow实现，本论文复现使用Pytorch
+ CUDA，主要代码中约有50%
CUDA，50%python。本论文主要记录复现思路，以及复现过程中遇到的主要问题。复现见&lt;a href&gt;Github repo: Enigmatisms/NeRF&lt;/a&gt;&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/dynamic.gif&quot; style=&quot;zoom:60%;&quot;&gt;
&lt;/center&gt;
&lt;center&gt;
Figure 1. blender synthetic dataset - drums 训练过程可视化（从epoch 1-
epoch 400）
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="NeRF" scheme="https://enigmatisms.github.io/tags/NeRF/"/>
    
  </entry>
  
  <entry>
    <title>Neural Radiance Field【1】</title>
    <link href="https://enigmatisms.github.io/2022/03/13/Neural-Radiance-Field%E3%80%901%E3%80%91/"/>
    <id>https://enigmatisms.github.io/2022/03/13/Neural-Radiance-Field%E3%80%901%E3%80%91/</id>
    <published>2022-03-13T12:05:21.000Z</published>
    <updated>2022-08-13T08:36:55.127Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;neural-rf&quot;&gt;Neural RF&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ 深度学习的大环境下，视图合成（view
synthesis）必然不会缺席（毕竟没什么数学能力也能搞，是吧）。NeRF作为其中比较杰出的工作之一，文章后续也受到很多关注，包括但不限于【NeRF++，NeRF--，Point
NeRF】。本文是一篇关于NeRF及其++版本的论文理解，后续将在[Neural Radiance
Field【2】]中介绍Point NeRF以及NeRF的复现：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2003.08934.pdf?ref=https://githubhelp.com&quot;&gt;Mildenhall,
Ben, et al. &quot;Nerf: Representing scenes as neural radiance fields for
view synthesis.&quot; &lt;em&gt;European conference on computer vision&lt;/em&gt;.
Springer, Cham, 2020.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2010.07492.pdf&quot;&gt;Zhang, Kai, et al.
&quot;Nerf++: Analyzing and improving neural radiance fields.&quot; &lt;em&gt;arXiv
preprint arXiv:2010.07492&lt;/em&gt; (2020).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src=&quot;/2022/03/13/Neural-Radiance-Field%E3%80%901%E3%80%91/bench.gif&quot; style=&quot;zoom:100%;&quot;&gt;
&lt;/center&gt;
&lt;center&gt;
Figure 1. 拿个视频当NeRF demo是吧?（误）
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="NeRF" scheme="https://enigmatisms.github.io/tags/NeRF/"/>
    
  </entry>
  
  <entry>
    <title>远古SDF文档</title>
    <link href="https://enigmatisms.github.io/2022/02/22/%E8%BF%9C%E5%8F%A4SDF%E6%96%87%E6%A1%A3/"/>
    <id>https://enigmatisms.github.io/2022/02/22/%E8%BF%9C%E5%8F%A4SDF%E6%96%87%E6%A1%A3/</id>
    <published>2022-02-22T09:17:43.000Z</published>
    <updated>2025-10-01T09:29:48.956Z</updated>
    
    
      
      
        
        
    <summary type="html">&lt;iframe src=&quot;//www.slideshare.net/slideshow/embed_code/key/dUI2s72z0jLiEq&quot; width=&quot;750&quot; height=&quot;420&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot;</summary>
        
      
    
    
    
    <category term="snippets" scheme="https://enigmatisms.github.io/categories/snippets/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="SLAM" scheme="https://enigmatisms.github.io/tags/SLAM/"/>
    
  </entry>
  
  <entry>
    <title>简单的ROS跨设备控制</title>
    <link href="https://enigmatisms.github.io/2022/02/22/%E7%AE%80%E5%8D%95%E7%9A%84ROS%E8%B7%A8%E8%AE%BE%E5%A4%87%E6%8E%A7%E5%88%B6/"/>
    <id>https://enigmatisms.github.io/2022/02/22/%E7%AE%80%E5%8D%95%E7%9A%84ROS%E8%B7%A8%E8%AE%BE%E5%A4%87%E6%8E%A7%E5%88%B6/</id>
    <published>2022-02-22T09:16:48.000Z</published>
    <updated>2025-10-01T09:29:48.957Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;rrrros&quot;&gt;RRRROS&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;​
ROS常用的进程通信机制是消息传递，是基于各个node与master的XML-RPC实现，并且可能用到TCP/UDP等传输层协议，非常地网络。这样看来，ROS进行跨设备通信应该是比较简单的。本篇主要记录一个简单的ROS跨设备应用场景，并简介其中的原理。&lt;/p&gt;</summary>
    
    
    
    <category term="snippets" scheme="https://enigmatisms.github.io/categories/snippets/"/>
    
    
    <category term="ROS" scheme="https://enigmatisms.github.io/tags/ROS/"/>
    
  </entry>
  
  <entry>
    <title>2D激光SLAM中的SDF表征</title>
    <link href="https://enigmatisms.github.io/2022/02/21/2D%E6%BF%80%E5%85%89SLAM%E4%B8%AD%E7%9A%84SDF%E8%A1%A8%E5%BE%81/"/>
    <id>https://enigmatisms.github.io/2022/02/21/2D%E6%BF%80%E5%85%89SLAM%E4%B8%AD%E7%9A%84SDF%E8%A1%A8%E5%BE%81/</id>
    <published>2022-02-21T06:04:27.000Z</published>
    <updated>2022-02-25T00:28:25.325Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;sdf-slam&quot;&gt;SDF-SLAM&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​
在家配电脑环境工程时，真没有事干，就只能看看论文了。之前太naive了，了解得少，只知道2D地图表征常用栅格图以及点云，不常用的是隐式函数（implicit
function），却忘记了还有SDF这个中间表征。查找2D-SLAM文献时，蹦出了几篇SDF相关的文章，都还算中规中矩，通俗易懂（比起什么cartographer分支定界来说，简直太友好了，不过说起来，这几篇论文中除了cartographer魔改论文之外，真的谈了后端吗？）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Fossel, Joscha-David, Karl Tuyls, and Jürgen Sturm. &quot;2D-SDF-SLAM:
A signed distance function based SLAM frontend for laser scanners.&quot;
&lt;em&gt;2015 IEEE/RSJ International Conference on Intelligent Robots and
Systems (IROS)&lt;/em&gt;. IEEE, 2015.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Daun, Kevin, et al. &quot;Large scale 2d laser slam using truncated
signed distance functions.&quot; &lt;em&gt;2019 IEEE International Symposium on
Safety, Security, and Rescue Robotics (SSRR)&lt;/em&gt;. IEEE, 2019.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fu, Xingyin, et al. &quot;Improved Signed Distance Function for 2D
Real-time SLAM and Accurate Localization.&quot; &lt;em&gt;arXiv preprint
arXiv:2101.08018&lt;/em&gt; (2021).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​ P.S.
本文内容并不多。虽然这有三篇论文，其中值得大篇幅讲的不可能塞在这篇博客中，不值得大篇幅讲的都在这了。&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="SLAM" scheme="https://enigmatisms.github.io/tags/SLAM/"/>
    
    <category term="表征" scheme="https://enigmatisms.github.io/tags/%E8%A1%A8%E5%BE%81/"/>
    
  </entry>
  
</feed>
