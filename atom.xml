<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Event Horizon</title>
  <icon>https://enigmatisms.github.io/icon.png</icon>
  <subtitle>Technical &amp; Personal Docs.</subtitle>
  <link href="https://enigmatisms.github.io/atom.xml" rel="self"/>
  
  <link href="https://enigmatisms.github.io/"/>
  <updated>2023-01-16T14:19:29.586Z</updated>
  <id>https://enigmatisms.github.io/</id>
  
  <author>
    <name>Enigmatisms</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Taichi-Learning-II</title>
    <link href="https://enigmatisms.github.io/2023/01/15/Taichi-Learning-II/"/>
    <id>https://enigmatisms.github.io/2023/01/15/Taichi-Learning-II/</id>
    <published>2023-01-15T13:43:34.000Z</published>
    <updated>2023-01-16T14:19:29.586Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;taichi-lang-ii&quot;&gt;Taichi Lang II&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ 深入了解Taichi语言，简单的并行算法设计无法满足我（毕竟真要说并行算法设计，Taichi所需的工作量与CUDA暂时没办法比）。Taichi中重要的两个features：稀疏数据结构（SSDS），可微编程（differentiable programming）目前对我而言比较重要的就是SSDS，可微编程... 可微渲染可能可以用到，但是本身实在是太复杂了... 我一直觉得，不动手就学不到真正的知识，所以还是给自己布置了一道题，并且要求将SSDS以及在第一篇博客完成后学到的内容整合到此题的解答中。本文是最后一篇Taichi 入门博客，关于一些进阶的用法以及特性，以及在实现题目：flocking simulation（鸟群模拟）中所学到的一些知识。文末附有flocking sim的视频。&lt;/p&gt;
&lt;p&gt;​ 预计我下一步将会使用Taichi写一个带有participating media功能的path tracer（3D，之前Rust + CUDA写了一个没开源的2D tracer，只能看光路，不能看渲染结果（毕竟是2D）），以加深我对光线追踪算法的理解。不过这是个大项目，简单版本的也至少涉及到mesh的读取、加载、光线弹射、采样、介质实现、蒙特卡洛积分等等... 想想就刺激。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;frame 52 (红色为掠食者，白色为普通鸟)&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;frame 58 (红色为掠食者，白色为普通鸟)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/2023/01/15/Taichi-Learning-II/000052.png&quot; alt=&quot;000052&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/2023/01/15/Taichi-Learning-II/000058.png&quot; alt=&quot;000058&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;center&gt;
Figure 1. Flocking simulation with predators (64 regular boids (this is not a typo) and 4 predators)
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="CUDA" scheme="https://enigmatisms.github.io/tags/CUDA/"/>
    
    <category term="LLVM" scheme="https://enigmatisms.github.io/tags/LLVM/"/>
    
    <category term="Taichi lang" scheme="https://enigmatisms.github.io/tags/Taichi-lang/"/>
    
  </entry>
  
  <entry>
    <title>Taichi Learning I</title>
    <link href="https://enigmatisms.github.io/2023/01/11/Taichi-Learning-I/"/>
    <id>https://enigmatisms.github.io/2023/01/11/Taichi-Learning-I/</id>
    <published>2023-01-11T03:53:43.000Z</published>
    <updated>2023-01-16T14:16:01.264Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;taichi-lang-i&quot;&gt;Taichi Lang I&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ 巨佬们的工作（胡渊明，李子懋 both from MIT CSAIL）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Taichi: A Language for High-Performance Computation on Spatially Sparse Data Structures. ToG 2019&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​ 刚好最近工作与图形学高度相关，并且一直觉得自己Python方面的技术栈太浅了（语法、代码加速了解得不够深入），于是想了解一下这个语言（与Python高度耦合）。这个语言在前年七月我刚开始做毕设的时候Dinger就在絮絮叨叨说Taichi怎么怎么香了，当时也玩了几个demo，但没有去了解语言本身。最近开始了解后觉得，要深入了解这个语言还是需要一些外围知识的辅助（比如，学了CUDA、LLVM等则会觉得接受其设计思想是一件比较容易的事情）。学这个语言的目标当然是用Taichi写一个简单的 path tracer 出来叻...。本文的主要内容有：（1）这几天学习时遇到的问题（2）一些Taichi底层原理（3）Python decorator补充（4）自己做的一些小demo。&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/2023/01/11/Taichi-Learning-I/logo.png&quot; style=&quot;zoom: 50%;&quot;&gt;
&lt;/center&gt;
&lt;center&gt;
Figure 1. 混元形意太极 闪电五连鞭
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="CUDA" scheme="https://enigmatisms.github.io/tags/CUDA/"/>
    
    <category term="LLVM" scheme="https://enigmatisms.github.io/tags/LLVM/"/>
    
    <category term="Taichi lang" scheme="https://enigmatisms.github.io/tags/Taichi-lang/"/>
    
  </entry>
  
  <entry>
    <title>Rust C++小记录</title>
    <link href="https://enigmatisms.github.io/2022/08/20/Rust-C-%E5%B0%8F%E8%AE%B0%E5%BD%95/"/>
    <id>https://enigmatisms.github.io/2022/08/20/Rust-C-%E5%B0%8F%E8%AE%B0%E5%BD%95/</id>
    <published>2022-08-20T07:46:13.000Z</published>
    <updated>2022-08-20T07:50:27.941Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;rustc&quot;&gt;Rust/C++&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;​ 很久之前（3个月前吧）写的文档了，当时还在学Rust以及零零散散地学一些C++STL库用法（哪知《effective modern C++》这般好书？）。Rust部分的记录还挺有趣的，C++部分就没有那么有趣了。索性就贴在此处，供日后查阅。（不过很长啊，这叫snippet？）&lt;/p&gt;</summary>
    
    
    
    <category term="snippet" scheme="https://enigmatisms.github.io/categories/snippet/"/>
    
    
    <category term="Rust" scheme="https://enigmatisms.github.io/tags/Rust/"/>
    
    <category term="C++" scheme="https://enigmatisms.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Ref NeRF复现</title>
    <link href="https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/"/>
    <id>https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/</id>
    <published>2022-08-13T08:35:58.000Z</published>
    <updated>2022-08-20T07:51:37.089Z</updated>
    
    
    <summary type="html">&lt;h2 id=&quot;ref-nerf复现&quot;&gt;Ref NeRF复现&lt;/h2&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ 科研恢复性训练。之前把CUDA加速的全并行shadow caster写完了，算是复习了CUDA、Rust以及FFI的使用。深度学习方面就以复现Ref NeRF为一个小任务。论文&lt;a href=&quot;https://dorverbin.github.io/refnerf/&quot;&gt;CVPR 2022 Best Student Honorable Mention: Ref NeRF - Structured View-Dependent Appearance for Neural Radiance Fields&lt;/a&gt;对反射现象进行了良好的建模。之前我一直在研究折射现象的NeRF建模，就折射建模思路而言，此文对我有很大的启发。并且个人认为，基于Ref NeRF以及mip NeRF作为框架是比较好的选择（除此之外就是要考虑如何让训练变快了，Instant NGP当然是不二选择）。当然，由于在复现过程中也遇到了许多问题，本文在阐述复现思路以及论文理解的同时，也会探讨踩过的坑。目前，Ref NeRF的复现结果还没有达到令我满意的程度，只是具备雏形，毕竟融合两篇文章的idea可能导致冲突，深度学习这种玄学就更是这样了，模型炸了都不知道从哪一个先开始。复现见 &lt;a href=&quot;https://github.com/Enigmatisms/NeRF&quot;&gt;Enigmatisms/NeRF&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2022/08/13/Mip-NeRF-Ref-NeRF/ezgif-1-8207b1faa2.gif&quot;&gt;&lt;/p&gt;
&lt;center&gt;
Figure 1. Ref NeRF半成品(Shinny Blender - Helmet)。从左至右：RGB、depth与“奇怪的法向量”
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="NeRF" scheme="https://enigmatisms.github.io/tags/NeRF/"/>
    
  </entry>
  
  <entry>
    <title>Rust CUDA混合编程</title>
    <link href="https://enigmatisms.github.io/2022/08/09/Rust-CUDA%E6%B7%B7%E5%90%88%E7%BC%96%E7%A8%8B/"/>
    <id>https://enigmatisms.github.io/2022/08/09/Rust-CUDA%E6%B7%B7%E5%90%88%E7%BC%96%E7%A8%8B/</id>
    <published>2022-08-09T06:11:59.000Z</published>
    <updated>2022-08-20T07:39:32.185Z</updated>
    
    
    <summary type="html">&lt;p&gt;​ （未完成，请勿点击）Rust FFI（foriegn function interface）非常有吸引力，特别是当你用熟了&lt;a href=&quot;https://github.com/nannou-org/nannou&quot;&gt;nannou&lt;/a&gt;库之后（啊，nannou，比OpenCV香了不知道多少倍，OpenGL-base库牛逼！）。CUDA编程也属于很有吸引力的活动（谁会讨厌优化代码，在已经比多线程CPU快n倍的基础上看着它跑得越来越快呢）。两者放在一起只能说是让人觉得万事皆空。本文记录了在以下两个项目：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LSMv2：CUDA加速的激光雷达仿真器（simple 2D ray caster）&lt;/li&gt;
&lt;li&gt;ShadowCaster：CUDA加速的空域计算算法（2D阴影投射算法）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​ 中，使用CUDA/Rust混合编程所遇到的/产生的：（1）语言方面的坑。（2）CUDA程序设计上的一些坑。（3）一些算法设计思路。&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="GPU" scheme="https://enigmatisms.github.io/tags/GPU/"/>
    
    <category term="CUDA" scheme="https://enigmatisms.github.io/tags/CUDA/"/>
    
    <category term="Rust FFI" scheme="https://enigmatisms.github.io/tags/Rust-FFI/"/>
    
  </entry>
  
  <entry>
    <title>Mip NeRF思想注入与更多的NeRF方法</title>
    <link href="https://enigmatisms.github.io/2022/05/03/Mip-NeRF%E6%80%9D%E6%83%B3%E6%B3%A8%E5%85%A5%E4%B8%8E%E6%9B%B4%E5%A4%9A%E7%9A%84NeRF%E6%96%B9%E6%B3%95/"/>
    <id>https://enigmatisms.github.io/2022/05/03/Mip-NeRF%E6%80%9D%E6%83%B3%E6%B3%A8%E5%85%A5%E4%B8%8E%E6%9B%B4%E5%A4%9A%E7%9A%84NeRF%E6%96%B9%E6%B3%95/</id>
    <published>2022-05-03T07:42:06.000Z</published>
    <updated>2022-08-24T23:20:48.138Z</updated>
    
    
    <summary type="html">&lt;p&gt;​ （未完成，请勿点击）。最近读了非常多关于NeRF的论文，毕竟这玩意从ECCV 2020被提出来之后就爆火了，变体层出不穷，基本上我能想到的卷法，都有人卷过了。低垂的果实总是被有能力又有准备的人先摘走，留下来的都是一些需要费大力气才能摘到的果实。论文不仅需要读，好的论文一定要复现，才能深入了解其精髓，西安交大人工智能学院的刘龙军副教授曾经在组会上说到：读论文不复现等于白读！大家都深以为然:&amp;gt;。而其中最有复现价值（并且难度没那么高的，不像Instant NGP，official repo代码都看不懂）的当属：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ICCV 2021: &lt;a href=&quot;https://arxiv.org/abs/2103.13415&quot;&gt;Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ECCV 2022: &lt;a href=&quot;https://arxiv.org/abs/2111.12077&quot;&gt;Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​ 其中Mip NeRF 360中的proposal network已经成为目前个人所实现的NeRF框架的基础。本文是复现过程中的一些心得以及对其他所读的NeRF论文的总结。&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="NeRF" scheme="https://enigmatisms.github.io/tags/NeRF/"/>
    
  </entry>
  
  <entry>
    <title>Rust学习 II</title>
    <link href="https://enigmatisms.github.io/2022/05/03/Rust%E5%AD%A6%E4%B9%A0-II/"/>
    <id>https://enigmatisms.github.io/2022/05/03/Rust%E5%AD%A6%E4%B9%A0-II/</id>
    <published>2022-05-03T04:01:41.000Z</published>
    <updated>2022-05-03T04:04:18.561Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;rust---ii&quot;&gt;Rust - II&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intro&quot;&gt;I. Intro&lt;/h2&gt;
&lt;p&gt;​ 变量的lifetime之前的部分，理解起来都比较简单。而一到lifetime出场，一群妖魔鬼怪也就跟着出场了。不过其实是因为之前的两天学习中，对于变量的引用，所有权的租借理解不够到位。本文仍然是在跟着Rust官方（的非官方，它自己写的）教程学习过程中，整活扩展的一些记录。&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="Rust" scheme="https://enigmatisms.github.io/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>Rust学习 I</title>
    <link href="https://enigmatisms.github.io/2022/05/03/Rust%E5%AD%A6%E4%B9%A0-I/"/>
    <id>https://enigmatisms.github.io/2022/05/03/Rust%E5%AD%A6%E4%B9%A0-I/</id>
    <published>2022-05-03T03:57:35.000Z</published>
    <updated>2022-05-03T04:04:12.549Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;rust---i&quot;&gt;Rust - I&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;intros&quot;&gt;Intros&lt;/h2&gt;
&lt;p&gt;​ Rust，好！可能主要由于所有权机制上的创新，学习时的感觉与学其他语言的感觉完全不同，于是没有像学JS一样，觉得无聊，也没有像觉像学haskell一样，觉得过于抽象。但是这样一种语言创新，必然会给学习带来障碍，毕竟编程思想是完全不同的。此外，可能我使用Rust的工具链不对，个人认为vscode对于Rust的支持明显不足（缺乏自动补全，没有函数快速查看以及定义跳转等等），第一天学的时候，只能实现一些强逻辑性算法（比如什么快排，归并排序等等），无法深入使用数据结构（给我一个数据结构我根本不知道里面有什么方法）。&lt;/p&gt;
&lt;p&gt;​ 第一天快结束时，想学习一下Rust的可视化工具Plotters，结果发现，之前从菜鸟教程了解的写法过于粗浅，基本看不懂Plotters代码，遂投身更加深入的学习。但却发现，给自己设置的小目标 --- 写一个链表，按照之前了解的语法知识，我都是写不出来的。快要放弃只是接触到了一个教程以及其官方文档：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://rust-unofficial.github.io/too-many-lists/index.html&quot;&gt;Rust unofficial - Learning Rust With Entirely Too Many Linked Lists&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://doc.rust-lang.org/std/index.html&quot;&gt;Rust-lang docs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​ 教程详细介绍了对于链表的实现，较为通俗易懂，有些难以思考的问题，其实沉下心来想也很快能想出来。本文是跟着教程实现过程中，笔者对于遇到的一些问题的处理方法以及自己的心得。由于笔者非常不喜欢依葫芦画瓢（因为这样，感觉自己完全学不到东西），所以笔者也在自己的实现中整活（超前学习），本文也记录了整活过程中遇到的坑及处理方法。本篇为Rust学习心得的第一章。&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="Rust" scheme="https://enigmatisms.github.io/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>Cartographer编译问题整理</title>
    <link href="https://enigmatisms.github.io/2022/04/11/Cartographer%E7%BC%96%E8%AF%91%E9%97%AE%E9%A2%98%E6%95%B4%E7%90%86/"/>
    <id>https://enigmatisms.github.io/2022/04/11/Cartographer%E7%BC%96%E8%AF%91%E9%97%AE%E9%A2%98%E6%95%B4%E7%90%86/</id>
    <published>2022-04-11T06:21:38.000Z</published>
    <updated>2022-04-11T06:27:04.128Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;cartographer&quot;&gt;Cartographer&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;​ 毕设工作设计到与cartographer进行定量实验比较。本人在&lt;a href=&quot;https://github.com/Enigmatisms/cartographer_tester&quot;&gt;Enigmatisms/cartographer_tester&lt;/a&gt;中整理了cartographer以及ros驱动代码，添加了自动化轨迹读取等功能，两周前在Ubuntu 18.04上已经完成了测试，但在Ubuntu 20.04上一直编译不通过，调了一下午才调出来。本文记录了cartographer在不同版本的Ubuntu上（尤其是20.04）的一些典型编译问题以及解决方案。笔者现已经通过文中所说的解决方案完成了cartographer的编译。&lt;/p&gt;</summary>
    
    
    
    <category term="snippet" scheme="https://enigmatisms.github.io/categories/snippet/"/>
    
    
    <category term="SLAM" scheme="https://enigmatisms.github.io/tags/SLAM/"/>
    
    <category term="环境工程" scheme="https://enigmatisms.github.io/tags/%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>NeRF论文复现</title>
    <link href="https://enigmatisms.github.io/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/"/>
    <id>https://enigmatisms.github.io/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/</id>
    <published>2022-03-26T16:44:24.000Z</published>
    <updated>2022-04-16T22:51:23.619Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;nerf&quot;&gt;NeRF&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;​ 最近工程浓度太高，关于【如何设计】以及【为什么】的思考显著少于【如何实现】以及【怎么解决】。为了平衡科研与工程，我复现了最近读的一篇多视角重建论文（见上一篇博客 &lt;a href=&quot;https://enigmatisms.github.io/2022/03/13/Neural-Randiance-Field【1】/&quot;&gt;Neural Randiance Field【1】&lt;/a&gt;）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2003.08934.pdf?ref=https://githubhelp.com&quot;&gt;Mildenhall, Ben, et al. &quot;Nerf: Representing scenes as neural radiance fields for view synthesis.&quot; &lt;em&gt;European conference on computer vision&lt;/em&gt;. Springer, Cham, 2020.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​ NeRF这篇论文，读的时候觉得作者写得还是非常清晰，只要搞清楚了基本概念，流畅地读下来基本上没什么问题。但实现过程中，发现到处都是坑（坑主要来源于个人没有清晰的设计思路，不同模块间的输入输出连续性不强，导致接口经常改动，此外... 有些问题确实也挺坑的）。有别于NeRF的官方tensorflow实现，本论文复现使用Pytorch + CUDA，主要代码中约有50% CUDA，50%python。本论文主要记录复现思路，以及复现过程中遇到的主要问题。复现见&lt;a href&gt;Github repo: Enigmatisms/NeRF&lt;/a&gt;&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/2022/03/27/NeRF%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/dynamic.gif&quot; style=&quot;zoom:60%;&quot;&gt;
&lt;/center&gt;
&lt;center&gt;
Figure 1. blender synthetic dataset - drums 训练过程可视化（从epoch 1- epoch 400）
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="NeRF" scheme="https://enigmatisms.github.io/tags/NeRF/"/>
    
  </entry>
  
  <entry>
    <title>Neural Radiance Field【1】</title>
    <link href="https://enigmatisms.github.io/2022/03/13/Neural-Radiance-Field%E3%80%901%E3%80%91/"/>
    <id>https://enigmatisms.github.io/2022/03/13/Neural-Radiance-Field%E3%80%901%E3%80%91/</id>
    <published>2022-03-13T12:05:21.000Z</published>
    <updated>2022-08-13T08:36:55.127Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;neural-rf&quot;&gt;Neural RF&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ 深度学习的大环境下，视图合成（view synthesis）必然不会缺席（毕竟没什么数学能力也能搞，是吧）。NeRF作为其中比较杰出的工作之一，文章后续也受到很多关注，包括但不限于【NeRF++，NeRF--，Point NeRF】。本文是一篇关于NeRF及其++版本的论文理解，后续将在[Neural Radiance Field【2】]中介绍Point NeRF以及NeRF的复现：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2003.08934.pdf?ref=https://githubhelp.com&quot;&gt;Mildenhall, Ben, et al. &quot;Nerf: Representing scenes as neural radiance fields for view synthesis.&quot; &lt;em&gt;European conference on computer vision&lt;/em&gt;. Springer, Cham, 2020.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2010.07492.pdf&quot;&gt;Zhang, Kai, et al. &quot;Nerf++: Analyzing and improving neural radiance fields.&quot; &lt;em&gt;arXiv preprint arXiv:2010.07492&lt;/em&gt; (2020).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src=&quot;/2022/03/13/Neural-Radiance-Field%E3%80%901%E3%80%91/bench.gif&quot; style=&quot;zoom:100%;&quot;&gt;
&lt;/center&gt;
&lt;center&gt;
Figure 1. 拿个视频当NeRF demo是吧?（误）
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="NeRF" scheme="https://enigmatisms.github.io/tags/NeRF/"/>
    
  </entry>
  
  <entry>
    <title>远古SDF文档</title>
    <link href="https://enigmatisms.github.io/2022/02/22/%E8%BF%9C%E5%8F%A4SDF%E6%96%87%E6%A1%A3/"/>
    <id>https://enigmatisms.github.io/2022/02/22/%E8%BF%9C%E5%8F%A4SDF%E6%96%87%E6%A1%A3/</id>
    <published>2022-02-22T09:17:43.000Z</published>
    <updated>2022-02-25T00:44:11.858Z</updated>
    
    
      
      
        
        
    <summary type="html">&lt;iframe src=&quot;//www.slideshare.net/slideshow/embed_code/key/dUI2s72z0jLiEq&quot; width=&quot;750&quot; height=&quot;420&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot;</summary>
        
      
    
    
    
    <category term="snippet" scheme="https://enigmatisms.github.io/categories/snippet/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="SLAM" scheme="https://enigmatisms.github.io/tags/SLAM/"/>
    
  </entry>
  
  <entry>
    <title>简单的ROS跨设备控制</title>
    <link href="https://enigmatisms.github.io/2022/02/22/%E7%AE%80%E5%8D%95%E7%9A%84ROS%E8%B7%A8%E8%AE%BE%E5%A4%87%E6%8E%A7%E5%88%B6/"/>
    <id>https://enigmatisms.github.io/2022/02/22/%E7%AE%80%E5%8D%95%E7%9A%84ROS%E8%B7%A8%E8%AE%BE%E5%A4%87%E6%8E%A7%E5%88%B6/</id>
    <published>2022-02-22T09:16:48.000Z</published>
    <updated>2022-02-25T00:23:43.573Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;rrrros&quot;&gt;RRRROS&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;​ ROS常用的进程通信机制是消息传递，是基于各个node与master的XML-RPC实现，并且可能用到TCP/UDP等传输层协议，非常地网络。这样看来，ROS进行跨设备通信应该是比较简单的。本篇主要记录一个简单的ROS跨设备应用场景，并简介其中的原理。&lt;/p&gt;</summary>
    
    
    
    <category term="snippet" scheme="https://enigmatisms.github.io/categories/snippet/"/>
    
    
    <category term="ROS" scheme="https://enigmatisms.github.io/tags/ROS/"/>
    
  </entry>
  
  <entry>
    <title>2D激光SLAM中的SDF表征</title>
    <link href="https://enigmatisms.github.io/2022/02/21/2D%E6%BF%80%E5%85%89SLAM%E4%B8%AD%E7%9A%84SDF%E8%A1%A8%E5%BE%81/"/>
    <id>https://enigmatisms.github.io/2022/02/21/2D%E6%BF%80%E5%85%89SLAM%E4%B8%AD%E7%9A%84SDF%E8%A1%A8%E5%BE%81/</id>
    <published>2022-02-21T06:04:27.000Z</published>
    <updated>2022-02-25T00:28:25.325Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;sdf-slam&quot;&gt;SDF-SLAM&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ 在家配电脑环境工程时，真没有事干，就只能看看论文了。之前太naive了，了解得少，只知道2D地图表征常用栅格图以及点云，不常用的是隐式函数（implicit function），却忘记了还有SDF这个中间表征。查找2D-SLAM文献时，蹦出了几篇SDF相关的文章，都还算中规中矩，通俗易懂（比起什么cartographer分支定界来说，简直太友好了，不过说起来，这几篇论文中除了cartographer魔改论文之外，真的谈了后端吗？）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Fossel, Joscha-David, Karl Tuyls, and Jürgen Sturm. &quot;2D-SDF-SLAM: A signed distance function based SLAM frontend for laser scanners.&quot; &lt;em&gt;2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)&lt;/em&gt;. IEEE, 2015.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Daun, Kevin, et al. &quot;Large scale 2d laser slam using truncated signed distance functions.&quot; &lt;em&gt;2019 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)&lt;/em&gt;. IEEE, 2019.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fu, Xingyin, et al. &quot;Improved Signed Distance Function for 2D Real-time SLAM and Accurate Localization.&quot; &lt;em&gt;arXiv preprint arXiv:2101.08018&lt;/em&gt; (2021).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​ P.S. 本文内容并不多。虽然这有三篇论文，其中值得大篇幅讲的不可能塞在这篇博客中，不值得大篇幅讲的都在这了。&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="SLAM" scheme="https://enigmatisms.github.io/tags/SLAM/"/>
    
    <category term="表征" scheme="https://enigmatisms.github.io/tags/%E8%A1%A8%E5%BE%81/"/>
    
  </entry>
  
  <entry>
    <title>Hexo NexT主题 更强的自定义页面</title>
    <link href="https://enigmatisms.github.io/2022/02/18/Hexo-NexT%E4%B8%BB%E9%A2%98-%E6%9B%B4%E5%BC%BA%E7%9A%84%E8%87%AA%E5%AE%9A%E4%B9%89%E9%A1%B5%E9%9D%A2/"/>
    <id>https://enigmatisms.github.io/2022/02/18/Hexo-NexT%E4%B8%BB%E9%A2%98-%E6%9B%B4%E5%BC%BA%E7%9A%84%E8%87%AA%E5%AE%9A%E4%B9%89%E9%A1%B5%E9%9D%A2/</id>
    <published>2022-02-17T18:12:01.000Z</published>
    <updated>2022-02-17T19:11:47.776Z</updated>
    
    
    <summary type="html">&lt;h2 id=&quot;hexo-next美化&quot;&gt;Hexo NexT美化&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;​ Hexo NexT主题博客默认只有一个主页面，虽然可以在config.yml中选择以哪个板块作为主页面，但假如我想有多个不同的页面都与主页一样有页面预览，还是难以直接做到的。网上确实有一篇教程：&lt;a href=&quot;https://finisky.github.io/customizecategorybyextension/&quot;&gt;【Hexo添加自定义分类菜单项并定制页面布局(简洁版)】&lt;/a&gt;，我的snippet板块第一版就是用这个教程搭建的，但之后发现存在一些问题。那么应该如何解决呢？&lt;/p&gt;</summary>
    
    
    
    <category term="snippet" scheme="https://enigmatisms.github.io/categories/snippet/"/>
    
    
    <category term="hexo" scheme="https://enigmatisms.github.io/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>Redmi G 2021锐龙版双系统环境工程记录</title>
    <link href="https://enigmatisms.github.io/2022/02/17/Redmi-G-2021%E9%94%90%E9%BE%99%E7%89%88%E5%8F%8C%E7%B3%BB%E7%BB%9F%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B%E8%AE%B0%E5%BD%95/"/>
    <id>https://enigmatisms.github.io/2022/02/17/Redmi-G-2021%E9%94%90%E9%BE%99%E7%89%88%E5%8F%8C%E7%B3%BB%E7%BB%9F%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B%E8%AE%B0%E5%BD%95/</id>
    <published>2022-02-17T07:14:40.000Z</published>
    <updated>2022-02-17T07:17:50.067Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;amd-yes&quot;&gt;AMD Yes!&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;新电脑 Redmi G 2021 Ryzen7 版装&lt;strong&gt;&lt;u&gt;双系统&lt;/u&gt;&lt;/strong&gt; （win11 + ubuntu 18.04 LTS）过程中遇到了一些问题，以后如果要换设备大概率还得再来一遍，本篇权当记录。不过说实话，从本篇字数来看，应该算得上一篇正规post而不是snippet了。这确实也与snippet板块的设置理念相悖，不过可能我就是那么啰嗦吧。PS：本文与AMD yes没有任何关系。&lt;/p&gt;</summary>
    
    
    
    <category term="snippet" scheme="https://enigmatisms.github.io/categories/snippet/"/>
    
    
    <category term="环境工程" scheme="https://enigmatisms.github.io/tags/%E7%8E%AF%E5%A2%83%E5%B7%A5%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>关于卷积的一些思考</title>
    <link href="https://enigmatisms.github.io/2022/02/11/%E5%85%B3%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"/>
    <id>https://enigmatisms.github.io/2022/02/11/%E5%85%B3%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/</id>
    <published>2022-02-11T14:27:13.000Z</published>
    <updated>2022-02-11T18:02:18.015Z</updated>
    
    
      
      
        
        
    <summary type="html">&lt;iframe src=&quot;//www.slideshare.net/slideshow/embed_code/key/EeH6ZygZvj9G5m&quot; width=&quot;750&quot; height=&quot;420&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot;</summary>
        
      
    
    
    
    <category term="snippet" scheme="https://enigmatisms.github.io/categories/snippet/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
  </entry>
  
  <entry>
    <title>3D Reconstruction with Posed Mono-cam Images</title>
    <link href="https://enigmatisms.github.io/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/"/>
    <id>https://enigmatisms.github.io/2022/02/06/3D-Reconstruction-with-Posed-Mono-cam-Images/</id>
    <published>2022-02-06T07:05:50.000Z</published>
    <updated>2022-02-08T16:04:04.327Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;re3d&quot;&gt;Re3D&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ 电脑还没到，我[#]。不得不说京东有些店是真的脑瘫，买RTX发AMD，AMD yes也别这样啊。没办法工作的情况下只能看论文，继续3D重建。3D重建有些部分与我当前工作有重合之处，我也想从中获得一些启发。本文是两篇小论文以及一本书（这本书的其中一卷）的一个小理解：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2003.10432.pdf?ref=https://githubhelp.com&quot;&gt;Murez, Zak, et al. &quot;Atlas: End-to-end 3d scene reconstruction from posed images.&quot; &lt;em&gt;European Conference on Computer Vision&lt;/em&gt;. Springer, Cham, 2020.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://proceedings.neurips.cc/paper/2021/file/0a87257e5308197df43230edf4ad1dae-Paper.pdf&quot;&gt;Bozic, Aljaz, et al. &quot;Transformerfusion: Monocular rgb scene reconstruction using transformers.&quot; &lt;em&gt;Advances in Neural Information Processing Systems&lt;/em&gt; 34 (2021)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;书（不得不说这本... 期刊？写得真不错，CV方向的基础以及前瞻，不过是当时的前瞻了，可能也比较老）: &lt;a href=&quot;https://www.nowpublishers.com/CGV&quot;&gt;Foundations and Trends® in Computer Graphics and Vision&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​ 附注：不让我工作我就打原神。&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="3D重建" scheme="https://enigmatisms.github.io/tags/3D%E9%87%8D%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>我贫瘠的数学世界【1】- SAM与优化方法</title>
    <link href="https://enigmatisms.github.io/2022/01/30/%E6%88%91%E8%B4%AB%E7%98%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B8%96%E7%95%8C%E3%80%901%E3%80%91-SAM%E4%B8%8E%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/"/>
    <id>https://enigmatisms.github.io/2022/01/30/%E6%88%91%E8%B4%AB%E7%98%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B8%96%E7%95%8C%E3%80%901%E3%80%91-SAM%E4%B8%8E%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/</id>
    <published>2022-01-30T03:04:30.000Z</published>
    <updated>2022-02-03T18:18:41.342Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;bfgsam&quot;&gt;BFGSAM&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ 很长一段时间没有静下心来看过有很强理论性的内容了，我十分担心自己会丧失理论上的思考能力以及数学计算能力。正好之前在看某篇论文时，看到其中提到一种叫做SAM（sharpness aware minimization）的方法，说是效果还行，此前保存了SAM论文，但没去细读。最近寒假由于电脑故障没办法工作，很闲，便重新了解了一些数值优化方面的知识（比如拟牛顿族），并读了读SAM（虽然读完感觉？？？这怎么这么魔法）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2010.01412.pdf&quot;&gt;ICLR 2021: Foret, Pierre, et al. &quot;Sharpness-aware minimization for efficiently improving generalization.&quot; &lt;em&gt;arXiv preprint arXiv:2010.01412&lt;/em&gt; (2020).&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;u&gt;《我这种菜鸡哪有资格觉得DL顶会论文魔法》系列&lt;/u&gt;&lt;/strong&gt;（下图图源论文）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2022/01/30/%E6%88%91%E8%B4%AB%E7%98%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B8%96%E7%95%8C%E3%80%901%E3%80%91-SAM%E4%B8%8E%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/sam.png&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="优化理论" scheme="https://enigmatisms.github.io/tags/%E4%BC%98%E5%8C%96%E7%90%86%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>Instant Neural Graphics Primitives</title>
    <link href="https://enigmatisms.github.io/2022/01/23/Instant-Neural-Graphics-Primitives/"/>
    <id>https://enigmatisms.github.io/2022/01/23/Instant-Neural-Graphics-Primitives/</id>
    <published>2022-01-23T14:29:53.000Z</published>
    <updated>2022-01-26T16:15:50.936Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;instant-ngp&quot;&gt;Instant NGP&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&quot;i.-intros&quot;&gt;I. Intros&lt;/h2&gt;
&lt;p&gt;​ 保研前是想搞3D重建来着，大概是无缘吧（xD）。最近老被安利 【5s NeRF训练】，听起来很强的样子，速度提升了好几个数量级，遂观摩了一下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.pdf&quot;&gt;&lt;strong&gt;Instant Neural Graphics Primitives with a Multiresolution Hash Encoding&lt;/strong&gt; Thomas Müller, Alex Evans, Christoph Schied, Alexander Keller arXiv:2201.05989 [cs.CV], Jan 2022&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​ 文章很有趣，对我现有工作有一定的启发价值，当然结果也很nice：&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/2022/01/23/Instant-Neural-Graphics-Primitives/robot5.gif&quot; style=&quot;zoom:125%;&quot;&gt;
&lt;/center&gt;
&lt;center&gt;
Figure 1. Hoho. Da. Nice.
&lt;/center&gt;</summary>
    
    
    
    <category term="learning" scheme="https://enigmatisms.github.io/categories/learning/"/>
    
    
    <category term="knowings" scheme="https://enigmatisms.github.io/tags/knowings/"/>
    
    <category term="DL" scheme="https://enigmatisms.github.io/tags/DL/"/>
    
    <category term="3D重建" scheme="https://enigmatisms.github.io/tags/3D%E9%87%8D%E5%BB%BA/"/>
    
  </entry>
  
</feed>
