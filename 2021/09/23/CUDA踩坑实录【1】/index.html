<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">

<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.1">
<script>
    (function(){
        if(''){
            if (prompt('Provide Access Code') !== ''){
                alert('Incorrect access code.');
                history.back();
            }
        }
    })();
</script>


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="RbBW2OguDsx3OoyQghfVhVDSgpBgwKw3Em9kY2pJUvU">

<link rel="stylesheet" href="/css/main.css">
<link href="https://fonts.googleapis.com/css?family=Noto+Serif+SC|Roboto&display=swap" rel="stylesheet">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab:300,300italic,400,400italic,700,700italic%7CNoto+Serif+SC:300,300italic,400,400italic,700,700italic%7CFira+Code:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/black/pace-theme-center-atom.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"enigmatisms.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.10.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"width":240},"copycode":false,"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"Oops... We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

  <meta name="description" content="CUDA I  I. Introduction ​ 在复现A Decomposition Model for Stereo Matching这篇论文的时候，发现其Sparse matching并不是直接的pytorch实现。本来我想直接pytorch了事的，但仔细一思考后觉得虽然反向传播实现不用考虑了，但是整体变得很慢。阅读官方源码发现时看到一些我不太懂的东西，后来我才知道这些是CUDA自定">
<meta property="og:type" content="website">
<meta property="og:title" content="CUDA踩坑实录【1】">
<meta property="og:url" content="https://enigmatisms.github.io/2021/09/23/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%901%E3%80%91/index.html">
<meta property="og:site_name" content="Event Horizon">
<meta property="og:description" content="CUDA I  I. Introduction ​ 在复现A Decomposition Model for Stereo Matching这篇论文的时候，发现其Sparse matching并不是直接的pytorch实现。本来我想直接pytorch了事的，但仔细一思考后觉得虽然反向传播实现不用考虑了，但是整体变得很慢。阅读官方源码发现时看到一些我不太懂的东西，后来我才知道这些是CUDA自定">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://enigmatisms.github.io/2021/09/23/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%901%E3%80%91/bubbles.PNG">
<meta property="og:image" content="https://enigmatisms.github.io/2021/09/23/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%901%E3%80%91/block.png">
<meta property="article:published_time" content="2021-09-22T16:06:38.000Z">
<meta property="article:modified_time" content="2021-09-24T01:52:46.588Z">
<meta property="article:author" content="Enigmatisms">
<meta property="article:tag" content="knowings">
<meta property="article:tag" content="GPU">
<meta property="article:tag" content="CUDA">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://enigmatisms.github.io/2021/09/23/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%901%E3%80%91/bubbles.PNG">


<link rel="canonical" href="https://enigmatisms.github.io/2021/09/23/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%901%E3%80%91/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://enigmatisms.github.io/2021/09/23/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%901%E3%80%91/","path":"2021/09/23/CUDA踩坑实录【1】/","title":"CUDA踩坑实录【1】"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>CUDA踩坑实录【1】 | Event Horizon</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="Event Horizon" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Event Horizon</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Technical & Personal Docs.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-snippets"><a href="/snippets/" rel="section"><i class="fa fa-key fa-fw"></i>snippets</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-male fa-fw"></i>About</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">36</span></a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-cubes fa-fw"></i>Categories<span class="badge">7</span></a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-folder-open fa-fw"></i>Archives<span class="badge">50</span></a></li>
        <li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#cuda-i"><span class="nav-text">CUDA I</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#i.-introduction"><span class="nav-text">I. Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ii.-%E4%BB%BB%E5%8A%A1%E8%AE%BE%E5%AE%9A"><span class="nav-text">II. 任务设定</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="nav-text">2.1 基础知识</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#dims"><span class="nav-text">2.1.1 Dims</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dynamic-parallelism%E8%B8%A9%E5%9D%91"><span class="nav-text">2.2 Dynamic Parallelism踩坑</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-text">
但是CUDA dynamic parallelism + Python却有一大堆坑
</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#reference"><span class="nav-text">Reference</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Enigmatisms"
      src="/images/enigma.gif">
  <p class="site-author-name" itemprop="name">Enigmatisms</p>
  <div class="site-description" itemprop="description">Amat Victoria Curam.</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">50</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">36</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Enigmatisms" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Enigmatisms" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/984041003@qq.com" title="E-Mail → 984041003@qq.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fas fa-rss fa-fw"></i>RSS</a>
      </span>
  </div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdn.jsdelivr.net/npm/@creativecommons/vocabulary@2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/Enigmatisms" class="github-corner" title="Welcome to take a look" aria-label="Welcome to take a look" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://enigmatisms.github.io/2021/09/23/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%901%E3%80%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/enigma.gif">
      <meta itemprop="name" content="Enigmatisms">
      <meta itemprop="description" content="Amat Victoria Curam.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Event Horizon">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          CUDA踩坑实录【1】
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-09-23 00:06:38" itemprop="dateCreated datePublished" datetime="2021-09-23T00:06:38+08:00">2021-09-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2021-09-24 09:52:46" itemprop="dateModified" datetime="2021-09-24T09:52:46+08:00">2021-09-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/learning/" itemprop="url" rel="index"><span itemprop="name">learning</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>5k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>5 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="cuda-i">CUDA I</h1>
<hr>
<h2 id="i.-introduction">I. Introduction</h2>
<p>​ 在复现<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2104.07516"><strong>A Decomposition Model for Stereo Matching</strong></a>这篇论文的时候，发现其Sparse matching并不是直接的pytorch实现。本来我想直接pytorch了事的，但仔细一思考后觉得虽然反向传播实现不用考虑了，但是整体变得很慢。阅读官方源码发现时看到一些我不太懂的东西，后来我才知道这些是CUDA自定义pytorch算子，是pytorch的CUDA extension。出于以下目的：</p>
<ul>
<li>复习CUDA（特别是在学习完GPU存储结构与计算之后，急需实践）</li>
<li>学习setuptools的使用以及torch的CUDA extension写法</li>
</ul>
<p>​ 我给自己定了一个小型的CUDA任务，与SDF以及marching cubes算法十分相关。项目见<a target="_blank" rel="noopener" href="https://github.com/Enigmatisms/CuTorch">[🔗Enigmatisms/CuTorch]</a></p>
<span id="more"></span>
<hr>
<h2 id="ii.-任务设定">II. 任务设定</h2>
<p>​ 在一个800x600的画布内，随机生成一些“泡泡”，这些泡泡在运动过程中应该可以自由地融合。泡泡的融合不是简单地叠加，叠加应当是平滑的。如下图所示：</p>
<p><img src="/2021/09/23/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%901%E3%80%91/bubbles.PNG" style="zoom: 67%;"></p>
<center>
Figure 1. 泡泡融合问题
</center>
<p>​ 每个泡泡对应着2D平面上半径为r，中心为(x, y)的一个圆。那么需要计算：</p>
<ul>
<li>每个泡泡对应圆的SDF，并且将其叠加在一起</li>
<li>设置一个阈值，跨越此阈值的部分将形成边结构（也就是等高线）</li>
</ul>
<p>​ 整个小项目的完整知识在这里：<a target="_blank" rel="noopener" href="http://jamie-wong.com/2014/08/19/metaballs-and-marching-squares/">【Jamie Wong: Metaballs and Marching Squares】</a>。写得非常不错，6月份做SDF的点云融合时，曾经参考过其marching cubes的实现方法。本文与具体的算法实现没有太大的关系，因为算法本身非常简单。</p>
<hr>
<h3 id="基础知识">2.1 基础知识</h3>
<h4 id="dims">2.1.1 Dims</h4>
<p>​ grid 与 block是CUDA的分级管理的两个层次，grid相当于是block的集合，而block相当于是thread的集合（或者warp的集合）。但我在写CUDA的时候好像并没有看到warp的直接使用。注意grid与block两者的维度 gridDim以及blockDim 千万别搞混了。对于一个kernel:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel_function &lt;&lt;&lt;A, B&gt;&gt;&gt; ();</span><br></pre></td></tr></table></figure>
<p>​ A指定的是grid的形状，可以是dim3类型，也可以是一个数字（指定block），A是数字的情形很常用，二维图像处理一般可以这么做：A，B分别代表图像的某一个维度。</p>
<p>​ B指定的是block形状，数据类型同理。那么gridDim则反映了A的输入，blockDim反映B的输入，比如：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>)</span></span>;</span><br><span class="line">kernel_func &lt;&lt;&lt;grid, block&gt;&gt;&gt; ();</span><br></pre></td></tr></table></figure>
<p>​ 在kernel内部，会有：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(gridDim.x, gridDim.y, gridDim.z)=(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>);</span><br><span class="line">(blockDim.x, blockDim.y, blockDim.z)=(<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>);</span><br></pre></td></tr></table></figure>
<p>​ 相应地，blockIdx.x <span class="math inline">\(\in\)</span> [0, gridDim.x ), threadIdx.x <span class="math inline">\(\in\)</span> [0, blockDim.x)。每一个实际的id，其范围是层级式的。block id与grid有关，thread id与block有关。并且也要注意以下的问题：</p>
<blockquote>
<p>Goal: Have enough transactions in flight to saturate the memory bus.</p>
<p>Latency can be hidden by having more transactions in flight. [1]</p>
</blockquote>
<p><img src="/2021/09/23/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%901%E3%80%91/block.png"></p>
<center>
Figure 2. occupancy注意事项（来源<a href="#refs">[1]</a>)
</center>
<h3 id="dynamic-parallelism踩坑">2.2 Dynamic Parallelism踩坑</h3>
<p>​ Dynamic parallelism，我更愿意直观地称之为：nested kernels（嵌套的核函数）。以我自己的代码为例，我尝试了一下嵌套核函数：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">fineGrainedTask</span><span class="params">(<span class="type">const</span> <span class="type">float</span>* <span class="type">const</span> bubbles, <span class="type">const</span> <span class="type">int</span> x, <span class="type">const</span> <span class="type">int</span> y, <span class="type">float</span>* shared_tmp)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> id = threadIdx.x, base = <span class="number">3</span> * id;</span><br><span class="line">    <span class="type">const</span> <span class="type">float</span> cx = bubbles[base], cy = bubbles[base + <span class="number">1</span>], radius = bubbles[base + <span class="number">2</span>];</span><br><span class="line">    shared_tmp[id] = <span class="built_in">signedDistance</span>(x, y, cx, cy, radius);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">calculateSDF</span><span class="params">(<span class="type">const</span> <span class="type">float</span>* <span class="type">const</span> bubbles, <span class="type">const</span> <span class="type">int</span> num, <span class="type">float</span>* output)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> y = threadIdx.x, x = blockIdx.x, id = y * gridDim.x + x;</span><br><span class="line">    <span class="type">float</span> distance = <span class="number">0.0</span>;</span><br><span class="line">    <span class="comment">// fineGrainedTask &lt;&lt;&lt; 1, num &gt;&gt;&gt; (bubbles, x, y, tmp);</span></span><br><span class="line">    <span class="comment">// cudaDeviceSynchronize();</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; num; i++) &#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> base = <span class="number">3</span> * i;</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span> cx = bubbles[base], cy = bubbles[base + <span class="number">1</span>], radius = bubbles[base + <span class="number">2</span>];</span><br><span class="line">        distance += <span class="built_in">signedDistance</span>(x, y, cx, cy, radius);</span><br><span class="line">    &#125;</span><br><span class="line">    output[id] = distance - <span class="number">1.0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 第二个函数 <code>__global__ void calculateSDF</code> 是主核函数。其目的是求二维矩阵中每一个点(i, j)的SDF值。而显然，每次输入的泡泡数量(num)可以很大，那么内部求signed distance的for循环，应该是可以并行化的。第一个函数<code>__global__ void fineGrainedTask</code> 就是为了做这样的并行，在第十行也被调用了（num路并行，使用__shared__保存临时的结果）。</p>
<p>​ CUDA在 architecture 35以及之后就支持这种nested的dynamic parallelism结构，允许核函数内部调用核函数，因为确实也是会有层次并行的需求的。</p>
<div class="note danger"><center>
<h3>
但是CUDA dynamic parallelism + Python却有一大堆坑
</h3>
</center>
</div>
<p>​ 假如只是使用CUDA + CPP进行嵌套核函数的编写，虽然有点小坑，但是很快就能过编译：</p>
<p>​ Dynamic parallelism需要separate compilation，CMake里面有很简单的设置：</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set_property</span>(CUDA_SEPARABLE_COMPILATION <span class="keyword">ON</span>)</span><br></pre></td></tr></table></figure>
<p>​ 但需要注意两点：</p>
<ul>
<li>separate compilation需要指定arch：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-gencode=arch=compute_35,code=sm_35</span><br></pre></td></tr></table></figure>
<ul>
<li>nvcc编译的时候，会指定：<code>-lcudadevrt -lcudart</code>，在/usr的某个文件夹下有一个动态库(libcudart.so)以及一个静态库（我的设备上是静态库：cudadevrt.a）。不方便设置这两个编译flag的时候，在target_link_libraries中可以手动链接。</li>
</ul>
<p>​ 但是Python setuptools编译并没有那么友好。首先我也知道我需要进行separate compilation，所以我需要指定：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">setup(</span><br><span class="line">    name=<span class="string">&#x27;march&#x27;</span>,</span><br><span class="line">    ext_modules=[</span><br><span class="line">        CUDAExtension(<span class="string">&#x27;march&#x27;</span>, [</span><br><span class="line">                <span class="string">&#x27;src/marchingCubes.cu&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;src/sdf_kernel.cu&#x27;</span>,</span><br><span class="line">            ],</span><br><span class="line">            include_dirs=[include_dirs],</span><br><span class="line">            extra_compile_args=&#123;<span class="string">&#x27;cxx&#x27;</span>: [<span class="string">&#x27;-g&#x27;</span>,</span><br><span class="line">            ],</span><br><span class="line">                <span class="string">&#x27;nvcc&#x27;</span>: [<span class="string">&#x27;-O3&#x27;</span>, <span class="string">&#x27;-use_fast_math&#x27;</span>,</span><br><span class="line">                 <span class="comment">################# Here #############</span></span><br><span class="line">				<span class="string">&#x27;-rdc=true&#x27;</span>, <span class="string">&#x27;-gencode=arch=compute_35,code=sm_35&#x27;</span></span><br><span class="line">            ]&#125;,</span><br><span class="line">        )</span><br><span class="line">    ],</span><br><span class="line">    cmdclass=&#123;</span><br><span class="line">        <span class="string">&#x27;build_ext&#x27;</span>: BuildExtension</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p>​ <code>-rdc=true</code>貌似和<code>-dc</code>作用差不多。还需要手动指定一下架构代数，默认好像是一个很小的代。好，不要忘了增加<code>-lcudadevrt</code>以及<code>-lcudart</code>以“保证”可以链接到CUDA的一些库。</p>
<p>​ 看起来很简单，编它。编译通过，很好，跑它。首先import torch（由于本项目C++内部使用了libtorch，里面的libc10.so需要torch导入，不先import的话会报错）。再import march（我的库名称），这一步直接死掉：</p>
<blockquote>
<p>什么什么undefined symbol，与CUDA库相关。</p>
</blockquote>
<p>​ 大概意思就是：<code>cudadevrt.a</code>你根本没有链接上，里面还有一些函数定义呢。好家伙，python的所有库都是动态加载的，你一个静态库你叫我怎么加载（简单的方法就是：(1) 重新编译静态库为动态库 (2) 编译整个项目为一个extension，具体原理我也不懂）？我还指望你直接给我编译到march这个库里面呢。</p>
<p>​ 尝试了很多方法，无论是在C++ 编译flags里面链接，还是nvcc flags，还是stackoverflow上说的所谓：setup函数的extra_compile_objects参数，没有一个有效果的。</p>
<p>​ 我也尝试过手动分别编译：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvcc -O3 -use_fast_math -gencode=arch=compute_70,code=sm_70 -dc -I/opt/libtorch/include/ -I/opt/libtorch/include/torch/csrc/api/include/ -I//usr/include/python3.6m src/sdf_kernel.cu src/marchingCubes.cu -Xcompiler -fPIC </span><br><span class="line">nvcc -O3 -use_fast_math -gencode=arch=compute_70,code=sm_70 -dlink -L/usr/local/cuda-10.1/targets/x86_64-linux/lib/ -lcudadevrt -lcudart sdf_kernel.o marchingCubes.o -shared -o libdlink.so</span><br></pre></td></tr></table></figure>
<p>​ 想把两个cuda文件编译跟原有的静态动态库一起编译成一个动态库，但是中途报了有关fPIC的错误，说是这样编译是不被允许的，反正不是那种很简单的错误。。。搞了半天，无果。各种问题都出了，最后我甚至都怀疑是编译器的bug（自信！）。最后貌似在CUDA forum的某个地方看见有人说，Python现在对这个的支持还不是特别好，就弃坑了。</p>
<p>​ 最后一个小坑就是：tmd不要随便用很高的代数！不知道为什么，我在setup函数nvcc参数设置时，定代数为：<code>-gencode=arch=compute_70,code=sm_70</code>。结果跑结果的时候，输出图像一片漆黑。最后查出来结果是：<strong><u>核函数根本没有被执行，跳过了</u></strong>，开始我以为出了内存问题（老 千（次）越（界）了）（PS：CUDA runtime出错可能导致核函数不执行），写了个CUDA错误检查，发现完全没有错误。最后灵光一闪，我把代数改成了35，好了。。。</p>
<p>​ 感觉被坑死了。原本预计一个下午解决，结果因为grid/block搞混，结果错误，多调了3小时，又因为dynamic parallelism，多调了6小时。</p>
<p>​ 菜，或许就是这样的吧？</p>
<p>​ 完整的项目以及结果见<a target="_blank" rel="noopener" href="https://github.com/Enigmatisms/CuTorch">[🔗Enigmatisms/CuTorch]</a></p>
<hr>
<h2 id="reference">Reference</h2>
<p><span id="refs"></span></p>
<p>[1] <a target="_blank" rel="noopener" href="https://on-demand.gputechconf.com/gtc-express/2011/presentations/cuda_webinars_WarpsAndOccupancy.pdf">CUDA Warps and Occupancy</a></p>
<p></p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>Post author:  </strong>Enigmatisms
  </li>
  <li class="post-copyright-link">
      <strong>Post link: </strong>
      <a href="https://enigmatisms.github.io/2021/09/23/CUDA%E8%B8%A9%E5%9D%91%E5%AE%9E%E5%BD%95%E3%80%901%E3%80%91/" title="CUDA踩坑实录【1】">https://enigmatisms.github.io/2021/09/23/CUDA踩坑实录【1】/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/knowings/" rel="tag"><i class="fa fa-tag"></i> knowings</a>
              <a href="/tags/GPU/" rel="tag"><i class="fa fa-tag"></i> GPU</a>
              <a href="/tags/CUDA/" rel="tag"><i class="fa fa-tag"></i> CUDA</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/09/04/%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%A4%E7%AF%87%E5%8F%8C%E7%9B%AE%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/" rel="prev" title="【笔记】两篇双目相关论文">
                  <i class="fa fa-chevron-left"></i> 【笔记】两篇双目相关论文
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/10/15/Correspondence-Problem-Papers/" rel="next" title="Correspondence Problem Papers">
                  Correspondence Problem Papers <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.5/lib/darkmode-js.min.js"></script>
<script>
new Darkmode({
saveInCookies: true, // default: true,
label: '🌓', // default: ''
autoMatchOsTheme: true // default: true
})
.showWidget();
</script>

<div class="copyright">
  &copy; 2021.1 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-anchor"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Enigmatisms</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="Symbols count total">303k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">4:36</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <script src='https://unpkg.com/mermaid@/dist/mermaid.min.js'></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({theme: 'forest'});
    }
  </script>

    </div>
  </footer>

  
  <script size="256" alpha="0.3" zIndex="-1" src="https://cdn.jsdelivr.net/npm/ribbon.js@1.0.2/dist/ribbon.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdn.jsdelivr.net/npm/pdfobject@2.2.7/pdfobject.min.js","integrity":"sha256-ph3Dk89VmuTVXG6x/RDzk53SU9LPdAh1tpv0UvnDZ2I="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":"forest","js":{"url":"https://cdn.jsdelivr.net/npm/mermaid@8.13.10/dist/mermaid.min.js","integrity":"sha256-CmZCFVnvol9YL23PfjDflGY5nJwE+Mf/JN+8v+tD/34="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>


  <script src="/js/third-party/pace.js"></script>

  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"Enigmatisms/Enigmatisms.github.io","issue_term":"pathname","theme":"github-light"}</script>
<script src="/js/third-party/comments/utterances.js"></script>

</body>
</html>
