<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">

<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.1">
<script>
    (function(){
        if(''){
            if (prompt('Provide Access Code') !== ''){
                alert('Incorrect access code.');
                history.back();
            }
        }
    })();
</script>


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="RbBW2OguDsx3OoyQghfVhVDSgpBgwKw3Em9kY2pJUvU">

<link rel="stylesheet" href="/css/main.css">
<link href="https://fonts.googleapis.com/css?family=Noto+Serif+SC|Roboto&display=swap" rel="stylesheet">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab:300,300italic,400,400italic,700,700italic%7CNoto+Serif+SC:300,300italic,400,400italic,700,700italic%7CFira+Code:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/black/pace-theme-center-atom.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"enigmatisms.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.10.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"width":240},"copycode":false,"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"Oops... We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

  <meta name="description" content="Ref NeRF复现  I. Intros ​ 科研恢复性训练。之前把CUDA加速的全并行shadow caster写完了，算是复习了CUDA、Rust以及FFI的使用。深度学习方面就以复现Ref NeRF为一个小任务。论文CVPR 2022 Best Student Honorable Mention: Ref NeRF - Structured View-Dependent App">
<meta property="og:type" content="website">
<meta property="og:title" content="Ref NeRF复现">
<meta property="og:url" content="https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/index.html">
<meta property="og:site_name" content="Event Horizon">
<meta property="og:description" content="Ref NeRF复现  I. Intros ​ 科研恢复性训练。之前把CUDA加速的全并行shadow caster写完了，算是复习了CUDA、Rust以及FFI的使用。深度学习方面就以复现Ref NeRF为一个小任务。论文CVPR 2022 Best Student Honorable Mention: Ref NeRF - Structured View-Dependent App">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/ezgif-1-8207b1faa2.gif">
<meta property="og:image" content="https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/zenith.jpg">
<meta property="og:image" content="https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/network.png">
<meta property="og:image" content="https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/false_ball_2.png">
<meta property="og:image" content="https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/result_001.png">
<meta property="og:image" content="https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/no_prop_002.png">
<meta property="og:image" content="https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/prop_003.png">
<meta property="og:image" content="https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/curves.png">
<meta property="og:image" content="https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/Screenshot%20from%202022-08-19%2013-31-01.png">
<meta property="og:image" content="https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/ezgif-1-8207b1faa2.gif">
<meta property="article:published_time" content="2022-08-13T08:35:58.000Z">
<meta property="article:modified_time" content="2022-08-20T07:51:37.089Z">
<meta property="article:author" content="Enigmatisms">
<meta property="article:tag" content="knowings">
<meta property="article:tag" content="DL">
<meta property="article:tag" content="NeRF">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/ezgif-1-8207b1faa2.gif">


<link rel="canonical" href="https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/","path":"2022/08/13/Mip-NeRF-Ref-NeRF/","title":"Ref NeRF复现"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Ref NeRF复现 | Event Horizon</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="Event Horizon" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Event Horizon</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Technical & Personal Docs.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-snippets"><a href="/snippets/" rel="section"><i class="fa fa-key fa-fw"></i>snippets</a></li>
        <li class="menu-item menu-item-owner-info"><a href="/owner-info/" rel="section"><i class="fa fa-user-astronaut fa-fw"></i>owner-info</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">47</span></a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-cubes fa-fw"></i>Categories<span class="badge">7</span></a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-folder-open fa-fw"></i>Archives<span class="badge">66</span></a></li>
        <li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#ref-nerf%E5%A4%8D%E7%8E%B0"><span class="nav-text">Ref NeRF复现</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#i.-intros"><span class="nav-text">I. Intros</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ii.-%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86"><span class="nav-text">II. 论文梳理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ref-nerf%E7%9A%84%E5%BB%BA%E6%A8%A1"><span class="nav-text">2.1 Ref NeRF的建模</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#directional-mlp%E4%BF%AE%E6%94%B9"><span class="nav-text">2.2 directional MLP修改</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B3%95%E5%90%91%E9%87%8F%E4%BC%B0%E8%AE%A1"><span class="nav-text">2.3 法向量估计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%89%A9%E5%B1%95%E7%9F%A5%E8%AF%86"><span class="nav-text">2.4 扩展知识</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%80%E4%BA%9B%E7%89%A9%E7%90%86%E6%A6%82%E5%BF%B5"><span class="nav-text">2.4.1 一些物理概念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%89%E5%9C%BA"><span class="nav-text">2.4.2 光场</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%90%83%E8%B0%90%E5%87%BD%E6%95%B0%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-text">2.5 球谐函数的使用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#iii.-%E5%A4%8D%E7%8E%B0%E7%BB%86%E8%8A%82"><span class="nav-text">III. 复现细节</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%80%BC%E5%BE%97%E4%B8%80%E6%8F%90%E7%9A%84%E7%82%B9"><span class="nav-text">3.1 值得一提的点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E4%BA%9B%E5%9D%91"><span class="nav-text">3.2 一些坑</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#reference"><span class="nav-text">Reference</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Enigmatisms"
      src="/images/enigma.gif">
  <p class="site-author-name" itemprop="name">Enigmatisms</p>
  <div class="site-description" itemprop="description">Amat Victoria Curam.</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">66</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">47</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Enigmatisms" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Enigmatisms" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/984041003@qq.com" title="E-Mail → 984041003@qq.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fas fa-rss fa-fw"></i>RSS</a>
      </span>
  </div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdn.jsdelivr.net/npm/@creativecommons/vocabulary@2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/Enigmatisms" class="github-corner" title="Welcome to take a look" aria-label="Welcome to take a look" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/enigma.gif">
      <meta itemprop="name" content="Enigmatisms">
      <meta itemprop="description" content="Amat Victoria Curam.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Event Horizon">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Ref NeRF复现
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-08-13 16:35:58" itemprop="dateCreated datePublished" datetime="2022-08-13T16:35:58+08:00">2022-08-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-08-20 15:51:37" itemprop="dateModified" datetime="2022-08-20T15:51:37+08:00">2022-08-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/learning/" itemprop="url" rel="index"><span itemprop="name">learning</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>15k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>14 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="ref-nerf复现">Ref NeRF复现</h2>
<hr>
<h2 id="i.-intros">I. Intros</h2>
<p>​ 科研恢复性训练。之前把CUDA加速的全并行shadow
caster写完了，算是复习了CUDA、Rust以及FFI的使用。深度学习方面就以复现Ref
NeRF为一个小任务。论文<a target="_blank" rel="noopener" href="https://dorverbin.github.io/refnerf/">CVPR 2022 Best Student
Honorable Mention: Ref NeRF - Structured View-Dependent Appearance for
Neural Radiance
Fields</a>对反射现象进行了良好的建模。之前我一直在研究折射现象的NeRF建模，就折射建模思路而言，此文对我有很大的启发。并且个人认为，基于Ref
NeRF以及mip
NeRF作为框架是比较好的选择（除此之外就是要考虑如何让训练变快了，Instant
NGP当然是不二选择）。当然，由于在复现过程中也遇到了许多问题，本文在阐述复现思路以及论文理解的同时，也会探讨踩过的坑。目前，Ref
NeRF的复现结果还没有达到令我满意的程度，只是具备雏形，毕竟融合两篇文章的idea可能导致冲突，深度学习这种玄学就更是这样了，模型炸了都不知道从哪一个先开始。复现见
<a target="_blank" rel="noopener" href="https://github.com/Enigmatisms/NeRF">Enigmatisms/NeRF</a></p>
<p><img src="/2022/08/13/Mip-NeRF-Ref-NeRF/ezgif-1-8207b1faa2.gif"></p>
<center>
Figure 1. Ref NeRF半成品(Shinny Blender -
Helmet)。从左至右：RGB、depth与“奇怪的法向量”
</center>
<span id="more"></span>
<hr>
<h2 id="ii.-论文梳理">II. 论文梳理</h2>
<h3 id="ref-nerf的建模">2.1 Ref NeRF的建模</h3>
<p>​ Ref NeRF建模了表面反射，此工作比之前所看过的一篇处理反射的NeRF（<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2111.15234">NeRFReN</a>）更有价值。个人认为，Ref
NeRF可以被认为是一个不完整的光线传播模型，较好地解决了反射问题，只需要加上折射部分就可以使得NeRF处理基本的光线传播现象。本文对Ref
NeRF的主要思路进行梳理，并且基于笔者对本论文的理解，在之前实现的NeRF（mip
NeRF 360）基础上，增加Ref NeRF模块。</p>
<p>​ Ref
NeRF处理的首要问题是光线的反射问题，反射一般分为两种：镜面反射（specularity）以及漫反射（diffusion）。那么根据Phong反射模型（以及之前学过半吊子图形学基础），被观察到的光线（强度）将为：
<span class="math display">\[
\begin{equation}\label{phong}
I_o=k_aI_a+\sum_{i}k_d\left( l_i\cdot n\right)I_i+\sum_i k_s(r_i\cdot
v)^pI_i
\end{equation}
\]</span> ​ 其中，下标为a的部分与环境光（ambient
light）有关；下标含有d则与漫反射有关，而下标含有s则与镜面高光有关。为了更好地解释Ref
NeRF的反射模型处理以及回顾一下Phong模型这个基础模型，这里对公式<span class="math inline">\(\eqref{phong}\)</span>模型简单解释：</p>
<ul>
<li>第一项代表环境光对观察结果的影响：环境光只对结果产生常数offset</li>
<li>第二项代表了所有光源在物体上产生的漫反射。漫反射与观察方向无关，只要能观察到，就是“恒定”的。光源i
(<span class="math inline">\(l_i\)</span>为其发射的某一光线的方向）发射光越是能垂直表面（与法向平行），漫反射越强。</li>
<li>第三项代表了镜面高光：不一定是完全的镜面反射（所以称之为镜面高光），可以稍显模糊，但是其强度是与视角有关的。<span class="math inline">\(r_i\)</span>代表了反射光线的方向，<span class="math inline">\(v\)</span>则代表了观察方向。两者重合（点乘结果接近1）时，反射较强。指数p用于加强衰减，可知p越大，<span class="math inline">\((r_i\cdot
v)^p\)</span>变化越快。也即视线与反射方向重合发生变化时，镜面高光的变化越明显。</li>
</ul>
<p>​ Ref NeRF对于后两个部分都进行了建模： <span class="math display">\[
\begin{equation}\label{ref}
L_{out}(\hat{\omega_{o}})\propto \int
L_{in}(\hat{\omega_{i}})p(\hat{\omega_{i}}\cdot\hat{\omega_{r}})d\hat{\omega_{i}}=F(\hat{\omega_{r}})
\end{equation}
\]</span> ​ 其中<span class="math inline">\(\hat{\omega_{o}}\)</span>是观察方向（相机到物体），<span class="math inline">\(\hat{\omega_{i}}\)</span>是光线的入射方向（光源到物体），<span class="math inline">\(\hat{\omega_{r}}\)</span>是观察方向在物体上的反射（可以认为是相机按照<span class="math inline">\(\hat{\omega_{o}}\)</span>方向发射光后反射的方向）。那么显然，<span class="math inline">\(\hat{\omega_{i}}\cdot\hat{\omega_{r}}\)</span>就是公式<span class="math inline">\(\eqref{phong}\)</span>中的 <span class="math inline">\(r_i\cdot
v\)</span>。在此工作中，函数p等均是神经网络（学出来的反射，强），并且作者强调，此函数就是反射方向
<span class="math inline">\(\hat{\omega_{r}}\)</span>的函数（内部包含了观察视角方向信息）。反射方向的求解非常简单，这里不赘述。不过我不禁思考，如果把作者的反射模型从Phong模型换成Bling
Phong模型会怎么样？在复现中笔者进行了尝试，结果见实验部分。</p>
<p>​ 作者花大力气改造原始NeRF的directional MLP，spatial
MLP则只是输出了一些新的辅助信息。directional MLP必须要能够输出真正的view
dependent颜色。作者认为：spatial
MLP也需要直接预测颜色，但是此颜色应该是受环境光、漫反射等影响产生的（由公式
<span class="math inline">\(\eqref{phong}\)</span>可知，环境光与漫反射均与视角无关），视角不变的颜色。严格来说，此部分颜色并非albedo（由于漫反射存在）。而directional
MLP应当产生镜面高光部分。作者对directional MLP作了如下修改：</p>
<h3 id="directional-mlp修改">2.2 directional MLP修改</h3>
<p>​ 首先，作者做了一个类似于mip NeRF中光锥处理的操作。mip
NeRF中，为了达到mip
map的效果，作者将点采样变为了光锥采样，以考虑整个光锥中的所有信息。Ref
NeRF中，作者认为“反射”也不能仅仅考虑单个反射方向。由于物体实际是凹凸不平的，并非完美的镜面，表面法向量并非完全一致。可以认为，物体表面的凹凸起伏（噪声），使得反射发生了一些改变（distortion），物体表面噪声的概率分布，经过反射的数学操作后被映射成了新的分布。并且：</p>
<ul>
<li>新的分布应该是各方向对称的。由于我们并不知道物体表面能有什么样的各向异性特征。</li>
<li>法向量分布的期望应该是 <span class="math inline">\(\hat{\omega_{r}}\)</span>，也即根据求得的表面法向量以及观察方向求出的反射方向。其背后的intuition（总觉得，不应该翻译成直觉，故我这里用了一个英文单词，以表示：我觉得这里用中文表达不了那种意思）很好理解。</li>
<li>法向量的方差应该受到物体表面粗糙程度进行控制。表面越粗糙，方差越大（法向量分布较广、分散）。这很符合现实。</li>
</ul>
<p>​ 作者使用了一种叫做 von
Mises-Fisher（简写为vMF）的概率分布。此分布的pdf非常像高斯分布pdf，估计也有差不多的性质。个人推测作者选这个函数是为了方便进行后续的数学推导以及近似，就像mip
NeRF中，将光锥用混合高斯模型进行近似一样。有了此分布，自然需要使用积分将所有可能的反射方向考虑进去。当然不是直接求期望（求出来就是
<span class="math inline">\(\hat{\omega_{r}}\)</span>，就直接trivial了）。考虑到，在将
<span class="math inline">\(\hat{\omega_{r}}\)</span> 输入到directional
MLP之前，需要进行positional encoding。在mip NeRF中，positional
encoding参与了积分，在此处实际上也类似：我们需要在高维空间中求每一维度的期望。但作者并没有用sinusoidal
positional encoding，而是使用球谐函数（spherical
harmonics）对方向进行表示。最后对每一维球谐函数进行积分： <span class="math display">\[
\begin{equation}\label{sphere}
\mathbb{E}_{\hat\omega\sim{\text{vMF}(\hat{\omega_{r}},\kappa)}}[Y^m_{l}(\hat\omega)]\approx
\exp(\frac{-l(l+1)}{\kappa})Y^m_{l}(\hat\omega)
\end{equation}
\]</span> ​ 其中，<span class="math inline">\(\kappa\)</span>为表面粗糙度的倒数（此值越大，越光滑），<span class="math inline">\(Y^m_{l}(\hat\omega)\)</span>表示球谐函数（m，l都表示了其阶）。不难从公式<span class="math inline">\(\eqref{sphere}\)</span>看出，积分近似后的球谐encoding实际上多了一个系数，此系数受到球谐阶（频率的指数）以及表面光滑程度（<span class="math inline">\(\kappa\)</span>）的影响。显然，<span class="math inline">\(\kappa\)</span>越小，对于高阶（频）球谐影响越大。这也就反映了这样一个事实：<u><strong>光滑程度</strong></u>减小，高低频信息均有所衰减，但<u><strong>高频信息</strong></u>衰减更严重。通过
<span class="math inline">\(\kappa\)</span>就能直接影响输出结果中镜面高光的强度（模糊性以及保留细节多少）。</p>
<p>​ 当然作者不仅仅给directional MLP提供了<span class="math inline">\(\hat{\omega_{r}}\)</span>，如公式 <span class="math inline">\(\eqref{phong}\)</span>所示第二项的<span class="math inline">\(l_i\cdot n\)</span>也被传入网络（<span class="math inline">\(d\cdot
n\)</span>，d为观察方向，n为法向量），这并不是要建模漫反射，而是考虑到一些稍微复杂一些的效应，如菲涅尔效应（并非全反射，部分反射部分折射，反射所占的比例需要另外计算）等等。</p>
<h3 id="法向量估计">2.3 法向量估计</h3>
<p>​ 作者使用volume density的梯度可以估计法向量，但作者说：</p>
<blockquote>
<ol type="1">
<li>normal vectors estimated from its volume density gradient as in
Equation 3 are often extremely noisy</li>
<li>NeRF tends to "fake" specular highlights by embedding emitters
inside the object and partially occluding them with a "foggy" diffuse
surface</li>
</ol>
</blockquote>
<p>​
确实，（1）很显然，已经有很多论文做这方面的工作了，不是添加正则化项就是采用一些表面重建技术获得好的表面。（2）的话通常也是由“集中性”正则化项解决的（只不过作者的想法不太一样）。</p>
<ul>
<li><p>问题（1）的解决（<strong><u>prediction
penalty</u></strong>）：通过spatial MLP预测某一点的法向量<span class="math inline">\(\hat{n}\)</span>，与梯度法向量<span class="math inline">\(n&#39;\)</span>求MSE： <span class="math display">\[
  \begin{equation}
  L_{n}=\sum_{i}w_i\Vert \hat{n}_i-n&#39;_i\Vert
  \end{equation}
  \]</span> 由于<span class="math inline">\(\hat{n}\)</span>相对比较光滑，而<span class="math inline">\(n&#39;\)</span>是对不光滑的density求的一阶导，就更不光滑了。用光滑数据帮助不光滑的梯度进行学习，可以起到对梯度的光滑作用。但为什么<span class="math inline">\(\hat{n}\)</span>比较光滑？这是作者说的，其实我比较纳闷，毕竟这玩意是学出来的。我的理解是：可以认为，此处需要网络也同时将<span class="math inline">\(n&#39;\)</span>学出来（利用<span class="math inline">\(n&#39;\)</span>作为监督）。但是网络的表示能力有限，特别是参数较少时，只能达到对<span class="math inline">\(n&#39;\)</span>低频部分的学习。</p></li>
<li><p>问题（2）的解决（<strong><u>orientation
loss</u></strong>）：作者设计了一个正则化项：此正则化惩罚反向法向量，也即“背面”。但也不是盲目对背面进行惩罚，毕竟volume
sampling过程中是可以在有效的背面进行采样的，故用下式： <span class="math display">\[
  \begin{equation}\label{reg}
  R_o=\sum_i{w_i\max(0,\hat{n}_i\cdot d)}
  \end{equation}
  \]</span> 其中 <span class="math inline">\(w_i\)</span>
为点weight值，<span class="math inline">\(d\)</span>为光线方向。此处也即惩罚
法向量与光线方向相同部分。并且与weight有关，这就说明：被遮挡的有效背面不会被影响（weight低），而fake
surface（在半透明surface后的embedded
emitter表面）将会被惩罚（其density衰减方向与光线方向一致）</p></li>
</ul>
<p>​
作者自己也解释了一下，为什么这两个loss结合在一起就work了：网络对于法向量的预测（<span class="math inline">\(\hat{n}\)</span>），与density梯度对应的法向量<span class="math inline">\(n&#39;\)</span>之间的关系大致有两种：</p>
<ul>
<li><span class="math inline">\(\hat{n}\)</span> 偏离 <span class="math inline">\(n&#39;\)</span>。那么此时，prediction
penalty较大，网络偏向于使得两者相等，则可以达到平滑梯度的目的。</li>
<li><span class="math inline">\(\hat{n}\)</span> 很接近 <span class="math inline">\(n&#39;\)</span>。那么此时，由于 <span class="math inline">\(\hat{n}\approx
n&#39;\)</span>，我们可以认为公式<span class="math inline">\(\eqref{reg}\)</span>作用在<span class="math inline">\(n&#39;\)</span>上。这也就达到了惩罚的目的。</li>
</ul>
<h3 id="扩展知识">2.4 扩展知识</h3>
<h4 id="一些物理概念">2.4.1 一些物理概念</h4>
<p>（1）能量，功率与辐射通量</p>
<p>​
能量的单位一般采用（J），而功率则是单位时间内的能量（J/s，定义为W），此概念与通量（flux）是同一个概念。与接收能量的面积没有关系。</p>
<p>（2）辐照度与辐出度</p>
<p>​
辐照度（irradiance）与辐射度（radiosity）是两个类似的概念，与面积有关。单位面积的通量（或者说，功率），单位是：<span class="math inline">\(W/m^2\)</span>。注意，此面积是光照的“正对面积”，也即需要进行投影处理。当表面法向量与光线入射（出射）方向垂直时，辐照度以及辐射度最大。当然，以上讨论仅限于面平行光源。对于点光源而言，其辐照（射）度与距离的关系遵循平方反比定律（距离越远，辐照（射）度越低）。</p>
<p>（3）立体角与辐射强度（intensity）</p>
<p>​ 立体角表达的物理意义是：1立体角对应在单位球上截取的大小为<span class="math inline">\(r^2\)</span>，其中<span class="math inline">\(r\)</span>为球的半径。也即： <span class="math display">\[
\begin{equation}
\Omega = \frac{A_{sr}}{r^2}{\text{sr}}
\end{equation}
\]</span> ​ <span class="math inline">\(\text{sr}\)</span>是单位，而不是变量或常量。其中<span class="math inline">\(A_{sr}\)</span>则是对应大小的球面切片面积。有了立体角之后，可以使用立体角
+ 3D点 +
3D方向来描述任意光线。光线从给定的3D点出射，方向是给定的3D方向，<u><strong>光锥的形状</strong></u>由立体角确定。通过单位立体角的辐射功率（通量）称为辐射强度，单位是<span class="math inline">\(W/\text{sr}\)</span>。辐射强度描述的是光源的属性，而非空间中某一点受光照的特性。故给定某一光源，不考虑空间中的其他因素的影响，空间中任意一点的辐射照度都是一样的。</p>
<p>（4）辐射率（radiance）</p>
<p>​
搞NeRF也有一段时间了，还没有搞清楚radiance的意义。此前只是将radiance当作是观察到的物体的颜色，而现在这里将对辐射率的物理含义进行介绍。上文已经介绍了辐射强度的概念，并且可知，辐射强度与空间特性无关，只与光源有关，而我们又希望获得某一光源在空间中某一位置可产生的影响。则定义辐射率：单位时间、单位面积、单位立体角通过的光能。也即单位面积、单位立体角的功率。单位是：<span class="math inline">\(W(m^2
\text{sr})^{-1}\)</span>。光源辐照能力改变（如灯光的亮暗），反映于功率变化（<span class="math inline">\(W\)</span>）。而光源的“能量聚集度”（可以想象一个可以调焦的手电筒）反映在辐射强度上（影响单位为
<span class="math inline">\(\text{sr}\)</span>
的项）。物体距离光源的远近则反映在面积项上（平方反比）。这也恰好与成像结果直接相关，故可以将radiance理解为空间中一点成像的结果（如RGB值）。</p>
<h4 id="光场">2.4.2 光场</h4>
<p>​ 四维光场是否只是一个近似？四维光场认为，在empty
space内部，radiance（也就是产生的RGB值）是恒定的。也就是说，无论我从此光线上的哪一点开始积分，最后得到的RGB值都是一样的，此RGB值与光线上的积分距离（或是深度）无关。那么这样可以从五维的光场建模中，去掉一个维度，实际则为四维的。个人更愿意将“四维”理解为一个五维空间中的四维流形，因为此深度维度并非五维度基中之一，也不能用其线性组合描述。理解了四维光场的由来，我们回头检查一下假设：<strong><u>空域内部radiance为常数</u></strong>。正常情况下：无半透明物体或者介质，这是成立的。引入半透明物体与介质后（比如混浊溶液，胶体，雾），个人认为此假设不成立，那么表四光场还是应该使用五维函数。</p>
<h3 id="球谐函数的使用">2.5 球谐函数的使用</h3>
<p>​
打开维基百科，查之。woc，我看到了什么。总之很复杂了，本人本科所学的数学知识不够用（或者说是遗忘了）。关于球谐函数本身的理解，个人的看法是：类似于傅里叶变换，展开成基函数的线性组合（这些基函数独立分析时其实形式较为简单，但组合起来就能表示非常丰富的内容），并且不像泰勒展开（泰勒展开的物理意义不甚好理解），球谐函数有<strong><u>频率</u></strong>概念，并且三维空间中的球谐函数仍然很好理解，非常具有物理直观性。如果想要知道如何初步理解，这里推荐<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/351289217">【知乎：球谐函数介绍（Spherical
Harmonics）】</a>，我就不赘述了。下面只给出结论，实球谐函数的形式如下：
<span class="math display">\[
\begin{equation}\label{real_sh}
Y_{lm}(\theta,\phi)=\begin{cases}
(-1)^m\sqrt{2\frac{(2l+1)}{4\pi}\frac{(l-|m|)!}{(l+|m|)!}}P_l^{|m|}(\cos\theta)\sin(|m|\phi),
\text{ if }m &lt;0\\
\sqrt{\frac{2l+1}{4\pi}}P_l^m(\cos\theta),\text{ if }m=0\\
(-1)^m\sqrt{2\frac{(2l+1)}{4\pi}\frac{(l-m)!}{(l+m)!}}P_l^{m}(\cos\theta)\cos(m\phi),
\text{ if }m &gt;0\\
\end{cases}
\end{equation}
\]</span> ​ 其中，<span class="math inline">\(\phi,\theta\)</span>是方位角（azimuthal
angles），<span class="math inline">\(l,m\)</span>为此球谐函数的阶？（此处实际上涉及到一个微分方程求解问题，此二变量与解的个数有关）。另外，比较令人疑惑的是
<span class="math inline">\(P^{|m|}_l\)</span>，这实际上代表的是伴随勒让德多项式（associated
Legendre polynomials）。这里，<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Associated_Legendre_polynomials">Wikipedia</a>会告诉你勒让德多项式的奇妙性质，但是我不关心（说实在的，一开始看到这样的公式我还在想应该如何高效实现这么多微分）。这里直接给出维基上写的闭式公式：
<span class="math display">\[
\begin{equation}\label{legendre}
P^m_l(x)=(-1)^m\cdot2^l\cdot(1-x^2)^{m/2}\sum^l_{k=m}\frac{k!}{(k-m)!}\cdot
x^{k-m}\cdot \pmatrix{l\\k} \pmatrix{\frac{l+k-1}{2}\\l}
\end{equation}
\]</span> ​
此公式的代码实现就简单多了，我们只需要关心最后的求和项。求和项中涉及到求组合数，可以选择使用lookup
table，预先计算一个大小为 <span class="math inline">\(2^L\cdot
2^L\)</span>的矩阵（L应该不会很大）。那么： <span class="math display">\[
\begin{equation}
\frac{k!}{(k-m)!}\cdot x^{k-m}
\end{equation}
\]</span> ​
应该如何计算？能不用for循环就不用for循环（多用GPU操作！！）。观察容易知道：求和项中的首项是<span class="math inline">\(m!x^0\)</span>，此后每一项与前一项的关系是： <span class="math display">\[
\begin{equation}
T_{k+1}=T_{k}\cdot x\cdot \frac{k+1}{k+1-m}
\end{equation}
\]</span> ​ 故我们应该有这样的一个张量（一行，<span class="math inline">\(l-m\)</span>列）：第一列是 <span class="math inline">\(m!\)</span>，此后所有列是：<span class="math inline">\([\frac{m+1}{1}x,\frac{m+2}{2}x,\frac{m+3}{3}x,...,\frac{l}{l-m}x]\)</span>。那么实现就是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># device 某个传入函数的张量t的t.device</span></span><br><span class="line">rare = (torch.arange(m+<span class="number">1</span>,l+<span class="number">1</span>, device = device) / torch.arange(<span class="number">1</span>,l-m+<span class="number">1</span>, device = device)).unsqueeze(<span class="number">0</span>) * x</span><br><span class="line">whole = torch.cat([torch.ones(<span class="number">1</span>, <span class="number">1</span>, device = device) * m_factorial, rare], dim = -<span class="number">1</span>)</span><br><span class="line">whole_prod = torch.cumprod(whole, dim = -<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>​ 此后，根据lookup或者在线求解公式<span class="math inline">\(\eqref{legendre}\)</span>中的组合数，就能求得求和式中的每一项，进而也就求出了整个多项式。但这只是针对
<span class="math inline">\({m,l}\)</span>求出了结果，而 <span class="math inline">\(m,l\)</span>
如何进行并行计算我就不懂了。不过其实也没必要懂：</p>
<ul>
<li>NeRF的positional encoding，不同的相位（<span class="math inline">\(\sin,\cos\)</span>）以及不同的频率是串行计算最后concatenate的</li>
<li>大可以自定义CUDA算子，写一个forward再写一个backward函数。forward好写而backward不好写罢了（这玩意显然是有闭式解的，推起来比较麻烦），故CUDA自定义算子：全并行但费脑子（哈，而且还不一定有pytorch快，例如之前我用thrust的sort库对比pytorch的张量sort，前者就比后者慢），pytorch实现弱并行，但不费脑子。</li>
</ul>
<p>​
球谐函数的使用也说明了，我们在处理<strong><u>方向</u></strong>时，需要将三维的方向转化为二维的方向角（才能喂给球谐函数，当然，球谐函数确实有笛卡尔坐标系表示，但这不是我们的讨论范畴）。下面，笔者简单讨论一下文中球谐函数在vMF分布下的期望求解（论文附录部分）。作者要证明：
<span class="math display">\[
\begin{equation}
\mathbb{E}_{\hat \omega\sim
\text{vMF}({\hat\omega_r,\kappa})}[Y_l^m(\hat\omega)]=
A_l(\kappa)Y_l^m(\hat\omega_r)
\end{equation}
\]</span> ​ 我们只讨论上式中<span class="math inline">\(A_l(\kappa)\)</span>怎么来的，而<strong><u>不关心</u></strong>（所以在这不推导）<span class="math inline">\(A_l(\kappa)\)</span>如何近似为那个只与<span class="math inline">\(l,\kappa\)</span>有关的指数形式（近似的推导部分，但凡有点耐心。。。emmm）。首先，作者把积分空间进行了线性变换：进行了旋转。将
<span class="math inline">\(\hat\omega_r\)</span>旋转至z轴，那么根据vMF分布的形式以及随机变量函数的期望的计算：
<span class="math display">\[
\begin{align}
&amp;P_{\text{vMF}({\hat\omega_r,\kappa})}(\omega)=c(\kappa)\exp(\kappa\hat\omega_r^T\omega)\\
&amp;\mathbb{E}_{\hat \omega\sim
\text{vMF}({\hat\omega_r,\kappa})}[Y_l^m(\hat\omega)]=
c(\kappa)\int_S Y_l^m(\omega)
\exp(\kappa\hat\omega_r^T\omega)d\omega\label{expect}
\end{align}
\]</span> ​ 则将 <span class="math inline">\(\omega&#39;=R\omega\)</span>中，可以得到： <span class="math display">\[
\begin{align}
\mathbb{E}_{\hat \omega\sim
\text{vMF}({\hat\omega_r,\kappa})}[Y_l^m(\hat\omega)]&amp;=
c(\kappa)\int_S Y_l^m(R^{-1}\omega&#39;) \exp(\kappa
(R^{-1}z)^TR^{-1}\omega&#39;)dR^{-1}\omega&#39; \label{ints}\\
&amp;=c(\kappa)\int_S Y_l^m(R^{-1}\omega&#39;) \exp(\kappa
z^T\omega&#39;)dR^{-1}\omega&#39; \label{intm}\\
&amp;=c(\kappa)\int_S Y_l^m(R^{-1}\omega&#39;) \exp(\kappa
\cos\theta)d\omega&#39; \label{inte}
\end{align}
\]</span> ​ 从公式<span class="math inline">\(\eqref{ints}\)</span>到<span class="math inline">\(\eqref{intm}\)</span>很好理解，旋转向量的的正交性可以立刻抵消exp中的R。而公式<span class="math inline">\(\eqref{intm}\)</span>到<span class="math inline">\(\eqref{inte}\)</span>则稍微有点绕：</p>
<ul>
<li><span class="math inline">\(z^T\omega&#39;\)</span>恰好是 <span class="math inline">\(\omega&#39;\)</span> 的方位角（中的俯仰角<span class="math inline">\(\theta\)</span>）</li>
<li><span class="math inline">\(dR^{-1}\omega&#39;\)</span>中的 <span class="math inline">\(R^{-1}\)</span>原先需要被提出来，但由于其行列式为1（旋转矩阵嘛），不会影响最后函数输出的单个值的结果（注意，对于每一个<span class="math inline">\(m, l\)</span>而言，公式<span class="math inline">\(\eqref{ints}\)</span>的输出都是一个值），故可以省略</li>
</ul>
<p>​ 此后，根据球谐函数的性质（比如展开为Wigner D
Matrix表示以及其正交性），我们最后可以将公式<span class="math inline">\(\eqref{ints}\)</span>左边写为： <span class="math display">\[
\begin{equation}
\mathbb{E}_{\hat \omega\sim
\text{vMF}({\hat\omega_r,\kappa})}[Y_l^m(\hat\omega)]=
c(\kappa)D^{(l)}_{m0}(\hat{\omega}_r)\int_{S^2}Y_{l}^0(\hat{\omega})e^{\kappa\cos\theta}
d\hat{\omega}\label{origin}
\end{equation}
\]</span> ​ 其中：<span class="math inline">\(D^{(l)}_{m0}(\hat{\omega}_r)\)</span>以及<span class="math inline">\(Y_{l}^0(\hat{\omega})\)</span>的形式都是已知的，这里不在赘述了（确实很麻烦）。我们只将上式的积分部分进行拆解。由于积分实际上是在球面上完成的，这里实际进行了一次二重积分（球面积分），将笛卡尔坐标系转化为球面的天顶角：<span class="math inline">\((x, y, z)\rightarrow(\theta,\phi
)\)</span>，这里给出一张图：</p>
<center>
<img src="/2022/08/13/Mip-NeRF-Ref-NeRF/zenith.jpg" style="zoom:50%;">
</center>
<center>
Figure 2. Ref NeRF半球积分示意图
</center>
<p>​
图中的黑色圆圈就是“积分对象”：可以看做球体的上半球表面是由无数个圆环组成的，对应了角度为<span class="math inline">\(\theta\)</span>（确定了位置），半径为<span class="math inline">\(\sin
\theta\)</span>（确定了形状）的圆圈（可知<span class="math inline">\(\phi\)</span>的积分范围是<span class="math inline">\(-\pi\rightarrow\pi\)</span>）：故积分可以拆成（首先知道<span class="math inline">\(Y_l^0(\hat{\omega})=P_l(\cos\theta)\)</span>）:
<span class="math display">\[
\begin{equation}
\int_{S^2}Y_{l}^0(\hat{\omega})e^{\kappa\cos\theta}
d\hat{\omega}=\int_{-\pi}^{\pi}\int_{0}^{\pi}P_l(\cos\theta)e^{\kappa\cos\theta}\sin\theta
d\theta d\phi
\end{equation}
\]</span> ​ <span class="math inline">\(\theta\)</span>的范围是<span class="math inline">\([0,
\pi]\)</span>，这是因为我们只需要积分上半球。由于反射不可能发生在下半球，可知下半球<span class="math inline">\([-\pi,0]\)</span>的所有输出都是0。这样，根据论文中所说的步骤，进一步替换积分变量，展开并简化可以推出IDE公式。</p>
<p>​ 但是，选择实函数形式的球谐并不是一个很好的选择。首先，公式<span class="math inline">\(\eqref{real_sh}\)</span>已经展示了实函数形式的复杂性（主要是有分支）；此外，我们需要考虑到，角度形式的SH需要把方向向量转化为天顶角，这种额外的操作看着就很不优雅。建议使用笛卡尔坐标系形式的球谐函数。参见<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Spherical_harmonics#Separated_Cartesian_form">Wikipedia/Shperical
Harmonics - Separated Cartesian
form</a>，可刺激了，虚函数运算与二项式公式的结合哦。不过只要使用这种方法实现，利用Pytorch就很简单：</p>
<ul>
<li>首先Pytorch支持虚数运算。这里吐槽一下，Pytorch支持的虚数运算基于<code>torch.complex64</code>类型，一看到<code>64</code>就知道怎么回事了，运算量可能等同于float32运算（两个float32存在一块），在使用auto
mixed
precision时，complex32将可能产生一系列的问题，很多算子都没有对complex32有支持。而假设我们使用APEX库的O2等级优化，所有的float32都会变成float16，那么这里参与运算的复数就会产生一系列未定义算子的问题。（什么ComplexHalf未定义这些算子啊之类的报错）</li>
<li>SH在这就是用作encoding，所以其实只需要将结果的实部、虚部取出来作为encoding的成分就好了。可以认为，原来的positional
encoding是用了正交相位的两种基底进行表示，而SH其实也是正交的两种基底（实与虚在虚平面上是正交的）进行表示。</li>
</ul>
<hr>
<h2 id="iii.-复现细节">III. 复现细节</h2>
<h3 id="值得一提的点">3.1 值得一提的点</h3>
<p><img src="/2022/08/13/Mip-NeRF-Ref-NeRF/network.png" style="zoom:50%;"></p>
<center>
Figure 3. Ref-NeRF网络结构
</center>
<p>​ 其实，没什么好说的。根据Ref NeRF论文图，复现的内容如下：</p>
<div class="note info"><p>​ 首先修改spatial network，在spatia
network之后追加三个head。三个head的输入就是spatial network的输出：</p>
<ul>
<li><p>opacity &amp; roughness head:
由于τ（density）与ρ（roughness）都是没有输出范围限制的（但是都需要大于0，故ρ之后与τ类似，单独处理即可）。注意roughness与opacity都需要经过bias之后再通过softplus激活（软ReLU）</p></li>
<li><p>color &amp; tint head: <span class="math inline">\(c_d,s\)</span>都是[0, 1]
之间的值，故输出直接变6维。color与tint都使用sigmoid进行激活，不过bias不同。</p></li>
<li><p>normal
head：预测法向量，三维，需要进行normalize，不需要任何激活</p></li>
</ul>
</div>
<div class="note success"><p>​ 需要绕一下的部分是法向量。法向量的来源有两个：（1）spatial
network计算的density，可以对位置求导。Pytorch中，要实现对位置求导需要使得输入的位置向量可导：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">fine_pos.requires_grad = <span class="literal">True</span>										    <span class="comment"># 此步必要	</span></span><br><span class="line">fine_rgbo, pred_normal = mip_net.forward(fine_pos, fine_dir)</span><br><span class="line">r_num, p_num, _ = fine_rgbo.shape</span><br><span class="line">density_grad, = torch.autograd.grad(fine_rgbo[..., -<span class="number">1</span>], fine_pos, 			  <span class="comment"># fine_pos 是可优化的</span></span><br><span class="line">       torch.ones(r_num, p_num, device = fine_rgbo.device), retain_graph = <span class="literal">True</span> <span class="comment"># retain graph使得计算图可以继续backward</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>​ 另一个来源就是spatial network之后的normal
head，预测。预测的结果在经过正则化（orientation
loss）以及预测误差（与density
grad的差别）backward之后，应当可以学出较好的结果。</p>
</div>
<p>​ 此外注意，directional network变深了。可以认为directional
network有spatial network一样的结构（包括8层256 hidden
units的MLP，并且有skip connection）。</p>
<h3 id="一些坑">3.2 一些坑</h3>
<p>​ 由于笔者复现Ref NeRF基于之前实现的<a target="_blank" rel="noopener" href="https://github.com/Enigmatisms/NeRF">Enigmatisms/NeRF</a>，这个repo中实现的NeRF并非原始NeRF，而是mip
NeRF 360（部分），主要包含这样的特性：</p>
<ul>
<li>本repo实现了mip NeRF 360中的proposal network
distillation。也即：coarse-to-fine的stratified
sampling并没有使用。stratified sampling非常慢（由于coarse
network需要forward所有点，fine network也要forward），proposal
network则是用浅MLP（5层），forward点后直接输出预测的density，再利用fine
network输出的density（weight）进行监督。这样就能完成从fine
network到proposal network的蒸馏。此蒸馏的实现较为复杂（weight
bound的计算），这里不赘述。我也不想单开一篇博客讨论。</li>
<li>使用了自动混合精度（amp），可以选用apex或者torch.native_scaler</li>
</ul>
<p>​ proposal
network着实坑了我一把。复现完成（第一版）之后，跑了一下shinny
blender的ball数据集：</p>
<p><img src="/2022/08/13/Mip-NeRF-Ref-NeRF/false_ball_2.png" style="zoom: 67%;"></p>
<center>
Figure 4. 为什么那么多噪点？
</center>
<p>​
如上图第一列：很多噪点。这些噪点是什么？一开始我也不敢下结论，毕竟不知道是不是自己的ref
nerf复现有问题。于是我将深度以及normal都可视化了出来（后两列）。可见，深度图中也存在很多空洞，normal就不说了吧（事实上，normal学习一直有问题，normal本身就比较难学）。空洞产生的可能原因有两个：</p>
<ul>
<li>density学习有问题，有些位置density非常低</li>
<li>采样（不管是训练还是测试时）位置不对，采样在了一些空的位置</li>
</ul>
<p>​ 于是我开了一个新的分支，在此分支上我将proposal
network删掉了，使用原始NeRF的coarse-to-fine框架进行测试。对比图如下图所示：左边为原始proposal
network存在时，训练60轮之后的结果，而右边则为原始NeRF训练40轮之后的结果。可以看出，原始NeRF框架下的采样是（至少相对上是）没问题的。但笔者并不想放弃proposal
network（个人觉得这个方法比较优雅），故笔者将proposal
network进行了小的改动：</p>
<!-- tab 原始Proposal Network -->
<p>​ 原始prop net输入coarse points之后，输出density，此后coarse
points将会被弃用。根据density计算的weight，将指导inverse sampling，fine
network的输入只为inverse
sampling的结果（也就是说，集中在weight高的地方）。假设，prop
net计算的density有缺陷，也即weight有缺陷，在实际的表面附近weight很小，在空域中weight大，那么inverse
sampling可能无法在此条光线上采到有效的点。</p>
<!-- endtab -->
<!-- tab 修改后的Proposal Network -->
<p>​ 很简单，就是复用coarse points，将coarse
depths（采样的长度）与inverse sampling的采样长度（fine
depths）进行拼接，排序。但其实在实现中，要考虑proposal network的weight
bound计算。啊，这一步很复杂。可以这么说：</p>
<ul>
<li>proposal
network需要预测每一个采样点（fine采样点）的weight上界（weight
bound）。上界如何计算？两个fine采样点之间会存在一个采样区间，此区间将会与coarse采样的区间重合，则此fine采样区间的weight上界应该是所有与之有交集的coarse区间weight之和。</li>
<li>coarse points合并到fine
points相当于修改了fine采样区间。那么就需要计算更多区间交集。这里我不赘述方法，详见：<a target="_blank" rel="noopener" href="https://github.com/Enigmatisms/NeRF/blob/635509b005a3272a0cddeac60a7aeac9432dddd1/py/nerf_base.py#L53">NeRF/coarseFineMerge</a>以及<a target="_blank" rel="noopener" href="https://github.com/Enigmatisms/NeRF/blob/635509b005a3272a0cddeac60a7aeac9432dddd1/py/addtional.py#L15">NeRF/getBounds</a></li>
</ul>
<!-- endtab -->
<p>​
这样修改，也就使得每条光线上，既有均匀采样的部分（保证了coverage），又使得density大的部分可以有更多采样点。可能有人觉得，不就是增加了一些采样点吗？这样为什么能保证proposal
network的学习是正确的呢？很简单，网络不仅有更加充足的输入，fine
network提供给proposal network的监督也更加充足了（见【修改后的Proposal
Network】部分，其中我们说到“更多的区间交集”）。</p>
<p><img src="/2022/08/13/Mip-NeRF-Ref-NeRF/result_001.png" style="zoom:67%;"></p>
<center>
Figure 5. shinny blender helmet数据集，训练20轮
</center>
<table>
<colgroup>
<col style="width: 52%">
<col style="width: 47%">
</colgroup>
<thead>
<tr>
<th style="text-align: center;">无proposal net 训练40轮（4k次）</th>
<th style="text-align: center;">有proposal net 训练60轮（6k次）</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><img src="/2022/08/13/Mip-NeRF-Ref-NeRF/no_prop_002.png"></td>
<td style="text-align: center;"><img src="/2022/08/13/Mip-NeRF-Ref-NeRF/prop_003.png"></td>
</tr>
</tbody>
</table>
<p>​
修改后的方法，只训练20轮输出后的结果就让我觉得肯定是改对了，如上图所示。接下来将展示【未完成训练】时的训练结果。由于原始Ref
NeRF使用<span class="math inline">\(2^{14}\)</span>大小的batch，需要训练250k轮。我设备能力有限，只batch大小为<span class="math inline">\(2^9\)</span>（差了32倍），也没训练到250k就先暂停了（笑死，我的3060
for
laptop，有个风扇坏了，训练的时候能飙到83度，所以我得开一台电风扇对着我电脑吹）。下面是简单的结果展示：</p>
<p><img src="/2022/08/13/Mip-NeRF-Ref-NeRF/curves.png"></p>
<center>
Figure 6. 训练不是一次完成的，保存checkpoint短点续训。收敛性并不好
</center>
<p>​
从上图看出，虽然训练应该远没有结束（这才不到7小时），PSNR曲线的上升能力属实堪忧。笔者感觉PSNR无法上升至论文中的29，个人认为可能的问题仍然是出在proposal
network上。目前正在尝试一种改进的方法。</p>
<p><img src="/2022/08/13/Mip-NeRF-Ref-NeRF/Screenshot%20from%202022-08-19%2013-31-01.png"></p>
<center>
Figure 7. 有趣的手动退火
</center>
<p>​
效果大概就是这样（如下图所示）。从左到右分别是：RGB，深度与法向量。emm，法向量大概是可视化错了。不过学的应该也有一些问题，在某些视角能看到头盔上的条纹对应的法向量与其他位置不一致。PSNR为19，还是太模糊了一点。</p>
<p><img src="/2022/08/13/Mip-NeRF-Ref-NeRF/ezgif-1-8207b1faa2.gif"></p>
<center>
Figure 8. 旋转头盔
</center>
<hr>
<h2 id="reference">Reference</h2>
<ul>
<li><p>https://en.wikipedia.org/wiki/Spherical_harmonics</p></li>
<li><p>https://en.wikipedia.org/wiki/Associated_Legendre_polynomials</p></li>
<li><p>扩展阅读: https://dellaert.github.io/NeRF22/</p></li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>Post author:  </strong>Enigmatisms
  </li>
  <li class="post-copyright-link">
      <strong>Post link: </strong>
      <a href="https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/" title="Ref NeRF复现">https://enigmatisms.github.io/2022/08/13/Mip-NeRF-Ref-NeRF/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/knowings/" rel="tag"><i class="fa fa-tag"></i> knowings</a>
              <a href="/tags/DL/" rel="tag"><i class="fa fa-tag"></i> DL</a>
              <a href="/tags/NeRF/" rel="tag"><i class="fa fa-tag"></i> NeRF</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/08/09/Rust-CUDA%E6%B7%B7%E5%90%88%E7%BC%96%E7%A8%8B/" rel="prev" title="Rust CUDA混合编程">
                  <i class="fa fa-chevron-left"></i> Rust CUDA混合编程
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/08/20/Rust-C-%E5%B0%8F%E8%AE%B0%E5%BD%95/" rel="next" title="Rust C++小记录">
                  Rust C++小记录 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.5/lib/darkmode-js.min.js"></script>
<script>
new Darkmode({
saveInCookies: true, // default: true,
label: '🌓', // default: ''
autoMatchOsTheme: true // default: true
})
.showWidget();
</script>

<div class="copyright">
  &copy; 2021.1 – 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-anchor"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Enigmatisms</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="Symbols count total">475k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">7:12</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <script src='https://unpkg.com/mermaid@/dist/mermaid.min.js'></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({theme: 'forest'});
    }
  </script>

    </div>
  </footer>

  
  <script size="256" alpha="0.3" zIndex="-1" src="https://cdn.jsdelivr.net/npm/ribbon.js@1.0.2/dist/ribbon.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdn.jsdelivr.net/npm/pdfobject@2.2.7/pdfobject.min.js","integrity":"sha256-ph3Dk89VmuTVXG6x/RDzk53SU9LPdAh1tpv0UvnDZ2I="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":"forest","js":{"url":"https://cdn.jsdelivr.net/npm/mermaid@8.13.10/dist/mermaid.min.js","integrity":"sha256-CmZCFVnvol9YL23PfjDflGY5nJwE+Mf/JN+8v+tD/34="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>


  <script src="/js/third-party/pace.js"></script>

  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"Enigmatisms/Enigmatisms.github.io","issue_term":"pathname","theme":"github-light"}</script>
<script src="/js/third-party/comments/utterances.js"></script>

</body>
</html>
